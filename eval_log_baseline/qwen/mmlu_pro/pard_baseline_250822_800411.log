Baseline API server started with PID: 165. Waiting...
Waiting for server to be ready at http://127.0.0.1:8004/v1/qwen/chat/completions...........................................Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Initializing baseline models...
Loading Qwen model: Qwen/Qwen2.5-7B-Instruct
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.41it/s].Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  3.41it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  3.36it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.94it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]
.............................................................................................................The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
.Loading Dream model: Dream-org/Dream-v0-Instruct-7B
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  2.47it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.78it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.79it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.83it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]
/opt/conda/envs/kjl_dllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/opt/conda/envs/kjl_dllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
.............................................................................................................INFO:     Started server process [165]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)
All baseline models initialized.
INFO:     127.0.0.1:43858 - "GET /v1/qwen/chat/completions HTTP/1.1" 405 Method Not Allowed
2025-08-22:18:34:01,182 INFO     [__main__:379] Selected Tasks: ['mmlu_pro']
2025-08-22:18:34:01,272 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-08-22:18:34:01,272 INFO     [lm_eval.evaluator:206] Initializing local-chat-completions model, with arguments: {'base_url': 'http://127.0.0.1:8004/v1/qwen/chat/completions', 'model': 'Qwen/Qwen2.5-7B-Instruct', 'eos_string': "'<|im_end|>'", 'truncate': True}
2025-08-22:18:34:01,272 WARNING  [lm_eval.models.openai_completions:116] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-08-22:18:34:01,272 INFO     [lm_eval.models.api_models:115] Using max length 2048 - 1
2025-08-22:18:34:01,272 INFO     [lm_eval.models.api_models:118] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-08-22:18:34:01,272 INFO     [lm_eval.models.api_models:133] Using tokenizer None
2025-08-22:18:34:28,652 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_biology from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_business from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_chemistry from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_computer_science from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_economics from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_engineering from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_health from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_history from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_law from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_math from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_other from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_philosophy from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_physics from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:275] Overwriting default num_fewshot of mmlu_pro_psychology from 5 to 5
2025-08-22:18:34:28,653 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-08-22:18:34:28,655 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_biology on rank 0...
  0%|          | 0/717 [00:00<?, ?it/s] 14%|█▍        | 99/717 [00:00<00:00, 983.75it/s] 28%|██▊       | 199/717 [00:00<00:00, 989.18it/s] 42%|████▏     | 303/717 [00:00<00:00, 1009.28it/s] 57%|█████▋    | 407/717 [00:00<00:00, 1018.82it/s] 71%|███████   | 509/717 [00:00<00:00, 1016.09it/s] 85%|████████▌ | 611/717 [00:00<00:00, 1017.27it/s] 99%|█████████▉| 713/717 [00:00<00:00, 1015.66it/s]100%|██████████| 717/717 [00:00<00:00, 1011.98it/s]
2025-08-22:18:34:29,424 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_business on rank 0...
  0%|          | 0/789 [00:00<?, ?it/s] 13%|█▎        | 102/789 [00:00<00:00, 1019.01it/s] 26%|██▌       | 206/789 [00:00<00:00, 1028.12it/s] 39%|███▉      | 309/789 [00:00<00:00, 1021.59it/s] 52%|█████▏    | 413/789 [00:00<00:00, 1028.25it/s] 66%|██████▌   | 517/789 [00:00<00:00, 1031.51it/s] 79%|███████▊  | 621/789 [00:00<00:00, 1010.25it/s] 92%|█████████▏| 723/789 [00:00<00:00, 1001.52it/s]100%|██████████| 789/789 [00:00<00:00, 1015.22it/s]
2025-08-22:18:34:30,265 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_chemistry on rank 0...
  0%|          | 0/1132 [00:00<?, ?it/s]  9%|▉         | 104/1132 [00:00<00:00, 1031.58it/s] 18%|█▊        | 208/1132 [00:00<00:00, 1033.00it/s] 28%|██▊       | 312/1132 [00:00<00:00, 1013.04it/s] 37%|███▋      | 415/1132 [00:00<00:00, 1016.22it/s] 46%|████▌     | 517/1132 [00:00<00:00, 1010.58it/s] 55%|█████▍    | 620/1132 [00:00<00:00, 1016.87it/s] 64%|██████▍   | 722/1132 [00:00<00:00, 1017.86it/s] 73%|███████▎  | 824/1132 [00:00<00:00, 1009.95it/s] 82%|████████▏ | 926/1132 [00:00<00:00, 1011.46it/s] 91%|█████████ | 1029/1132 [00:01<00:00, 1015.04it/s]100%|██████████| 1132/1132 [00:01<00:00, 1018.05it/s]100%|██████████| 1132/1132 [00:01<00:00, 1016.30it/s]
2025-08-22:18:34:31,469 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_computer_science on rank 0...
  0%|          | 0/410 [00:00<?, ?it/s] 24%|██▍       | 100/410 [00:00<00:00, 995.18it/s] 49%|████▉     | 202/410 [00:00<00:00, 1005.36it/s] 74%|███████▍  | 304/410 [00:00<00:00, 1009.68it/s] 99%|█████████▉| 405/410 [00:00<00:00, 993.99it/s] 100%|██████████| 410/410 [00:00<00:00, 997.91it/s]
2025-08-22:18:34:31,930 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_economics on rank 0...
  0%|          | 0/844 [00:00<?, ?it/s] 12%|█▏        | 102/844 [00:00<00:00, 1013.32it/s] 24%|██▍       | 204/844 [00:00<00:00, 1001.73it/s] 36%|███▌      | 305/844 [00:00<00:00, 1003.13it/s] 48%|████▊     | 407/844 [00:00<00:00, 1006.52it/s] 60%|██████    | 509/844 [00:00<00:00, 1010.66it/s] 72%|███████▏  | 611/844 [00:00<00:00, 1010.71it/s] 85%|████████▍ | 714/844 [00:00<00:00, 1014.05it/s] 97%|█████████▋| 817/844 [00:00<00:00, 1016.23it/s]100%|██████████| 844/844 [00:00<00:00, 1011.74it/s]
2025-08-22:18:34:32,832 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_engineering on rank 0...
  0%|          | 0/969 [00:00<?, ?it/s] 11%|█         | 104/969 [00:00<00:00, 1029.66it/s] 21%|██▏       | 208/969 [00:00<00:00, 1029.97it/s] 32%|███▏      | 311/969 [00:00<00:00, 1029.44it/s] 43%|████▎     | 415/969 [00:00<00:00, 1032.22it/s] 54%|█████▎    | 519/969 [00:00<00:00, 1034.89it/s] 64%|██████▍   | 624/969 [00:00<00:00, 1037.63it/s] 75%|███████▌  | 729/969 [00:00<00:00, 1038.94it/s] 86%|████████▌ | 833/969 [00:00<00:00, 1037.72it/s] 97%|█████████▋| 937/969 [00:00<00:00, 1032.80it/s]100%|██████████| 969/969 [00:00<00:00, 1034.04it/s]
2025-08-22:18:34:33,852 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_health on rank 0...
  0%|          | 0/818 [00:00<?, ?it/s] 13%|█▎        | 103/818 [00:00<00:00, 1023.36it/s] 25%|██▌       | 207/818 [00:00<00:00, 1029.60it/s] 38%|███▊      | 312/818 [00:00<00:00, 1034.70it/s] 51%|█████     | 416/818 [00:00<00:00, 1026.57it/s] 64%|██████▎   | 520/818 [00:00<00:00, 1029.14it/s] 76%|███████▌  | 623/818 [00:00<00:00, 1026.97it/s] 89%|████████▉ | 726/818 [00:00<00:00, 1025.17it/s]100%|██████████| 818/818 [00:00<00:00, 1026.46it/s]
2025-08-22:18:34:34,717 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_history on rank 0...
  0%|          | 0/381 [00:00<?, ?it/s] 25%|██▍       | 94/381 [00:00<00:00, 935.89it/s] 51%|█████     | 193/381 [00:00<00:00, 966.50it/s] 77%|███████▋  | 292/381 [00:00<00:00, 974.87it/s]100%|██████████| 381/381 [00:00<00:00, 972.42it/s]
2025-08-22:18:34:35,146 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_law on rank 0...
  0%|          | 0/1101 [00:00<?, ?it/s]  9%|▉         | 100/1101 [00:00<00:01, 999.06it/s] 18%|█▊        | 202/1101 [00:00<00:00, 1006.98it/s] 28%|██▊       | 303/1101 [00:00<00:00, 1005.77it/s] 37%|███▋      | 404/1101 [00:00<00:00, 1007.19it/s] 46%|████▌     | 506/1101 [00:00<00:00, 1010.42it/s] 55%|█████▌    | 608/1101 [00:00<00:00, 1006.54it/s] 64%|██████▍   | 710/1101 [00:00<00:00, 1010.32it/s] 74%|███████▍  | 812/1101 [00:00<00:00, 1009.03it/s] 83%|████████▎ | 913/1101 [00:00<00:00, 1007.97it/s] 92%|█████████▏| 1014/1101 [00:01<00:00, 1006.01it/s]100%|██████████| 1101/1101 [00:01<00:00, 1007.22it/s]
2025-08-22:18:34:36,337 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_math on rank 0...
  0%|          | 0/1351 [00:00<?, ?it/s]  7%|▋         | 99/1351 [00:00<00:01, 984.80it/s] 15%|█▍        | 198/1351 [00:00<00:01, 924.43it/s] 22%|██▏       | 300/1351 [00:00<00:01, 962.31it/s] 30%|██▉       | 401/1351 [00:00<00:00, 978.69it/s] 37%|███▋      | 501/1351 [00:00<00:00, 985.35it/s] 45%|████▍     | 603/1351 [00:00<00:00, 994.75it/s] 52%|█████▏    | 703/1351 [00:00<00:01, 602.07it/s] 59%|█████▉    | 803/1351 [00:01<00:00, 687.93it/s] 67%|██████▋   | 901/1351 [00:01<00:00, 756.24it/s] 74%|███████▍  | 1002/1351 [00:01<00:00, 819.24it/s] 81%|████████▏ | 1101/1351 [00:01<00:00, 863.90it/s] 89%|████████▉ | 1202/1351 [00:01<00:00, 903.24it/s] 96%|█████████▋| 1302/1351 [00:01<00:00, 929.94it/s]100%|██████████| 1351/1351 [00:01<00:00, 861.24it/s]
2025-08-22:18:34:38,015 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_other on rank 0...
  0%|          | 0/924 [00:00<?, ?it/s] 11%|█         | 99/924 [00:00<00:00, 983.35it/s] 22%|██▏       | 202/924 [00:00<00:00, 1007.50it/s] 33%|███▎      | 303/924 [00:00<00:00, 992.41it/s]  44%|████▍     | 405/924 [00:00<00:00, 1000.47it/s] 55%|█████▍    | 506/924 [00:00<00:00, 1000.79it/s] 66%|██████▌   | 609/924 [00:00<00:00, 1007.47it/s] 77%|███████▋  | 710/924 [00:00<00:00, 1005.48it/s] 88%|████████▊ | 814/924 [00:00<00:00, 1013.34it/s] 99%|█████████▉| 916/924 [00:00<00:00, 1012.17it/s]100%|██████████| 924/924 [00:00<00:00, 1006.26it/s]
2025-08-22:18:34:39,015 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_philosophy on rank 0...
  0%|          | 0/499 [00:00<?, ?it/s] 20%|██        | 100/499 [00:00<00:00, 999.18it/s] 40%|████      | 202/499 [00:00<00:00, 1011.09it/s] 61%|██████    | 304/499 [00:00<00:00, 1010.53it/s] 82%|████████▏ | 407/499 [00:00<00:00, 1016.14it/s]100%|██████████| 499/499 [00:00<00:00, 1012.36it/s]
2025-08-22:18:34:39,557 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_physics on rank 0...
  0%|          | 0/1299 [00:00<?, ?it/s]  8%|▊         | 101/1299 [00:00<00:01, 1007.37it/s] 16%|█▌        | 204/1299 [00:00<00:01, 1015.67it/s] 24%|██▎       | 306/1299 [00:00<00:00, 1010.81it/s] 31%|███▏      | 409/1299 [00:00<00:00, 1014.32it/s] 39%|███▉      | 511/1299 [00:00<00:00, 1013.84it/s] 47%|████▋     | 614/1299 [00:00<00:00, 1017.77it/s] 55%|█████▌    | 716/1299 [00:00<00:00, 1018.07it/s] 63%|██████▎   | 820/1299 [00:00<00:00, 1022.56it/s] 71%|███████   | 924/1299 [00:00<00:00, 1025.31it/s] 79%|███████▉  | 1027/1299 [00:01<00:00, 1024.49it/s] 87%|████████▋ | 1130/1299 [00:01<00:00, 1021.57it/s] 95%|█████████▍| 1233/1299 [00:01<00:00, 1021.79it/s]100%|██████████| 1299/1299 [00:01<00:00, 1019.59it/s]
2025-08-22:18:34:40,937 INFO     [lm_eval.api.task:420] Building contexts for mmlu_pro_psychology on rank 0...
  0%|          | 0/798 [00:00<?, ?it/s] 12%|█▏        | 96/798 [00:00<00:00, 958.90it/s] 25%|██▍       | 198/798 [00:00<00:00, 989.75it/s] 37%|███▋      | 299/798 [00:00<00:00, 996.55it/s] 50%|█████     | 400/798 [00:00<00:00, 1001.69it/s] 63%|██████▎   | 501/798 [00:00<00:00, 1002.96it/s] 76%|███████▌  | 603/798 [00:00<00:00, 1007.06it/s] 88%|████████▊ | 705/798 [00:00<00:00, 1009.31it/s]100%|██████████| 798/798 [00:00<00:00, 1002.28it/s]
2025-08-22:18:34:41,799 INFO     [lm_eval.evaluator:517] Running generate_until requests
Requesting API:   0%|          | 0/12032 [00:00<?, ?it/s]2025-08-22:18:34:41,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
/opt/conda/envs/kjl_dllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/opt/conda/envs/kjl_dllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/opt/conda/envs/kjl_dllm/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:651: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
INFO:     127.0.0.1:45522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 1/12032 [00:05<18:05:27,  5.41s/it]2025-08-22:18:34:47,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 2/12032 [00:09<14:59:48,  4.49s/it]2025-08-22:18:34:51,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 3/12032 [00:13<13:55:13,  4.17s/it]2025-08-22:18:34:54,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 4/12032 [00:16<13:29:43,  4.04s/it]2025-08-22:18:34:58,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 5/12032 [00:20<12:24:04,  3.71s/it]2025-08-22:18:35:01,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 6/12032 [00:22<10:30:19,  3.14s/it]2025-08-22:18:35:03,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 7/12032 [00:23<8:51:55,  2.65s/it] 2025-08-22:18:35:05,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 8/12032 [00:27<10:06:56,  3.03s/it]2025-08-22:18:35:09,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 9/12032 [00:29<9:16:12,  2.78s/it] 2025-08-22:18:35:11,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 10/12032 [00:33<10:03:04,  3.01s/it]2025-08-22:18:35:15,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 11/12032 [00:36<10:20:28,  3.10s/it]2025-08-22:18:35:18,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 12/12032 [00:40<11:03:27,  3.31s/it]2025-08-22:18:35:22,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 13/12032 [00:44<11:34:14,  3.47s/it]2025-08-22:18:35:26,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 14/12032 [00:47<11:20:56,  3.40s/it]2025-08-22:18:35:29,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 15/12032 [00:50<10:51:37,  3.25s/it]2025-08-22:18:35:32,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 16/12032 [00:52<9:39:16,  2.89s/it] 2025-08-22:18:35:34,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 17/12032 [00:56<10:24:11,  3.12s/it]2025-08-22:18:35:37,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 18/12032 [00:58<10:08:10,  3.04s/it]2025-08-22:18:35:40,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 19/12032 [01:02<11:04:11,  3.32s/it]2025-08-22:18:35:44,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 20/12032 [01:06<11:30:26,  3.45s/it]2025-08-22:18:35:48,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 21/12032 [01:10<11:53:38,  3.56s/it]2025-08-22:18:35:52,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 22/12032 [01:14<12:13:20,  3.66s/it]2025-08-22:18:35:56,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 23/12032 [01:18<12:24:02,  3.72s/it]2025-08-22:18:36:00,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 24/12032 [01:22<12:32:06,  3.76s/it]2025-08-22:18:36:03,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 25/12032 [01:25<12:05:09,  3.62s/it]2025-08-22:18:36:07,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 26/12032 [01:29<12:15:10,  3.67s/it]2025-08-22:18:36:11,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 27/12032 [01:30<10:21:56,  3.11s/it]2025-08-22:18:36:12,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 28/12032 [01:34<11:11:59,  3.36s/it]2025-08-22:18:36:16,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 29/12032 [01:38<11:41:18,  3.51s/it]2025-08-22:18:36:20,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 30/12032 [01:42<11:59:50,  3.60s/it]2025-08-22:18:36:24,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 31/12032 [01:46<12:13:57,  3.67s/it]2025-08-22:18:36:28,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 32/12032 [01:50<12:27:26,  3.74s/it]2025-08-22:18:36:32,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 33/12032 [01:53<11:30:23,  3.45s/it]2025-08-22:18:36:34,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 34/12032 [01:56<11:53:11,  3.57s/it]2025-08-22:18:36:38,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 35/12032 [02:00<11:33:30,  3.47s/it]2025-08-22:18:36:41,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 36/12032 [02:04<11:57:12,  3.59s/it]2025-08-22:18:36:45,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 37/12032 [02:07<12:12:48,  3.67s/it]2025-08-22:18:36:49,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 38/12032 [02:11<12:23:31,  3.72s/it]2025-08-22:18:36:53,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 39/12032 [02:15<12:31:40,  3.76s/it]2025-08-22:18:36:57,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 40/12032 [02:19<12:36:46,  3.79s/it]2025-08-22:18:37:01,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 41/12032 [02:21<11:19:34,  3.40s/it]2025-08-22:18:37:03,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 42/12032 [02:24<10:24:45,  3.13s/it]2025-08-22:18:37:06,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 43/12032 [02:28<11:09:24,  3.35s/it]2025-08-22:18:37:10,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 44/12032 [02:32<11:37:29,  3.49s/it]2025-08-22:18:37:13,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 45/12032 [02:35<11:57:34,  3.59s/it]2025-08-22:18:37:17,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 46/12032 [02:39<12:11:22,  3.66s/it]2025-08-22:18:37:21,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 47/12032 [02:43<12:22:59,  3.72s/it]2025-08-22:18:37:25,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 48/12032 [02:46<11:33:36,  3.47s/it]2025-08-22:18:37:28,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 49/12032 [02:48<9:46:35,  2.94s/it] 2025-08-22:18:37:30,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 50/12032 [02:51<10:23:54,  3.12s/it]2025-08-22:18:37:33,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 51/12032 [02:55<11:04:30,  3.33s/it]2025-08-22:18:37:37,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 52/12032 [02:59<11:35:45,  3.48s/it]2025-08-22:18:37:41,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 53/12032 [03:03<11:58:37,  3.60s/it]2025-08-22:18:37:45,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 54/12032 [03:06<11:49:46,  3.56s/it]2025-08-22:18:37:48,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 55/12032 [03:10<12:05:16,  3.63s/it]2025-08-22:18:37:52,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 56/12032 [03:14<12:16:27,  3.69s/it]2025-08-22:18:37:56,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 57/12032 [03:18<12:22:13,  3.72s/it]2025-08-22:18:37:59,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 58/12032 [03:21<12:28:01,  3.75s/it]2025-08-22:18:38:03,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 59/12032 [03:25<12:30:51,  3.76s/it]2025-08-22:18:38:07,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   0%|          | 60/12032 [03:29<12:35:55,  3.79s/it]2025-08-22:18:38:11,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 61/12032 [03:32<11:17:34,  3.40s/it]2025-08-22:18:38:13,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 62/12032 [03:35<11:41:41,  3.52s/it]2025-08-22:18:38:17,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 63/12032 [03:38<10:36:12,  3.19s/it]2025-08-22:18:38:20,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 64/12032 [03:42<11:22:29,  3.42s/it]2025-08-22:18:38:24,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 65/12032 [03:46<11:45:49,  3.54s/it]2025-08-22:18:38:27,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 66/12032 [03:49<12:03:29,  3.63s/it]2025-08-22:18:38:31,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 67/12032 [03:53<12:14:39,  3.68s/it]2025-08-22:18:38:35,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 68/12032 [03:57<12:23:51,  3.73s/it]2025-08-22:18:38:39,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 69/12032 [03:59<10:25:25,  3.14s/it]2025-08-22:18:38:41,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 70/12032 [04:03<11:08:06,  3.35s/it]2025-08-22:18:38:45,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 71/12032 [04:06<11:36:07,  3.49s/it]2025-08-22:18:38:48,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 72/12032 [04:10<11:54:56,  3.59s/it]2025-08-22:18:38:52,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 73/12032 [04:12<10:30:47,  3.16s/it]2025-08-22:18:38:54,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 74/12032 [04:16<11:09:56,  3.36s/it]2025-08-22:18:38:58,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 75/12032 [04:20<11:39:53,  3.51s/it]2025-08-22:18:39:02,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 76/12032 [04:24<11:59:40,  3.61s/it]2025-08-22:18:39:06,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 77/12032 [04:26<9:55:55,  2.99s/it] 2025-08-22:18:39:07,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 78/12032 [04:29<10:47:19,  3.25s/it]2025-08-22:18:39:11,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 79/12032 [04:33<11:21:51,  3.42s/it]2025-08-22:18:39:15,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 80/12032 [04:37<11:45:27,  3.54s/it]2025-08-22:18:39:19,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 81/12032 [04:39<10:08:10,  3.05s/it]2025-08-22:18:39:21,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 82/12032 [04:41<9:05:03,  2.74s/it] 2025-08-22:18:39:23,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 83/12032 [04:45<10:09:22,  3.06s/it]2025-08-22:18:39:27,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 84/12032 [04:49<10:55:12,  3.29s/it]2025-08-22:18:39:30,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 85/12032 [04:52<10:55:44,  3.29s/it]2025-08-22:18:39:34,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 86/12032 [04:56<11:33:23,  3.48s/it]2025-08-22:18:39:38,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 87/12032 [05:00<11:55:07,  3.59s/it]2025-08-22:18:39:42,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 88/12032 [05:03<12:08:57,  3.66s/it]2025-08-22:18:39:45,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 89/12032 [05:07<12:20:53,  3.72s/it]2025-08-22:18:39:49,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 90/12032 [05:11<12:28:08,  3.76s/it]2025-08-22:18:39:53,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 91/12032 [05:15<12:33:00,  3.78s/it]2025-08-22:18:39:57,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 92/12032 [05:19<12:37:56,  3.81s/it]2025-08-22:18:40:01,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 93/12032 [05:23<12:39:30,  3.82s/it]2025-08-22:18:40:05,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 94/12032 [05:27<12:40:34,  3.82s/it]2025-08-22:18:40:08,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 95/12032 [05:30<12:41:30,  3.83s/it]2025-08-22:18:40:12,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 96/12032 [05:34<12:42:07,  3.83s/it]2025-08-22:18:40:16,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 97/12032 [05:37<11:58:01,  3.61s/it]2025-08-22:18:40:19,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 98/12032 [05:41<12:11:22,  3.68s/it]2025-08-22:18:40:23,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 99/12032 [05:44<11:14:46,  3.39s/it]2025-08-22:18:40:26,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 100/12032 [05:48<11:41:12,  3.53s/it]2025-08-22:18:40:30,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 101/12032 [05:52<11:59:20,  3.62s/it]2025-08-22:18:40:33,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 102/12032 [05:55<12:12:48,  3.69s/it]2025-08-22:18:40:37,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 103/12032 [05:57<10:33:33,  3.19s/it]2025-08-22:18:40:39,797 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 104/12032 [06:01<11:18:54,  3.42s/it]2025-08-22:18:40:43,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 105/12032 [06:05<11:25:04,  3.45s/it]2025-08-22:18:40:47,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 106/12032 [06:09<11:48:42,  3.57s/it]2025-08-22:18:40:51,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 107/12032 [06:13<12:08:23,  3.66s/it]2025-08-22:18:40:55,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 108/12032 [06:17<12:19:04,  3.72s/it]2025-08-22:18:40:58,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 109/12032 [06:18<10:20:22,  3.12s/it]2025-08-22:18:41:00,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 110/12032 [06:20<8:55:56,  2.70s/it] 2025-08-22:18:41:02,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 111/12032 [06:24<10:06:56,  3.05s/it]2025-08-22:18:41:06,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 112/12032 [06:27<10:06:56,  3.06s/it]2025-08-22:18:41:09,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 113/12032 [06:31<10:55:30,  3.30s/it]2025-08-22:18:41:13,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 114/12032 [06:35<11:30:38,  3.48s/it]2025-08-22:18:41:16,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 115/12032 [06:38<11:52:28,  3.59s/it]2025-08-22:18:41:20,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 116/12032 [06:40<9:31:58,  2.88s/it] 2025-08-22:18:41:22,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 117/12032 [06:44<10:28:40,  3.17s/it]2025-08-22:18:41:25,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 118/12032 [06:46<10:05:28,  3.05s/it]2025-08-22:18:41:28,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 119/12032 [06:50<10:35:23,  3.20s/it]2025-08-22:18:41:32,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 120/12032 [06:54<11:14:41,  3.40s/it]2025-08-22:18:41:36,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 121/12032 [06:55<8:53:33,  2.69s/it] 2025-08-22:18:41:37,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 122/12032 [06:57<8:20:17,  2.52s/it]2025-08-22:18:41:39,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 123/12032 [07:00<9:16:06,  2.80s/it]2025-08-22:18:41:42,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 124/12032 [07:02<8:03:48,  2.44s/it]2025-08-22:18:41:44,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 125/12032 [07:05<8:25:01,  2.54s/it]2025-08-22:18:41:47,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 126/12032 [07:06<7:11:16,  2.17s/it]2025-08-22:18:41:48,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 127/12032 [07:07<6:14:07,  1.89s/it]2025-08-22:18:41:49,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 128/12032 [07:11<8:09:14,  2.47s/it]2025-08-22:18:41:53,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 129/12032 [07:15<9:15:53,  2.80s/it]2025-08-22:18:41:57,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 130/12032 [07:19<10:18:01,  3.12s/it]2025-08-22:18:42:00,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 131/12032 [07:20<8:56:17,  2.70s/it] 2025-08-22:18:42:02,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 132/12032 [07:24<10:03:07,  3.04s/it]2025-08-22:18:42:06,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 133/12032 [07:28<10:48:58,  3.27s/it]2025-08-22:18:42:10,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 134/12032 [07:30<9:57:41,  3.01s/it] 2025-08-22:18:42:12,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 135/12032 [07:34<10:32:02,  3.19s/it]2025-08-22:18:42:16,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 136/12032 [07:37<10:15:54,  3.11s/it]2025-08-22:18:42:19,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 137/12032 [07:41<11:02:52,  3.34s/it]2025-08-22:18:42:23,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 138/12032 [07:45<11:33:28,  3.50s/it]2025-08-22:18:42:26,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 139/12032 [07:48<11:52:32,  3.59s/it]2025-08-22:18:42:30,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 140/12032 [07:52<12:05:40,  3.66s/it]2025-08-22:18:42:34,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 141/12032 [07:56<12:15:53,  3.71s/it]2025-08-22:18:42:38,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 142/12032 [08:00<12:00:49,  3.64s/it]2025-08-22:18:42:41,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 143/12032 [08:03<12:09:58,  3.68s/it]2025-08-22:18:42:45,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 144/12032 [08:07<12:17:41,  3.72s/it]2025-08-22:18:42:49,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 145/12032 [08:11<12:23:17,  3.75s/it]2025-08-22:18:42:53,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 146/12032 [08:14<11:30:21,  3.48s/it]2025-08-22:18:42:56,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 147/12032 [08:15<9:02:50,  2.74s/it] 2025-08-22:18:42:57,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 148/12032 [08:19<10:05:07,  3.06s/it]2025-08-22:18:43:00,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 149/12032 [08:22<10:50:35,  3.28s/it]2025-08-22:18:43:04,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|          | 150/12032 [08:26<11:24:20,  3.46s/it]2025-08-22:18:43:08,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 151/12032 [08:29<10:13:05,  3.10s/it]2025-08-22:18:43:10,868 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 152/12032 [08:32<10:59:22,  3.33s/it]2025-08-22:18:43:14,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 153/12032 [08:36<11:27:00,  3.47s/it]2025-08-22:18:43:18,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 154/12032 [08:40<11:47:28,  3.57s/it]2025-08-22:18:43:22,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 155/12032 [08:44<12:00:21,  3.64s/it]2025-08-22:18:43:26,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 156/12032 [08:48<12:11:13,  3.69s/it]2025-08-22:18:43:29,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 157/12032 [08:50<10:58:47,  3.33s/it]2025-08-22:18:43:32,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 158/12032 [08:52<9:35:43,  2.91s/it] 2025-08-22:18:43:34,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 159/12032 [08:56<10:26:08,  3.16s/it]2025-08-22:18:43:38,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 160/12032 [08:59<10:42:35,  3.25s/it]2025-08-22:18:43:41,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 161/12032 [09:03<11:16:55,  3.42s/it]2025-08-22:18:43:45,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 162/12032 [09:07<11:30:59,  3.49s/it]2025-08-22:18:43:49,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 163/12032 [09:10<11:22:41,  3.45s/it]2025-08-22:18:43:52,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 164/12032 [09:12<9:25:00,  2.86s/it] 2025-08-22:18:43:53,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 165/12032 [09:15<10:20:07,  3.14s/it]2025-08-22:18:43:57,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 166/12032 [09:19<10:57:24,  3.32s/it]2025-08-22:18:44:01,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 167/12032 [09:23<11:28:57,  3.48s/it]2025-08-22:18:44:05,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 168/12032 [09:24<8:53:23,  2.70s/it] 2025-08-22:18:44:06,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 169/12032 [09:28<9:55:53,  3.01s/it]2025-08-22:18:44:09,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 170/12032 [09:29<8:44:20,  2.65s/it]2025-08-22:18:44:11,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 171/12032 [09:31<7:40:37,  2.33s/it]2025-08-22:18:44:13,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 172/12032 [09:34<8:02:19,  2.44s/it]2025-08-22:18:44:15,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 173/12032 [09:37<9:24:20,  2.86s/it]2025-08-22:18:44:19,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 174/12032 [09:41<10:22:05,  3.15s/it]2025-08-22:18:44:23,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 175/12032 [09:45<11:01:54,  3.35s/it]2025-08-22:18:44:27,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 176/12032 [09:49<11:29:00,  3.49s/it]2025-08-22:18:44:31,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 177/12032 [09:52<10:43:42,  3.26s/it]2025-08-22:18:44:33,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 178/12032 [09:54<10:02:05,  3.05s/it]2025-08-22:18:44:36,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 179/12032 [09:58<10:42:00,  3.25s/it]2025-08-22:18:44:40,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   1%|▏         | 180/12032 [10:01<10:39:03,  3.24s/it]2025-08-22:18:44:43,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 181/12032 [10:04<10:43:29,  3.26s/it]2025-08-22:18:44:46,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 182/12032 [10:08<10:47:04,  3.28s/it]2025-08-22:18:44:50,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 183/12032 [10:09<8:56:53,  2.72s/it] 2025-08-22:18:44:51,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 184/12032 [10:13<10:02:56,  3.05s/it]2025-08-22:18:44:55,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 185/12032 [10:17<10:45:57,  3.27s/it]2025-08-22:18:44:59,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 186/12032 [10:21<11:17:31,  3.43s/it]2025-08-22:18:45:02,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 187/12032 [10:23<10:21:13,  3.15s/it]2025-08-22:18:45:05,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 188/12032 [10:27<11:00:37,  3.35s/it]2025-08-22:18:45:09,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 189/12032 [10:30<11:13:09,  3.41s/it]2025-08-22:18:45:12,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 190/12032 [10:32<9:35:21,  2.92s/it] 2025-08-22:18:45:14,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 191/12032 [10:36<10:28:22,  3.18s/it]2025-08-22:18:45:18,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 192/12032 [10:39<10:11:37,  3.10s/it]2025-08-22:18:45:21,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 193/12032 [10:43<10:50:59,  3.30s/it]2025-08-22:18:45:25,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 194/12032 [10:46<11:19:43,  3.45s/it]2025-08-22:18:45:28,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 195/12032 [10:50<11:40:50,  3.55s/it]2025-08-22:18:45:32,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 196/12032 [10:54<11:53:45,  3.62s/it]2025-08-22:18:45:36,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 197/12032 [10:56<9:57:39,  3.03s/it] 2025-08-22:18:45:38,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 198/12032 [11:00<10:44:44,  3.27s/it]2025-08-22:18:45:41,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 199/12032 [11:03<11:15:49,  3.43s/it]2025-08-22:18:45:45,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 200/12032 [11:07<11:37:02,  3.53s/it]2025-08-22:18:45:49,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 201/12032 [11:11<11:53:03,  3.62s/it]2025-08-22:18:45:53,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 202/12032 [11:14<11:23:48,  3.47s/it]2025-08-22:18:45:56,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 203/12032 [11:18<11:43:32,  3.57s/it]2025-08-22:18:46:00,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 204/12032 [11:22<11:56:46,  3.64s/it]2025-08-22:18:46:03,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 205/12032 [11:25<12:06:34,  3.69s/it]2025-08-22:18:46:07,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 206/12032 [11:29<12:14:40,  3.73s/it]2025-08-22:18:46:11,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 207/12032 [11:32<10:46:43,  3.28s/it]2025-08-22:18:46:13,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 208/12032 [11:34<9:52:07,  3.00s/it] 2025-08-22:18:46:16,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 209/12032 [11:38<10:38:54,  3.24s/it]2025-08-22:18:46:20,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 210/12032 [11:41<11:12:43,  3.41s/it]2025-08-22:18:46:23,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 211/12032 [11:43<9:35:36,  2.92s/it] 2025-08-22:18:46:25,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 212/12032 [11:47<10:27:00,  3.18s/it]2025-08-22:18:46:29,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 213/12032 [11:51<11:04:21,  3.37s/it]2025-08-22:18:46:33,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 214/12032 [11:54<11:08:33,  3.39s/it]2025-08-22:18:46:36,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 215/12032 [11:56<9:37:56,  2.93s/it] 2025-08-22:18:46:38,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 216/12032 [11:59<9:15:48,  2.82s/it]2025-08-22:18:46:41,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 217/12032 [12:03<10:17:30,  3.14s/it]2025-08-22:18:46:44,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 218/12032 [12:06<11:01:48,  3.36s/it]2025-08-22:18:46:48,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 219/12032 [12:10<11:26:18,  3.49s/it]2025-08-22:18:46:52,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 220/12032 [12:14<11:44:31,  3.58s/it]2025-08-22:18:46:56,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 221/12032 [12:17<11:20:54,  3.46s/it]2025-08-22:18:46:59,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 222/12032 [12:21<11:40:55,  3.56s/it]2025-08-22:18:47:03,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 223/12032 [12:25<11:55:04,  3.63s/it]2025-08-22:18:47:07,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 224/12032 [12:29<12:03:31,  3.68s/it]2025-08-22:18:47:10,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 225/12032 [12:32<11:53:15,  3.62s/it]2025-08-22:18:47:14,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 226/12032 [12:36<12:04:15,  3.68s/it]2025-08-22:18:47:18,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 227/12032 [12:40<12:13:30,  3.73s/it]2025-08-22:18:47:22,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 228/12032 [12:42<10:19:24,  3.15s/it]2025-08-22:18:47:23,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 229/12032 [12:45<10:57:40,  3.34s/it]2025-08-22:18:47:27,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 230/12032 [12:49<10:49:03,  3.30s/it]2025-08-22:18:47:30,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 231/12032 [12:52<11:17:47,  3.45s/it]2025-08-22:18:47:34,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 232/12032 [12:55<10:21:17,  3.16s/it]2025-08-22:18:47:37,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 233/12032 [12:59<10:58:31,  3.35s/it]2025-08-22:18:47:40,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 234/12032 [13:02<11:28:17,  3.50s/it]2025-08-22:18:47:44,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 235/12032 [13:06<11:46:12,  3.59s/it]2025-08-22:18:47:48,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 236/12032 [13:10<11:59:13,  3.66s/it]2025-08-22:18:47:52,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 237/12032 [13:14<12:10:34,  3.72s/it]2025-08-22:18:47:56,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 238/12032 [13:18<12:18:39,  3.76s/it]2025-08-22:18:48:00,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 239/12032 [13:22<12:24:38,  3.79s/it]2025-08-22:18:48:04,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 240/12032 [13:25<11:54:31,  3.64s/it]2025-08-22:18:48:07,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 241/12032 [13:29<12:05:06,  3.69s/it]2025-08-22:18:48:11,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 242/12032 [13:32<12:05:37,  3.69s/it]2025-08-22:18:48:14,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 243/12032 [13:35<10:35:14,  3.23s/it]2025-08-22:18:48:16,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 244/12032 [13:37<9:42:11,  2.96s/it] 2025-08-22:18:48:19,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 245/12032 [13:41<10:32:04,  3.22s/it]2025-08-22:18:48:23,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 246/12032 [13:45<11:10:17,  3.41s/it]2025-08-22:18:48:26,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 247/12032 [13:48<11:32:30,  3.53s/it]2025-08-22:18:48:30,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 248/12032 [13:51<10:13:34,  3.12s/it]2025-08-22:18:48:32,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 249/12032 [13:53<9:54:39,  3.03s/it] 2025-08-22:18:48:35,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 250/12032 [13:57<10:27:37,  3.20s/it]2025-08-22:18:48:39,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 251/12032 [14:01<11:01:42,  3.37s/it]2025-08-22:18:48:43,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 252/12032 [14:04<10:52:16,  3.32s/it]2025-08-22:18:48:46,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 253/12032 [14:08<11:25:20,  3.49s/it]2025-08-22:18:48:50,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 254/12032 [14:11<10:58:22,  3.35s/it]2025-08-22:18:48:53,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 255/12032 [14:15<11:25:48,  3.49s/it]2025-08-22:18:48:57,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 256/12032 [14:17<10:34:38,  3.23s/it]2025-08-22:18:48:59,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 257/12032 [14:21<11:10:08,  3.41s/it]2025-08-22:18:49:03,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 258/12032 [14:23<9:53:30,  3.02s/it] 2025-08-22:18:49:05,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 259/12032 [14:27<10:40:28,  3.26s/it]2025-08-22:18:49:09,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 260/12032 [14:31<10:56:10,  3.34s/it]2025-08-22:18:49:13,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 261/12032 [14:35<11:27:07,  3.50s/it]2025-08-22:18:49:16,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 262/12032 [14:37<10:03:38,  3.08s/it]2025-08-22:18:49:18,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 263/12032 [14:40<10:49:00,  3.31s/it]2025-08-22:18:49:22,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 264/12032 [14:44<11:21:43,  3.48s/it]2025-08-22:18:49:26,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 265/12032 [14:48<11:39:37,  3.57s/it]2025-08-22:18:49:30,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 266/12032 [14:50<10:06:36,  3.09s/it]2025-08-22:18:49:32,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 267/12032 [14:54<10:31:45,  3.22s/it]2025-08-22:18:49:35,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 268/12032 [14:57<10:16:53,  3.15s/it]2025-08-22:18:49:38,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 269/12032 [15:00<10:54:40,  3.34s/it]2025-08-22:18:49:42,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 270/12032 [15:03<10:16:16,  3.14s/it]2025-08-22:18:49:45,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 271/12032 [15:07<10:55:53,  3.35s/it]2025-08-22:18:49:49,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 272/12032 [15:11<11:22:15,  3.48s/it]2025-08-22:18:49:53,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 273/12032 [15:14<11:40:19,  3.57s/it]2025-08-22:18:49:56,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 274/12032 [15:18<11:53:35,  3.64s/it]2025-08-22:18:50:00,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 275/12032 [15:22<12:06:45,  3.71s/it]2025-08-22:18:50:04,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 276/12032 [15:26<11:52:59,  3.64s/it]2025-08-22:18:50:07,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 277/12032 [15:29<12:02:59,  3.69s/it]2025-08-22:18:50:11,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 278/12032 [15:31<10:15:23,  3.14s/it]2025-08-22:18:50:13,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 279/12032 [15:35<10:56:14,  3.35s/it]2025-08-22:18:50:17,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 280/12032 [15:39<11:26:17,  3.50s/it]2025-08-22:18:50:21,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 281/12032 [15:42<10:47:25,  3.31s/it]2025-08-22:18:50:24,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 282/12032 [15:43<8:54:46,  2.73s/it] 2025-08-22:18:50:25,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 283/12032 [15:47<10:00:02,  3.06s/it]2025-08-22:18:50:29,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 284/12032 [15:51<10:44:26,  3.29s/it]2025-08-22:18:50:33,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 285/12032 [15:53<9:54:40,  3.04s/it] 2025-08-22:18:50:35,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 286/12032 [15:57<10:47:01,  3.31s/it]2025-08-22:18:50:39,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 287/12032 [16:01<10:47:19,  3.31s/it]2025-08-22:18:50:42,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 288/12032 [16:02<9:11:12,  2.82s/it] 2025-08-22:18:50:44,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 289/12032 [16:04<8:13:25,  2.52s/it]2025-08-22:18:50:46,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 290/12032 [16:08<9:30:18,  2.91s/it]2025-08-22:18:50:50,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 291/12032 [16:12<10:24:40,  3.19s/it]2025-08-22:18:50:54,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 292/12032 [16:16<11:04:56,  3.40s/it]2025-08-22:18:50:57,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 293/12032 [16:20<11:32:41,  3.54s/it]2025-08-22:18:51:01,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 294/12032 [16:21<9:36:48,  2.95s/it] 2025-08-22:18:51:03,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 295/12032 [16:24<9:15:35,  2.84s/it]2025-08-22:18:51:05,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 296/12032 [16:27<10:13:50,  3.14s/it]2025-08-22:18:51:09,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 297/12032 [16:31<10:52:16,  3.34s/it]2025-08-22:18:51:13,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 298/12032 [16:35<11:24:37,  3.50s/it]2025-08-22:18:51:17,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 299/12032 [16:37<9:53:52,  3.04s/it] 2025-08-22:18:51:19,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   2%|▏         | 300/12032 [16:41<10:40:17,  3.27s/it]2025-08-22:18:51:23,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 301/12032 [16:45<11:10:59,  3.43s/it]2025-08-22:18:51:27,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 302/12032 [16:49<11:34:19,  3.55s/it]2025-08-22:18:51:30,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 303/12032 [16:51<10:24:25,  3.19s/it]2025-08-22:18:51:33,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 304/12032 [16:55<11:00:01,  3.38s/it]2025-08-22:18:51:37,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 305/12032 [16:58<10:47:26,  3.31s/it]2025-08-22:18:51:40,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 306/12032 [17:01<10:07:02,  3.11s/it]2025-08-22:18:51:42,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 307/12032 [17:04<10:47:44,  3.31s/it]2025-08-22:18:51:46,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 308/12032 [17:08<11:16:36,  3.46s/it]2025-08-22:18:51:50,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 309/12032 [17:11<10:42:05,  3.29s/it]2025-08-22:18:51:53,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 310/12032 [17:14<10:26:54,  3.21s/it]2025-08-22:18:51:56,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 311/12032 [17:18<11:03:06,  3.39s/it]2025-08-22:18:52:00,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 312/12032 [17:22<11:26:29,  3.51s/it]2025-08-22:18:52:04,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 313/12032 [17:25<10:50:53,  3.33s/it]2025-08-22:18:52:06,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 314/12032 [17:28<11:10:21,  3.43s/it]2025-08-22:18:52:10,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 315/12032 [17:32<11:35:59,  3.56s/it]2025-08-22:18:52:14,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 316/12032 [17:35<10:38:31,  3.27s/it]2025-08-22:18:52:17,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 317/12032 [17:39<11:13:57,  3.45s/it]2025-08-22:18:52:20,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 318/12032 [17:42<11:34:14,  3.56s/it]2025-08-22:18:52:24,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 319/12032 [17:46<11:48:10,  3.63s/it]2025-08-22:18:52:28,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 320/12032 [17:48<10:08:57,  3.12s/it]2025-08-22:18:52:30,443 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 321/12032 [17:52<10:50:06,  3.33s/it]2025-08-22:18:52:34,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 322/12032 [17:56<11:17:08,  3.47s/it]2025-08-22:18:52:38,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 323/12032 [17:57<9:22:16,  2.88s/it] 2025-08-22:18:52:39,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 324/12032 [18:00<9:26:13,  2.90s/it]2025-08-22:18:52:42,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 325/12032 [18:04<10:19:58,  3.18s/it]2025-08-22:18:52:46,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 326/12032 [18:08<10:56:35,  3.37s/it]2025-08-22:18:52:50,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 327/12032 [18:09<9:14:44,  2.84s/it] 2025-08-22:18:52:51,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 328/12032 [18:12<9:04:04,  2.79s/it]2025-08-22:18:52:54,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 329/12032 [18:15<8:48:33,  2.71s/it]2025-08-22:18:52:56,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 330/12032 [18:18<9:51:10,  3.03s/it]2025-08-22:18:53:00,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 331/12032 [18:22<10:35:50,  3.26s/it]2025-08-22:18:53:04,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 332/12032 [18:26<11:07:49,  3.42s/it]2025-08-22:18:53:08,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 333/12032 [18:30<11:27:58,  3.53s/it]2025-08-22:18:53:12,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 334/12032 [18:34<11:43:23,  3.61s/it]2025-08-22:18:53:15,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 335/12032 [18:37<11:55:58,  3.67s/it]2025-08-22:18:53:19,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 336/12032 [18:41<11:38:20,  3.58s/it]2025-08-22:18:53:23,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 337/12032 [18:45<11:50:05,  3.64s/it]2025-08-22:18:53:26,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 338/12032 [18:48<11:59:12,  3.69s/it]2025-08-22:18:53:30,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 339/12032 [18:52<12:02:52,  3.71s/it]2025-08-22:18:53:34,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 340/12032 [18:55<10:47:58,  3.33s/it]2025-08-22:18:53:36,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 341/12032 [18:57<9:55:46,  3.06s/it] 2025-08-22:18:53:39,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 342/12032 [19:00<10:20:39,  3.19s/it]2025-08-22:18:53:42,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 343/12032 [19:03<9:30:15,  2.93s/it] 2025-08-22:18:53:45,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 344/12032 [19:07<10:21:33,  3.19s/it]2025-08-22:18:53:48,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 345/12032 [19:10<10:59:37,  3.39s/it]2025-08-22:18:53:52,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 346/12032 [19:13<10:37:41,  3.27s/it]2025-08-22:18:53:55,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 347/12032 [19:16<10:23:14,  3.20s/it]2025-08-22:18:53:58,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 348/12032 [19:20<10:58:21,  3.38s/it]2025-08-22:18:54:02,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 349/12032 [19:24<11:20:52,  3.50s/it]2025-08-22:18:54:06,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 350/12032 [19:28<11:38:17,  3.59s/it]2025-08-22:18:54:10,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 351/12032 [19:31<11:10:31,  3.44s/it]2025-08-22:18:54:13,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 352/12032 [19:35<11:30:22,  3.55s/it]2025-08-22:18:54:17,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 353/12032 [19:37<10:32:11,  3.25s/it]2025-08-22:18:54:19,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 354/12032 [19:41<11:06:02,  3.42s/it]2025-08-22:18:54:23,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 355/12032 [19:45<11:32:49,  3.56s/it]2025-08-22:18:54:27,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 356/12032 [19:48<11:04:33,  3.41s/it]2025-08-22:18:54:30,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 357/12032 [19:52<11:27:38,  3.53s/it]2025-08-22:18:54:34,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 358/12032 [19:54<9:48:40,  3.03s/it] 2025-08-22:18:54:36,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 359/12032 [19:55<8:07:45,  2.51s/it]2025-08-22:18:54:37,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 360/12032 [19:59<9:23:30,  2.90s/it]2025-08-22:18:54:41,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 361/12032 [20:01<8:27:29,  2.61s/it]2025-08-22:18:54:43,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 362/12032 [20:05<9:38:57,  2.98s/it]2025-08-22:18:54:46,923 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 363/12032 [20:06<8:25:17,  2.60s/it]2025-08-22:18:54:48,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 364/12032 [20:10<9:39:31,  2.98s/it]2025-08-22:18:54:52,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 365/12032 [20:14<10:17:03,  3.17s/it]2025-08-22:18:54:56,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 366/12032 [20:16<9:16:28,  2.86s/it] 2025-08-22:18:54:58,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 367/12032 [20:20<10:16:02,  3.17s/it]2025-08-22:18:55:02,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 368/12032 [20:24<10:51:58,  3.35s/it]2025-08-22:18:55:05,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 369/12032 [20:28<11:24:34,  3.52s/it]2025-08-22:18:55:09,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 370/12032 [20:29<9:23:56,  2.90s/it] 2025-08-22:18:55:11,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 371/12032 [20:33<10:19:18,  3.19s/it]2025-08-22:18:55:15,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 372/12032 [20:36<10:38:00,  3.28s/it]2025-08-22:18:55:18,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 373/12032 [20:39<10:30:02,  3.24s/it]2025-08-22:18:55:21,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 374/12032 [20:43<11:04:07,  3.42s/it]2025-08-22:18:55:25,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 375/12032 [20:47<11:28:54,  3.55s/it]2025-08-22:18:55:29,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 376/12032 [20:51<11:43:56,  3.62s/it]2025-08-22:18:55:33,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 377/12032 [20:55<11:54:21,  3.68s/it]2025-08-22:18:55:37,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 378/12032 [20:57<10:19:12,  3.19s/it]2025-08-22:18:55:39,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 379/12032 [21:01<10:53:02,  3.36s/it]2025-08-22:18:55:42,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 380/12032 [21:03<9:39:22,  2.98s/it] 2025-08-22:18:55:45,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 381/12032 [21:06<10:16:52,  3.18s/it]2025-08-22:18:55:48,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 382/12032 [21:10<10:55:12,  3.37s/it]2025-08-22:18:55:52,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 383/12032 [21:14<11:22:37,  3.52s/it]2025-08-22:18:55:56,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 384/12032 [21:15<9:12:55,  2.85s/it] 2025-08-22:18:55:57,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 385/12032 [21:19<10:08:46,  3.14s/it]2025-08-22:18:56:01,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 386/12032 [21:22<10:14:41,  3.17s/it]2025-08-22:18:56:04,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 387/12032 [21:26<10:52:33,  3.36s/it]2025-08-22:18:56:08,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 388/12032 [21:28<9:40:04,  2.99s/it] 2025-08-22:18:56:10,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 389/12032 [21:31<9:24:20,  2.91s/it]2025-08-22:18:56:13,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 390/12032 [21:35<10:16:37,  3.18s/it]2025-08-22:18:56:17,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 391/12032 [21:38<9:54:21,  3.06s/it] 2025-08-22:18:56:19,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 392/12032 [21:39<8:03:36,  2.49s/it]2025-08-22:18:56:21,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 393/12032 [21:40<6:39:41,  2.06s/it]2025-08-22:18:56:22,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 394/12032 [21:43<7:35:45,  2.35s/it]2025-08-22:18:56:25,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 395/12032 [21:47<9:00:57,  2.79s/it]2025-08-22:18:56:28,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 396/12032 [21:49<8:27:42,  2.62s/it]2025-08-22:18:56:31,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 397/12032 [21:53<9:36:49,  2.97s/it]2025-08-22:18:56:34,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 398/12032 [21:56<9:57:28,  3.08s/it]2025-08-22:18:56:38,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 399/12032 [21:59<10:17:05,  3.18s/it]2025-08-22:18:56:41,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 400/12032 [22:03<10:22:58,  3.21s/it]2025-08-22:18:56:45,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 401/12032 [22:06<10:51:31,  3.36s/it]2025-08-22:18:56:48,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 402/12032 [22:10<10:59:14,  3.40s/it]2025-08-22:18:56:52,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 403/12032 [22:12<9:17:18,  2.88s/it] 2025-08-22:18:56:53,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 404/12032 [22:15<10:10:00,  3.15s/it]2025-08-22:18:56:57,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 405/12032 [22:19<10:15:18,  3.18s/it]2025-08-22:18:57:00,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 406/12032 [22:22<10:16:46,  3.18s/it]2025-08-22:18:57:04,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 407/12032 [22:26<10:56:00,  3.39s/it]2025-08-22:18:57:07,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 408/12032 [22:29<10:33:16,  3.27s/it]2025-08-22:18:57:10,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 409/12032 [22:31<9:58:52,  3.09s/it] 2025-08-22:18:57:13,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 410/12032 [22:35<10:41:05,  3.31s/it]2025-08-22:18:57:17,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 411/12032 [22:39<11:08:47,  3.45s/it]2025-08-22:18:57:21,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 412/12032 [22:43<11:29:31,  3.56s/it]2025-08-22:18:57:25,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 413/12032 [22:46<11:21:25,  3.52s/it]2025-08-22:18:57:28,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 414/12032 [22:50<11:45:09,  3.64s/it]2025-08-22:18:57:32,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 415/12032 [22:53<10:59:26,  3.41s/it]2025-08-22:18:57:35,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 416/12032 [22:56<10:57:10,  3.39s/it]2025-08-22:18:57:38,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 417/12032 [23:00<11:20:46,  3.52s/it]2025-08-22:18:57:42,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 418/12032 [23:04<11:38:40,  3.61s/it]2025-08-22:18:57:46,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 419/12032 [23:08<11:51:50,  3.68s/it]2025-08-22:18:57:50,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 420/12032 [23:11<11:48:25,  3.66s/it]2025-08-22:18:57:53,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   3%|▎         | 421/12032 [23:15<11:58:33,  3.71s/it]2025-08-22:18:57:57,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 422/12032 [23:19<12:05:55,  3.75s/it]2025-08-22:18:58:01,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 423/12032 [23:23<12:10:20,  3.77s/it]2025-08-22:18:58:05,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 424/12032 [23:25<10:21:51,  3.21s/it]2025-08-22:18:58:07,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 425/12032 [23:29<10:59:08,  3.41s/it]2025-08-22:18:58:10,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 426/12032 [23:32<11:22:05,  3.53s/it]2025-08-22:18:58:14,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 427/12032 [23:36<11:40:39,  3.62s/it]2025-08-22:18:58:18,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 428/12032 [23:39<10:46:09,  3.34s/it]2025-08-22:18:58:21,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 429/12032 [23:41<9:37:18,  2.99s/it] 2025-08-22:18:58:23,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 430/12032 [23:45<10:26:33,  3.24s/it]2025-08-22:18:58:27,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 431/12032 [23:49<11:00:47,  3.42s/it]2025-08-22:18:58:31,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 432/12032 [23:50<8:57:37,  2.78s/it] 2025-08-22:18:58:32,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 433/12032 [23:54<9:58:46,  3.10s/it]2025-08-22:18:58:36,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 434/12032 [23:58<10:40:11,  3.31s/it]2025-08-22:18:58:40,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 435/12032 [24:02<11:12:18,  3.48s/it]2025-08-22:18:58:43,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 436/12032 [24:05<11:33:20,  3.59s/it]2025-08-22:18:58:47,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 437/12032 [24:09<11:46:59,  3.66s/it]2025-08-22:18:58:51,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 438/12032 [24:13<11:54:09,  3.70s/it]2025-08-22:18:58:55,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 439/12032 [24:17<12:00:27,  3.73s/it]2025-08-22:18:58:59,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 440/12032 [24:21<12:04:14,  3.75s/it]2025-08-22:18:59:02,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 441/12032 [24:23<11:01:54,  3.43s/it]2025-08-22:18:59:05,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 442/12032 [24:25<8:54:28,  2.77s/it] 2025-08-22:18:59:06,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 443/12032 [24:28<9:56:55,  3.09s/it]2025-08-22:18:59:10,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 444/12032 [24:32<10:01:36,  3.11s/it]2025-08-22:18:59:13,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 445/12032 [24:35<10:45:14,  3.34s/it]2025-08-22:18:59:17,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 446/12032 [24:39<11:12:17,  3.48s/it]2025-08-22:18:59:21,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 447/12032 [24:43<11:34:06,  3.59s/it]2025-08-22:18:59:25,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 448/12032 [24:47<11:24:58,  3.55s/it]2025-08-22:18:59:28,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 449/12032 [24:50<11:44:40,  3.65s/it]2025-08-22:18:59:32,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 450/12032 [24:54<11:56:19,  3.71s/it]2025-08-22:18:59:36,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▎         | 451/12032 [24:57<11:09:20,  3.47s/it]2025-08-22:18:59:39,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 452/12032 [25:01<11:28:39,  3.57s/it]2025-08-22:18:59:43,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 453/12032 [25:05<11:41:36,  3.64s/it]2025-08-22:18:59:47,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 454/12032 [25:09<11:54:20,  3.70s/it]2025-08-22:18:59:50,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 455/12032 [25:12<12:00:38,  3.73s/it]2025-08-22:18:59:54,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 456/12032 [25:16<12:05:06,  3.76s/it]2025-08-22:18:59:58,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 457/12032 [25:20<12:05:31,  3.76s/it]2025-08-22:19:00:02,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 458/12032 [25:24<12:05:58,  3.76s/it]2025-08-22:19:00:06,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 459/12032 [25:27<11:36:50,  3.61s/it]2025-08-22:19:00:09,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 460/12032 [25:31<11:29:03,  3.57s/it]2025-08-22:19:00:12,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 461/12032 [25:34<11:40:55,  3.63s/it]2025-08-22:19:00:16,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 462/12032 [25:38<11:49:43,  3.68s/it]2025-08-22:19:00:20,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 463/12032 [25:42<11:56:45,  3.72s/it]2025-08-22:19:00:24,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 464/12032 [25:44<10:49:31,  3.37s/it]2025-08-22:19:00:26,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 465/12032 [25:48<11:07:36,  3.46s/it]2025-08-22:19:00:30,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 466/12032 [25:52<11:27:54,  3.57s/it]2025-08-22:19:00:34,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 467/12032 [25:55<11:08:44,  3.47s/it]2025-08-22:19:00:37,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 468/12032 [25:59<11:27:04,  3.56s/it]2025-08-22:19:00:41,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 469/12032 [26:03<11:42:25,  3.64s/it]2025-08-22:19:00:45,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 470/12032 [26:07<11:53:54,  3.70s/it]2025-08-22:19:00:49,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 471/12032 [26:11<12:03:32,  3.76s/it]2025-08-22:19:00:52,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 472/12032 [26:13<10:29:05,  3.27s/it]2025-08-22:19:00:55,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 473/12032 [26:17<11:02:08,  3.44s/it]2025-08-22:19:00:58,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 474/12032 [26:20<11:24:53,  3.56s/it]2025-08-22:19:01:02,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 475/12032 [26:24<11:40:59,  3.64s/it]2025-08-22:19:01:06,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 476/12032 [26:28<11:48:42,  3.68s/it]2025-08-22:19:01:10,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 477/12032 [26:32<11:55:57,  3.72s/it]2025-08-22:19:01:14,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 478/12032 [26:36<11:58:54,  3.73s/it]2025-08-22:19:01:17,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 479/12032 [26:39<12:02:40,  3.75s/it]2025-08-22:19:01:21,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 480/12032 [26:42<11:18:24,  3.52s/it]2025-08-22:19:01:24,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 481/12032 [26:46<11:41:40,  3.64s/it]2025-08-22:19:01:28,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 482/12032 [26:50<11:56:06,  3.72s/it]2025-08-22:19:01:32,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 483/12032 [26:54<12:01:14,  3.75s/it]2025-08-22:19:01:36,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 484/12032 [26:58<12:05:29,  3.77s/it]2025-08-22:19:01:40,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 485/12032 [27:02<12:06:55,  3.78s/it]2025-08-22:19:01:43,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 486/12032 [27:05<12:09:33,  3.79s/it]2025-08-22:19:01:47,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 487/12032 [27:09<12:17:45,  3.83s/it]2025-08-22:19:01:51,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 488/12032 [27:13<12:15:35,  3.82s/it]2025-08-22:19:01:55,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 489/12032 [27:17<12:14:47,  3.82s/it]2025-08-22:19:01:59,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 490/12032 [27:21<12:15:15,  3.82s/it]2025-08-22:19:02:03,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 491/12032 [27:25<12:14:54,  3.82s/it]2025-08-22:19:02:06,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 492/12032 [27:28<12:13:55,  3.82s/it]2025-08-22:19:02:10,717 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 493/12032 [27:32<12:14:15,  3.82s/it]2025-08-22:19:02:14,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 494/12032 [27:36<12:16:09,  3.83s/it]2025-08-22:19:02:18,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 495/12032 [27:39<11:33:51,  3.61s/it]2025-08-22:19:02:21,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 496/12032 [27:43<11:51:45,  3.70s/it]2025-08-22:19:02:25,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 497/12032 [27:47<12:03:06,  3.76s/it]2025-08-22:19:02:29,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 498/12032 [27:51<12:11:54,  3.81s/it]2025-08-22:19:02:33,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 499/12032 [27:55<12:11:22,  3.80s/it]2025-08-22:19:02:37,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 500/12032 [27:58<12:11:39,  3.81s/it]2025-08-22:19:02:40,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 501/12032 [28:02<12:17:06,  3.84s/it]2025-08-22:19:02:44,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 502/12032 [28:06<11:43:28,  3.66s/it]2025-08-22:19:02:47,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 503/12032 [28:09<11:35:23,  3.62s/it]2025-08-22:19:02:51,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 504/12032 [28:13<11:47:56,  3.68s/it]2025-08-22:19:02:55,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 505/12032 [28:16<11:19:44,  3.54s/it]2025-08-22:19:02:58,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 506/12032 [28:18<9:48:52,  3.07s/it] 2025-08-22:19:03:00,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 507/12032 [28:22<10:48:02,  3.37s/it]2025-08-22:19:03:04,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 508/12032 [28:24<9:03:05,  2.83s/it] 2025-08-22:19:03:06,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 509/12032 [28:27<9:44:04,  3.04s/it]2025-08-22:19:03:09,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 510/12032 [28:29<8:49:04,  2.76s/it]2025-08-22:19:03:11,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 511/12032 [28:32<8:49:53,  2.76s/it]2025-08-22:19:03:14,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 512/12032 [28:36<9:51:17,  3.08s/it]2025-08-22:19:03:18,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 513/12032 [28:39<9:24:45,  2.94s/it]2025-08-22:19:03:20,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 514/12032 [28:43<10:19:54,  3.23s/it]2025-08-22:19:03:24,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 515/12032 [28:46<10:52:46,  3.40s/it]2025-08-22:19:03:28,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 516/12032 [28:50<11:20:29,  3.55s/it]2025-08-22:19:03:32,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 517/12032 [28:51<9:00:25,  2.82s/it] 2025-08-22:19:03:33,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 518/12032 [28:54<8:58:38,  2.81s/it]2025-08-22:19:03:36,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 519/12032 [28:56<8:31:53,  2.67s/it]2025-08-22:19:03:38,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 520/12032 [29:00<9:00:23,  2.82s/it]2025-08-22:19:03:41,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 521/12032 [29:04<10:00:22,  3.13s/it]2025-08-22:19:03:45,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 522/12032 [29:07<10:19:14,  3.23s/it]2025-08-22:19:03:49,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 523/12032 [29:11<10:54:08,  3.41s/it]2025-08-22:19:03:53,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 524/12032 [29:15<11:15:42,  3.52s/it]2025-08-22:19:03:56,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 525/12032 [29:17<10:04:09,  3.15s/it]2025-08-22:19:03:59,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 526/12032 [29:21<10:33:09,  3.30s/it]2025-08-22:19:04:02,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 527/12032 [29:22<9:02:38,  2.83s/it] 2025-08-22:19:04:04,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 528/12032 [29:24<7:46:09,  2.43s/it]2025-08-22:19:04:06,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 529/12032 [29:28<9:05:18,  2.84s/it]2025-08-22:19:04:09,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 530/12032 [29:29<8:10:40,  2.56s/it]2025-08-22:19:04:11,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 531/12032 [29:31<7:22:28,  2.31s/it]2025-08-22:19:04:13,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 532/12032 [29:34<7:24:57,  2.32s/it]2025-08-22:19:04:15,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 533/12032 [29:37<8:50:34,  2.77s/it]2025-08-22:19:04:19,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 534/12032 [29:40<8:33:14,  2.68s/it]2025-08-22:19:04:22,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 535/12032 [29:43<9:19:05,  2.92s/it]2025-08-22:19:04:25,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 536/12032 [29:46<9:02:47,  2.83s/it]2025-08-22:19:04:28,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 537/12032 [29:50<10:00:02,  3.13s/it]2025-08-22:19:04:32,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 538/12032 [29:54<10:43:45,  3.36s/it]2025-08-22:19:04:35,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 539/12032 [29:57<10:17:40,  3.22s/it]2025-08-22:19:04:38,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 540/12032 [30:00<10:51:55,  3.40s/it]2025-08-22:19:04:42,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   4%|▍         | 541/12032 [30:04<11:15:18,  3.53s/it]2025-08-22:19:04:46,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 542/12032 [30:08<11:31:23,  3.61s/it]2025-08-22:19:04:50,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 543/12032 [30:12<11:42:54,  3.67s/it]2025-08-22:19:04:54,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 544/12032 [30:16<11:51:53,  3.72s/it]2025-08-22:19:04:57,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 545/12032 [30:19<11:58:26,  3.75s/it]2025-08-22:19:05:01,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 546/12032 [30:23<12:00:39,  3.76s/it]2025-08-22:19:05:05,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 547/12032 [30:27<12:03:33,  3.78s/it]2025-08-22:19:05:09,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 548/12032 [30:29<10:05:43,  3.16s/it]2025-08-22:19:05:11,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 549/12032 [30:32<9:55:26,  3.11s/it] 2025-08-22:19:05:14,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 550/12032 [30:36<10:35:29,  3.32s/it]2025-08-22:19:05:17,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 551/12032 [30:39<11:03:56,  3.47s/it]2025-08-22:19:05:21,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 552/12032 [30:43<11:22:27,  3.57s/it]2025-08-22:19:05:25,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 553/12032 [30:47<11:37:06,  3.64s/it]2025-08-22:19:05:29,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 554/12032 [30:49<10:28:06,  3.28s/it]2025-08-22:19:05:31,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 555/12032 [30:53<10:57:05,  3.44s/it]2025-08-22:19:05:35,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 556/12032 [30:57<11:19:18,  3.55s/it]2025-08-22:19:05:39,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 557/12032 [31:00<10:39:50,  3.35s/it]2025-08-22:19:05:42,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 558/12032 [31:04<11:05:11,  3.48s/it]2025-08-22:19:05:46,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 559/12032 [31:05<8:41:54,  2.73s/it] 2025-08-22:19:05:47,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 560/12032 [31:07<7:55:19,  2.49s/it]2025-08-22:19:05:48,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 561/12032 [31:10<9:10:18,  2.88s/it]2025-08-22:19:05:52,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 562/12032 [31:12<7:33:11,  2.37s/it]2025-08-22:19:05:53,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 563/12032 [31:13<6:51:35,  2.15s/it]2025-08-22:19:05:55,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 564/12032 [31:16<7:49:22,  2.46s/it]2025-08-22:19:05:58,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 565/12032 [31:20<9:08:09,  2.87s/it]2025-08-22:19:06:02,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 566/12032 [31:23<9:21:09,  2.94s/it]2025-08-22:19:06:05,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 567/12032 [31:26<9:30:24,  2.99s/it]2025-08-22:19:06:08,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 568/12032 [31:28<7:59:05,  2.51s/it]2025-08-22:19:06:10,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 569/12032 [31:32<9:15:03,  2.91s/it]2025-08-22:19:06:14,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 570/12032 [31:36<10:08:55,  3.19s/it]2025-08-22:19:06:17,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 571/12032 [31:37<8:51:48,  2.78s/it] 2025-08-22:19:06:19,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 572/12032 [31:39<8:05:04,  2.54s/it]2025-08-22:19:06:21,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 573/12032 [31:42<8:03:37,  2.53s/it]2025-08-22:19:06:24,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 574/12032 [31:44<7:36:29,  2.39s/it]2025-08-22:19:06:26,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 575/12032 [31:48<8:56:14,  2.81s/it]2025-08-22:19:06:30,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 576/12032 [31:52<9:54:10,  3.11s/it]2025-08-22:19:06:33,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 577/12032 [31:55<9:58:39,  3.14s/it]2025-08-22:19:06:37,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 578/12032 [31:56<8:30:13,  2.67s/it]2025-08-22:19:06:38,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 579/12032 [31:59<8:57:30,  2.82s/it]2025-08-22:19:06:41,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 580/12032 [32:03<9:53:32,  3.11s/it]2025-08-22:19:06:45,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 581/12032 [32:07<10:25:58,  3.28s/it]2025-08-22:19:06:49,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 582/12032 [32:11<10:53:30,  3.42s/it]2025-08-22:19:06:53,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 583/12032 [32:14<10:59:57,  3.46s/it]2025-08-22:19:06:56,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 584/12032 [32:18<11:15:11,  3.54s/it]2025-08-22:19:07:00,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 585/12032 [32:22<11:28:04,  3.61s/it]2025-08-22:19:07:04,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 586/12032 [32:26<11:39:38,  3.67s/it]2025-08-22:19:07:07,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 587/12032 [32:28<10:47:04,  3.39s/it]2025-08-22:19:07:10,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 588/12032 [32:32<11:11:58,  3.52s/it]2025-08-22:19:07:14,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 589/12032 [32:35<10:24:37,  3.28s/it]2025-08-22:19:07:17,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 590/12032 [32:39<10:54:21,  3.43s/it]2025-08-22:19:07:20,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 591/12032 [32:42<11:18:32,  3.56s/it]2025-08-22:19:07:24,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 592/12032 [32:46<11:35:26,  3.65s/it]2025-08-22:19:07:28,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 593/12032 [32:50<11:14:08,  3.54s/it]2025-08-22:19:07:31,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 594/12032 [32:53<11:31:03,  3.63s/it]2025-08-22:19:07:35,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 595/12032 [32:55<9:56:16,  3.13s/it] 2025-08-22:19:07:37,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 596/12032 [32:59<10:35:03,  3.33s/it]2025-08-22:19:07:41,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 597/12032 [33:03<11:02:48,  3.48s/it]2025-08-22:19:07:45,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 598/12032 [33:06<10:07:09,  3.19s/it]2025-08-22:19:07:47,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 599/12032 [33:09<10:43:52,  3.38s/it]2025-08-22:19:07:51,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 600/12032 [33:13<11:10:16,  3.52s/it]2025-08-22:19:07:55,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▍         | 601/12032 [33:17<11:31:01,  3.63s/it]2025-08-22:19:07:59,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 602/12032 [33:18<9:12:00,  2.90s/it] 2025-08-22:19:08:00,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 603/12032 [33:22<10:06:45,  3.19s/it]2025-08-22:19:08:04,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 604/12032 [33:26<10:45:08,  3.39s/it]2025-08-22:19:08:08,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 605/12032 [33:28<9:26:07,  2.97s/it] 2025-08-22:19:08:10,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 606/12032 [33:30<8:09:25,  2.57s/it]2025-08-22:19:08:11,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 607/12032 [33:31<7:08:40,  2.25s/it]2025-08-22:19:08:13,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 608/12032 [33:35<8:39:32,  2.73s/it]2025-08-22:19:08:17,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 609/12032 [33:37<8:25:02,  2.65s/it]2025-08-22:19:08:19,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 610/12032 [33:41<9:37:42,  3.03s/it]2025-08-22:19:08:23,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 611/12032 [33:45<10:21:28,  3.26s/it]2025-08-22:19:08:27,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 612/12032 [33:49<10:56:33,  3.45s/it]2025-08-22:19:08:31,385 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 613/12032 [33:52<10:10:38,  3.21s/it]2025-08-22:19:08:34,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 614/12032 [33:54<9:03:49,  2.86s/it] 2025-08-22:19:08:36,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 615/12032 [33:56<8:17:12,  2.61s/it]2025-08-22:19:08:38,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 616/12032 [34:00<9:28:19,  2.99s/it]2025-08-22:19:08:41,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 617/12032 [34:03<10:17:46,  3.25s/it]2025-08-22:19:08:45,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 618/12032 [34:06<9:38:58,  3.04s/it] 2025-08-22:19:08:48,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 619/12032 [34:10<10:23:13,  3.28s/it]2025-08-22:19:08:52,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 620/12032 [34:14<10:52:27,  3.43s/it]2025-08-22:19:08:56,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 621/12032 [34:17<11:13:54,  3.54s/it]2025-08-22:19:08:59,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 622/12032 [34:21<11:30:21,  3.63s/it]2025-08-22:19:09:03,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 623/12032 [34:23<9:49:50,  3.10s/it] 2025-08-22:19:09:05,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 624/12032 [34:27<10:27:48,  3.30s/it]2025-08-22:19:09:09,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 625/12032 [34:31<10:53:36,  3.44s/it]2025-08-22:19:09:13,037 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 626/12032 [34:35<11:17:53,  3.57s/it]2025-08-22:19:09:16,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 627/12032 [34:38<11:16:37,  3.56s/it]2025-08-22:19:09:20,446 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 628/12032 [34:40<9:41:23,  3.06s/it] 2025-08-22:19:09:22,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 629/12032 [34:44<10:23:08,  3.28s/it]2025-08-22:19:09:26,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 630/12032 [34:48<10:54:13,  3.44s/it]2025-08-22:19:09:29,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 631/12032 [34:51<11:13:10,  3.54s/it]2025-08-22:19:09:33,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 632/12032 [34:55<11:26:41,  3.61s/it]2025-08-22:19:09:37,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 633/12032 [34:58<10:28:30,  3.31s/it]2025-08-22:19:09:40,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 634/12032 [35:00<9:15:17,  2.92s/it] 2025-08-22:19:09:42,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 635/12032 [35:03<9:04:03,  2.86s/it]2025-08-22:19:09:44,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 636/12032 [35:05<9:08:34,  2.89s/it]2025-08-22:19:09:47,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 637/12032 [35:07<7:35:23,  2.40s/it]2025-08-22:19:09:49,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 638/12032 [35:10<8:53:09,  2.81s/it]2025-08-22:19:09:52,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 639/12032 [35:14<9:48:20,  3.10s/it]2025-08-22:19:09:56,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 640/12032 [35:16<8:30:05,  2.69s/it]2025-08-22:19:09:58,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 641/12032 [35:18<7:29:26,  2.37s/it]2025-08-22:19:09:59,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 642/12032 [35:19<6:49:27,  2.16s/it]2025-08-22:19:10:01,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 643/12032 [35:21<6:48:55,  2.15s/it]2025-08-22:19:10:03,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 644/12032 [35:23<6:11:44,  1.96s/it]2025-08-22:19:10:05,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 645/12032 [35:26<6:58:29,  2.21s/it]2025-08-22:19:10:08,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 646/12032 [35:29<7:56:45,  2.51s/it]2025-08-22:19:10:11,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 647/12032 [35:33<9:08:05,  2.89s/it]2025-08-22:19:10:15,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 648/12032 [35:37<10:01:53,  3.17s/it]2025-08-22:19:10:18,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 649/12032 [35:40<10:40:20,  3.38s/it]2025-08-22:19:10:22,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 650/12032 [35:42<9:03:06,  2.86s/it] 2025-08-22:19:10:24,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 651/12032 [35:46<9:57:32,  3.15s/it]2025-08-22:19:10:28,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 652/12032 [35:50<10:34:38,  3.35s/it]2025-08-22:19:10:32,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 653/12032 [35:53<11:00:15,  3.48s/it]2025-08-22:19:10:35,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 654/12032 [35:57<11:19:32,  3.58s/it]2025-08-22:19:10:39,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 655/12032 [36:01<11:35:38,  3.67s/it]2025-08-22:19:10:43,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 656/12032 [36:05<11:43:44,  3.71s/it]2025-08-22:19:10:47,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 657/12032 [36:07<10:34:46,  3.35s/it]2025-08-22:19:10:49,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 658/12032 [36:11<11:02:10,  3.49s/it]2025-08-22:19:10:53,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 659/12032 [36:15<11:19:35,  3.59s/it]2025-08-22:19:10:57,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 660/12032 [36:19<11:34:59,  3.67s/it]2025-08-22:19:11:01,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   5%|▌         | 661/12032 [36:23<11:43:41,  3.71s/it]2025-08-22:19:11:05,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 662/12032 [36:25<10:19:43,  3.27s/it]2025-08-22:19:11:07,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 663/12032 [36:29<10:50:28,  3.43s/it]2025-08-22:19:11:11,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 664/12032 [36:32<10:10:27,  3.22s/it]2025-08-22:19:11:13,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 665/12032 [36:35<10:43:50,  3.40s/it]2025-08-22:19:11:17,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 666/12032 [36:39<11:07:52,  3.53s/it]2025-08-22:19:11:21,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 667/12032 [36:41<9:10:07,  2.90s/it] 2025-08-22:19:11:22,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 668/12032 [36:44<10:00:27,  3.17s/it]2025-08-22:19:11:26,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 669/12032 [36:48<10:35:46,  3.36s/it]2025-08-22:19:11:30,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 670/12032 [36:51<10:27:43,  3.31s/it]2025-08-22:19:11:33,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 671/12032 [36:55<10:55:01,  3.46s/it]2025-08-22:19:11:37,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 672/12032 [36:57<9:41:33,  3.07s/it] 2025-08-22:19:11:39,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 673/12032 [37:01<10:21:53,  3.28s/it]2025-08-22:19:11:43,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 674/12032 [37:05<10:51:53,  3.44s/it]2025-08-22:19:11:47,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 675/12032 [37:07<9:33:46,  3.03s/it] 2025-08-22:19:11:49,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 676/12032 [37:09<8:46:14,  2.78s/it]2025-08-22:19:11:51,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 677/12032 [37:13<9:44:48,  3.09s/it]2025-08-22:19:11:55,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 678/12032 [37:16<9:59:39,  3.17s/it]2025-08-22:19:11:58,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 679/12032 [37:20<10:37:10,  3.37s/it]2025-08-22:19:12:02,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 680/12032 [37:22<8:46:39,  2.78s/it] 2025-08-22:19:12:04,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 681/12032 [37:23<7:20:12,  2.33s/it]2025-08-22:19:12:05,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 682/12032 [37:27<8:43:29,  2.77s/it]2025-08-22:19:12:09,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 683/12032 [37:31<9:43:22,  3.08s/it]2025-08-22:19:12:12,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 684/12032 [37:34<10:28:22,  3.32s/it]2025-08-22:19:12:16,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 685/12032 [37:37<9:53:16,  3.14s/it] 2025-08-22:19:12:19,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 686/12032 [37:41<10:30:36,  3.33s/it]2025-08-22:19:12:23,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 687/12032 [37:45<10:57:19,  3.48s/it]2025-08-22:19:12:27,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 688/12032 [37:49<11:15:41,  3.57s/it]2025-08-22:19:12:30,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 689/12032 [37:51<9:55:37,  3.15s/it] 2025-08-22:19:12:33,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 690/12032 [37:54<10:29:41,  3.33s/it]2025-08-22:19:12:36,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 691/12032 [37:58<11:00:31,  3.49s/it]2025-08-22:19:12:40,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 692/12032 [38:02<11:20:16,  3.60s/it]2025-08-22:19:12:44,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 693/12032 [38:06<11:30:21,  3.65s/it]2025-08-22:19:12:48,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 694/12032 [38:08<10:22:15,  3.29s/it]2025-08-22:19:12:50,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 695/12032 [38:12<10:53:34,  3.46s/it]2025-08-22:19:12:54,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 696/12032 [38:16<11:14:25,  3.57s/it]2025-08-22:19:12:58,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 697/12032 [38:20<11:18:05,  3.59s/it]2025-08-22:19:13:02,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 698/12032 [38:22<9:48:49,  3.12s/it] 2025-08-22:19:13:04,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 699/12032 [38:26<10:27:45,  3.32s/it]2025-08-22:19:13:07,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 700/12032 [38:28<9:27:10,  3.00s/it] 2025-08-22:19:13:10,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 701/12032 [38:31<10:01:43,  3.19s/it]2025-08-22:19:13:13,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 702/12032 [38:35<10:35:39,  3.37s/it]2025-08-22:19:13:17,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 703/12032 [38:39<11:01:01,  3.50s/it]2025-08-22:19:13:21,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 704/12032 [38:43<11:18:17,  3.59s/it]2025-08-22:19:13:25,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 705/12032 [38:45<9:44:44,  3.10s/it] 2025-08-22:19:13:27,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 706/12032 [38:49<10:26:05,  3.32s/it]2025-08-22:19:13:30,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 707/12032 [38:52<10:15:47,  3.26s/it]2025-08-22:19:13:34,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 708/12032 [38:53<8:41:33,  2.76s/it] 2025-08-22:19:13:35,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 709/12032 [38:55<7:53:50,  2.51s/it]2025-08-22:19:13:37,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 710/12032 [38:59<9:05:50,  2.89s/it]2025-08-22:19:13:41,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 711/12032 [39:03<9:56:22,  3.16s/it]2025-08-22:19:13:45,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 712/12032 [39:06<9:46:32,  3.11s/it]2025-08-22:19:13:48,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 713/12032 [39:10<10:30:24,  3.34s/it]2025-08-22:19:13:52,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 714/12032 [39:13<10:56:10,  3.48s/it]2025-08-22:19:13:55,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 715/12032 [39:15<8:59:46,  2.86s/it] 2025-08-22:19:13:57,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 716/12032 [39:17<8:27:39,  2.69s/it]2025-08-22:19:13:59,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 717/12032 [39:21<9:29:42,  3.02s/it]2025-08-22:19:14:03,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 718/12032 [39:22<7:36:23,  2.42s/it]2025-08-22:19:14:04,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 719/12032 [39:23<6:09:09,  1.96s/it]2025-08-22:19:14:05,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 720/12032 [39:24<5:26:01,  1.73s/it]2025-08-22:19:14:06,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 721/12032 [39:25<4:27:25,  1.42s/it]2025-08-22:19:14:07,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 722/12032 [39:26<4:32:19,  1.44s/it]2025-08-22:19:14:08,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 723/12032 [39:30<6:57:21,  2.21s/it]2025-08-22:19:14:12,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 724/12032 [39:32<6:46:24,  2.16s/it]2025-08-22:19:14:14,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 725/12032 [39:33<5:20:49,  1.70s/it]2025-08-22:19:14:15,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 726/12032 [39:34<4:22:06,  1.39s/it]2025-08-22:19:14:15,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 727/12032 [39:34<3:44:44,  1.19s/it]2025-08-22:19:14:16,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 728/12032 [39:35<3:19:16,  1.06s/it]2025-08-22:19:14:17,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 729/12032 [39:37<3:40:47,  1.17s/it]2025-08-22:19:14:18,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 730/12032 [39:37<3:25:13,  1.09s/it]2025-08-22:19:14:19,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 731/12032 [39:38<3:08:48,  1.00s/it]2025-08-22:19:14:20,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 732/12032 [39:39<3:15:46,  1.04s/it]2025-08-22:19:14:21,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 733/12032 [39:40<2:59:37,  1.05it/s]2025-08-22:19:14:22,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 734/12032 [39:44<5:40:55,  1.81s/it]2025-08-22:19:14:26,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 735/12032 [39:48<7:34:43,  2.42s/it]2025-08-22:19:14:30,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 736/12032 [39:52<8:51:32,  2.82s/it]2025-08-22:19:14:33,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 737/12032 [39:55<9:26:30,  3.01s/it]2025-08-22:19:14:37,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 738/12032 [39:59<10:11:05,  3.25s/it]2025-08-22:19:14:41,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 739/12032 [40:02<10:26:24,  3.33s/it]2025-08-22:19:14:44,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 740/12032 [40:04<8:59:07,  2.86s/it] 2025-08-22:19:14:46,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 741/12032 [40:08<9:51:45,  3.14s/it]2025-08-22:19:14:50,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 742/12032 [40:12<10:31:01,  3.35s/it]2025-08-22:19:14:54,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 743/12032 [40:15<10:07:44,  3.23s/it]2025-08-22:19:14:56,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 744/12032 [40:18<10:39:15,  3.40s/it]2025-08-22:19:15:00,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 745/12032 [40:21<9:52:27,  3.15s/it] 2025-08-22:19:15:03,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 746/12032 [40:25<10:29:01,  3.34s/it]2025-08-22:19:15:07,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 747/12032 [40:27<9:15:25,  2.95s/it] 2025-08-22:19:15:09,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 748/12032 [40:28<7:53:20,  2.52s/it]2025-08-22:19:15:10,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 749/12032 [40:32<9:08:05,  2.91s/it]2025-08-22:19:15:14,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 750/12032 [40:36<9:59:50,  3.19s/it]2025-08-22:19:15:18,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▌         | 751/12032 [40:40<10:35:55,  3.38s/it]2025-08-22:19:15:22,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 752/12032 [40:43<10:11:08,  3.25s/it]2025-08-22:19:15:25,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 753/12032 [40:47<10:40:01,  3.40s/it]2025-08-22:19:15:28,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 754/12032 [40:50<11:00:39,  3.51s/it]2025-08-22:19:15:32,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 755/12032 [40:53<10:05:51,  3.22s/it]2025-08-22:19:15:35,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 756/12032 [40:57<10:39:39,  3.40s/it]2025-08-22:19:15:39,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 757/12032 [41:00<10:59:28,  3.51s/it]2025-08-22:19:15:42,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 758/12032 [41:04<10:46:55,  3.44s/it]2025-08-22:19:15:46,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 759/12032 [41:08<11:06:21,  3.55s/it]2025-08-22:19:15:49,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 760/12032 [41:11<11:19:45,  3.62s/it]2025-08-22:19:15:53,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 761/12032 [41:15<11:33:20,  3.69s/it]2025-08-22:19:15:57,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 762/12032 [41:19<11:45:32,  3.76s/it]2025-08-22:19:16:01,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 763/12032 [41:21<9:49:11,  3.14s/it] 2025-08-22:19:16:03,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 764/12032 [41:24<9:42:06,  3.10s/it]2025-08-22:19:16:06,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 765/12032 [41:25<7:54:57,  2.53s/it]2025-08-22:19:16:07,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 766/12032 [41:29<9:12:32,  2.94s/it]2025-08-22:19:16:11,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 767/12032 [41:33<10:04:50,  3.22s/it]2025-08-22:19:16:15,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 768/12032 [41:36<10:32:55,  3.37s/it]2025-08-22:19:16:18,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 769/12032 [41:40<11:06:13,  3.55s/it]2025-08-22:19:16:22,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 770/12032 [41:44<11:24:37,  3.65s/it]2025-08-22:19:16:26,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 771/12032 [41:46<9:36:03,  3.07s/it] 2025-08-22:19:16:28,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 772/12032 [41:47<7:41:11,  2.46s/it]2025-08-22:19:16:29,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 773/12032 [41:49<6:42:46,  2.15s/it]2025-08-22:19:16:30,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 774/12032 [41:52<7:36:13,  2.43s/it]2025-08-22:19:16:33,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 775/12032 [41:52<5:58:51,  1.91s/it]2025-08-22:19:16:34,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 776/12032 [41:55<6:37:32,  2.12s/it]2025-08-22:19:16:37,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 777/12032 [41:56<5:17:30,  1.69s/it]2025-08-22:19:16:37,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 778/12032 [41:56<4:14:19,  1.36s/it]2025-08-22:19:16:38,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 779/12032 [41:57<4:11:22,  1.34s/it]2025-08-22:19:16:39,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 780/12032 [41:58<3:39:09,  1.17s/it]2025-08-22:19:16:40,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 781/12032 [41:59<3:12:22,  1.03s/it]2025-08-22:19:16:41,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   6%|▋         | 782/12032 [42:03<5:51:10,  1.87s/it]2025-08-22:19:16:45,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 783/12032 [42:06<7:21:59,  2.36s/it]2025-08-22:19:16:48,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 784/12032 [42:10<8:45:52,  2.81s/it]2025-08-22:19:16:52,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 785/12032 [42:14<9:43:56,  3.12s/it]2025-08-22:19:16:56,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 786/12032 [42:18<10:26:29,  3.34s/it]2025-08-22:19:17:00,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 787/12032 [42:22<10:54:45,  3.49s/it]2025-08-22:19:17:04,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 788/12032 [42:26<11:16:58,  3.61s/it]2025-08-22:19:17:07,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 789/12032 [42:29<10:45:30,  3.44s/it]2025-08-22:19:17:10,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 790/12032 [42:31<10:09:36,  3.25s/it]2025-08-22:19:17:13,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 791/12032 [42:34<9:33:02,  3.06s/it] 2025-08-22:19:17:16,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 792/12032 [42:38<10:16:25,  3.29s/it]2025-08-22:19:17:20,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 793/12032 [42:41<9:59:25,  3.20s/it] 2025-08-22:19:17:23,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 794/12032 [42:45<10:35:04,  3.39s/it]2025-08-22:19:17:27,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 795/12032 [42:49<10:59:58,  3.52s/it]2025-08-22:19:17:30,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 796/12032 [42:52<11:19:29,  3.63s/it]2025-08-22:19:17:34,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 797/12032 [42:55<10:28:26,  3.36s/it]2025-08-22:19:17:37,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 798/12032 [42:59<10:54:08,  3.49s/it]2025-08-22:19:17:41,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 799/12032 [43:03<11:11:53,  3.59s/it]2025-08-22:19:17:45,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 800/12032 [43:07<11:23:19,  3.65s/it]2025-08-22:19:17:48,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 801/12032 [43:10<11:33:34,  3.71s/it]2025-08-22:19:17:52,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 802/12032 [43:13<10:33:07,  3.38s/it]2025-08-22:19:17:55,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 803/12032 [43:16<10:17:42,  3.30s/it]2025-08-22:19:17:58,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 804/12032 [43:19<9:49:37,  3.15s/it] 2025-08-22:19:18:01,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 805/12032 [43:21<9:09:39,  2.94s/it]2025-08-22:19:18:03,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 806/12032 [43:25<10:00:15,  3.21s/it]2025-08-22:19:18:07,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 807/12032 [43:29<10:33:59,  3.39s/it]2025-08-22:19:18:11,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 808/12032 [43:33<10:58:18,  3.52s/it]2025-08-22:19:18:15,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 809/12032 [43:37<11:14:08,  3.60s/it]2025-08-22:19:18:18,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 810/12032 [43:40<11:28:00,  3.68s/it]2025-08-22:19:18:22,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 811/12032 [43:44<11:36:25,  3.72s/it]2025-08-22:19:18:26,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 812/12032 [43:48<11:39:46,  3.74s/it]2025-08-22:19:18:30,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 813/12032 [43:52<11:42:31,  3.76s/it]2025-08-22:19:18:34,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 814/12032 [43:56<11:46:28,  3.78s/it]2025-08-22:19:18:38,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 815/12032 [44:00<11:48:17,  3.79s/it]2025-08-22:19:18:41,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 816/12032 [44:03<11:49:54,  3.80s/it]2025-08-22:19:18:45,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 817/12032 [44:07<11:49:25,  3.80s/it]2025-08-22:19:18:49,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 818/12032 [44:10<11:01:59,  3.54s/it]2025-08-22:19:18:52,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 819/12032 [44:14<11:16:19,  3.62s/it]2025-08-22:19:18:56,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 820/12032 [44:17<10:46:00,  3.46s/it]2025-08-22:19:18:59,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 821/12032 [44:21<11:05:53,  3.56s/it]2025-08-22:19:19:03,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 822/12032 [44:25<11:19:25,  3.64s/it]2025-08-22:19:19:06,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 823/12032 [44:26<8:56:33,  2.87s/it] 2025-08-22:19:19:08,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 824/12032 [44:29<9:12:49,  2.96s/it]2025-08-22:19:19:11,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 825/12032 [44:33<9:59:35,  3.21s/it]2025-08-22:19:19:14,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 826/12032 [44:36<10:32:33,  3.39s/it]2025-08-22:19:19:18,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 827/12032 [44:40<10:57:45,  3.52s/it]2025-08-22:19:19:22,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 828/12032 [44:44<11:14:07,  3.61s/it]2025-08-22:19:19:26,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 829/12032 [44:47<10:30:52,  3.38s/it]2025-08-22:19:19:29,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 830/12032 [44:51<10:55:09,  3.51s/it]2025-08-22:19:19:33,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 831/12032 [44:55<11:13:36,  3.61s/it]2025-08-22:19:19:36,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 832/12032 [44:58<11:25:58,  3.67s/it]2025-08-22:19:19:40,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 833/12032 [45:02<10:55:08,  3.51s/it]2025-08-22:19:19:43,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 834/12032 [45:05<11:12:46,  3.60s/it]2025-08-22:19:19:47,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 835/12032 [45:09<11:23:09,  3.66s/it]2025-08-22:19:19:51,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 836/12032 [45:12<10:17:00,  3.31s/it]2025-08-22:19:19:53,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 837/12032 [45:12<7:53:13,  2.54s/it] 2025-08-22:19:19:54,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 838/12032 [45:14<7:19:41,  2.36s/it]2025-08-22:19:19:56,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 839/12032 [45:16<6:52:39,  2.21s/it]2025-08-22:19:19:58,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 840/12032 [45:17<5:59:05,  1.93s/it]2025-08-22:19:19:59,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 841/12032 [45:19<5:25:06,  1.74s/it]2025-08-22:19:20:01,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 842/12032 [45:21<5:59:41,  1.93s/it]2025-08-22:19:20:03,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 843/12032 [45:22<5:18:41,  1.71s/it]2025-08-22:19:20:04,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 844/12032 [45:24<4:58:26,  1.60s/it]2025-08-22:19:20:06,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 845/12032 [45:24<4:06:21,  1.32s/it]2025-08-22:19:20:06,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 846/12032 [45:25<3:30:42,  1.13s/it]2025-08-22:19:20:07,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 847/12032 [45:27<4:16:48,  1.38s/it]2025-08-22:19:20:09,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 848/12032 [45:28<3:39:47,  1.18s/it]2025-08-22:19:20:10,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 849/12032 [45:29<3:30:31,  1.13s/it]2025-08-22:19:20:11,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 850/12032 [45:30<3:18:30,  1.07s/it]2025-08-22:19:20:11,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 851/12032 [45:33<5:51:28,  1.89s/it]2025-08-22:19:20:15,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 852/12032 [45:37<7:18:28,  2.35s/it]2025-08-22:19:20:19,204 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 853/12032 [45:41<8:42:37,  2.81s/it]2025-08-22:19:20:23,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 854/12032 [45:45<9:39:39,  3.11s/it]2025-08-22:19:20:26,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 855/12032 [45:48<10:19:04,  3.32s/it]2025-08-22:19:20:30,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 856/12032 [45:52<10:47:55,  3.48s/it]2025-08-22:19:20:34,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 857/12032 [45:56<11:14:05,  3.62s/it]2025-08-22:19:20:38,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 858/12032 [46:00<11:19:10,  3.65s/it]2025-08-22:19:20:42,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 859/12032 [46:04<11:28:15,  3.70s/it]2025-08-22:19:20:46,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 860/12032 [46:07<11:33:57,  3.73s/it]2025-08-22:19:20:49,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 861/12032 [46:11<11:42:12,  3.77s/it]2025-08-22:19:20:53,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 862/12032 [46:15<11:46:33,  3.80s/it]2025-08-22:19:20:57,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 863/12032 [46:19<11:48:55,  3.81s/it]2025-08-22:19:21:01,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 864/12032 [46:22<11:12:37,  3.61s/it]2025-08-22:19:21:04,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 865/12032 [46:26<11:26:12,  3.69s/it]2025-08-22:19:21:08,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 866/12032 [46:27<8:53:25,  2.87s/it] 2025-08-22:19:21:09,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 867/12032 [46:30<9:17:58,  3.00s/it]2025-08-22:19:21:12,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 868/12032 [46:34<10:03:55,  3.25s/it]2025-08-22:19:21:16,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 869/12032 [46:38<10:36:02,  3.42s/it]2025-08-22:19:21:20,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 870/12032 [46:42<10:57:07,  3.53s/it]2025-08-22:19:21:24,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 871/12032 [46:46<11:11:05,  3.61s/it]2025-08-22:19:21:27,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 872/12032 [46:48<9:55:01,  3.20s/it] 2025-08-22:19:21:30,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 873/12032 [46:50<9:15:00,  2.98s/it]2025-08-22:19:21:32,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 874/12032 [46:54<10:02:11,  3.24s/it]2025-08-22:19:21:36,443 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 875/12032 [46:58<10:33:32,  3.41s/it]2025-08-22:19:21:40,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 876/12032 [47:00<9:22:23,  3.02s/it] 2025-08-22:19:21:42,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 877/12032 [47:04<10:10:05,  3.28s/it]2025-08-22:19:21:46,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 878/12032 [47:07<9:45:06,  3.15s/it] 2025-08-22:19:21:49,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 879/12032 [47:11<10:22:50,  3.35s/it]2025-08-22:19:21:52,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 880/12032 [47:14<10:03:24,  3.25s/it]2025-08-22:19:21:55,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 881/12032 [47:15<8:24:18,  2.71s/it] 2025-08-22:19:21:57,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 882/12032 [47:19<9:25:10,  3.04s/it]2025-08-22:19:22:01,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 883/12032 [47:23<10:07:50,  3.27s/it]2025-08-22:19:22:05,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 884/12032 [47:26<10:38:18,  3.44s/it]2025-08-22:19:22:08,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 885/12032 [47:29<10:12:01,  3.29s/it]2025-08-22:19:22:11,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 886/12032 [47:32<9:41:13,  3.13s/it] 2025-08-22:19:22:14,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 887/12032 [47:35<9:43:49,  3.14s/it]2025-08-22:19:22:17,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 888/12032 [47:39<10:26:11,  3.37s/it]2025-08-22:19:22:21,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 889/12032 [47:43<10:53:11,  3.52s/it]2025-08-22:19:22:25,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 890/12032 [47:47<11:09:05,  3.60s/it]2025-08-22:19:22:29,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 891/12032 [47:51<11:23:27,  3.68s/it]2025-08-22:19:22:33,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 892/12032 [47:55<11:30:54,  3.72s/it]2025-08-22:19:22:36,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 893/12032 [47:58<11:37:56,  3.76s/it]2025-08-22:19:22:40,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 894/12032 [48:00<9:51:00,  3.18s/it] 2025-08-22:19:22:42,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 895/12032 [48:04<10:25:15,  3.37s/it]2025-08-22:19:22:46,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 896/12032 [48:08<10:51:21,  3.51s/it]2025-08-22:19:22:50,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 897/12032 [48:11<10:42:16,  3.46s/it]2025-08-22:19:22:53,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 898/12032 [48:14<10:24:21,  3.36s/it]2025-08-22:19:22:56,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 899/12032 [48:18<10:49:33,  3.50s/it]2025-08-22:19:23:00,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 900/12032 [48:22<10:57:43,  3.55s/it]2025-08-22:19:23:04,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 901/12032 [48:24<9:33:45,  3.09s/it] 2025-08-22:19:23:06,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   7%|▋         | 902/12032 [48:26<8:46:26,  2.84s/it]2025-08-22:19:23:08,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 903/12032 [48:28<8:09:31,  2.64s/it]2025-08-22:19:23:10,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 904/12032 [48:29<6:16:33,  2.03s/it]2025-08-22:19:23:11,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 905/12032 [48:30<5:27:47,  1.77s/it]2025-08-22:19:23:12,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 906/12032 [48:31<4:35:15,  1.48s/it]2025-08-22:19:23:13,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 907/12032 [48:33<4:46:24,  1.54s/it]2025-08-22:19:23:14,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 908/12032 [48:33<3:53:23,  1.26s/it]2025-08-22:19:23:15,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 909/12032 [48:34<3:47:49,  1.23s/it]2025-08-22:19:23:16,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 910/12032 [48:37<5:06:21,  1.65s/it]2025-08-22:19:23:19,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 911/12032 [48:38<4:08:33,  1.34s/it]2025-08-22:19:23:19,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 912/12032 [48:41<6:25:47,  2.08s/it]2025-08-22:19:23:23,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 913/12032 [48:42<5:08:48,  1.67s/it]2025-08-22:19:23:24,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 914/12032 [48:43<4:42:48,  1.53s/it]2025-08-22:19:23:25,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 915/12032 [48:44<4:07:49,  1.34s/it]2025-08-22:19:23:26,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 916/12032 [48:48<6:25:05,  2.08s/it]2025-08-22:19:23:30,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 917/12032 [48:52<7:57:22,  2.58s/it]2025-08-22:19:23:34,117 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 918/12032 [48:56<9:03:33,  2.93s/it]2025-08-22:19:23:37,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 919/12032 [48:58<8:50:16,  2.86s/it]2025-08-22:19:23:40,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 920/12032 [49:00<7:56:54,  2.58s/it]2025-08-22:19:23:42,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 921/12032 [49:04<9:03:44,  2.94s/it]2025-08-22:19:23:46,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 922/12032 [49:08<9:49:20,  3.18s/it]2025-08-22:19:23:50,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 923/12032 [49:11<10:20:48,  3.35s/it]2025-08-22:19:23:53,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 924/12032 [49:15<10:43:20,  3.47s/it]2025-08-22:19:23:57,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 925/12032 [49:19<10:59:34,  3.56s/it]2025-08-22:19:24:01,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 926/12032 [49:23<11:09:10,  3.62s/it]2025-08-22:19:24:05,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 927/12032 [49:26<11:16:45,  3.66s/it]2025-08-22:19:24:08,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 928/12032 [49:30<11:20:48,  3.68s/it]2025-08-22:19:24:12,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 929/12032 [49:33<10:26:31,  3.39s/it]2025-08-22:19:24:15,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 930/12032 [49:36<9:48:48,  3.18s/it] 2025-08-22:19:24:17,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 931/12032 [49:39<9:35:26,  3.11s/it]2025-08-22:19:24:20,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 932/12032 [49:42<10:13:12,  3.31s/it]2025-08-22:19:24:24,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 933/12032 [49:45<9:14:43,  3.00s/it] 2025-08-22:19:24:26,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 934/12032 [49:49<10:05:54,  3.28s/it]2025-08-22:19:24:30,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 935/12032 [49:52<10:35:12,  3.43s/it]2025-08-22:19:24:34,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 936/12032 [49:56<10:55:38,  3.55s/it]2025-08-22:19:24:38,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 937/12032 [49:59<10:01:39,  3.25s/it]2025-08-22:19:24:41,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 938/12032 [50:02<10:30:25,  3.41s/it]2025-08-22:19:24:44,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 939/12032 [50:06<10:50:22,  3.52s/it]2025-08-22:19:24:48,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 940/12032 [50:10<11:03:45,  3.59s/it]2025-08-22:19:24:52,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 941/12032 [50:13<10:29:29,  3.41s/it]2025-08-22:19:24:55,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 942/12032 [50:17<10:54:56,  3.54s/it]2025-08-22:19:24:59,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 943/12032 [50:18<8:35:08,  2.79s/it] 2025-08-22:19:25:00,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 944/12032 [50:22<9:28:46,  3.08s/it]2025-08-22:19:25:03,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 945/12032 [50:24<8:50:13,  2.87s/it]2025-08-22:19:25:06,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 946/12032 [50:26<8:02:04,  2.61s/it]2025-08-22:19:25:08,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 947/12032 [50:30<9:06:52,  2.96s/it]2025-08-22:19:25:12,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 948/12032 [50:32<8:00:04,  2.60s/it]2025-08-22:19:25:13,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 949/12032 [50:35<9:05:23,  2.95s/it]2025-08-22:19:25:17,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 950/12032 [50:39<9:36:20,  3.12s/it]2025-08-22:19:25:21,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 951/12032 [50:42<9:16:14,  3.01s/it]2025-08-22:19:25:23,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 952/12032 [50:45<9:59:10,  3.24s/it]2025-08-22:19:25:27,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 953/12032 [50:48<9:17:28,  3.02s/it]2025-08-22:19:25:30,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 954/12032 [50:50<8:08:27,  2.65s/it]2025-08-22:19:25:31,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 955/12032 [50:50<6:21:24,  2.07s/it]2025-08-22:19:25:32,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 956/12032 [50:51<5:11:04,  1.69s/it]2025-08-22:19:25:33,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 957/12032 [50:52<4:30:32,  1.47s/it]2025-08-22:19:25:34,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 958/12032 [50:53<3:41:21,  1.20s/it]2025-08-22:19:25:35,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 959/12032 [50:54<3:21:05,  1.09s/it]2025-08-22:19:25:35,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 960/12032 [50:54<3:07:07,  1.01s/it]2025-08-22:19:25:36,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 961/12032 [50:58<5:19:02,  1.73s/it]2025-08-22:19:25:40,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 962/12032 [50:59<4:31:29,  1.47s/it]2025-08-22:19:25:40,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 963/12032 [51:02<6:37:00,  2.15s/it]2025-08-22:19:25:44,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 964/12032 [51:06<8:07:43,  2.64s/it]2025-08-22:19:25:48,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 965/12032 [51:10<9:09:30,  2.98s/it]2025-08-22:19:25:52,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 966/12032 [51:14<9:56:27,  3.23s/it]2025-08-22:19:25:56,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 967/12032 [51:18<10:28:39,  3.41s/it]2025-08-22:19:25:59,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 968/12032 [51:21<10:50:09,  3.53s/it]2025-08-22:19:26:03,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 969/12032 [51:25<10:34:07,  3.44s/it]2025-08-22:19:26:06,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 970/12032 [51:28<10:54:18,  3.55s/it]2025-08-22:19:26:10,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 971/12032 [51:32<11:10:23,  3.64s/it]2025-08-22:19:26:14,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 972/12032 [51:36<11:17:38,  3.68s/it]2025-08-22:19:26:18,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 973/12032 [51:38<9:30:14,  3.09s/it] 2025-08-22:19:26:20,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 974/12032 [51:39<7:44:20,  2.52s/it]2025-08-22:19:26:21,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 975/12032 [51:43<8:47:27,  2.86s/it]2025-08-22:19:26:24,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 976/12032 [51:46<9:38:10,  3.14s/it]2025-08-22:19:26:28,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 977/12032 [51:49<9:06:06,  2.96s/it]2025-08-22:19:26:31,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 978/12032 [51:53<9:54:02,  3.22s/it]2025-08-22:19:26:35,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 979/12032 [51:54<8:15:21,  2.69s/it]2025-08-22:19:26:36,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 980/12032 [51:58<9:16:13,  3.02s/it]2025-08-22:19:26:40,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 981/12032 [52:01<9:34:13,  3.12s/it]2025-08-22:19:26:43,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 982/12032 [52:04<9:21:53,  3.05s/it]2025-08-22:19:26:46,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 983/12032 [52:06<8:28:11,  2.76s/it]2025-08-22:19:26:48,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 984/12032 [52:09<8:16:43,  2.70s/it]2025-08-22:19:26:51,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 985/12032 [52:13<9:17:10,  3.03s/it]2025-08-22:19:26:54,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 986/12032 [52:16<10:00:24,  3.26s/it]2025-08-22:19:26:58,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 987/12032 [52:20<10:16:40,  3.35s/it]2025-08-22:19:27:02,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 988/12032 [52:24<10:40:02,  3.48s/it]2025-08-22:19:27:06,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 989/12032 [52:27<10:33:04,  3.44s/it]2025-08-22:19:27:09,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 990/12032 [52:31<10:53:22,  3.55s/it]2025-08-22:19:27:13,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 991/12032 [52:35<11:05:32,  3.62s/it]2025-08-22:19:27:17,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 992/12032 [52:38<10:44:28,  3.50s/it]2025-08-22:19:27:20,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 993/12032 [52:41<10:40:56,  3.48s/it]2025-08-22:19:27:23,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 994/12032 [52:45<10:22:30,  3.38s/it]2025-08-22:19:27:26,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 995/12032 [52:46<8:15:55,  2.70s/it] 2025-08-22:19:27:27,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 996/12032 [52:49<9:14:13,  3.01s/it]2025-08-22:19:27:31,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 997/12032 [52:52<9:04:02,  2.96s/it]2025-08-22:19:27:34,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 998/12032 [52:56<9:50:40,  3.21s/it]2025-08-22:19:27:38,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 999/12032 [53:00<10:21:14,  3.38s/it]2025-08-22:19:27:42,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1000/12032 [53:00<7:50:13,  2.56s/it]2025-08-22:19:27:42,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1001/12032 [53:04<8:24:36,  2.74s/it]2025-08-22:19:27:45,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1002/12032 [53:07<9:21:48,  3.06s/it]2025-08-22:19:27:49,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1003/12032 [53:11<10:07:21,  3.30s/it]2025-08-22:19:27:53,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1004/12032 [53:15<10:39:54,  3.48s/it]2025-08-22:19:27:57,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1005/12032 [53:16<8:20:17,  2.72s/it] 2025-08-22:19:27:58,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1006/12032 [53:18<7:45:10,  2.53s/it]2025-08-22:19:28:00,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1007/12032 [53:19<6:14:34,  2.04s/it]2025-08-22:19:28:01,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1008/12032 [53:20<4:58:32,  1.62s/it]2025-08-22:19:28:02,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1009/12032 [53:20<4:06:37,  1.34s/it]2025-08-22:19:28:02,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1010/12032 [53:22<4:34:00,  1.49s/it]2025-08-22:19:28:04,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1011/12032 [53:24<4:52:18,  1.59s/it]2025-08-22:19:28:06,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1012/12032 [53:25<3:55:52,  1.28s/it]2025-08-22:19:28:07,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1013/12032 [53:29<6:16:28,  2.05s/it]2025-08-22:19:28:10,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1014/12032 [53:32<7:54:00,  2.58s/it]2025-08-22:19:28:14,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1015/12032 [53:36<9:02:34,  2.95s/it]2025-08-22:19:28:18,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1016/12032 [53:39<9:11:06,  3.00s/it]2025-08-22:19:28:21,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1017/12032 [53:43<9:56:11,  3.25s/it]2025-08-22:19:28:25,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1018/12032 [53:47<10:27:13,  3.42s/it]2025-08-22:19:28:29,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1019/12032 [53:51<10:48:51,  3.54s/it]2025-08-22:19:28:33,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1020/12032 [53:53<9:53:09,  3.23s/it] 2025-08-22:19:28:35,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1021/12032 [53:57<10:23:20,  3.40s/it]2025-08-22:19:28:39,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   8%|▊         | 1022/12032 [54:01<10:44:33,  3.51s/it]2025-08-22:19:28:43,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1023/12032 [54:03<9:48:52,  3.21s/it] 2025-08-22:19:28:45,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1024/12032 [54:07<10:21:57,  3.39s/it]2025-08-22:19:28:49,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1025/12032 [54:11<10:41:55,  3.50s/it]2025-08-22:19:28:53,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1026/12032 [54:13<9:39:59,  3.16s/it] 2025-08-22:19:28:55,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1027/12032 [54:17<10:01:39,  3.28s/it]2025-08-22:19:28:59,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1028/12032 [54:21<10:26:23,  3.42s/it]2025-08-22:19:29:02,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1029/12032 [54:24<10:44:42,  3.52s/it]2025-08-22:19:29:06,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1030/12032 [54:28<10:55:34,  3.58s/it]2025-08-22:19:29:10,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1031/12032 [54:32<11:05:11,  3.63s/it]2025-08-22:19:29:14,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1032/12032 [54:33<9:17:53,  3.04s/it] 2025-08-22:19:29:15,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1033/12032 [54:37<9:59:51,  3.27s/it]2025-08-22:19:29:19,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1034/12032 [54:41<10:28:10,  3.43s/it]2025-08-22:19:29:23,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1035/12032 [54:45<10:45:52,  3.52s/it]2025-08-22:19:29:27,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1036/12032 [54:46<9:01:30,  2.95s/it] 2025-08-22:19:29:28,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1037/12032 [54:50<9:46:05,  3.20s/it]2025-08-22:19:29:32,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1038/12032 [54:54<10:16:39,  3.37s/it]2025-08-22:19:29:36,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1039/12032 [54:58<10:40:04,  3.49s/it]2025-08-22:19:29:40,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1040/12032 [55:00<9:25:37,  3.09s/it] 2025-08-22:19:29:42,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1041/12032 [55:04<10:04:46,  3.30s/it]2025-08-22:19:29:45,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1042/12032 [55:06<8:48:10,  2.88s/it] 2025-08-22:19:29:47,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1043/12032 [55:09<9:29:06,  3.11s/it]2025-08-22:19:29:51,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1044/12032 [55:12<9:33:26,  3.13s/it]2025-08-22:19:29:54,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1045/12032 [55:16<10:08:36,  3.32s/it]2025-08-22:19:29:58,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1046/12032 [55:18<8:50:49,  2.90s/it] 2025-08-22:19:30:00,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1047/12032 [55:22<9:39:28,  3.17s/it]2025-08-22:19:30:04,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1048/12032 [55:26<10:12:51,  3.35s/it]2025-08-22:19:30:07,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1049/12032 [55:29<10:34:54,  3.47s/it]2025-08-22:19:30:11,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1050/12032 [55:33<10:52:16,  3.56s/it]2025-08-22:19:30:15,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1051/12032 [55:37<11:03:24,  3.62s/it]2025-08-22:19:30:19,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▊         | 1052/12032 [55:40<10:33:32,  3.46s/it]2025-08-22:19:30:22,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1053/12032 [55:44<10:47:51,  3.54s/it]2025-08-22:19:30:26,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1054/12032 [55:48<11:02:09,  3.62s/it]2025-08-22:19:30:29,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1055/12032 [55:51<10:33:19,  3.46s/it]2025-08-22:19:30:32,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1056/12032 [55:55<11:06:06,  3.64s/it]2025-08-22:19:30:37,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1057/12032 [55:58<11:12:47,  3.68s/it]2025-08-22:19:30:40,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1058/12032 [56:00<9:20:17,  3.06s/it] 2025-08-22:19:30:42,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1059/12032 [56:04<9:58:05,  3.27s/it]2025-08-22:19:30:46,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1060/12032 [56:08<10:23:50,  3.41s/it]2025-08-22:19:30:49,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1061/12032 [56:10<9:50:06,  3.23s/it] 2025-08-22:19:30:52,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1062/12032 [56:14<10:21:07,  3.40s/it]2025-08-22:19:30:56,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1063/12032 [56:18<10:46:11,  3.53s/it]2025-08-22:19:31:00,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1064/12032 [56:22<10:58:48,  3.60s/it]2025-08-22:19:31:04,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1065/12032 [56:26<11:10:54,  3.67s/it]2025-08-22:19:31:07,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1066/12032 [56:29<11:00:46,  3.62s/it]2025-08-22:19:31:11,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1067/12032 [56:32<10:36:44,  3.48s/it]2025-08-22:19:31:14,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1068/12032 [56:36<10:56:13,  3.59s/it]2025-08-22:19:31:18,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1069/12032 [56:40<11:05:03,  3.64s/it]2025-08-22:19:31:22,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1070/12032 [56:43<10:32:09,  3.46s/it]2025-08-22:19:31:25,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1071/12032 [56:47<10:55:33,  3.59s/it]2025-08-22:19:31:29,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1072/12032 [56:49<9:26:34,  3.10s/it] 2025-08-22:19:31:31,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1073/12032 [56:52<9:49:08,  3.23s/it]2025-08-22:19:31:34,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1074/12032 [56:56<10:21:17,  3.40s/it]2025-08-22:19:31:38,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1075/12032 [57:00<10:39:39,  3.50s/it]2025-08-22:19:31:42,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1076/12032 [57:02<9:42:37,  3.19s/it] 2025-08-22:19:31:44,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1077/12032 [57:03<7:39:16,  2.52s/it]2025-08-22:19:31:45,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1078/12032 [57:04<5:57:39,  1.96s/it]2025-08-22:19:31:46,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1079/12032 [57:05<4:44:52,  1.56s/it]2025-08-22:19:31:46,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1080/12032 [57:05<4:05:14,  1.34s/it]2025-08-22:19:31:47,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1081/12032 [57:07<4:01:02,  1.32s/it]2025-08-22:19:31:48,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1082/12032 [57:07<3:31:48,  1.16s/it]2025-08-22:19:31:49,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1083/12032 [57:08<3:11:39,  1.05s/it]2025-08-22:19:31:50,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1084/12032 [57:09<3:04:38,  1.01s/it]2025-08-22:19:31:51,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1085/12032 [57:10<2:43:34,  1.12it/s]2025-08-22:19:31:52,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1086/12032 [57:10<2:31:02,  1.21it/s]2025-08-22:19:31:52,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1087/12032 [57:11<2:32:54,  1.19it/s]2025-08-22:19:31:53,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1088/12032 [57:14<4:02:35,  1.33s/it]2025-08-22:19:31:56,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1089/12032 [57:18<6:23:13,  2.10s/it]2025-08-22:19:32:00,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1090/12032 [57:22<8:00:51,  2.64s/it]2025-08-22:19:32:03,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1091/12032 [57:25<9:04:12,  2.98s/it]2025-08-22:19:32:07,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1092/12032 [57:29<9:28:44,  3.12s/it]2025-08-22:19:32:11,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1093/12032 [57:33<10:05:18,  3.32s/it]2025-08-22:19:32:14,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1094/12032 [57:36<10:32:06,  3.47s/it]2025-08-22:19:32:18,725 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1095/12032 [57:40<10:22:58,  3.42s/it]2025-08-22:19:32:22,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1096/12032 [57:44<10:56:00,  3.60s/it]2025-08-22:19:32:26,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1097/12032 [57:48<11:20:57,  3.74s/it]2025-08-22:19:32:30,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1098/12032 [57:52<11:31:42,  3.80s/it]2025-08-22:19:32:34,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1099/12032 [57:54<10:34:41,  3.48s/it]2025-08-22:19:32:36,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1100/12032 [57:58<10:50:45,  3.57s/it]2025-08-22:19:32:40,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1101/12032 [58:02<10:59:45,  3.62s/it]2025-08-22:19:32:44,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1102/12032 [58:05<10:36:15,  3.49s/it]2025-08-22:19:32:47,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1103/12032 [58:07<9:09:42,  3.02s/it] 2025-08-22:19:32:49,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1104/12032 [58:11<9:53:50,  3.26s/it]2025-08-22:19:32:53,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1105/12032 [58:15<10:21:51,  3.41s/it]2025-08-22:19:32:57,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1106/12032 [58:18<10:40:25,  3.52s/it]2025-08-22:19:33:00,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1107/12032 [58:22<10:52:24,  3.58s/it]2025-08-22:19:33:04,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1108/12032 [58:24<9:15:16,  3.05s/it] 2025-08-22:19:33:06,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1109/12032 [58:28<9:55:19,  3.27s/it]2025-08-22:19:33:10,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1110/12032 [58:30<9:14:07,  3.04s/it]2025-08-22:19:33:12,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1111/12032 [58:34<9:51:29,  3.25s/it]2025-08-22:19:33:16,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1112/12032 [58:38<10:17:42,  3.39s/it]2025-08-22:19:33:20,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1113/12032 [58:42<10:39:24,  3.51s/it]2025-08-22:19:33:23,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1114/12032 [58:45<10:52:19,  3.58s/it]2025-08-22:19:33:27,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1115/12032 [58:49<11:01:32,  3.64s/it]2025-08-22:19:33:31,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1116/12032 [58:53<11:07:33,  3.67s/it]2025-08-22:19:33:35,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1117/12032 [58:57<11:10:30,  3.69s/it]2025-08-22:19:33:38,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1118/12032 [59:00<10:50:47,  3.58s/it]2025-08-22:19:33:42,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1119/12032 [59:04<10:58:57,  3.62s/it]2025-08-22:19:33:45,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1120/12032 [59:07<11:09:05,  3.68s/it]2025-08-22:19:33:49,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1121/12032 [59:10<9:48:16,  3.23s/it] 2025-08-22:19:33:51,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1122/12032 [59:13<10:17:30,  3.40s/it]2025-08-22:19:33:55,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1123/12032 [59:17<10:36:01,  3.50s/it]2025-08-22:19:33:59,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1124/12032 [59:21<10:49:31,  3.57s/it]2025-08-22:19:34:03,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1125/12032 [59:23<9:29:23,  3.13s/it] 2025-08-22:19:34:05,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1126/12032 [59:27<10:04:59,  3.33s/it]2025-08-22:19:34:09,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1127/12032 [59:30<10:27:08,  3.45s/it]2025-08-22:19:34:12,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1128/12032 [59:34<10:42:43,  3.54s/it]2025-08-22:19:34:16,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1129/12032 [59:38<10:58:08,  3.62s/it]2025-08-22:19:34:20,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1130/12032 [59:42<11:04:09,  3.66s/it]2025-08-22:19:34:24,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1131/12032 [59:46<11:13:27,  3.71s/it]2025-08-22:19:34:27,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1132/12032 [59:49<11:16:28,  3.72s/it]2025-08-22:19:34:31,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1133/12032 [59:53<11:21:04,  3.75s/it]2025-08-22:19:34:35,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1134/12032 [59:57<11:21:26,  3.75s/it]2025-08-22:19:34:39,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1135/12032 [1:00:01<11:26:58,  3.78s/it]2025-08-22:19:34:43,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1136/12032 [1:00:04<11:23:31,  3.76s/it]2025-08-22:19:34:46,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1137/12032 [1:00:08<11:22:52,  3.76s/it]2025-08-22:19:34:50,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1138/12032 [1:00:12<11:23:18,  3.76s/it]2025-08-22:19:34:54,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1139/12032 [1:00:13<9:03:40,  2.99s/it] 2025-08-22:19:34:55,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1140/12032 [1:00:14<7:22:12,  2.44s/it]2025-08-22:19:34:56,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1141/12032 [1:00:15<5:53:13,  1.95s/it]2025-08-22:19:34:57,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1142/12032 [1:00:16<4:54:19,  1.62s/it]2025-08-22:19:34:58,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:   9%|▉         | 1143/12032 [1:00:17<4:04:30,  1.35s/it]2025-08-22:19:34:59,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1144/12032 [1:00:18<4:01:54,  1.33s/it]2025-08-22:19:35:00,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1145/12032 [1:00:19<3:28:07,  1.15s/it]2025-08-22:19:35:01,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1146/12032 [1:00:19<3:04:40,  1.02s/it]2025-08-22:19:35:01,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1147/12032 [1:00:23<5:32:41,  1.83s/it]2025-08-22:19:35:05,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1148/12032 [1:00:24<4:27:51,  1.48s/it]2025-08-22:19:35:06,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1149/12032 [1:00:25<3:51:11,  1.27s/it]2025-08-22:19:35:06,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1150/12032 [1:00:25<3:23:35,  1.12s/it]2025-08-22:19:35:07,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1151/12032 [1:00:29<5:46:01,  1.91s/it]2025-08-22:19:35:11,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1152/12032 [1:00:31<5:47:00,  1.91s/it]2025-08-22:19:35:13,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1153/12032 [1:00:35<7:29:03,  2.48s/it]2025-08-22:19:35:17,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1154/12032 [1:00:39<8:40:01,  2.87s/it]2025-08-22:19:35:20,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1155/12032 [1:00:42<8:43:09,  2.89s/it]2025-08-22:19:35:23,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1156/12032 [1:00:45<9:32:31,  3.16s/it]2025-08-22:19:35:27,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1157/12032 [1:00:48<9:01:09,  2.99s/it]2025-08-22:19:35:30,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1158/12032 [1:00:52<9:43:16,  3.22s/it]2025-08-22:19:35:34,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1159/12032 [1:00:55<10:11:28,  3.37s/it]2025-08-22:19:35:37,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1160/12032 [1:00:58<9:13:52,  3.06s/it] 2025-08-22:19:35:40,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1161/12032 [1:00:59<7:40:14,  2.54s/it]2025-08-22:19:35:41,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1162/12032 [1:01:02<7:55:13,  2.62s/it]2025-08-22:19:35:44,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1163/12032 [1:01:06<8:59:04,  2.98s/it]2025-08-22:19:35:48,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1164/12032 [1:01:10<9:46:17,  3.24s/it]2025-08-22:19:35:51,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1165/12032 [1:01:12<9:03:20,  3.00s/it]2025-08-22:19:35:54,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1166/12032 [1:01:16<9:46:23,  3.24s/it]2025-08-22:19:35:58,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1167/12032 [1:01:20<10:19:07,  3.42s/it]2025-08-22:19:36:01,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1168/12032 [1:01:23<10:36:14,  3.51s/it]2025-08-22:19:36:05,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1169/12032 [1:01:27<10:49:36,  3.59s/it]2025-08-22:19:36:09,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1170/12032 [1:01:31<11:01:06,  3.65s/it]2025-08-22:19:36:13,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1171/12032 [1:01:32<8:53:26,  2.95s/it] 2025-08-22:19:36:14,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1172/12032 [1:01:35<8:47:06,  2.91s/it]2025-08-22:19:36:17,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1173/12032 [1:01:38<8:59:51,  2.98s/it]2025-08-22:19:36:20,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1174/12032 [1:01:40<7:52:22,  2.61s/it]2025-08-22:19:36:22,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1175/12032 [1:01:44<8:55:10,  2.96s/it]2025-08-22:19:36:26,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1176/12032 [1:01:47<9:27:58,  3.14s/it]2025-08-22:19:36:29,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1177/12032 [1:01:51<10:02:52,  3.33s/it]2025-08-22:19:36:33,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1178/12032 [1:01:55<10:28:01,  3.47s/it]2025-08-22:19:36:37,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1179/12032 [1:01:59<10:45:33,  3.57s/it]2025-08-22:19:36:40,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1180/12032 [1:02:02<10:55:32,  3.62s/it]2025-08-22:19:36:44,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1181/12032 [1:02:06<11:03:42,  3.67s/it]2025-08-22:19:36:48,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1182/12032 [1:02:10<11:10:50,  3.71s/it]2025-08-22:19:36:52,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1183/12032 [1:02:14<11:13:48,  3.73s/it]2025-08-22:19:36:56,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1184/12032 [1:02:17<11:14:05,  3.73s/it]2025-08-22:19:36:59,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1185/12032 [1:02:21<11:16:09,  3.74s/it]2025-08-22:19:37:03,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1186/12032 [1:02:25<11:18:20,  3.75s/it]2025-08-22:19:37:07,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1187/12032 [1:02:29<11:19:05,  3.76s/it]2025-08-22:19:37:11,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1188/12032 [1:02:32<10:40:23,  3.54s/it]2025-08-22:19:37:14,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1189/12032 [1:02:36<10:51:55,  3.61s/it]2025-08-22:19:37:17,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1190/12032 [1:02:39<10:57:29,  3.64s/it]2025-08-22:19:37:21,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1191/12032 [1:02:43<11:03:26,  3.67s/it]2025-08-22:19:37:25,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1192/12032 [1:02:47<11:07:28,  3.69s/it]2025-08-22:19:37:29,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1193/12032 [1:02:50<10:52:37,  3.61s/it]2025-08-22:19:37:32,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1194/12032 [1:02:54<10:59:39,  3.65s/it]2025-08-22:19:37:36,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1195/12032 [1:02:58<11:04:05,  3.68s/it]2025-08-22:19:37:40,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1196/12032 [1:03:01<11:08:46,  3.70s/it]2025-08-22:19:37:43,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1197/12032 [1:03:05<11:08:25,  3.70s/it]2025-08-22:19:37:47,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1198/12032 [1:03:09<10:58:22,  3.65s/it]2025-08-22:19:37:51,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1199/12032 [1:03:12<11:05:01,  3.68s/it]2025-08-22:19:37:54,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1200/12032 [1:03:16<11:08:44,  3.70s/it]2025-08-22:19:37:58,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1201/12032 [1:03:20<11:11:54,  3.72s/it]2025-08-22:19:38:02,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1202/12032 [1:03:23<10:25:33,  3.47s/it]2025-08-22:19:38:05,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|▉         | 1203/12032 [1:03:27<10:45:02,  3.57s/it]2025-08-22:19:38:09,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1204/12032 [1:03:30<10:37:16,  3.53s/it]2025-08-22:19:38:12,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1205/12032 [1:03:34<10:51:57,  3.61s/it]2025-08-22:19:38:16,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1206/12032 [1:03:38<11:02:05,  3.67s/it]2025-08-22:19:38:20,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1207/12032 [1:03:42<11:11:13,  3.72s/it]2025-08-22:19:38:23,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1208/12032 [1:03:45<11:13:45,  3.73s/it]2025-08-22:19:38:27,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1209/12032 [1:03:47<9:05:47,  3.03s/it] 2025-08-22:19:38:29,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1210/12032 [1:03:47<7:05:33,  2.36s/it]2025-08-22:19:38:29,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1211/12032 [1:03:49<6:30:33,  2.17s/it]2025-08-22:19:38:31,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1212/12032 [1:03:51<6:29:02,  2.16s/it]2025-08-22:19:38:33,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1213/12032 [1:03:53<5:49:09,  1.94s/it]2025-08-22:19:38:35,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1214/12032 [1:03:54<4:48:44,  1.60s/it]2025-08-22:19:38:35,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1215/12032 [1:03:54<4:05:44,  1.36s/it]2025-08-22:19:38:36,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1216/12032 [1:03:55<3:19:19,  1.11s/it]2025-08-22:19:38:37,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1217/12032 [1:03:57<4:20:42,  1.45s/it]2025-08-22:19:38:39,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1218/12032 [1:04:01<6:25:49,  2.14s/it]2025-08-22:19:38:43,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1219/12032 [1:04:05<7:53:55,  2.63s/it]2025-08-22:19:38:47,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1220/12032 [1:04:08<8:53:34,  2.96s/it]2025-08-22:19:38:50,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1221/12032 [1:04:12<9:36:43,  3.20s/it]2025-08-22:19:38:54,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1222/12032 [1:04:16<10:06:53,  3.37s/it]2025-08-22:19:38:58,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1223/12032 [1:04:20<10:27:45,  3.48s/it]2025-08-22:19:39:02,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1224/12032 [1:04:23<10:42:31,  3.57s/it]2025-08-22:19:39:05,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1225/12032 [1:04:25<9:05:31,  3.03s/it] 2025-08-22:19:39:07,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1226/12032 [1:04:28<8:43:19,  2.91s/it]2025-08-22:19:39:10,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1227/12032 [1:04:32<9:29:09,  3.16s/it]2025-08-22:19:39:13,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1228/12032 [1:04:34<8:41:28,  2.90s/it]2025-08-22:19:39:16,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1229/12032 [1:04:38<9:29:54,  3.17s/it]2025-08-22:19:39:19,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1230/12032 [1:04:39<7:59:38,  2.66s/it]2025-08-22:19:39:21,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1231/12032 [1:04:41<7:26:16,  2.48s/it]2025-08-22:19:39:23,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1232/12032 [1:04:43<6:44:08,  2.25s/it]2025-08-22:19:39:25,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1233/12032 [1:04:47<8:04:23,  2.69s/it]2025-08-22:19:39:28,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1234/12032 [1:04:50<9:01:46,  3.01s/it]2025-08-22:19:39:32,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1235/12032 [1:04:54<9:44:00,  3.25s/it]2025-08-22:19:39:36,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1236/12032 [1:04:57<8:56:31,  2.98s/it]2025-08-22:19:39:38,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1237/12032 [1:04:59<8:22:05,  2.79s/it]2025-08-22:19:39:41,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1238/12032 [1:05:01<8:01:01,  2.67s/it]2025-08-22:19:39:43,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1239/12032 [1:05:05<8:59:48,  3.00s/it]2025-08-22:19:39:47,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1240/12032 [1:05:09<9:43:16,  3.24s/it]2025-08-22:19:39:51,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1241/12032 [1:05:13<10:11:57,  3.40s/it]2025-08-22:19:39:54,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1242/12032 [1:05:16<10:34:38,  3.53s/it]2025-08-22:19:39:58,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1243/12032 [1:05:20<10:22:21,  3.46s/it]2025-08-22:19:40:02,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1244/12032 [1:05:23<10:36:53,  3.54s/it]2025-08-22:19:40:05,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1245/12032 [1:05:25<8:38:06,  2.88s/it] 2025-08-22:19:40:07,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1246/12032 [1:05:26<7:29:20,  2.50s/it]2025-08-22:19:40:08,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1247/12032 [1:05:30<8:35:41,  2.87s/it]2025-08-22:19:40:12,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1248/12032 [1:05:34<9:34:42,  3.20s/it]2025-08-22:19:40:16,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1249/12032 [1:05:38<10:04:58,  3.37s/it]2025-08-22:19:40:20,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1250/12032 [1:05:40<8:52:52,  2.97s/it] 2025-08-22:19:40:22,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1251/12032 [1:05:44<9:38:47,  3.22s/it]2025-08-22:19:40:26,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1252/12032 [1:05:47<9:56:23,  3.32s/it]2025-08-22:19:40:29,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1253/12032 [1:05:49<8:14:12,  2.75s/it]2025-08-22:19:40:31,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1254/12032 [1:05:51<8:14:55,  2.76s/it]2025-08-22:19:40:33,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1255/12032 [1:05:55<9:10:05,  3.06s/it]2025-08-22:19:40:37,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1256/12032 [1:05:59<9:23:34,  3.14s/it]2025-08-22:19:40:40,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1257/12032 [1:06:01<9:08:48,  3.06s/it]2025-08-22:19:40:43,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1258/12032 [1:06:05<9:47:35,  3.27s/it]2025-08-22:19:40:47,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1259/12032 [1:06:08<9:42:44,  3.25s/it]2025-08-22:19:40:50,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1260/12032 [1:06:11<8:50:15,  2.95s/it]2025-08-22:19:40:53,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1261/12032 [1:06:12<6:58:53,  2.33s/it]2025-08-22:19:40:53,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1262/12032 [1:06:12<5:26:35,  1.82s/it]2025-08-22:19:40:54,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  10%|█         | 1263/12032 [1:06:16<6:48:51,  2.28s/it]2025-08-22:19:40:57,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1264/12032 [1:06:17<6:17:04,  2.10s/it]2025-08-22:19:40:59,551 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1265/12032 [1:06:19<6:18:56,  2.11s/it]2025-08-22:19:41:01,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1266/12032 [1:06:20<5:04:47,  1.70s/it]2025-08-22:19:41:02,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1267/12032 [1:06:22<5:17:42,  1.77s/it]2025-08-22:19:41:04,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1268/12032 [1:06:24<5:26:03,  1.82s/it]2025-08-22:19:41:06,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1269/12032 [1:06:25<4:29:16,  1.50s/it]2025-08-22:19:41:07,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1270/12032 [1:06:26<4:05:07,  1.37s/it]2025-08-22:19:41:08,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1271/12032 [1:06:27<3:43:09,  1.24s/it]2025-08-22:19:41:09,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1272/12032 [1:06:29<4:36:52,  1.54s/it]2025-08-22:19:41:11,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1273/12032 [1:06:30<3:54:43,  1.31s/it]2025-08-22:19:41:12,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1274/12032 [1:06:30<3:21:42,  1.13s/it]2025-08-22:19:41:12,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1275/12032 [1:06:32<3:23:11,  1.13s/it]2025-08-22:19:41:13,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1276/12032 [1:06:33<3:27:48,  1.16s/it]2025-08-22:19:41:15,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1277/12032 [1:06:37<5:46:28,  1.93s/it]2025-08-22:19:41:18,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1278/12032 [1:06:40<7:24:10,  2.48s/it]2025-08-22:19:41:22,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1279/12032 [1:06:44<8:32:58,  2.86s/it]2025-08-22:19:41:26,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1280/12032 [1:06:48<9:27:04,  3.16s/it]2025-08-22:19:41:30,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1281/12032 [1:06:52<10:00:20,  3.35s/it]2025-08-22:19:41:34,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1282/12032 [1:06:55<10:22:52,  3.48s/it]2025-08-22:19:41:37,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1283/12032 [1:06:58<9:26:08,  3.16s/it] 2025-08-22:19:41:40,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1284/12032 [1:07:01<9:12:30,  3.08s/it]2025-08-22:19:41:43,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1285/12032 [1:07:05<9:51:10,  3.30s/it]2025-08-22:19:41:46,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1286/12032 [1:07:08<10:17:12,  3.45s/it]2025-08-22:19:41:50,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1287/12032 [1:07:12<10:00:07,  3.35s/it]2025-08-22:19:41:53,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1288/12032 [1:07:14<9:26:25,  3.16s/it] 2025-08-22:19:41:56,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1289/12032 [1:07:18<9:59:56,  3.35s/it]2025-08-22:19:42:00,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1290/12032 [1:07:21<9:29:12,  3.18s/it]2025-08-22:19:42:03,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1291/12032 [1:07:25<10:00:50,  3.36s/it]2025-08-22:19:42:06,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1292/12032 [1:07:28<10:22:39,  3.48s/it]2025-08-22:19:42:10,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1293/12032 [1:07:32<10:39:02,  3.57s/it]2025-08-22:19:42:14,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1294/12032 [1:07:36<10:48:48,  3.63s/it]2025-08-22:19:42:18,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1295/12032 [1:07:40<10:54:58,  3.66s/it]2025-08-22:19:42:21,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1296/12032 [1:07:42<9:45:25,  3.27s/it] 2025-08-22:19:42:24,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1297/12032 [1:07:46<10:11:57,  3.42s/it]2025-08-22:19:42:28,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1298/12032 [1:07:50<10:31:05,  3.53s/it]2025-08-22:19:42:31,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1299/12032 [1:07:53<10:44:45,  3.60s/it]2025-08-22:19:42:35,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1300/12032 [1:07:57<10:24:55,  3.49s/it]2025-08-22:19:42:38,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1301/12032 [1:07:59<9:49:41,  3.30s/it] 2025-08-22:19:42:41,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1302/12032 [1:08:03<10:15:00,  3.44s/it]2025-08-22:19:42:45,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1303/12032 [1:08:07<10:31:21,  3.53s/it]2025-08-22:19:42:49,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1304/12032 [1:08:10<9:49:34,  3.30s/it] 2025-08-22:19:42:51,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1305/12032 [1:08:13<10:17:23,  3.45s/it]2025-08-22:19:42:55,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1306/12032 [1:08:16<9:50:50,  3.31s/it] 2025-08-22:19:42:58,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1307/12032 [1:08:20<10:16:03,  3.45s/it]2025-08-22:19:43:02,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1308/12032 [1:08:24<10:34:14,  3.55s/it]2025-08-22:19:43:06,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1309/12032 [1:08:26<9:10:24,  3.08s/it] 2025-08-22:19:43:08,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1310/12032 [1:08:30<9:47:35,  3.29s/it]2025-08-22:19:43:12,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1311/12032 [1:08:33<10:09:41,  3.41s/it]2025-08-22:19:43:15,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1312/12032 [1:08:37<10:29:03,  3.52s/it]2025-08-22:19:43:19,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1313/12032 [1:08:41<10:41:12,  3.59s/it]2025-08-22:19:43:23,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1314/12032 [1:08:45<10:48:52,  3.63s/it]2025-08-22:19:43:27,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1315/12032 [1:08:48<10:12:32,  3.43s/it]2025-08-22:19:43:30,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1316/12032 [1:08:50<9:10:58,  3.08s/it] 2025-08-22:19:43:32,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1317/12032 [1:08:51<6:58:30,  2.34s/it]2025-08-22:19:43:32,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1318/12032 [1:08:54<8:14:01,  2.77s/it]2025-08-22:19:43:36,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1319/12032 [1:08:58<9:14:57,  3.11s/it]2025-08-22:19:43:40,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1320/12032 [1:09:02<9:49:55,  3.30s/it]2025-08-22:19:43:44,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1321/12032 [1:09:05<9:19:13,  3.13s/it]2025-08-22:19:43:47,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1322/12032 [1:09:08<9:53:14,  3.32s/it]2025-08-22:19:43:50,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1323/12032 [1:09:09<7:34:23,  2.55s/it]2025-08-22:19:43:51,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1324/12032 [1:09:10<6:24:59,  2.16s/it]2025-08-22:19:43:52,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1325/12032 [1:09:11<5:18:23,  1.78s/it]2025-08-22:19:43:53,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1326/12032 [1:09:12<4:31:13,  1.52s/it]2025-08-22:19:43:54,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1327/12032 [1:09:16<6:32:19,  2.20s/it]2025-08-22:19:43:58,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1328/12032 [1:09:17<5:03:01,  1.70s/it]2025-08-22:19:43:58,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1329/12032 [1:09:19<5:58:38,  2.01s/it]2025-08-22:19:44:01,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1330/12032 [1:09:20<4:54:24,  1.65s/it]2025-08-22:19:44:02,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1331/12032 [1:09:24<6:48:30,  2.29s/it]2025-08-22:19:44:06,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1332/12032 [1:09:25<6:01:42,  2.03s/it]2025-08-22:19:44:07,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1333/12032 [1:09:26<5:04:35,  1.71s/it]2025-08-22:19:44:08,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1334/12032 [1:09:27<4:16:58,  1.44s/it]2025-08-22:19:44:09,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1335/12032 [1:09:31<6:22:24,  2.14s/it]2025-08-22:19:44:13,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1336/12032 [1:09:33<6:36:36,  2.22s/it]2025-08-22:19:44:15,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1337/12032 [1:09:37<8:00:04,  2.69s/it]2025-08-22:19:44:19,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1338/12032 [1:09:41<9:20:56,  3.15s/it]2025-08-22:19:44:23,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1339/12032 [1:09:45<10:09:00,  3.42s/it]2025-08-22:19:44:27,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1340/12032 [1:09:49<10:41:00,  3.60s/it]2025-08-22:19:44:31,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1341/12032 [1:09:53<10:52:01,  3.66s/it]2025-08-22:19:44:35,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1342/12032 [1:09:57<10:58:21,  3.70s/it]2025-08-22:19:44:39,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1343/12032 [1:10:01<11:02:03,  3.72s/it]2025-08-22:19:44:43,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1344/12032 [1:10:04<10:41:52,  3.60s/it]2025-08-22:19:44:46,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1345/12032 [1:10:07<10:20:37,  3.48s/it]2025-08-22:19:44:49,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1346/12032 [1:10:11<10:36:16,  3.57s/it]2025-08-22:19:44:53,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1347/12032 [1:10:15<10:46:50,  3.63s/it]2025-08-22:19:44:57,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1348/12032 [1:10:19<10:59:47,  3.71s/it]2025-08-22:19:45:01,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1349/12032 [1:10:21<9:27:25,  3.19s/it] 2025-08-22:19:45:03,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1350/12032 [1:10:24<9:58:20,  3.36s/it]2025-08-22:19:45:06,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1351/12032 [1:10:28<10:24:06,  3.51s/it]2025-08-22:19:45:10,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1352/12032 [1:10:32<10:39:26,  3.59s/it]2025-08-22:19:45:14,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█         | 1353/12032 [1:10:36<10:48:58,  3.65s/it]2025-08-22:19:45:18,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1354/12032 [1:10:40<11:00:37,  3.71s/it]2025-08-22:19:45:22,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1355/12032 [1:10:44<11:04:22,  3.73s/it]2025-08-22:19:45:25,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1356/12032 [1:10:47<11:07:28,  3.75s/it]2025-08-22:19:45:29,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1357/12032 [1:10:51<10:44:32,  3.62s/it]2025-08-22:19:45:32,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1358/12032 [1:10:54<10:26:39,  3.52s/it]2025-08-22:19:45:36,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1359/12032 [1:10:58<10:40:28,  3.60s/it]2025-08-22:19:45:40,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1360/12032 [1:11:01<10:50:38,  3.66s/it]2025-08-22:19:45:43,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1361/12032 [1:11:05<10:55:38,  3.69s/it]2025-08-22:19:45:47,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1362/12032 [1:11:07<9:13:56,  3.11s/it] 2025-08-22:19:45:49,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1363/12032 [1:11:11<9:47:53,  3.31s/it]2025-08-22:19:45:53,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1364/12032 [1:11:15<10:15:47,  3.46s/it]2025-08-22:19:45:56,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1365/12032 [1:11:18<10:32:11,  3.56s/it]2025-08-22:19:46:00,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1366/12032 [1:11:21<9:42:51,  3.28s/it] 2025-08-22:19:46:03,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1367/12032 [1:11:25<10:09:13,  3.43s/it]2025-08-22:19:46:07,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1368/12032 [1:11:29<10:27:02,  3.53s/it]2025-08-22:19:46:10,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1369/12032 [1:11:32<10:26:10,  3.52s/it]2025-08-22:19:46:14,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1370/12032 [1:11:34<8:52:28,  3.00s/it] 2025-08-22:19:46:16,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1371/12032 [1:11:38<9:34:37,  3.23s/it]2025-08-22:19:46:19,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1372/12032 [1:11:41<10:02:23,  3.39s/it]2025-08-22:19:46:23,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1373/12032 [1:11:45<10:11:41,  3.44s/it]2025-08-22:19:46:27,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1374/12032 [1:11:49<10:30:22,  3.55s/it]2025-08-22:19:46:31,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1375/12032 [1:11:52<10:41:05,  3.61s/it]2025-08-22:19:46:34,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1376/12032 [1:11:56<10:51:15,  3.67s/it]2025-08-22:19:46:38,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1377/12032 [1:12:00<10:59:27,  3.71s/it]2025-08-22:19:46:42,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1378/12032 [1:12:03<10:10:12,  3.44s/it]2025-08-22:19:46:45,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1379/12032 [1:12:07<10:30:03,  3.55s/it]2025-08-22:19:46:49,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1380/12032 [1:12:10<9:59:09,  3.37s/it] 2025-08-22:19:46:52,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1381/12032 [1:12:13<9:49:32,  3.32s/it]2025-08-22:19:46:55,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1382/12032 [1:12:16<9:36:51,  3.25s/it]2025-08-22:19:46:58,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  11%|█▏        | 1383/12032 [1:12:20<10:04:21,  3.41s/it]2025-08-22:19:47:02,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1384/12032 [1:12:23<10:24:16,  3.52s/it]2025-08-22:19:47:05,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1385/12032 [1:12:26<9:47:19,  3.31s/it] 2025-08-22:19:47:08,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1386/12032 [1:12:29<9:29:24,  3.21s/it]2025-08-22:19:47:11,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1387/12032 [1:12:32<9:02:14,  3.06s/it]2025-08-22:19:47:14,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1388/12032 [1:12:34<8:20:02,  2.82s/it]2025-08-22:19:47:16,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1389/12032 [1:12:38<9:10:53,  3.11s/it]2025-08-22:19:47:20,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1390/12032 [1:12:42<9:47:09,  3.31s/it]2025-08-22:19:47:24,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1391/12032 [1:12:44<8:28:26,  2.87s/it]2025-08-22:19:47:25,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1392/12032 [1:12:47<9:16:29,  3.14s/it]2025-08-22:19:47:29,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1393/12032 [1:12:50<8:20:37,  2.82s/it]2025-08-22:19:47:31,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1394/12032 [1:12:51<7:21:04,  2.49s/it]2025-08-22:19:47:33,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1395/12032 [1:12:52<5:51:31,  1.98s/it]2025-08-22:19:47:34,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1396/12032 [1:12:53<4:42:02,  1.59s/it]2025-08-22:19:47:35,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1397/12032 [1:12:56<6:30:55,  2.21s/it]2025-08-22:19:47:38,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1398/12032 [1:12:57<5:12:03,  1.76s/it]2025-08-22:19:47:39,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1399/12032 [1:12:58<4:42:43,  1.60s/it]2025-08-22:19:47:40,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1400/12032 [1:13:00<4:24:53,  1.49s/it]2025-08-22:19:47:41,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1401/12032 [1:13:00<3:48:41,  1.29s/it]2025-08-22:19:47:42,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1402/12032 [1:13:01<3:16:24,  1.11s/it]2025-08-22:19:47:43,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1403/12032 [1:13:03<3:43:32,  1.26s/it]2025-08-22:19:47:44,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1404/12032 [1:13:03<3:13:34,  1.09s/it]2025-08-22:19:47:45,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1405/12032 [1:13:06<4:45:47,  1.61s/it]2025-08-22:19:47:48,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1406/12032 [1:13:07<4:26:53,  1.51s/it]2025-08-22:19:47:49,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1407/12032 [1:13:08<3:45:44,  1.27s/it]2025-08-22:19:47:50,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1408/12032 [1:13:09<3:22:28,  1.14s/it]2025-08-22:19:47:51,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1409/12032 [1:13:13<5:40:56,  1.93s/it]2025-08-22:19:47:55,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1410/12032 [1:13:15<5:55:38,  2.01s/it]2025-08-22:19:47:57,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1411/12032 [1:13:19<7:28:12,  2.53s/it]2025-08-22:19:48:01,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1412/12032 [1:13:22<8:33:44,  2.90s/it]2025-08-22:19:48:04,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1413/12032 [1:13:26<9:22:28,  3.18s/it]2025-08-22:19:48:08,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1414/12032 [1:13:29<8:41:12,  2.95s/it]2025-08-22:19:48:11,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1415/12032 [1:13:32<9:25:34,  3.20s/it]2025-08-22:19:48:14,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1416/12032 [1:13:36<9:55:58,  3.37s/it]2025-08-22:19:48:18,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1417/12032 [1:13:40<10:18:22,  3.50s/it]2025-08-22:19:48:22,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1418/12032 [1:13:42<8:51:14,  3.00s/it] 2025-08-22:19:48:24,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1419/12032 [1:13:46<9:33:37,  3.24s/it]2025-08-22:19:48:28,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1420/12032 [1:13:49<9:56:15,  3.37s/it]2025-08-22:19:48:31,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1421/12032 [1:13:53<10:16:00,  3.48s/it]2025-08-22:19:48:35,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1422/12032 [1:13:56<9:19:36,  3.16s/it] 2025-08-22:19:48:37,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1423/12032 [1:13:59<9:36:36,  3.26s/it]2025-08-22:19:48:41,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1424/12032 [1:14:02<9:02:32,  3.07s/it]2025-08-22:19:48:43,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1425/12032 [1:14:05<9:39:10,  3.28s/it]2025-08-22:19:48:47,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1426/12032 [1:14:09<9:54:47,  3.36s/it]2025-08-22:19:48:51,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1427/12032 [1:14:13<10:13:49,  3.47s/it]2025-08-22:19:48:55,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1428/12032 [1:14:16<10:29:22,  3.56s/it]2025-08-22:19:48:58,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1429/12032 [1:14:18<8:47:37,  2.99s/it] 2025-08-22:19:49:00,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1430/12032 [1:14:22<9:28:18,  3.22s/it]2025-08-22:19:49:04,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1431/12032 [1:14:26<9:57:06,  3.38s/it]2025-08-22:19:49:07,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1432/12032 [1:14:29<10:16:45,  3.49s/it]2025-08-22:19:49:11,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1433/12032 [1:14:33<10:28:32,  3.56s/it]2025-08-22:19:49:15,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1434/12032 [1:14:37<10:37:41,  3.61s/it]2025-08-22:19:49:19,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1435/12032 [1:14:41<10:44:30,  3.65s/it]2025-08-22:19:49:22,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1436/12032 [1:14:44<10:50:19,  3.68s/it]2025-08-22:19:49:26,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1437/12032 [1:14:48<10:55:21,  3.71s/it]2025-08-22:19:49:30,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1438/12032 [1:14:50<9:28:34,  3.22s/it] 2025-08-22:19:49:32,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1439/12032 [1:14:52<7:55:29,  2.69s/it]2025-08-22:19:49:33,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1440/12032 [1:14:55<8:49:41,  3.00s/it]2025-08-22:19:49:37,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1441/12032 [1:14:57<7:29:50,  2.55s/it]2025-08-22:19:49:39,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1442/12032 [1:15:01<8:34:57,  2.92s/it]2025-08-22:19:49:42,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1443/12032 [1:15:03<8:25:27,  2.86s/it]2025-08-22:19:49:45,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1444/12032 [1:15:07<9:11:40,  3.13s/it]2025-08-22:19:49:49,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1445/12032 [1:15:11<9:44:43,  3.31s/it]2025-08-22:19:49:53,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1446/12032 [1:15:15<10:07:28,  3.44s/it]2025-08-22:19:49:56,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1447/12032 [1:15:16<8:38:50,  2.94s/it] 2025-08-22:19:49:58,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1448/12032 [1:15:20<9:22:24,  3.19s/it]2025-08-22:19:50:02,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1449/12032 [1:15:24<9:52:44,  3.36s/it]2025-08-22:19:50:06,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1450/12032 [1:15:28<10:11:55,  3.47s/it]2025-08-22:19:50:09,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1451/12032 [1:15:31<10:25:26,  3.55s/it]2025-08-22:19:50:13,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1452/12032 [1:15:34<9:54:52,  3.37s/it] 2025-08-22:19:50:16,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1453/12032 [1:15:38<10:14:27,  3.49s/it]2025-08-22:19:50:20,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1454/12032 [1:15:41<9:24:55,  3.20s/it] 2025-08-22:19:50:22,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1455/12032 [1:15:42<7:52:05,  2.68s/it]2025-08-22:19:50:24,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1456/12032 [1:15:46<8:51:01,  3.01s/it]2025-08-22:19:50:28,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1457/12032 [1:15:48<8:15:41,  2.81s/it]2025-08-22:19:50:30,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1458/12032 [1:15:52<9:07:00,  3.10s/it]2025-08-22:19:50:34,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1459/12032 [1:15:55<8:46:00,  2.98s/it]2025-08-22:19:50:37,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1460/12032 [1:15:58<9:10:51,  3.13s/it]2025-08-22:19:50:40,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1461/12032 [1:16:01<9:14:37,  3.15s/it]2025-08-22:19:50:43,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1462/12032 [1:16:04<8:47:34,  2.99s/it]2025-08-22:19:50:46,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1463/12032 [1:16:08<9:26:56,  3.22s/it]2025-08-22:19:50:50,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1464/12032 [1:16:09<8:07:39,  2.77s/it]2025-08-22:19:50:51,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1465/12032 [1:16:10<6:26:02,  2.19s/it]2025-08-22:19:50:52,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1466/12032 [1:16:12<5:53:21,  2.01s/it]2025-08-22:19:50:54,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1467/12032 [1:16:13<4:42:39,  1.61s/it]2025-08-22:19:50:54,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1468/12032 [1:16:14<4:22:36,  1.49s/it]2025-08-22:19:50:56,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1469/12032 [1:16:14<3:39:32,  1.25s/it]2025-08-22:19:50:56,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1470/12032 [1:16:15<3:15:28,  1.11s/it]2025-08-22:19:50:57,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1471/12032 [1:16:17<3:32:48,  1.21s/it]2025-08-22:19:50:59,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1472/12032 [1:16:17<3:00:00,  1.02s/it]2025-08-22:19:50:59,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1473/12032 [1:16:21<5:08:00,  1.75s/it]2025-08-22:19:51:03,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1474/12032 [1:16:24<6:55:20,  2.36s/it]2025-08-22:19:51:06,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1475/12032 [1:16:27<7:12:56,  2.46s/it]2025-08-22:19:51:09,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1476/12032 [1:16:30<7:55:43,  2.70s/it]2025-08-22:19:51:12,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1477/12032 [1:16:32<7:00:37,  2.39s/it]2025-08-22:19:51:14,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1478/12032 [1:16:33<6:05:06,  2.08s/it]2025-08-22:19:51:15,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1479/12032 [1:16:37<7:35:35,  2.59s/it]2025-08-22:19:51:19,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1480/12032 [1:16:41<8:38:22,  2.95s/it]2025-08-22:19:51:23,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1481/12032 [1:16:45<9:22:58,  3.20s/it]2025-08-22:19:51:27,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1482/12032 [1:16:49<9:52:10,  3.37s/it]2025-08-22:19:51:30,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1483/12032 [1:16:52<9:34:46,  3.27s/it]2025-08-22:19:51:33,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1484/12032 [1:16:54<8:32:04,  2.91s/it]2025-08-22:19:51:36,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1485/12032 [1:16:57<9:17:12,  3.17s/it]2025-08-22:19:51:39,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1486/12032 [1:17:01<9:49:37,  3.35s/it]2025-08-22:19:51:43,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1487/12032 [1:17:04<9:27:12,  3.23s/it]2025-08-22:19:51:46,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1488/12032 [1:17:08<9:46:43,  3.34s/it]2025-08-22:19:51:50,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1489/12032 [1:17:12<10:10:48,  3.48s/it]2025-08-22:19:51:53,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1490/12032 [1:17:15<10:26:42,  3.57s/it]2025-08-22:19:51:57,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1491/12032 [1:17:19<10:37:27,  3.63s/it]2025-08-22:19:52:01,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1492/12032 [1:17:23<10:44:37,  3.67s/it]2025-08-22:19:52:05,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1493/12032 [1:17:27<10:53:13,  3.72s/it]2025-08-22:19:52:09,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1494/12032 [1:17:31<10:57:25,  3.74s/it]2025-08-22:19:52:12,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1495/12032 [1:17:34<10:35:39,  3.62s/it]2025-08-22:19:52:16,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1496/12032 [1:17:38<10:44:39,  3.67s/it]2025-08-22:19:52:19,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1497/12032 [1:17:41<10:50:37,  3.71s/it]2025-08-22:19:52:23,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1498/12032 [1:17:45<10:54:21,  3.73s/it]2025-08-22:19:52:27,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1499/12032 [1:17:48<10:07:58,  3.46s/it]2025-08-22:19:52:30,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1500/12032 [1:17:51<9:40:35,  3.31s/it] 2025-08-22:19:52:33,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1501/12032 [1:17:55<10:06:11,  3.45s/it]2025-08-22:19:52:37,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1502/12032 [1:17:58<10:17:01,  3.52s/it]2025-08-22:19:52:40,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▏        | 1503/12032 [1:18:02<10:31:45,  3.60s/it]2025-08-22:19:52:44,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  12%|█▎        | 1504/12032 [1:18:06<10:43:21,  3.67s/it]2025-08-22:19:52:48,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1505/12032 [1:18:09<9:56:38,  3.40s/it] 2025-08-22:19:52:51,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1506/12032 [1:18:12<9:25:00,  3.22s/it]2025-08-22:19:52:54,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1507/12032 [1:18:16<9:59:10,  3.42s/it]2025-08-22:19:52:57,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1508/12032 [1:18:19<10:23:35,  3.56s/it]2025-08-22:19:53:01,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1509/12032 [1:18:23<10:35:08,  3.62s/it]2025-08-22:19:53:05,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1510/12032 [1:18:27<10:52:14,  3.72s/it]2025-08-22:19:53:09,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1511/12032 [1:18:31<10:56:35,  3.74s/it]2025-08-22:19:53:13,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1512/12032 [1:18:34<10:15:04,  3.51s/it]2025-08-22:19:53:16,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1513/12032 [1:18:37<9:41:17,  3.32s/it] 2025-08-22:19:53:19,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1514/12032 [1:18:41<10:09:54,  3.48s/it]2025-08-22:19:53:22,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1515/12032 [1:18:44<10:10:06,  3.48s/it]2025-08-22:19:53:26,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1516/12032 [1:18:48<10:25:18,  3.57s/it]2025-08-22:19:53:30,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1517/12032 [1:18:52<10:37:17,  3.64s/it]2025-08-22:19:53:34,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1518/12032 [1:18:55<10:44:02,  3.68s/it]2025-08-22:19:53:37,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1519/12032 [1:18:59<10:56:19,  3.75s/it]2025-08-22:19:53:41,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1520/12032 [1:19:03<10:59:25,  3.76s/it]2025-08-22:19:53:45,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1521/12032 [1:19:07<11:00:16,  3.77s/it]2025-08-22:19:53:49,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1522/12032 [1:19:11<11:00:52,  3.77s/it]2025-08-22:19:53:53,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1523/12032 [1:19:15<11:06:58,  3.81s/it]2025-08-22:19:53:56,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1524/12032 [1:19:19<11:11:18,  3.83s/it]2025-08-22:19:54:00,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1525/12032 [1:19:22<11:12:09,  3.84s/it]2025-08-22:19:54:04,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1526/12032 [1:19:26<11:13:47,  3.85s/it]2025-08-22:19:54:08,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1527/12032 [1:19:30<11:10:51,  3.83s/it]2025-08-22:19:54:12,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1528/12032 [1:19:34<11:14:08,  3.85s/it]2025-08-22:19:54:16,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1529/12032 [1:19:38<11:12:47,  3.84s/it]2025-08-22:19:54:20,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1530/12032 [1:19:42<11:10:53,  3.83s/it]2025-08-22:19:54:23,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1531/12032 [1:19:45<11:09:16,  3.82s/it]2025-08-22:19:54:27,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1532/12032 [1:19:49<11:06:56,  3.81s/it]2025-08-22:19:54:31,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1533/12032 [1:19:53<11:06:10,  3.81s/it]2025-08-22:19:54:35,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1534/12032 [1:19:57<11:10:49,  3.83s/it]2025-08-22:19:54:39,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1535/12032 [1:20:01<11:09:03,  3.82s/it]2025-08-22:19:54:42,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1536/12032 [1:20:04<11:06:50,  3.81s/it]2025-08-22:19:54:46,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1537/12032 [1:20:08<11:05:49,  3.81s/it]2025-08-22:19:54:50,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1538/12032 [1:20:12<11:06:36,  3.81s/it]2025-08-22:19:54:54,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1539/12032 [1:20:16<11:06:30,  3.81s/it]2025-08-22:19:54:58,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1540/12032 [1:20:20<11:05:56,  3.81s/it]2025-08-22:19:55:01,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1541/12032 [1:20:23<11:04:50,  3.80s/it]2025-08-22:19:55:05,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1542/12032 [1:20:27<11:06:14,  3.81s/it]2025-08-22:19:55:09,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1543/12032 [1:20:31<11:05:29,  3.81s/it]2025-08-22:19:55:13,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1544/12032 [1:20:35<11:08:10,  3.82s/it]2025-08-22:19:55:17,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1545/12032 [1:20:39<11:07:20,  3.82s/it]2025-08-22:19:55:21,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1546/12032 [1:20:43<11:07:46,  3.82s/it]2025-08-22:19:55:24,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1547/12032 [1:20:46<11:06:36,  3.81s/it]2025-08-22:19:55:28,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1548/12032 [1:20:50<11:05:21,  3.81s/it]2025-08-22:19:55:32,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1549/12032 [1:20:54<11:04:02,  3.80s/it]2025-08-22:19:55:36,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1550/12032 [1:20:57<10:48:26,  3.71s/it]2025-08-22:19:55:39,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1551/12032 [1:21:01<10:53:00,  3.74s/it]2025-08-22:19:55:43,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1552/12032 [1:21:05<10:56:58,  3.76s/it]2025-08-22:19:55:47,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1553/12032 [1:21:09<10:56:25,  3.76s/it]2025-08-22:19:55:51,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1554/12032 [1:21:13<10:57:29,  3.76s/it]2025-08-22:19:55:54,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1555/12032 [1:21:15<9:59:20,  3.43s/it] 2025-08-22:19:55:57,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1556/12032 [1:21:19<10:18:37,  3.54s/it]2025-08-22:19:56:01,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1557/12032 [1:21:23<10:31:31,  3.62s/it]2025-08-22:19:56:05,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1558/12032 [1:21:26<10:31:03,  3.62s/it]2025-08-22:19:56:08,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1559/12032 [1:21:30<10:40:31,  3.67s/it]2025-08-22:19:56:12,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1560/12032 [1:21:34<10:47:55,  3.71s/it]2025-08-22:19:56:16,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1561/12032 [1:21:38<10:53:06,  3.74s/it]2025-08-22:19:56:20,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1562/12032 [1:21:42<10:55:52,  3.76s/it]2025-08-22:19:56:24,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1563/12032 [1:21:45<10:58:21,  3.77s/it]2025-08-22:19:56:27,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1564/12032 [1:21:49<10:57:13,  3.77s/it]2025-08-22:19:56:31,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1565/12032 [1:21:53<10:58:09,  3.77s/it]2025-08-22:19:56:35,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1566/12032 [1:21:57<11:00:19,  3.79s/it]2025-08-22:19:56:39,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1567/12032 [1:22:01<10:59:14,  3.78s/it]2025-08-22:19:56:42,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1568/12032 [1:22:04<10:58:35,  3.78s/it]2025-08-22:19:56:46,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1569/12032 [1:22:08<10:58:12,  3.77s/it]2025-08-22:19:56:50,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1570/12032 [1:22:12<10:57:39,  3.77s/it]2025-08-22:19:56:54,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1571/12032 [1:22:16<10:57:48,  3.77s/it]2025-08-22:19:56:58,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1572/12032 [1:22:19<10:57:03,  3.77s/it]2025-08-22:19:57:01,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1573/12032 [1:22:23<10:57:02,  3.77s/it]2025-08-22:19:57:05,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1574/12032 [1:22:27<10:57:41,  3.77s/it]2025-08-22:19:57:09,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1575/12032 [1:22:31<10:58:14,  3.78s/it]2025-08-22:19:57:13,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1576/12032 [1:22:35<10:57:40,  3.77s/it]2025-08-22:19:57:16,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1577/12032 [1:22:38<10:58:30,  3.78s/it]2025-08-22:19:57:20,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1578/12032 [1:22:42<11:00:09,  3.79s/it]2025-08-22:19:57:24,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1579/12032 [1:22:46<11:02:00,  3.80s/it]2025-08-22:19:57:28,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1580/12032 [1:22:50<11:01:39,  3.80s/it]2025-08-22:19:57:32,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1581/12032 [1:22:54<11:01:19,  3.80s/it]2025-08-22:19:57:35,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1582/12032 [1:22:57<11:02:56,  3.81s/it]2025-08-22:19:57:39,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1583/12032 [1:23:01<11:03:28,  3.81s/it]2025-08-22:19:57:43,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1584/12032 [1:23:05<11:00:43,  3.79s/it]2025-08-22:19:57:47,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1585/12032 [1:23:09<10:59:43,  3.79s/it]2025-08-22:19:57:51,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1586/12032 [1:23:13<10:59:49,  3.79s/it]2025-08-22:19:57:54,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1587/12032 [1:23:16<10:58:35,  3.78s/it]2025-08-22:19:57:58,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1588/12032 [1:23:20<11:03:12,  3.81s/it]2025-08-22:19:58:02,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1589/12032 [1:23:24<11:04:15,  3.82s/it]2025-08-22:19:58:06,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1590/12032 [1:23:28<11:03:59,  3.82s/it]2025-08-22:19:58:10,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1591/12032 [1:23:31<10:22:31,  3.58s/it]2025-08-22:19:58:13,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1592/12032 [1:23:35<10:34:24,  3.65s/it]2025-08-22:19:58:16,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1593/12032 [1:23:38<10:44:12,  3.70s/it]2025-08-22:19:58:20,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1594/12032 [1:23:42<10:49:33,  3.73s/it]2025-08-22:19:58:24,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1595/12032 [1:23:46<10:54:05,  3.76s/it]2025-08-22:19:58:28,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1596/12032 [1:23:50<10:57:57,  3.78s/it]2025-08-22:19:58:32,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1597/12032 [1:23:54<11:00:09,  3.80s/it]2025-08-22:19:58:36,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1598/12032 [1:23:58<11:04:49,  3.82s/it]2025-08-22:19:58:39,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1599/12032 [1:24:01<11:04:00,  3.82s/it]2025-08-22:19:58:43,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1600/12032 [1:24:05<11:03:35,  3.82s/it]2025-08-22:19:58:47,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1601/12032 [1:24:09<11:02:25,  3.81s/it]2025-08-22:19:58:51,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1602/12032 [1:24:13<11:04:17,  3.82s/it]2025-08-22:19:58:55,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1603/12032 [1:24:17<11:03:43,  3.82s/it]2025-08-22:19:58:59,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1604/12032 [1:24:20<11:01:06,  3.80s/it]2025-08-22:19:59:02,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1605/12032 [1:24:24<11:01:44,  3.81s/it]2025-08-22:19:59:06,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1606/12032 [1:24:28<11:01:35,  3.81s/it]2025-08-22:19:59:10,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1607/12032 [1:24:29<8:51:30,  3.06s/it] 2025-08-22:19:59:11,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1608/12032 [1:24:33<9:22:44,  3.24s/it]2025-08-22:19:59:15,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1609/12032 [1:24:36<9:02:13,  3.12s/it]2025-08-22:19:59:18,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1610/12032 [1:24:40<9:35:33,  3.31s/it]2025-08-22:19:59:22,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1611/12032 [1:24:43<9:28:45,  3.27s/it]2025-08-22:19:59:25,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1612/12032 [1:24:47<10:00:15,  3.46s/it]2025-08-22:19:59:29,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1613/12032 [1:24:49<8:35:09,  2.97s/it] 2025-08-22:19:59:30,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1614/12032 [1:24:52<8:42:34,  3.01s/it]2025-08-22:19:59:34,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1615/12032 [1:24:55<9:22:49,  3.24s/it]2025-08-22:19:59:37,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1616/12032 [1:24:59<9:17:33,  3.21s/it]2025-08-22:19:59:40,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1617/12032 [1:25:02<9:46:09,  3.38s/it]2025-08-22:19:59:44,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1618/12032 [1:25:06<9:51:20,  3.41s/it]2025-08-22:19:59:48,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1619/12032 [1:25:10<10:12:16,  3.53s/it]2025-08-22:19:59:52,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1620/12032 [1:25:13<10:27:53,  3.62s/it]2025-08-22:19:59:55,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1621/12032 [1:25:17<10:36:30,  3.67s/it]2025-08-22:19:59:59,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1622/12032 [1:25:21<10:44:40,  3.72s/it]2025-08-22:20:00:03,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1623/12032 [1:25:25<10:50:41,  3.75s/it]2025-08-22:20:00:07,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  13%|█▎        | 1624/12032 [1:25:29<10:51:57,  3.76s/it]2025-08-22:20:00:11,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1625/12032 [1:25:32<10:53:02,  3.76s/it]2025-08-22:20:00:14,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1626/12032 [1:25:36<10:53:50,  3.77s/it]2025-08-22:20:00:18,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1627/12032 [1:25:40<10:54:33,  3.77s/it]2025-08-22:20:00:22,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1628/12032 [1:25:44<10:56:18,  3.78s/it]2025-08-22:20:00:26,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1629/12032 [1:25:48<10:59:54,  3.81s/it]2025-08-22:20:00:30,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1630/12032 [1:25:52<11:02:01,  3.82s/it]2025-08-22:20:00:33,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1631/12032 [1:25:55<11:02:59,  3.82s/it]2025-08-22:20:00:37,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1632/12032 [1:25:59<11:03:11,  3.83s/it]2025-08-22:20:00:41,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1633/12032 [1:26:03<11:04:11,  3.83s/it]2025-08-22:20:00:45,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1634/12032 [1:26:07<11:04:04,  3.83s/it]2025-08-22:20:00:49,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1635/12032 [1:26:11<11:02:50,  3.83s/it]2025-08-22:20:00:53,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1636/12032 [1:26:15<11:03:06,  3.83s/it]2025-08-22:20:00:56,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1637/12032 [1:26:18<11:02:44,  3.83s/it]2025-08-22:20:01:00,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1638/12032 [1:26:22<11:02:13,  3.82s/it]2025-08-22:20:01:04,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1639/12032 [1:26:26<11:00:46,  3.81s/it]2025-08-22:20:01:08,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1640/12032 [1:26:30<11:01:31,  3.82s/it]2025-08-22:20:01:12,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1641/12032 [1:26:34<11:02:35,  3.83s/it]2025-08-22:20:01:16,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1642/12032 [1:26:37<11:01:27,  3.82s/it]2025-08-22:20:01:19,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1643/12032 [1:26:41<11:03:09,  3.83s/it]2025-08-22:20:01:23,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1644/12032 [1:26:45<11:06:02,  3.85s/it]2025-08-22:20:01:27,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1645/12032 [1:26:49<11:05:06,  3.84s/it]2025-08-22:20:01:31,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1646/12032 [1:26:53<11:07:19,  3.86s/it]2025-08-22:20:01:35,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1647/12032 [1:26:55<9:46:08,  3.39s/it] 2025-08-22:20:01:37,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1648/12032 [1:26:59<10:10:24,  3.53s/it]2025-08-22:20:01:41,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1649/12032 [1:27:03<10:26:45,  3.62s/it]2025-08-22:20:01:45,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1650/12032 [1:27:07<10:37:50,  3.69s/it]2025-08-22:20:01:49,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1651/12032 [1:27:11<10:45:18,  3.73s/it]2025-08-22:20:01:52,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1652/12032 [1:27:14<10:48:52,  3.75s/it]2025-08-22:20:01:56,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1653/12032 [1:27:18<10:51:38,  3.77s/it]2025-08-22:20:02:00,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▎        | 1654/12032 [1:27:22<10:54:13,  3.78s/it]2025-08-22:20:02:04,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1655/12032 [1:27:25<10:37:29,  3.69s/it]2025-08-22:20:02:07,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1656/12032 [1:27:29<10:43:59,  3.72s/it]2025-08-22:20:02:11,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1657/12032 [1:27:33<10:47:49,  3.75s/it]2025-08-22:20:02:15,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1658/12032 [1:27:37<10:50:08,  3.76s/it]2025-08-22:20:02:19,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1659/12032 [1:27:41<10:52:01,  3.77s/it]2025-08-22:20:02:23,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1660/12032 [1:27:44<10:53:58,  3.78s/it]2025-08-22:20:02:26,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1661/12032 [1:27:48<10:55:22,  3.79s/it]2025-08-22:20:02:30,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1662/12032 [1:27:52<10:53:48,  3.78s/it]2025-08-22:20:02:34,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1663/12032 [1:27:56<10:55:13,  3.79s/it]2025-08-22:20:02:38,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1664/12032 [1:28:00<10:56:25,  3.80s/it]2025-08-22:20:02:42,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1665/12032 [1:28:04<10:57:29,  3.81s/it]2025-08-22:20:02:45,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1666/12032 [1:28:07<10:55:58,  3.80s/it]2025-08-22:20:02:49,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1667/12032 [1:28:11<10:55:33,  3.79s/it]2025-08-22:20:02:53,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1668/12032 [1:28:15<10:53:42,  3.78s/it]2025-08-22:20:02:57,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1669/12032 [1:28:19<10:52:54,  3.78s/it]2025-08-22:20:03:00,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1670/12032 [1:28:22<10:51:33,  3.77s/it]2025-08-22:20:03:04,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1671/12032 [1:28:26<10:50:38,  3.77s/it]2025-08-22:20:03:08,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1672/12032 [1:28:30<10:50:01,  3.76s/it]2025-08-22:20:03:12,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1673/12032 [1:28:34<10:51:26,  3.77s/it]2025-08-22:20:03:16,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1674/12032 [1:28:37<10:50:05,  3.77s/it]2025-08-22:20:03:19,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1675/12032 [1:28:41<10:51:16,  3.77s/it]2025-08-22:20:03:23,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1676/12032 [1:28:45<10:53:04,  3.78s/it]2025-08-22:20:03:27,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1677/12032 [1:28:49<10:53:34,  3.79s/it]2025-08-22:20:03:31,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1678/12032 [1:28:53<10:53:23,  3.79s/it]2025-08-22:20:03:34,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1679/12032 [1:28:56<10:52:35,  3.78s/it]2025-08-22:20:03:38,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1680/12032 [1:29:00<10:56:43,  3.81s/it]2025-08-22:20:03:42,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1681/12032 [1:29:04<10:55:16,  3.80s/it]2025-08-22:20:03:46,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1682/12032 [1:29:08<10:56:39,  3.81s/it]2025-08-22:20:03:50,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1683/12032 [1:29:12<10:59:43,  3.82s/it]2025-08-22:20:03:54,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1684/12032 [1:29:16<11:03:23,  3.85s/it]2025-08-22:20:03:57,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1685/12032 [1:29:19<11:00:36,  3.83s/it]2025-08-22:20:04:01,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1686/12032 [1:29:23<10:58:08,  3.82s/it]2025-08-22:20:04:05,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1687/12032 [1:29:27<10:57:44,  3.81s/it]2025-08-22:20:04:09,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1688/12032 [1:29:31<10:58:30,  3.82s/it]2025-08-22:20:04:13,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1689/12032 [1:29:35<10:57:48,  3.82s/it]2025-08-22:20:04:16,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1690/12032 [1:29:38<10:57:00,  3.81s/it]2025-08-22:20:04:20,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1691/12032 [1:29:42<10:56:39,  3.81s/it]2025-08-22:20:04:24,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1692/12032 [1:29:46<10:31:06,  3.66s/it]2025-08-22:20:04:27,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1693/12032 [1:29:49<10:38:21,  3.70s/it]2025-08-22:20:04:31,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1694/12032 [1:29:50<8:22:53,  2.92s/it] 2025-08-22:20:04:32,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1695/12032 [1:29:52<7:30:32,  2.62s/it]2025-08-22:20:04:34,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1696/12032 [1:29:56<8:31:53,  2.97s/it]2025-08-22:20:04:38,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1697/12032 [1:30:00<9:13:38,  3.21s/it]2025-08-22:20:04:42,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1698/12032 [1:30:04<9:42:27,  3.38s/it]2025-08-22:20:04:46,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1699/12032 [1:30:07<9:12:53,  3.21s/it]2025-08-22:20:04:48,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1700/12032 [1:30:10<9:42:45,  3.38s/it]2025-08-22:20:04:52,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1701/12032 [1:30:12<8:34:50,  2.99s/it]2025-08-22:20:04:54,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1702/12032 [1:30:16<9:18:17,  3.24s/it]2025-08-22:20:04:58,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1703/12032 [1:30:20<9:34:45,  3.34s/it]2025-08-22:20:05:02,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1704/12032 [1:30:24<9:58:26,  3.48s/it]2025-08-22:20:05:05,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1705/12032 [1:30:27<10:17:57,  3.59s/it]2025-08-22:20:05:09,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1706/12032 [1:30:31<10:32:05,  3.67s/it]2025-08-22:20:05:13,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1707/12032 [1:30:35<10:38:33,  3.71s/it]2025-08-22:20:05:17,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1708/12032 [1:30:38<10:21:25,  3.61s/it]2025-08-22:20:05:20,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1709/12032 [1:30:42<10:31:46,  3.67s/it]2025-08-22:20:05:24,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1710/12032 [1:30:46<10:39:30,  3.72s/it]2025-08-22:20:05:28,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1711/12032 [1:30:50<10:45:19,  3.75s/it]2025-08-22:20:05:32,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1712/12032 [1:30:54<10:47:33,  3.76s/it]2025-08-22:20:05:36,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1713/12032 [1:30:58<10:49:27,  3.78s/it]2025-08-22:20:05:39,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1714/12032 [1:31:01<10:50:00,  3.78s/it]2025-08-22:20:05:43,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1715/12032 [1:31:05<10:53:00,  3.80s/it]2025-08-22:20:05:47,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1716/12032 [1:31:09<10:52:09,  3.79s/it]2025-08-22:20:05:51,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1717/12032 [1:31:13<10:52:44,  3.80s/it]2025-08-22:20:05:55,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1718/12032 [1:31:17<10:51:23,  3.79s/it]2025-08-22:20:05:58,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1719/12032 [1:31:20<10:53:31,  3.80s/it]2025-08-22:20:06:02,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1720/12032 [1:31:24<10:51:35,  3.79s/it]2025-08-22:20:06:06,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1721/12032 [1:31:28<10:54:33,  3.81s/it]2025-08-22:20:06:10,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1722/12032 [1:31:31<9:58:34,  3.48s/it] 2025-08-22:20:06:13,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1723/12032 [1:31:35<10:17:14,  3.59s/it]2025-08-22:20:06:16,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1724/12032 [1:31:38<10:28:29,  3.66s/it]2025-08-22:20:06:20,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1725/12032 [1:31:42<10:35:17,  3.70s/it]2025-08-22:20:06:24,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1726/12032 [1:31:46<10:40:22,  3.73s/it]2025-08-22:20:06:28,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1727/12032 [1:31:49<10:26:05,  3.65s/it]2025-08-22:20:06:31,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1728/12032 [1:31:53<10:33:27,  3.69s/it]2025-08-22:20:06:35,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1729/12032 [1:31:57<10:41:55,  3.74s/it]2025-08-22:20:06:39,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1730/12032 [1:32:01<10:47:24,  3.77s/it]2025-08-22:20:06:43,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1731/12032 [1:32:05<10:48:48,  3.78s/it]2025-08-22:20:06:47,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1732/12032 [1:32:09<10:51:11,  3.79s/it]2025-08-22:20:06:50,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1733/12032 [1:32:12<10:52:27,  3.80s/it]2025-08-22:20:06:54,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1734/12032 [1:32:16<10:53:16,  3.81s/it]2025-08-22:20:06:58,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1735/12032 [1:32:20<10:50:49,  3.79s/it]2025-08-22:20:07:02,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1736/12032 [1:32:24<10:50:50,  3.79s/it]2025-08-22:20:07:06,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1737/12032 [1:32:27<10:41:44,  3.74s/it]2025-08-22:20:07:09,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1738/12032 [1:32:31<10:46:47,  3.77s/it]2025-08-22:20:07:13,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1739/12032 [1:32:35<10:51:36,  3.80s/it]2025-08-22:20:07:17,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1740/12032 [1:32:39<10:54:42,  3.82s/it]2025-08-22:20:07:21,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1741/12032 [1:32:43<10:53:08,  3.81s/it]2025-08-22:20:07:25,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1742/12032 [1:32:46<10:53:46,  3.81s/it]2025-08-22:20:07:28,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1743/12032 [1:32:50<10:56:32,  3.83s/it]2025-08-22:20:07:32,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  14%|█▍        | 1744/12032 [1:32:54<10:55:55,  3.83s/it]2025-08-22:20:07:36,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1745/12032 [1:32:58<10:55:45,  3.82s/it]2025-08-22:20:07:40,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1746/12032 [1:33:02<10:55:51,  3.83s/it]2025-08-22:20:07:44,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1747/12032 [1:33:06<10:56:10,  3.83s/it]2025-08-22:20:07:48,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1748/12032 [1:33:09<10:53:59,  3.82s/it]2025-08-22:20:07:51,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1749/12032 [1:33:13<10:54:06,  3.82s/it]2025-08-22:20:07:55,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1750/12032 [1:33:16<9:33:40,  3.35s/it] 2025-08-22:20:07:57,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1751/12032 [1:33:18<8:43:26,  3.05s/it]2025-08-22:20:08:00,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1752/12032 [1:33:22<9:23:06,  3.29s/it]2025-08-22:20:08:04,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1753/12032 [1:33:26<9:49:32,  3.44s/it]2025-08-22:20:08:07,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1754/12032 [1:33:29<10:07:15,  3.55s/it]2025-08-22:20:08:11,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1755/12032 [1:33:33<10:20:09,  3.62s/it]2025-08-22:20:08:15,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1756/12032 [1:33:37<10:28:33,  3.67s/it]2025-08-22:20:08:19,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1757/12032 [1:33:41<10:36:01,  3.71s/it]2025-08-22:20:08:23,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1758/12032 [1:33:45<10:41:12,  3.74s/it]2025-08-22:20:08:26,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1759/12032 [1:33:48<10:43:41,  3.76s/it]2025-08-22:20:08:30,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1760/12032 [1:33:52<10:45:52,  3.77s/it]2025-08-22:20:08:34,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1761/12032 [1:33:56<10:47:23,  3.78s/it]2025-08-22:20:08:38,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1762/12032 [1:34:00<10:49:36,  3.80s/it]2025-08-22:20:08:42,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1763/12032 [1:34:03<10:30:20,  3.68s/it]2025-08-22:20:08:45,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1764/12032 [1:34:07<10:35:32,  3.71s/it]2025-08-22:20:08:49,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1765/12032 [1:34:11<10:40:02,  3.74s/it]2025-08-22:20:08:53,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1766/12032 [1:34:15<10:42:53,  3.76s/it]2025-08-22:20:08:56,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1767/12032 [1:34:18<10:43:13,  3.76s/it]2025-08-22:20:09:00,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1768/12032 [1:34:22<10:48:41,  3.79s/it]2025-08-22:20:09:04,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1769/12032 [1:34:25<9:39:52,  3.39s/it] 2025-08-22:20:09:06,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1770/12032 [1:34:28<10:02:59,  3.53s/it]2025-08-22:20:09:10,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1771/12032 [1:34:32<10:17:10,  3.61s/it]2025-08-22:20:09:14,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1772/12032 [1:34:36<10:27:20,  3.67s/it]2025-08-22:20:09:18,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1773/12032 [1:34:40<10:34:27,  3.71s/it]2025-08-22:20:09:22,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1774/12032 [1:34:44<10:41:57,  3.75s/it]2025-08-22:20:09:26,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1775/12032 [1:34:48<10:48:26,  3.79s/it]2025-08-22:20:09:29,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1776/12032 [1:34:51<10:48:45,  3.80s/it]2025-08-22:20:09:33,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1777/12032 [1:34:55<10:49:40,  3.80s/it]2025-08-22:20:09:37,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1778/12032 [1:34:59<10:51:24,  3.81s/it]2025-08-22:20:09:41,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1779/12032 [1:35:03<10:53:53,  3.83s/it]2025-08-22:20:09:45,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1780/12032 [1:35:07<10:52:43,  3.82s/it]2025-08-22:20:09:49,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1781/12032 [1:35:11<10:53:06,  3.82s/it]2025-08-22:20:09:52,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1782/12032 [1:35:14<10:53:26,  3.83s/it]2025-08-22:20:09:56,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1783/12032 [1:35:18<10:52:51,  3.82s/it]2025-08-22:20:10:00,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1784/12032 [1:35:22<10:52:13,  3.82s/it]2025-08-22:20:10:04,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1785/12032 [1:35:26<10:52:05,  3.82s/it]2025-08-22:20:10:08,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1786/12032 [1:35:30<10:52:44,  3.82s/it]2025-08-22:20:10:12,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1787/12032 [1:35:33<10:15:36,  3.61s/it]2025-08-22:20:10:15,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1788/12032 [1:35:37<10:27:05,  3.67s/it]2025-08-22:20:10:18,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1789/12032 [1:35:38<8:32:27,  3.00s/it] 2025-08-22:20:10:20,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1790/12032 [1:35:39<7:03:59,  2.48s/it]2025-08-22:20:10:21,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1791/12032 [1:35:43<8:11:29,  2.88s/it]2025-08-22:20:10:25,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1792/12032 [1:35:47<9:03:52,  3.19s/it]2025-08-22:20:10:29,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1793/12032 [1:35:51<9:35:51,  3.37s/it]2025-08-22:20:10:33,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1794/12032 [1:35:55<10:00:15,  3.52s/it]2025-08-22:20:10:37,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1795/12032 [1:35:59<10:14:56,  3.60s/it]2025-08-22:20:10:40,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1796/12032 [1:36:02<10:24:37,  3.66s/it]2025-08-22:20:10:44,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1797/12032 [1:36:06<10:32:03,  3.71s/it]2025-08-22:20:10:48,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1798/12032 [1:36:10<10:37:30,  3.74s/it]2025-08-22:20:10:52,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1799/12032 [1:36:14<10:41:08,  3.76s/it]2025-08-22:20:10:56,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1800/12032 [1:36:18<10:45:50,  3.79s/it]2025-08-22:20:10:59,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1801/12032 [1:36:21<10:46:43,  3.79s/it]2025-08-22:20:11:03,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1802/12032 [1:36:25<10:48:29,  3.80s/it]2025-08-22:20:11:07,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1803/12032 [1:36:29<10:50:26,  3.82s/it]2025-08-22:20:11:11,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▍        | 1804/12032 [1:36:33<10:51:09,  3.82s/it]2025-08-22:20:11:15,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1805/12032 [1:36:37<10:51:02,  3.82s/it]2025-08-22:20:11:19,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1806/12032 [1:36:41<10:51:49,  3.82s/it]2025-08-22:20:11:22,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1807/12032 [1:36:44<10:51:53,  3.83s/it]2025-08-22:20:11:26,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1808/12032 [1:36:48<10:53:06,  3.83s/it]2025-08-22:20:11:30,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1809/12032 [1:36:52<10:51:05,  3.82s/it]2025-08-22:20:11:34,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1810/12032 [1:36:56<10:48:59,  3.81s/it]2025-08-22:20:11:38,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1811/12032 [1:37:00<10:46:33,  3.80s/it]2025-08-22:20:11:41,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1812/12032 [1:37:03<10:47:15,  3.80s/it]2025-08-22:20:11:45,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1813/12032 [1:37:07<10:48:11,  3.81s/it]2025-08-22:20:11:49,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1814/12032 [1:37:11<10:48:01,  3.81s/it]2025-08-22:20:11:53,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1815/12032 [1:37:14<9:56:49,  3.50s/it] 2025-08-22:20:11:56,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1816/12032 [1:37:18<10:10:49,  3.59s/it]2025-08-22:20:11:59,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1817/12032 [1:37:21<10:21:00,  3.65s/it]2025-08-22:20:12:03,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1818/12032 [1:37:25<10:30:01,  3.70s/it]2025-08-22:20:12:07,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1819/12032 [1:37:29<10:32:49,  3.72s/it]2025-08-22:20:12:11,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1820/12032 [1:37:33<10:36:56,  3.74s/it]2025-08-22:20:12:15,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1821/12032 [1:37:37<10:38:55,  3.75s/it]2025-08-22:20:12:18,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1822/12032 [1:37:40<10:40:53,  3.77s/it]2025-08-22:20:12:22,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1823/12032 [1:37:44<10:44:28,  3.79s/it]2025-08-22:20:12:26,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1824/12032 [1:37:48<10:45:44,  3.80s/it]2025-08-22:20:12:30,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1825/12032 [1:37:52<10:48:37,  3.81s/it]2025-08-22:20:12:34,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1826/12032 [1:37:56<10:48:40,  3.81s/it]2025-08-22:20:12:37,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1827/12032 [1:37:59<10:49:01,  3.82s/it]2025-08-22:20:12:41,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1828/12032 [1:38:03<10:47:21,  3.81s/it]2025-08-22:20:12:45,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1829/12032 [1:38:07<10:47:45,  3.81s/it]2025-08-22:20:12:49,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1830/12032 [1:38:11<10:46:31,  3.80s/it]2025-08-22:20:12:53,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1831/12032 [1:38:14<9:59:12,  3.52s/it] 2025-08-22:20:12:56,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1832/12032 [1:38:18<10:13:16,  3.61s/it]2025-08-22:20:12:59,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1833/12032 [1:38:21<10:23:51,  3.67s/it]2025-08-22:20:13:03,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1834/12032 [1:38:25<10:30:33,  3.71s/it]2025-08-22:20:13:07,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1835/12032 [1:38:29<10:38:59,  3.76s/it]2025-08-22:20:13:11,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1836/12032 [1:38:33<10:42:50,  3.78s/it]2025-08-22:20:13:15,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1837/12032 [1:38:37<10:45:40,  3.80s/it]2025-08-22:20:13:19,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1838/12032 [1:38:41<10:48:50,  3.82s/it]2025-08-22:20:13:22,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1839/12032 [1:38:43<9:56:13,  3.51s/it] 2025-08-22:20:13:25,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1840/12032 [1:38:47<10:12:32,  3.61s/it]2025-08-22:20:13:29,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1841/12032 [1:38:51<10:24:57,  3.68s/it]2025-08-22:20:13:33,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1842/12032 [1:38:55<10:32:59,  3.73s/it]2025-08-22:20:13:37,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1843/12032 [1:38:59<10:37:32,  3.75s/it]2025-08-22:20:13:41,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1844/12032 [1:39:02<10:39:26,  3.77s/it]2025-08-22:20:13:44,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1845/12032 [1:39:05<9:43:06,  3.43s/it] 2025-08-22:20:13:47,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1846/12032 [1:39:09<10:00:29,  3.54s/it]2025-08-22:20:13:51,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1847/12032 [1:39:13<10:14:29,  3.62s/it]2025-08-22:20:13:55,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1848/12032 [1:39:17<10:28:20,  3.70s/it]2025-08-22:20:13:58,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1849/12032 [1:39:20<10:33:54,  3.74s/it]2025-08-22:20:14:02,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1850/12032 [1:39:24<10:37:36,  3.76s/it]2025-08-22:20:14:06,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1851/12032 [1:39:28<10:41:07,  3.78s/it]2025-08-22:20:14:10,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1852/12032 [1:39:32<10:43:44,  3.79s/it]2025-08-22:20:14:14,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1853/12032 [1:39:36<10:44:53,  3.80s/it]2025-08-22:20:14:18,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1854/12032 [1:39:40<10:44:39,  3.80s/it]2025-08-22:20:14:21,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1855/12032 [1:39:43<10:45:16,  3.80s/it]2025-08-22:20:14:25,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1856/12032 [1:39:47<10:45:17,  3.80s/it]2025-08-22:20:14:29,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1857/12032 [1:39:51<10:46:28,  3.81s/it]2025-08-22:20:14:33,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1858/12032 [1:39:55<10:46:02,  3.81s/it]2025-08-22:20:14:37,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1859/12032 [1:39:59<10:47:07,  3.82s/it]2025-08-22:20:14:40,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1860/12032 [1:40:02<10:46:56,  3.82s/it]2025-08-22:20:14:44,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1861/12032 [1:40:06<10:46:13,  3.81s/it]2025-08-22:20:14:48,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1862/12032 [1:40:10<10:47:17,  3.82s/it]2025-08-22:20:14:52,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1863/12032 [1:40:14<10:46:52,  3.82s/it]2025-08-22:20:14:56,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  15%|█▌        | 1864/12032 [1:40:18<10:47:14,  3.82s/it]2025-08-22:20:15:00,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1865/12032 [1:40:22<10:46:20,  3.81s/it]2025-08-22:20:15:03,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1866/12032 [1:40:25<10:44:28,  3.80s/it]2025-08-22:20:15:07,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1867/12032 [1:40:27<9:15:55,  3.28s/it] 2025-08-22:20:15:09,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1868/12032 [1:40:31<9:42:47,  3.44s/it]2025-08-22:20:15:13,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1869/12032 [1:40:35<9:49:45,  3.48s/it]2025-08-22:20:15:17,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1870/12032 [1:40:39<10:06:31,  3.58s/it]2025-08-22:20:15:20,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1871/12032 [1:40:42<10:16:42,  3.64s/it]2025-08-22:20:15:24,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1872/12032 [1:40:46<10:26:01,  3.70s/it]2025-08-22:20:15:28,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1873/12032 [1:40:50<10:32:31,  3.74s/it]2025-08-22:20:15:32,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1874/12032 [1:40:54<10:35:25,  3.75s/it]2025-08-22:20:15:36,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1875/12032 [1:40:58<10:38:48,  3.77s/it]2025-08-22:20:15:39,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1876/12032 [1:41:01<10:40:37,  3.78s/it]2025-08-22:20:15:43,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1877/12032 [1:41:05<10:43:06,  3.80s/it]2025-08-22:20:15:47,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1878/12032 [1:41:09<10:47:57,  3.83s/it]2025-08-22:20:15:51,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1879/12032 [1:41:13<10:57:55,  3.89s/it]2025-08-22:20:15:55,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1880/12032 [1:41:17<11:00:51,  3.91s/it]2025-08-22:20:15:59,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1881/12032 [1:41:21<11:00:00,  3.90s/it]2025-08-22:20:16:03,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1882/12032 [1:41:25<10:54:16,  3.87s/it]2025-08-22:20:16:07,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1883/12032 [1:41:29<10:50:56,  3.85s/it]2025-08-22:20:16:10,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1884/12032 [1:41:32<10:43:17,  3.80s/it]2025-08-22:20:16:14,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1885/12032 [1:41:34<9:18:14,  3.30s/it] 2025-08-22:20:16:16,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1886/12032 [1:41:38<9:44:13,  3.45s/it]2025-08-22:20:16:20,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1887/12032 [1:41:42<10:02:03,  3.56s/it]2025-08-22:20:16:24,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1888/12032 [1:41:46<10:17:47,  3.65s/it]2025-08-22:20:16:28,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1889/12032 [1:41:50<10:26:56,  3.71s/it]2025-08-22:20:16:32,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1890/12032 [1:41:54<10:30:47,  3.73s/it]2025-08-22:20:16:35,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1891/12032 [1:41:57<10:34:17,  3.75s/it]2025-08-22:20:16:39,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1892/12032 [1:42:01<10:37:43,  3.77s/it]2025-08-22:20:16:43,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1893/12032 [1:42:05<10:42:26,  3.80s/it]2025-08-22:20:16:47,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1894/12032 [1:42:09<10:45:36,  3.82s/it]2025-08-22:20:16:51,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1895/12032 [1:42:13<10:47:04,  3.83s/it]2025-08-22:20:16:55,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1896/12032 [1:42:17<10:47:10,  3.83s/it]2025-08-22:20:16:58,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1897/12032 [1:42:20<10:42:35,  3.80s/it]2025-08-22:20:17:02,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1898/12032 [1:42:24<10:45:05,  3.82s/it]2025-08-22:20:17:06,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1899/12032 [1:42:28<10:46:42,  3.83s/it]2025-08-22:20:17:10,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1900/12032 [1:42:32<10:45:52,  3.82s/it]2025-08-22:20:17:14,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1901/12032 [1:42:36<10:45:10,  3.82s/it]2025-08-22:20:17:18,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1902/12032 [1:42:40<10:49:03,  3.84s/it]2025-08-22:20:17:21,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1903/12032 [1:42:43<10:50:37,  3.85s/it]2025-08-22:20:17:25,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1904/12032 [1:42:47<10:50:39,  3.85s/it]2025-08-22:20:17:29,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1905/12032 [1:42:51<10:49:55,  3.85s/it]2025-08-22:20:17:33,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1906/12032 [1:42:55<10:49:55,  3.85s/it]2025-08-22:20:17:37,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1907/12032 [1:42:59<10:50:33,  3.86s/it]2025-08-22:20:17:41,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1908/12032 [1:43:03<10:49:46,  3.85s/it]2025-08-22:20:17:45,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1909/12032 [1:43:07<10:47:35,  3.84s/it]2025-08-22:20:17:48,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1910/12032 [1:43:10<10:49:16,  3.85s/it]2025-08-22:20:17:52,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1911/12032 [1:43:14<10:47:56,  3.84s/it]2025-08-22:20:17:56,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1912/12032 [1:43:18<10:47:20,  3.84s/it]2025-08-22:20:18:00,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1913/12032 [1:43:22<10:48:10,  3.84s/it]2025-08-22:20:18:04,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1914/12032 [1:43:26<10:49:36,  3.85s/it]2025-08-22:20:18:08,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1915/12032 [1:43:30<10:46:46,  3.84s/it]2025-08-22:20:18:11,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1916/12032 [1:43:33<10:47:14,  3.84s/it]2025-08-22:20:18:15,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1917/12032 [1:43:37<10:46:09,  3.83s/it]2025-08-22:20:18:19,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1918/12032 [1:43:41<10:44:35,  3.82s/it]2025-08-22:20:18:23,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1919/12032 [1:43:45<10:43:36,  3.82s/it]2025-08-22:20:18:27,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1920/12032 [1:43:49<10:44:30,  3.82s/it]2025-08-22:20:18:31,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1921/12032 [1:43:52<10:44:44,  3.83s/it]2025-08-22:20:18:34,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1922/12032 [1:43:56<10:43:04,  3.82s/it]2025-08-22:20:18:38,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1923/12032 [1:43:59<9:43:59,  3.47s/it] 2025-08-22:20:18:41,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1924/12032 [1:44:03<10:00:35,  3.57s/it]2025-08-22:20:18:45,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1925/12032 [1:44:07<10:11:15,  3.63s/it]2025-08-22:20:18:48,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1926/12032 [1:44:10<10:18:13,  3.67s/it]2025-08-22:20:18:52,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1927/12032 [1:44:14<10:25:44,  3.72s/it]2025-08-22:20:18:56,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1928/12032 [1:44:18<10:38:58,  3.79s/it]2025-08-22:20:19:00,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1929/12032 [1:44:22<10:38:54,  3.79s/it]2025-08-22:20:19:04,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1930/12032 [1:44:26<10:38:16,  3.79s/it]2025-08-22:20:19:07,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1931/12032 [1:44:29<10:38:56,  3.80s/it]2025-08-22:20:19:11,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1932/12032 [1:44:33<10:38:10,  3.79s/it]2025-08-22:20:19:15,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1933/12032 [1:44:37<10:37:45,  3.79s/it]2025-08-22:20:19:19,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1934/12032 [1:44:41<10:36:54,  3.78s/it]2025-08-22:20:19:23,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1935/12032 [1:44:45<10:36:31,  3.78s/it]2025-08-22:20:19:26,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1936/12032 [1:44:48<10:36:25,  3.78s/it]2025-08-22:20:19:30,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1937/12032 [1:44:52<10:37:00,  3.79s/it]2025-08-22:20:19:34,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1938/12032 [1:44:56<10:37:09,  3.79s/it]2025-08-22:20:19:38,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1939/12032 [1:45:00<10:37:34,  3.79s/it]2025-08-22:20:19:42,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1940/12032 [1:45:04<10:37:23,  3.79s/it]2025-08-22:20:19:45,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1941/12032 [1:45:07<10:36:45,  3.79s/it]2025-08-22:20:19:49,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1942/12032 [1:45:11<10:35:52,  3.78s/it]2025-08-22:20:19:53,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1943/12032 [1:45:15<10:36:03,  3.78s/it]2025-08-22:20:19:57,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1944/12032 [1:45:19<10:35:09,  3.78s/it]2025-08-22:20:20:00,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1945/12032 [1:45:22<10:34:46,  3.78s/it]2025-08-22:20:20:04,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1946/12032 [1:45:24<8:31:15,  3.04s/it] 2025-08-22:20:20:06,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1947/12032 [1:45:28<9:11:48,  3.28s/it]2025-08-22:20:20:09,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1948/12032 [1:45:31<9:37:06,  3.43s/it]2025-08-22:20:20:13,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1949/12032 [1:45:35<9:54:19,  3.54s/it]2025-08-22:20:20:17,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1950/12032 [1:45:39<10:05:55,  3.61s/it]2025-08-22:20:20:21,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1951/12032 [1:45:43<10:14:29,  3.66s/it]2025-08-22:20:20:25,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1952/12032 [1:45:46<9:46:59,  3.49s/it] 2025-08-22:20:20:28,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1953/12032 [1:45:50<10:01:29,  3.58s/it]2025-08-22:20:20:31,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1954/12032 [1:45:53<10:11:49,  3.64s/it]2025-08-22:20:20:35,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▌        | 1955/12032 [1:45:57<10:20:17,  3.69s/it]2025-08-22:20:20:39,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1956/12032 [1:46:01<10:29:15,  3.75s/it]2025-08-22:20:20:43,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1957/12032 [1:46:05<10:34:08,  3.78s/it]2025-08-22:20:20:47,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1958/12032 [1:46:09<10:35:28,  3.78s/it]2025-08-22:20:20:51,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1959/12032 [1:46:13<10:38:43,  3.80s/it]2025-08-22:20:20:54,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1960/12032 [1:46:16<10:38:05,  3.80s/it]2025-08-22:20:20:58,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1961/12032 [1:46:20<10:38:06,  3.80s/it]2025-08-22:20:21:02,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1962/12032 [1:46:23<9:35:58,  3.43s/it] 2025-08-22:20:21:05,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1963/12032 [1:46:27<9:54:44,  3.54s/it]2025-08-22:20:21:08,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1964/12032 [1:46:30<9:57:09,  3.56s/it]2025-08-22:20:21:12,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1965/12032 [1:46:33<9:31:31,  3.41s/it]2025-08-22:20:21:15,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1966/12032 [1:46:37<9:50:44,  3.52s/it]2025-08-22:20:21:19,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1967/12032 [1:46:40<9:35:10,  3.43s/it]2025-08-22:20:21:22,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1968/12032 [1:46:44<9:54:18,  3.54s/it]2025-08-22:20:21:26,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1969/12032 [1:46:48<10:07:47,  3.62s/it]2025-08-22:20:21:30,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1970/12032 [1:46:52<10:18:05,  3.69s/it]2025-08-22:20:21:33,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1971/12032 [1:46:55<10:23:27,  3.72s/it]2025-08-22:20:21:37,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1972/12032 [1:46:59<10:27:06,  3.74s/it]2025-08-22:20:21:41,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1973/12032 [1:47:03<10:31:38,  3.77s/it]2025-08-22:20:21:45,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1974/12032 [1:47:07<10:37:32,  3.80s/it]2025-08-22:20:21:49,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1975/12032 [1:47:11<10:38:20,  3.81s/it]2025-08-22:20:21:53,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1976/12032 [1:47:15<10:40:37,  3.82s/it]2025-08-22:20:21:56,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1977/12032 [1:47:18<10:44:01,  3.84s/it]2025-08-22:20:22:00,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1978/12032 [1:47:22<10:40:59,  3.83s/it]2025-08-22:20:22:04,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1979/12032 [1:47:26<10:40:37,  3.82s/it]2025-08-22:20:22:08,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1980/12032 [1:47:30<10:23:14,  3.72s/it]2025-08-22:20:22:11,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1981/12032 [1:47:33<10:28:00,  3.75s/it]2025-08-22:20:22:15,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1982/12032 [1:47:37<10:32:14,  3.77s/it]2025-08-22:20:22:19,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1983/12032 [1:47:41<10:33:45,  3.78s/it]2025-08-22:20:22:23,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1984/12032 [1:47:45<10:33:51,  3.78s/it]2025-08-22:20:22:27,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  16%|█▋        | 1985/12032 [1:47:49<10:34:10,  3.79s/it]2025-08-22:20:22:30,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1986/12032 [1:47:52<10:35:30,  3.80s/it]2025-08-22:20:22:34,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1987/12032 [1:47:56<10:37:26,  3.81s/it]2025-08-22:20:22:38,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1988/12032 [1:48:00<10:37:02,  3.81s/it]2025-08-22:20:22:42,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1989/12032 [1:48:04<10:36:35,  3.80s/it]2025-08-22:20:22:46,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1990/12032 [1:48:08<10:34:18,  3.79s/it]2025-08-22:20:22:49,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1991/12032 [1:48:11<10:34:29,  3.79s/it]2025-08-22:20:22:53,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1992/12032 [1:48:15<10:36:00,  3.80s/it]2025-08-22:20:22:57,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1993/12032 [1:48:19<10:35:11,  3.80s/it]2025-08-22:20:23:01,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1994/12032 [1:48:23<10:35:00,  3.80s/it]2025-08-22:20:23:05,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1995/12032 [1:48:27<10:34:02,  3.79s/it]2025-08-22:20:23:08,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1996/12032 [1:48:30<10:37:23,  3.81s/it]2025-08-22:20:23:12,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1997/12032 [1:48:34<10:36:06,  3.80s/it]2025-08-22:20:23:16,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1998/12032 [1:48:38<10:35:09,  3.80s/it]2025-08-22:20:23:20,363 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 1999/12032 [1:48:42<10:34:40,  3.80s/it]2025-08-22:20:23:24,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2000/12032 [1:48:46<10:38:08,  3.82s/it]2025-08-22:20:23:28,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2001/12032 [1:48:50<10:38:48,  3.82s/it]2025-08-22:20:23:31,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2002/12032 [1:48:53<10:38:16,  3.82s/it]2025-08-22:20:23:35,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2003/12032 [1:48:57<10:38:38,  3.82s/it]2025-08-22:20:23:39,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2004/12032 [1:49:01<10:38:39,  3.82s/it]2025-08-22:20:23:43,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2005/12032 [1:49:05<10:38:58,  3.82s/it]2025-08-22:20:23:47,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2006/12032 [1:49:07<9:28:18,  3.40s/it] 2025-08-22:20:23:49,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2007/12032 [1:49:11<9:50:25,  3.53s/it]2025-08-22:20:23:53,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2008/12032 [1:49:15<10:05:26,  3.62s/it]2025-08-22:20:23:57,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2009/12032 [1:49:19<10:13:36,  3.67s/it]2025-08-22:20:24:01,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2010/12032 [1:49:23<10:21:37,  3.72s/it]2025-08-22:20:24:04,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2011/12032 [1:49:26<10:30:13,  3.77s/it]2025-08-22:20:24:08,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2012/12032 [1:49:30<10:31:55,  3.78s/it]2025-08-22:20:24:12,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2013/12032 [1:49:34<10:37:30,  3.82s/it]2025-08-22:20:24:16,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2014/12032 [1:49:38<10:36:53,  3.81s/it]2025-08-22:20:24:20,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2015/12032 [1:49:42<10:40:13,  3.83s/it]2025-08-22:20:24:24,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2016/12032 [1:49:46<10:40:32,  3.84s/it]2025-08-22:20:24:27,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2017/12032 [1:49:49<10:40:40,  3.84s/it]2025-08-22:20:24:31,828 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2018/12032 [1:49:53<10:41:20,  3.84s/it]2025-08-22:20:24:35,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2019/12032 [1:49:57<10:46:16,  3.87s/it]2025-08-22:20:24:39,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2020/12032 [1:50:01<10:43:31,  3.86s/it]2025-08-22:20:24:43,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2021/12032 [1:50:05<10:40:57,  3.84s/it]2025-08-22:20:24:47,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2022/12032 [1:50:09<10:42:54,  3.85s/it]2025-08-22:20:24:51,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2023/12032 [1:50:13<10:39:19,  3.83s/it]2025-08-22:20:24:54,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2024/12032 [1:50:16<10:40:30,  3.84s/it]2025-08-22:20:24:58,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2025/12032 [1:50:20<10:37:29,  3.82s/it]2025-08-22:20:25:02,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2026/12032 [1:50:22<8:57:49,  3.23s/it] 2025-08-22:20:25:04,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2027/12032 [1:50:26<9:26:25,  3.40s/it]2025-08-22:20:25:08,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2028/12032 [1:50:30<9:45:20,  3.51s/it]2025-08-22:20:25:11,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2029/12032 [1:50:33<9:59:34,  3.60s/it]2025-08-22:20:25:15,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2030/12032 [1:50:37<9:58:35,  3.59s/it]2025-08-22:20:25:19,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2031/12032 [1:50:41<10:09:31,  3.66s/it]2025-08-22:20:25:23,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2032/12032 [1:50:45<10:18:18,  3.71s/it]2025-08-22:20:25:26,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2033/12032 [1:50:49<10:27:42,  3.77s/it]2025-08-22:20:25:30,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2034/12032 [1:50:52<10:33:07,  3.80s/it]2025-08-22:20:25:34,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2035/12032 [1:50:56<10:33:51,  3.80s/it]2025-08-22:20:25:38,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2036/12032 [1:51:00<10:35:39,  3.82s/it]2025-08-22:20:25:42,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2037/12032 [1:51:04<10:34:15,  3.81s/it]2025-08-22:20:25:46,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2038/12032 [1:51:08<10:35:31,  3.82s/it]2025-08-22:20:25:50,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2039/12032 [1:51:12<10:36:03,  3.82s/it]2025-08-22:20:25:53,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2040/12032 [1:51:15<10:34:31,  3.81s/it]2025-08-22:20:25:57,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2041/12032 [1:51:19<10:35:16,  3.82s/it]2025-08-22:20:26:01,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2042/12032 [1:51:23<10:34:41,  3.81s/it]2025-08-22:20:26:05,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2043/12032 [1:51:27<10:35:46,  3.82s/it]2025-08-22:20:26:09,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2044/12032 [1:51:31<10:35:20,  3.82s/it]2025-08-22:20:26:12,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2045/12032 [1:51:34<10:36:35,  3.82s/it]2025-08-22:20:26:16,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2046/12032 [1:51:38<10:36:54,  3.83s/it]2025-08-22:20:26:20,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2047/12032 [1:51:40<8:57:03,  3.23s/it] 2025-08-22:20:26:22,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2048/12032 [1:51:44<9:26:27,  3.40s/it]2025-08-22:20:26:26,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2049/12032 [1:51:48<9:47:25,  3.53s/it]2025-08-22:20:26:30,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2050/12032 [1:51:52<10:02:36,  3.62s/it]2025-08-22:20:26:33,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2051/12032 [1:51:55<10:14:40,  3.70s/it]2025-08-22:20:26:37,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2052/12032 [1:51:59<10:19:51,  3.73s/it]2025-08-22:20:26:41,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2053/12032 [1:52:03<10:24:46,  3.76s/it]2025-08-22:20:26:45,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2054/12032 [1:52:07<10:27:28,  3.77s/it]2025-08-22:20:26:49,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2055/12032 [1:52:11<10:27:34,  3.77s/it]2025-08-22:20:26:52,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2056/12032 [1:52:14<10:30:01,  3.79s/it]2025-08-22:20:26:56,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2057/12032 [1:52:18<10:30:00,  3.79s/it]2025-08-22:20:27:00,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2058/12032 [1:52:21<9:30:29,  3.43s/it] 2025-08-22:20:27:03,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2059/12032 [1:52:25<9:41:13,  3.50s/it]2025-08-22:20:27:06,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2060/12032 [1:52:26<8:13:41,  2.97s/it]2025-08-22:20:27:08,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2061/12032 [1:52:30<8:55:00,  3.22s/it]2025-08-22:20:27:12,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2062/12032 [1:52:34<9:25:45,  3.40s/it]2025-08-22:20:27:16,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2063/12032 [1:52:37<9:35:19,  3.46s/it]2025-08-22:20:27:19,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2064/12032 [1:52:41<9:51:33,  3.56s/it]2025-08-22:20:27:23,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2065/12032 [1:52:45<10:04:10,  3.64s/it]2025-08-22:20:27:27,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2066/12032 [1:52:49<10:11:47,  3.68s/it]2025-08-22:20:27:31,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2067/12032 [1:52:53<10:17:34,  3.72s/it]2025-08-22:20:27:35,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2068/12032 [1:52:57<10:23:35,  3.76s/it]2025-08-22:20:27:38,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2069/12032 [1:53:00<10:26:19,  3.77s/it]2025-08-22:20:27:42,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2070/12032 [1:53:04<10:27:42,  3.78s/it]2025-08-22:20:27:46,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2071/12032 [1:53:08<10:28:44,  3.79s/it]2025-08-22:20:27:50,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2072/12032 [1:53:12<10:31:22,  3.80s/it]2025-08-22:20:27:54,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2073/12032 [1:53:16<10:32:23,  3.81s/it]2025-08-22:20:27:57,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2074/12032 [1:53:19<10:31:58,  3.81s/it]2025-08-22:20:28:01,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2075/12032 [1:53:23<10:29:12,  3.79s/it]2025-08-22:20:28:05,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2076/12032 [1:53:27<10:33:05,  3.82s/it]2025-08-22:20:28:09,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2077/12032 [1:53:31<10:33:14,  3.82s/it]2025-08-22:20:28:13,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2078/12032 [1:53:35<10:34:02,  3.82s/it]2025-08-22:20:28:17,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2079/12032 [1:53:38<10:32:16,  3.81s/it]2025-08-22:20:28:20,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2080/12032 [1:53:42<10:35:05,  3.83s/it]2025-08-22:20:28:24,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2081/12032 [1:53:46<10:33:13,  3.82s/it]2025-08-22:20:28:28,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2082/12032 [1:53:50<10:31:46,  3.81s/it]2025-08-22:20:28:32,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2083/12032 [1:53:54<10:29:56,  3.80s/it]2025-08-22:20:28:36,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2084/12032 [1:53:57<10:29:27,  3.80s/it]2025-08-22:20:28:39,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2085/12032 [1:54:01<10:32:07,  3.81s/it]2025-08-22:20:28:43,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2086/12032 [1:54:05<10:30:33,  3.80s/it]2025-08-22:20:28:47,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2087/12032 [1:54:09<10:27:38,  3.79s/it]2025-08-22:20:28:51,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2088/12032 [1:54:13<10:25:55,  3.78s/it]2025-08-22:20:28:54,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2089/12032 [1:54:16<10:24:19,  3.77s/it]2025-08-22:20:28:58,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2090/12032 [1:54:20<10:24:53,  3.77s/it]2025-08-22:20:29:02,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2091/12032 [1:54:24<10:28:07,  3.79s/it]2025-08-22:20:29:06,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2092/12032 [1:54:28<10:27:45,  3.79s/it]2025-08-22:20:29:10,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2093/12032 [1:54:32<10:28:11,  3.79s/it]2025-08-22:20:29:13,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2094/12032 [1:54:35<10:27:59,  3.79s/it]2025-08-22:20:29:17,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2095/12032 [1:54:39<10:28:22,  3.79s/it]2025-08-22:20:29:21,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2096/12032 [1:54:43<10:29:09,  3.80s/it]2025-08-22:20:29:25,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2097/12032 [1:54:47<10:30:11,  3.81s/it]2025-08-22:20:29:29,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2098/12032 [1:54:51<10:31:18,  3.81s/it]2025-08-22:20:29:32,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2099/12032 [1:54:54<10:29:47,  3.80s/it]2025-08-22:20:29:36,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2100/12032 [1:54:58<10:29:54,  3.81s/it]2025-08-22:20:29:40,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2101/12032 [1:55:02<10:29:55,  3.81s/it]2025-08-22:20:29:44,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2102/12032 [1:55:06<10:30:23,  3.81s/it]2025-08-22:20:29:48,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2103/12032 [1:55:10<10:29:25,  3.80s/it]2025-08-22:20:29:51,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2104/12032 [1:55:13<10:30:15,  3.81s/it]2025-08-22:20:29:55,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  17%|█▋        | 2105/12032 [1:55:17<10:30:00,  3.81s/it]2025-08-22:20:29:59,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2106/12032 [1:55:21<10:29:00,  3.80s/it]2025-08-22:20:30:03,385 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2107/12032 [1:55:25<10:29:02,  3.80s/it]2025-08-22:20:30:07,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2108/12032 [1:55:29<10:29:17,  3.80s/it]2025-08-22:20:30:10,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2109/12032 [1:55:32<10:28:34,  3.80s/it]2025-08-22:20:30:14,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2110/12032 [1:55:36<10:29:41,  3.81s/it]2025-08-22:20:30:18,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2111/12032 [1:55:40<10:29:40,  3.81s/it]2025-08-22:20:30:22,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2112/12032 [1:55:44<10:28:04,  3.80s/it]2025-08-22:20:30:26,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2113/12032 [1:55:48<10:28:11,  3.80s/it]2025-08-22:20:30:30,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2114/12032 [1:55:51<10:28:54,  3.80s/it]2025-08-22:20:30:33,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2115/12032 [1:55:55<10:29:17,  3.81s/it]2025-08-22:20:30:37,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2116/12032 [1:55:59<10:29:14,  3.81s/it]2025-08-22:20:30:41,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2117/12032 [1:56:03<10:26:42,  3.79s/it]2025-08-22:20:30:45,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2118/12032 [1:56:07<10:25:50,  3.79s/it]2025-08-22:20:30:48,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2119/12032 [1:56:10<10:27:00,  3.80s/it]2025-08-22:20:30:52,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2120/12032 [1:56:14<10:25:14,  3.78s/it]2025-08-22:20:30:56,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2121/12032 [1:56:18<10:27:20,  3.80s/it]2025-08-22:20:31:00,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2122/12032 [1:56:22<10:28:45,  3.81s/it]2025-08-22:20:31:04,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2123/12032 [1:56:26<10:27:35,  3.80s/it]2025-08-22:20:31:07,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2124/12032 [1:56:29<10:27:35,  3.80s/it]2025-08-22:20:31:11,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2125/12032 [1:56:33<10:26:46,  3.80s/it]2025-08-22:20:31:15,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2126/12032 [1:56:37<10:27:50,  3.80s/it]2025-08-22:20:31:19,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2127/12032 [1:56:41<10:30:09,  3.82s/it]2025-08-22:20:31:23,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2128/12032 [1:56:45<10:29:10,  3.81s/it]2025-08-22:20:31:27,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2129/12032 [1:56:48<9:46:40,  3.55s/it] 2025-08-22:20:31:29,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2130/12032 [1:56:51<9:58:48,  3.63s/it]2025-08-22:20:31:33,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2131/12032 [1:56:55<10:07:03,  3.68s/it]2025-08-22:20:31:37,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2132/12032 [1:56:59<10:12:20,  3.71s/it]2025-08-22:20:31:41,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2133/12032 [1:57:03<10:21:39,  3.77s/it]2025-08-22:20:31:45,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2134/12032 [1:57:05<8:46:57,  3.19s/it] 2025-08-22:20:31:47,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2135/12032 [1:57:09<9:14:56,  3.36s/it]2025-08-22:20:31:50,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2136/12032 [1:57:12<9:34:33,  3.48s/it]2025-08-22:20:31:54,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2137/12032 [1:57:16<9:28:37,  3.45s/it]2025-08-22:20:31:58,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2138/12032 [1:57:19<9:44:14,  3.54s/it]2025-08-22:20:32:01,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2139/12032 [1:57:23<9:55:59,  3.61s/it]2025-08-22:20:32:05,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2140/12032 [1:57:27<10:10:22,  3.70s/it]2025-08-22:20:32:09,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2141/12032 [1:57:30<9:48:01,  3.57s/it] 2025-08-22:20:32:12,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2142/12032 [1:57:33<9:21:04,  3.40s/it]2025-08-22:20:32:15,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2143/12032 [1:57:36<9:00:25,  3.28s/it]2025-08-22:20:32:18,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2144/12032 [1:57:40<9:25:21,  3.43s/it]2025-08-22:20:32:22,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2145/12032 [1:57:44<9:46:08,  3.56s/it]2025-08-22:20:32:26,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2146/12032 [1:57:48<10:01:37,  3.65s/it]2025-08-22:20:32:30,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2147/12032 [1:57:52<10:09:45,  3.70s/it]2025-08-22:20:32:34,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2148/12032 [1:57:56<10:19:15,  3.76s/it]2025-08-22:20:32:37,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2149/12032 [1:57:59<10:23:12,  3.78s/it]2025-08-22:20:32:41,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2150/12032 [1:58:03<10:32:28,  3.84s/it]2025-08-22:20:32:45,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2151/12032 [1:58:07<10:32:15,  3.84s/it]2025-08-22:20:32:49,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2152/12032 [1:58:11<10:32:03,  3.84s/it]2025-08-22:20:32:53,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2153/12032 [1:58:14<10:04:19,  3.67s/it]2025-08-22:20:32:56,725 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2154/12032 [1:58:18<10:11:27,  3.71s/it]2025-08-22:20:33:00,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2155/12032 [1:58:22<10:17:57,  3.75s/it]2025-08-22:20:33:04,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2156/12032 [1:58:26<10:19:33,  3.76s/it]2025-08-22:20:33:08,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2157/12032 [1:58:30<10:22:20,  3.78s/it]2025-08-22:20:33:11,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2158/12032 [1:58:33<10:24:46,  3.80s/it]2025-08-22:20:33:15,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2159/12032 [1:58:37<10:25:10,  3.80s/it]2025-08-22:20:33:19,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2160/12032 [1:58:41<10:13:40,  3.73s/it]2025-08-22:20:33:23,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2161/12032 [1:58:45<10:19:03,  3.76s/it]2025-08-22:20:33:27,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2162/12032 [1:58:49<10:21:46,  3.78s/it]2025-08-22:20:33:30,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2163/12032 [1:58:52<10:23:19,  3.79s/it]2025-08-22:20:33:34,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2164/12032 [1:58:56<10:25:26,  3.80s/it]2025-08-22:20:33:38,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2165/12032 [1:59:00<10:25:41,  3.80s/it]2025-08-22:20:33:42,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2166/12032 [1:59:04<10:26:06,  3.81s/it]2025-08-22:20:33:46,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2167/12032 [1:59:08<10:26:49,  3.81s/it]2025-08-22:20:33:49,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2168/12032 [1:59:11<10:27:16,  3.82s/it]2025-08-22:20:33:53,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2169/12032 [1:59:15<10:27:57,  3.82s/it]2025-08-22:20:33:57,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2170/12032 [1:59:19<10:05:00,  3.68s/it]2025-08-22:20:34:00,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2171/12032 [1:59:22<10:11:51,  3.72s/it]2025-08-22:20:34:04,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2172/12032 [1:59:26<10:16:21,  3.75s/it]2025-08-22:20:34:08,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2173/12032 [1:59:30<10:22:29,  3.79s/it]2025-08-22:20:34:12,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2174/12032 [1:59:34<10:25:17,  3.81s/it]2025-08-22:20:34:16,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2175/12032 [1:59:38<10:26:16,  3.81s/it]2025-08-22:20:34:20,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2176/12032 [1:59:42<10:25:35,  3.81s/it]2025-08-22:20:34:23,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2177/12032 [1:59:45<10:25:30,  3.81s/it]2025-08-22:20:34:27,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2178/12032 [1:59:49<10:25:29,  3.81s/it]2025-08-22:20:34:31,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2179/12032 [1:59:53<10:31:06,  3.84s/it]2025-08-22:20:34:35,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2180/12032 [1:59:57<10:28:14,  3.83s/it]2025-08-22:20:34:39,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2181/12032 [1:59:59<9:23:12,  3.43s/it] 2025-08-22:20:34:41,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2182/12032 [2:00:02<8:23:09,  3.06s/it]2025-08-22:20:34:43,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2183/12032 [2:00:05<9:00:11,  3.29s/it]2025-08-22:20:34:47,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2184/12032 [2:00:09<9:26:21,  3.45s/it]2025-08-22:20:34:51,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2185/12032 [2:00:13<9:44:03,  3.56s/it]2025-08-22:20:34:55,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2186/12032 [2:00:17<9:56:34,  3.64s/it]2025-08-22:20:34:59,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2187/12032 [2:00:21<10:07:42,  3.70s/it]2025-08-22:20:35:03,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2188/12032 [2:00:25<10:12:56,  3.74s/it]2025-08-22:20:35:06,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2189/12032 [2:00:28<10:16:54,  3.76s/it]2025-08-22:20:35:10,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2190/12032 [2:00:32<10:21:05,  3.79s/it]2025-08-22:20:35:14,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2191/12032 [2:00:36<10:21:10,  3.79s/it]2025-08-22:20:35:18,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2192/12032 [2:00:40<10:22:42,  3.80s/it]2025-08-22:20:35:22,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2193/12032 [2:00:44<10:23:40,  3.80s/it]2025-08-22:20:35:26,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2194/12032 [2:00:47<10:23:34,  3.80s/it]2025-08-22:20:35:29,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2195/12032 [2:00:50<9:16:49,  3.40s/it] 2025-08-22:20:35:32,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2196/12032 [2:00:54<9:37:50,  3.52s/it]2025-08-22:20:35:36,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2197/12032 [2:00:58<9:52:34,  3.62s/it]2025-08-22:20:35:39,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2198/12032 [2:01:01<10:03:26,  3.68s/it]2025-08-22:20:35:43,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2199/12032 [2:01:05<10:08:05,  3.71s/it]2025-08-22:20:35:47,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2200/12032 [2:01:09<10:12:58,  3.74s/it]2025-08-22:20:35:51,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2201/12032 [2:01:13<10:16:20,  3.76s/it]2025-08-22:20:35:55,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2202/12032 [2:01:17<10:18:09,  3.77s/it]2025-08-22:20:35:58,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2203/12032 [2:01:20<10:20:04,  3.79s/it]2025-08-22:20:36:02,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2204/12032 [2:01:24<10:20:41,  3.79s/it]2025-08-22:20:36:06,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2205/12032 [2:01:28<10:22:01,  3.80s/it]2025-08-22:20:36:10,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2206/12032 [2:01:32<10:22:13,  3.80s/it]2025-08-22:20:36:14,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2207/12032 [2:01:36<10:21:54,  3.80s/it]2025-08-22:20:36:17,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2208/12032 [2:01:39<10:23:45,  3.81s/it]2025-08-22:20:36:21,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2209/12032 [2:01:43<10:25:13,  3.82s/it]2025-08-22:20:36:25,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2210/12032 [2:01:47<10:26:30,  3.83s/it]2025-08-22:20:36:29,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2211/12032 [2:01:51<10:25:57,  3.82s/it]2025-08-22:20:36:33,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2212/12032 [2:01:55<10:24:41,  3.82s/it]2025-08-22:20:36:37,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2213/12032 [2:01:59<10:22:34,  3.80s/it]2025-08-22:20:36:40,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2214/12032 [2:02:02<10:24:56,  3.82s/it]2025-08-22:20:36:44,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2215/12032 [2:02:06<10:24:32,  3.82s/it]2025-08-22:20:36:48,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2216/12032 [2:02:10<10:23:50,  3.81s/it]2025-08-22:20:36:52,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2217/12032 [2:02:14<10:22:20,  3.80s/it]2025-08-22:20:36:56,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2218/12032 [2:02:18<10:22:26,  3.81s/it]2025-08-22:20:36:59,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2219/12032 [2:02:19<8:19:59,  3.06s/it] 2025-08-22:20:37:01,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2220/12032 [2:02:23<8:55:16,  3.27s/it]2025-08-22:20:37:05,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2221/12032 [2:02:27<9:21:21,  3.43s/it]2025-08-22:20:37:08,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2222/12032 [2:02:30<9:37:28,  3.53s/it]2025-08-22:20:37:12,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2223/12032 [2:02:34<9:49:37,  3.61s/it]2025-08-22:20:37:16,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2224/12032 [2:02:38<9:57:47,  3.66s/it]2025-08-22:20:37:20,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  18%|█▊        | 2225/12032 [2:02:42<10:04:57,  3.70s/it]2025-08-22:20:37:23,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2226/12032 [2:02:45<9:45:22,  3.58s/it] 2025-08-22:20:37:27,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2227/12032 [2:02:49<9:55:00,  3.64s/it]2025-08-22:20:37:31,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2228/12032 [2:02:53<10:01:23,  3.68s/it]2025-08-22:20:37:34,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2229/12032 [2:02:56<10:07:59,  3.72s/it]2025-08-22:20:37:38,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2230/12032 [2:03:00<10:11:52,  3.75s/it]2025-08-22:20:37:42,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2231/12032 [2:03:04<10:13:56,  3.76s/it]2025-08-22:20:37:46,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2232/12032 [2:03:08<10:16:04,  3.77s/it]2025-08-22:20:37:50,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2233/12032 [2:03:11<10:16:11,  3.77s/it]2025-08-22:20:37:53,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2234/12032 [2:03:15<10:16:19,  3.77s/it]2025-08-22:20:37:57,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2235/12032 [2:03:19<10:16:36,  3.78s/it]2025-08-22:20:38:01,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2236/12032 [2:03:23<10:18:42,  3.79s/it]2025-08-22:20:38:05,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2237/12032 [2:03:25<9:13:12,  3.39s/it] 2025-08-22:20:38:07,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2238/12032 [2:03:29<9:33:17,  3.51s/it]2025-08-22:20:38:11,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2239/12032 [2:03:33<9:47:29,  3.60s/it]2025-08-22:20:38:15,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2240/12032 [2:03:37<9:58:40,  3.67s/it]2025-08-22:20:38:19,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2241/12032 [2:03:41<10:06:02,  3.71s/it]2025-08-22:20:38:22,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2242/12032 [2:03:44<10:10:35,  3.74s/it]2025-08-22:20:38:26,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2243/12032 [2:03:48<10:13:56,  3.76s/it]2025-08-22:20:38:30,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2244/12032 [2:03:52<10:15:09,  3.77s/it]2025-08-22:20:38:34,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2245/12032 [2:03:56<10:17:51,  3.79s/it]2025-08-22:20:38:38,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2246/12032 [2:04:00<10:22:10,  3.81s/it]2025-08-22:20:38:42,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2247/12032 [2:04:03<10:20:55,  3.81s/it]2025-08-22:20:38:45,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2248/12032 [2:04:07<10:21:56,  3.81s/it]2025-08-22:20:38:49,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2249/12032 [2:04:11<10:22:16,  3.82s/it]2025-08-22:20:38:53,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2250/12032 [2:04:15<10:22:59,  3.82s/it]2025-08-22:20:38:57,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2251/12032 [2:04:19<10:24:03,  3.83s/it]2025-08-22:20:39:01,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2252/12032 [2:04:23<10:23:00,  3.82s/it]2025-08-22:20:39:04,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2253/12032 [2:04:26<10:21:08,  3.81s/it]2025-08-22:20:39:08,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2254/12032 [2:04:30<10:23:46,  3.83s/it]2025-08-22:20:39:12,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▊        | 2255/12032 [2:04:34<10:23:51,  3.83s/it]2025-08-22:20:39:16,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2256/12032 [2:04:38<10:22:57,  3.82s/it]2025-08-22:20:39:20,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2257/12032 [2:04:42<10:21:48,  3.82s/it]2025-08-22:20:39:24,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2258/12032 [2:04:46<10:21:11,  3.81s/it]2025-08-22:20:39:27,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2259/12032 [2:04:48<9:18:00,  3.43s/it] 2025-08-22:20:39:30,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2260/12032 [2:04:52<9:36:23,  3.54s/it]2025-08-22:20:39:34,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2261/12032 [2:04:56<9:49:29,  3.62s/it]2025-08-22:20:39:37,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2262/12032 [2:04:59<9:58:08,  3.67s/it]2025-08-22:20:39:41,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2263/12032 [2:05:03<10:06:15,  3.72s/it]2025-08-22:20:39:45,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2264/12032 [2:05:07<10:10:24,  3.75s/it]2025-08-22:20:39:49,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2265/12032 [2:05:11<9:59:28,  3.68s/it] 2025-08-22:20:39:52,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2266/12032 [2:05:14<10:00:04,  3.69s/it]2025-08-22:20:39:56,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2267/12032 [2:05:18<9:59:17,  3.68s/it] 2025-08-22:20:40:00,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2268/12032 [2:05:22<10:12:02,  3.76s/it]2025-08-22:20:40:04,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2269/12032 [2:05:26<10:14:16,  3.78s/it]2025-08-22:20:40:08,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2270/12032 [2:05:30<10:16:14,  3.79s/it]2025-08-22:20:40:11,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2271/12032 [2:05:33<10:19:29,  3.81s/it]2025-08-22:20:40:15,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2272/12032 [2:05:37<10:20:51,  3.82s/it]2025-08-22:20:40:19,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2273/12032 [2:05:41<10:18:48,  3.80s/it]2025-08-22:20:40:23,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2274/12032 [2:05:45<10:20:47,  3.82s/it]2025-08-22:20:40:27,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2275/12032 [2:05:48<9:52:55,  3.65s/it] 2025-08-22:20:40:30,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2276/12032 [2:05:52<10:02:42,  3.71s/it]2025-08-22:20:40:34,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2277/12032 [2:05:56<10:06:13,  3.73s/it]2025-08-22:20:40:38,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2278/12032 [2:06:00<10:12:55,  3.77s/it]2025-08-22:20:40:41,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2279/12032 [2:06:03<10:13:57,  3.78s/it]2025-08-22:20:40:45,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2280/12032 [2:06:07<10:17:24,  3.80s/it]2025-08-22:20:40:49,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2281/12032 [2:06:11<10:16:26,  3.79s/it]2025-08-22:20:40:53,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2282/12032 [2:06:15<10:19:30,  3.81s/it]2025-08-22:20:40:57,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2283/12032 [2:06:19<10:16:36,  3.79s/it]2025-08-22:20:41:00,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2284/12032 [2:06:22<10:16:45,  3.80s/it]2025-08-22:20:41:04,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2285/12032 [2:06:26<10:14:15,  3.78s/it]2025-08-22:20:41:08,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2286/12032 [2:06:30<10:15:09,  3.79s/it]2025-08-22:20:41:12,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2287/12032 [2:06:34<10:17:55,  3.80s/it]2025-08-22:20:41:16,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2288/12032 [2:06:38<10:12:07,  3.77s/it]2025-08-22:20:41:19,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2289/12032 [2:06:41<10:13:30,  3.78s/it]2025-08-22:20:41:23,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2290/12032 [2:06:45<10:15:40,  3.79s/it]2025-08-22:20:41:27,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2291/12032 [2:06:48<9:09:30,  3.38s/it] 2025-08-22:20:41:29,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2292/12032 [2:06:51<9:32:55,  3.53s/it]2025-08-22:20:41:33,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2293/12032 [2:06:55<9:46:15,  3.61s/it]2025-08-22:20:41:37,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2294/12032 [2:06:59<9:55:16,  3.67s/it]2025-08-22:20:41:41,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2295/12032 [2:07:03<10:03:23,  3.72s/it]2025-08-22:20:41:45,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2296/12032 [2:07:07<10:06:48,  3.74s/it]2025-08-22:20:41:49,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2297/12032 [2:07:11<10:13:57,  3.78s/it]2025-08-22:20:41:52,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2298/12032 [2:07:14<10:16:32,  3.80s/it]2025-08-22:20:41:56,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2299/12032 [2:07:18<10:15:02,  3.79s/it]2025-08-22:20:42:00,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2300/12032 [2:07:22<10:15:03,  3.79s/it]2025-08-22:20:42:04,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2301/12032 [2:07:26<10:04:10,  3.73s/it]2025-08-22:20:42:07,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2302/12032 [2:07:29<10:06:16,  3.74s/it]2025-08-22:20:42:11,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2303/12032 [2:07:31<8:46:56,  3.25s/it] 2025-08-22:20:42:13,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2304/12032 [2:07:35<9:21:30,  3.46s/it]2025-08-22:20:42:17,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2305/12032 [2:07:39<9:39:51,  3.58s/it]2025-08-22:20:42:21,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2306/12032 [2:07:43<9:52:14,  3.65s/it]2025-08-22:20:42:25,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2307/12032 [2:07:47<10:00:45,  3.71s/it]2025-08-22:20:42:29,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2308/12032 [2:07:51<10:09:38,  3.76s/it]2025-08-22:20:42:33,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2309/12032 [2:07:55<10:11:37,  3.77s/it]2025-08-22:20:42:36,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2310/12032 [2:07:58<10:13:49,  3.79s/it]2025-08-22:20:42:40,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2311/12032 [2:08:02<10:12:45,  3.78s/it]2025-08-22:20:42:44,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2312/12032 [2:08:06<10:16:59,  3.81s/it]2025-08-22:20:42:48,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2313/12032 [2:08:10<10:17:12,  3.81s/it]2025-08-22:20:42:52,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2314/12032 [2:08:14<10:16:14,  3.80s/it]2025-08-22:20:42:55,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2315/12032 [2:08:18<10:18:56,  3.82s/it]2025-08-22:20:42:59,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2316/12032 [2:08:21<10:12:27,  3.78s/it]2025-08-22:20:43:03,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2317/12032 [2:08:25<10:15:56,  3.80s/it]2025-08-22:20:43:07,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2318/12032 [2:08:29<10:16:46,  3.81s/it]2025-08-22:20:43:11,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2319/12032 [2:08:33<10:19:34,  3.83s/it]2025-08-22:20:43:15,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2320/12032 [2:08:37<10:18:21,  3.82s/it]2025-08-22:20:43:18,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2321/12032 [2:08:40<10:18:31,  3.82s/it]2025-08-22:20:43:22,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2322/12032 [2:08:43<9:23:05,  3.48s/it] 2025-08-22:20:43:25,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2323/12032 [2:08:47<9:44:17,  3.61s/it]2025-08-22:20:43:29,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2324/12032 [2:08:51<9:55:02,  3.68s/it]2025-08-22:20:43:33,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2325/12032 [2:08:55<9:59:42,  3.71s/it]2025-08-22:20:43:36,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2326/12032 [2:08:58<10:04:47,  3.74s/it]2025-08-22:20:43:40,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2327/12032 [2:09:02<10:07:39,  3.76s/it]2025-08-22:20:43:44,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2328/12032 [2:09:06<10:09:38,  3.77s/it]2025-08-22:20:43:48,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2329/12032 [2:09:10<10:11:26,  3.78s/it]2025-08-22:20:43:52,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2330/12032 [2:09:14<10:13:50,  3.80s/it]2025-08-22:20:43:55,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2331/12032 [2:09:17<10:14:31,  3.80s/it]2025-08-22:20:43:59,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2332/12032 [2:09:21<10:16:00,  3.81s/it]2025-08-22:20:44:03,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2333/12032 [2:09:25<10:15:13,  3.81s/it]2025-08-22:20:44:07,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2334/12032 [2:09:29<10:17:54,  3.82s/it]2025-08-22:20:44:11,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2335/12032 [2:09:33<10:18:47,  3.83s/it]2025-08-22:20:44:15,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2336/12032 [2:09:37<10:18:02,  3.82s/it]2025-08-22:20:44:18,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2337/12032 [2:09:40<10:17:56,  3.82s/it]2025-08-22:20:44:22,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2338/12032 [2:09:44<10:19:51,  3.84s/it]2025-08-22:20:44:26,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2339/12032 [2:09:48<10:21:20,  3.85s/it]2025-08-22:20:44:30,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2340/12032 [2:09:52<10:23:24,  3.86s/it]2025-08-22:20:44:34,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2341/12032 [2:09:56<10:23:47,  3.86s/it]2025-08-22:20:44:38,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2342/12032 [2:10:00<10:23:55,  3.86s/it]2025-08-22:20:44:42,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2343/12032 [2:10:04<10:22:55,  3.86s/it]2025-08-22:20:44:45,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2344/12032 [2:10:07<10:23:50,  3.86s/it]2025-08-22:20:44:49,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2345/12032 [2:10:11<10:20:27,  3.84s/it]2025-08-22:20:44:53,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  19%|█▉        | 2346/12032 [2:10:15<10:18:10,  3.83s/it]2025-08-22:20:44:57,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2347/12032 [2:10:19<10:17:15,  3.82s/it]2025-08-22:20:45:01,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2348/12032 [2:10:23<10:18:29,  3.83s/it]2025-08-22:20:45:05,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2349/12032 [2:10:27<10:16:46,  3.82s/it]2025-08-22:20:45:08,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2350/12032 [2:10:30<10:15:18,  3.81s/it]2025-08-22:20:45:12,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2351/12032 [2:10:34<10:17:36,  3.83s/it]2025-08-22:20:45:16,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2352/12032 [2:10:38<10:18:48,  3.84s/it]2025-08-22:20:45:20,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2353/12032 [2:10:42<10:22:08,  3.86s/it]2025-08-22:20:45:24,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2354/12032 [2:10:46<10:23:06,  3.86s/it]2025-08-22:20:45:28,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2355/12032 [2:10:50<10:20:21,  3.85s/it]2025-08-22:20:45:31,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2356/12032 [2:10:53<10:17:36,  3.83s/it]2025-08-22:20:45:35,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2357/12032 [2:10:57<10:16:29,  3.82s/it]2025-08-22:20:45:39,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2358/12032 [2:11:01<10:17:07,  3.83s/it]2025-08-22:20:45:43,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2359/12032 [2:11:05<10:18:24,  3.84s/it]2025-08-22:20:45:47,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2360/12032 [2:11:09<10:17:27,  3.83s/it]2025-08-22:20:45:51,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2361/12032 [2:11:13<10:15:19,  3.82s/it]2025-08-22:20:45:54,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2362/12032 [2:11:16<10:16:10,  3.82s/it]2025-08-22:20:45:58,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2363/12032 [2:11:20<10:15:59,  3.82s/it]2025-08-22:20:46:02,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2364/12032 [2:11:24<10:14:21,  3.81s/it]2025-08-22:20:46:06,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2365/12032 [2:11:28<10:14:26,  3.81s/it]2025-08-22:20:46:10,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2366/12032 [2:11:32<10:14:38,  3.82s/it]2025-08-22:20:46:13,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2367/12032 [2:11:35<10:14:36,  3.82s/it]2025-08-22:20:46:17,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2368/12032 [2:11:39<10:14:47,  3.82s/it]2025-08-22:20:46:21,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2369/12032 [2:11:43<10:19:21,  3.85s/it]2025-08-22:20:46:25,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2370/12032 [2:11:47<10:17:05,  3.83s/it]2025-08-22:20:46:29,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2371/12032 [2:11:51<10:16:45,  3.83s/it]2025-08-22:20:46:33,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2372/12032 [2:11:55<10:20:05,  3.85s/it]2025-08-22:20:46:37,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2373/12032 [2:11:59<10:18:51,  3.84s/it]2025-08-22:20:46:40,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2374/12032 [2:12:02<10:17:12,  3.83s/it]2025-08-22:20:46:44,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2375/12032 [2:12:06<10:15:45,  3.83s/it]2025-08-22:20:46:48,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2376/12032 [2:12:10<10:16:20,  3.83s/it]2025-08-22:20:46:52,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2377/12032 [2:12:14<10:13:42,  3.81s/it]2025-08-22:20:46:56,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2378/12032 [2:12:17<9:27:27,  3.53s/it] 2025-08-22:20:46:58,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2379/12032 [2:12:20<9:43:27,  3.63s/it]2025-08-22:20:47:02,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2380/12032 [2:12:24<9:49:43,  3.67s/it]2025-08-22:20:47:06,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2381/12032 [2:12:28<9:57:05,  3.71s/it]2025-08-22:20:47:10,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2382/12032 [2:12:31<9:18:40,  3.47s/it]2025-08-22:20:47:13,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2383/12032 [2:12:35<9:34:09,  3.57s/it]2025-08-22:20:47:17,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2384/12032 [2:12:39<9:45:23,  3.64s/it]2025-08-22:20:47:20,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2385/12032 [2:12:42<9:49:32,  3.67s/it]2025-08-22:20:47:24,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2386/12032 [2:12:46<9:56:11,  3.71s/it]2025-08-22:20:47:28,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2387/12032 [2:12:50<10:01:09,  3.74s/it]2025-08-22:20:47:32,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2388/12032 [2:12:54<10:03:44,  3.76s/it]2025-08-22:20:47:36,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2389/12032 [2:12:58<10:06:44,  3.78s/it]2025-08-22:20:47:39,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2390/12032 [2:13:01<10:07:19,  3.78s/it]2025-08-22:20:47:43,663 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2391/12032 [2:13:05<10:07:35,  3.78s/it]2025-08-22:20:47:47,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2392/12032 [2:13:09<10:07:44,  3.78s/it]2025-08-22:20:47:51,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2393/12032 [2:13:13<10:09:12,  3.79s/it]2025-08-22:20:47:55,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2394/12032 [2:13:17<10:11:36,  3.81s/it]2025-08-22:20:47:58,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2395/12032 [2:13:20<10:11:57,  3.81s/it]2025-08-22:20:48:02,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2396/12032 [2:13:24<10:09:55,  3.80s/it]2025-08-22:20:48:06,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2397/12032 [2:13:28<10:10:04,  3.80s/it]2025-08-22:20:48:10,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2398/12032 [2:13:29<8:21:27,  3.12s/it] 2025-08-22:20:48:11,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2399/12032 [2:13:33<8:53:43,  3.32s/it]2025-08-22:20:48:15,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2400/12032 [2:13:36<8:12:57,  3.07s/it]2025-08-22:20:48:18,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2401/12032 [2:13:40<8:49:16,  3.30s/it]2025-08-22:20:48:21,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2402/12032 [2:13:43<9:13:39,  3.45s/it]2025-08-22:20:48:25,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2403/12032 [2:13:47<9:30:13,  3.55s/it]2025-08-22:20:48:29,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2404/12032 [2:13:51<9:41:22,  3.62s/it]2025-08-22:20:48:33,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2405/12032 [2:13:55<9:54:03,  3.70s/it]2025-08-22:20:48:37,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|█▉        | 2406/12032 [2:13:59<10:02:14,  3.75s/it]2025-08-22:20:48:41,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2407/12032 [2:14:03<10:04:07,  3.77s/it]2025-08-22:20:48:44,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2408/12032 [2:14:06<10:07:45,  3.79s/it]2025-08-22:20:48:48,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2409/12032 [2:14:10<10:10:00,  3.80s/it]2025-08-22:20:48:52,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2410/12032 [2:14:14<10:10:26,  3.81s/it]2025-08-22:20:48:56,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2411/12032 [2:14:18<10:10:08,  3.81s/it]2025-08-22:20:49:00,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2412/12032 [2:14:22<10:11:09,  3.81s/it]2025-08-22:20:49:03,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2413/12032 [2:14:25<10:11:15,  3.81s/it]2025-08-22:20:49:07,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2414/12032 [2:14:29<10:11:46,  3.82s/it]2025-08-22:20:49:11,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2415/12032 [2:14:33<10:11:01,  3.81s/it]2025-08-22:20:49:15,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2416/12032 [2:14:37<10:10:35,  3.81s/it]2025-08-22:20:49:19,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2417/12032 [2:14:41<10:10:58,  3.81s/it]2025-08-22:20:49:23,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2418/12032 [2:14:44<10:09:42,  3.81s/it]2025-08-22:20:49:26,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2419/12032 [2:14:48<10:11:11,  3.81s/it]2025-08-22:20:49:30,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2420/12032 [2:14:52<10:10:41,  3.81s/it]2025-08-22:20:49:34,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2421/12032 [2:14:56<10:08:57,  3.80s/it]2025-08-22:20:49:38,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2422/12032 [2:15:00<10:08:49,  3.80s/it]2025-08-22:20:49:42,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2423/12032 [2:15:04<10:08:03,  3.80s/it]2025-08-22:20:49:45,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2424/12032 [2:15:07<10:08:19,  3.80s/it]2025-08-22:20:49:49,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2425/12032 [2:15:11<10:15:15,  3.84s/it]2025-08-22:20:49:53,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2426/12032 [2:15:15<10:12:31,  3.83s/it]2025-08-22:20:49:57,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2427/12032 [2:15:19<10:10:23,  3.81s/it]2025-08-22:20:50:01,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2428/12032 [2:15:21<8:35:43,  3.22s/it] 2025-08-22:20:50:03,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2429/12032 [2:15:24<9:03:21,  3.39s/it]2025-08-22:20:50:06,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2430/12032 [2:15:28<9:24:15,  3.53s/it]2025-08-22:20:50:10,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2431/12032 [2:15:32<9:39:00,  3.62s/it]2025-08-22:20:50:14,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2432/12032 [2:15:36<9:46:33,  3.67s/it]2025-08-22:20:50:18,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2433/12032 [2:15:40<9:52:44,  3.71s/it]2025-08-22:20:50:22,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2434/12032 [2:15:44<9:58:10,  3.74s/it]2025-08-22:20:50:25,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2435/12032 [2:15:47<10:00:14,  3.75s/it]2025-08-22:20:50:29,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2436/12032 [2:15:51<9:45:25,  3.66s/it] 2025-08-22:20:50:33,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2437/12032 [2:15:55<9:52:21,  3.70s/it]2025-08-22:20:50:36,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2438/12032 [2:15:58<9:56:03,  3.73s/it]2025-08-22:20:50:40,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2439/12032 [2:16:02<10:00:09,  3.75s/it]2025-08-22:20:50:44,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2440/12032 [2:16:06<10:00:32,  3.76s/it]2025-08-22:20:50:48,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2441/12032 [2:16:10<10:03:02,  3.77s/it]2025-08-22:20:50:52,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2442/12032 [2:16:14<10:04:00,  3.78s/it]2025-08-22:20:50:55,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2443/12032 [2:16:17<10:04:16,  3.78s/it]2025-08-22:20:50:59,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2444/12032 [2:16:20<9:12:39,  3.46s/it] 2025-08-22:20:51:02,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2445/12032 [2:16:24<9:29:00,  3.56s/it]2025-08-22:20:51:06,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2446/12032 [2:16:28<9:40:24,  3.63s/it]2025-08-22:20:51:09,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2447/12032 [2:16:31<9:47:47,  3.68s/it]2025-08-22:20:51:13,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2448/12032 [2:16:35<9:53:33,  3.72s/it]2025-08-22:20:51:17,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2449/12032 [2:16:39<9:59:24,  3.75s/it]2025-08-22:20:51:21,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2450/12032 [2:16:43<10:01:02,  3.76s/it]2025-08-22:20:51:25,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2451/12032 [2:16:47<10:03:04,  3.78s/it]2025-08-22:20:51:28,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2452/12032 [2:16:50<10:04:07,  3.78s/it]2025-08-22:20:51:32,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2453/12032 [2:16:54<10:07:40,  3.81s/it]2025-08-22:20:51:36,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2454/12032 [2:16:58<10:10:53,  3.83s/it]2025-08-22:20:51:40,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2455/12032 [2:17:02<10:15:41,  3.86s/it]2025-08-22:20:51:44,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2456/12032 [2:17:06<10:12:53,  3.84s/it]2025-08-22:20:51:48,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2457/12032 [2:17:10<10:10:29,  3.83s/it]2025-08-22:20:51:52,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2458/12032 [2:17:13<10:08:54,  3.82s/it]2025-08-22:20:51:55,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2459/12032 [2:17:17<10:07:10,  3.81s/it]2025-08-22:20:51:59,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2460/12032 [2:17:21<10:08:18,  3.81s/it]2025-08-22:20:52:03,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2461/12032 [2:17:25<10:08:14,  3.81s/it]2025-08-22:20:52:07,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2462/12032 [2:17:29<10:07:55,  3.81s/it]2025-08-22:20:52:11,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2463/12032 [2:17:33<10:07:05,  3.81s/it]2025-08-22:20:52:14,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2464/12032 [2:17:36<10:06:07,  3.80s/it]2025-08-22:20:52:18,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2465/12032 [2:17:40<10:06:10,  3.80s/it]2025-08-22:20:52:22,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  20%|██        | 2466/12032 [2:17:44<10:06:02,  3.80s/it]2025-08-22:20:52:26,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2467/12032 [2:17:48<10:05:52,  3.80s/it]2025-08-22:20:52:30,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2468/12032 [2:17:52<10:08:40,  3.82s/it]2025-08-22:20:52:33,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2469/12032 [2:17:55<10:08:17,  3.82s/it]2025-08-22:20:52:37,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2470/12032 [2:17:59<10:06:26,  3.81s/it]2025-08-22:20:52:41,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2471/12032 [2:18:03<10:05:53,  3.80s/it]2025-08-22:20:52:45,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2472/12032 [2:18:07<10:06:51,  3.81s/it]2025-08-22:20:52:49,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2473/12032 [2:18:11<10:06:20,  3.81s/it]2025-08-22:20:52:52,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2474/12032 [2:18:12<8:10:50,  3.08s/it] 2025-08-22:20:52:54,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2475/12032 [2:18:16<8:47:58,  3.31s/it]2025-08-22:20:52:58,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2476/12032 [2:18:18<8:13:26,  3.10s/it]2025-08-22:20:53:00,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2477/12032 [2:18:22<8:32:19,  3.22s/it]2025-08-22:20:53:04,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2478/12032 [2:18:26<8:59:51,  3.39s/it]2025-08-22:20:53:08,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2479/12032 [2:18:30<9:25:09,  3.55s/it]2025-08-22:20:53:11,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2480/12032 [2:18:33<9:36:56,  3.62s/it]2025-08-22:20:53:15,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2481/12032 [2:18:37<9:44:41,  3.67s/it]2025-08-22:20:53:19,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2482/12032 [2:18:41<9:50:04,  3.71s/it]2025-08-22:20:53:23,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2483/12032 [2:18:45<9:55:40,  3.74s/it]2025-08-22:20:53:27,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2484/12032 [2:18:48<9:25:44,  3.56s/it]2025-08-22:20:53:30,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2485/12032 [2:18:52<9:38:07,  3.63s/it]2025-08-22:20:53:34,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2486/12032 [2:18:55<9:33:03,  3.60s/it]2025-08-22:20:53:37,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2487/12032 [2:18:59<9:41:42,  3.66s/it]2025-08-22:20:53:41,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2488/12032 [2:19:03<9:54:56,  3.74s/it]2025-08-22:20:53:45,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2489/12032 [2:19:07<10:00:19,  3.77s/it]2025-08-22:20:53:49,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2490/12032 [2:19:11<10:00:52,  3.78s/it]2025-08-22:20:53:52,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2491/12032 [2:19:14<10:00:16,  3.77s/it]2025-08-22:20:53:56,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2492/12032 [2:19:18<10:03:33,  3.80s/it]2025-08-22:20:54:00,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2493/12032 [2:19:22<10:03:40,  3.80s/it]2025-08-22:20:54:04,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2494/12032 [2:19:26<10:04:29,  3.80s/it]2025-08-22:20:54:08,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2495/12032 [2:19:30<10:04:35,  3.80s/it]2025-08-22:20:54:12,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2496/12032 [2:19:33<10:02:53,  3.79s/it]2025-08-22:20:54:15,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2497/12032 [2:19:37<10:01:28,  3.78s/it]2025-08-22:20:54:19,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2498/12032 [2:19:41<10:03:05,  3.80s/it]2025-08-22:20:54:23,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2499/12032 [2:19:45<10:03:13,  3.80s/it]2025-08-22:20:54:27,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2500/12032 [2:19:49<10:04:06,  3.80s/it]2025-08-22:20:54:30,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2501/12032 [2:19:52<10:02:01,  3.79s/it]2025-08-22:20:54:34,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2502/12032 [2:19:56<10:02:34,  3.79s/it]2025-08-22:20:54:38,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2503/12032 [2:20:00<10:05:18,  3.81s/it]2025-08-22:20:54:42,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2504/12032 [2:20:04<10:12:59,  3.86s/it]2025-08-22:20:54:46,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2505/12032 [2:20:08<10:10:46,  3.85s/it]2025-08-22:20:54:50,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2506/12032 [2:20:11<9:40:28,  3.66s/it] 2025-08-22:20:54:53,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2507/12032 [2:20:15<9:47:13,  3.70s/it]2025-08-22:20:54:57,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2508/12032 [2:20:18<9:14:30,  3.49s/it]2025-08-22:20:55:00,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2509/12032 [2:20:22<9:31:27,  3.60s/it]2025-08-22:20:55:04,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2510/12032 [2:20:26<9:46:44,  3.70s/it]2025-08-22:20:55:07,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2511/12032 [2:20:29<9:51:20,  3.73s/it]2025-08-22:20:55:11,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2512/12032 [2:20:33<9:55:03,  3.75s/it]2025-08-22:20:55:15,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2513/12032 [2:20:37<9:57:41,  3.77s/it]2025-08-22:20:55:19,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2514/12032 [2:20:39<8:47:33,  3.33s/it]2025-08-22:20:55:21,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2515/12032 [2:20:43<9:10:35,  3.47s/it]2025-08-22:20:55:25,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2516/12032 [2:20:47<9:15:36,  3.50s/it]2025-08-22:20:55:29,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2517/12032 [2:20:51<9:30:47,  3.60s/it]2025-08-22:20:55:32,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2518/12032 [2:20:54<9:40:07,  3.66s/it]2025-08-22:20:55:36,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2519/12032 [2:20:58<9:46:29,  3.70s/it]2025-08-22:20:55:40,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2520/12032 [2:21:02<9:50:46,  3.73s/it]2025-08-22:20:55:44,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2521/12032 [2:21:05<9:04:58,  3.44s/it]2025-08-22:20:55:47,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2522/12032 [2:21:09<9:22:46,  3.55s/it]2025-08-22:20:55:50,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2523/12032 [2:21:12<9:34:26,  3.62s/it]2025-08-22:20:55:54,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2524/12032 [2:21:16<9:44:17,  3.69s/it]2025-08-22:20:55:58,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2525/12032 [2:21:20<9:50:48,  3.73s/it]2025-08-22:20:56:02,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2526/12032 [2:21:24<9:54:56,  3.76s/it]2025-08-22:20:56:06,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2527/12032 [2:21:28<10:00:37,  3.79s/it]2025-08-22:20:56:10,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2528/12032 [2:21:31<9:59:23,  3.78s/it] 2025-08-22:20:56:13,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2529/12032 [2:21:35<10:04:00,  3.81s/it]2025-08-22:20:56:17,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2530/12032 [2:21:39<10:03:27,  3.81s/it]2025-08-22:20:56:21,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2531/12032 [2:21:43<10:02:17,  3.80s/it]2025-08-22:20:56:25,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2532/12032 [2:21:47<10:02:19,  3.80s/it]2025-08-22:20:56:29,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2533/12032 [2:21:51<10:04:20,  3.82s/it]2025-08-22:20:56:32,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2534/12032 [2:21:54<10:05:13,  3.82s/it]2025-08-22:20:56:36,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2535/12032 [2:21:58<10:06:37,  3.83s/it]2025-08-22:20:56:40,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2536/12032 [2:22:02<10:04:21,  3.82s/it]2025-08-22:20:56:44,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2537/12032 [2:22:06<10:06:25,  3.83s/it]2025-08-22:20:56:48,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2538/12032 [2:22:09<9:41:00,  3.67s/it] 2025-08-22:20:56:51,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2539/12032 [2:22:13<9:52:29,  3.74s/it]2025-08-22:20:56:55,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2540/12032 [2:22:16<9:28:55,  3.60s/it]2025-08-22:20:56:58,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2541/12032 [2:22:20<9:39:51,  3.67s/it]2025-08-22:20:57:02,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2542/12032 [2:22:24<9:46:43,  3.71s/it]2025-08-22:20:57:06,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2543/12032 [2:22:28<9:55:16,  3.76s/it]2025-08-22:20:57:10,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2544/12032 [2:22:31<9:01:08,  3.42s/it]2025-08-22:20:57:12,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2545/12032 [2:22:34<9:18:42,  3.53s/it]2025-08-22:20:57:16,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2546/12032 [2:22:38<9:31:00,  3.61s/it]2025-08-22:20:57:20,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2547/12032 [2:22:42<9:41:02,  3.68s/it]2025-08-22:20:57:24,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2548/12032 [2:22:46<9:48:09,  3.72s/it]2025-08-22:20:57:28,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2549/12032 [2:22:50<9:52:50,  3.75s/it]2025-08-22:20:57:31,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2550/12032 [2:22:53<9:55:51,  3.77s/it]2025-08-22:20:57:35,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2551/12032 [2:22:57<9:58:04,  3.78s/it]2025-08-22:20:57:39,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2552/12032 [2:23:01<10:01:45,  3.81s/it]2025-08-22:20:57:43,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2553/12032 [2:23:05<10:01:25,  3.81s/it]2025-08-22:20:57:47,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2554/12032 [2:23:09<10:00:23,  3.80s/it]2025-08-22:20:57:51,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2555/12032 [2:23:12<10:00:06,  3.80s/it]2025-08-22:20:57:54,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██        | 2556/12032 [2:23:16<10:02:02,  3.81s/it]2025-08-22:20:57:58,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2557/12032 [2:23:20<10:00:07,  3.80s/it]2025-08-22:20:58:02,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2558/12032 [2:23:24<10:00:53,  3.81s/it]2025-08-22:20:58:06,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2559/12032 [2:23:27<9:24:48,  3.58s/it] 2025-08-22:20:58:09,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2560/12032 [2:23:31<9:34:21,  3.64s/it]2025-08-22:20:58:13,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2561/12032 [2:23:35<9:41:17,  3.68s/it]2025-08-22:20:58:16,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2562/12032 [2:23:38<9:47:46,  3.72s/it]2025-08-22:20:58:20,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2563/12032 [2:23:42<9:50:17,  3.74s/it]2025-08-22:20:58:24,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2564/12032 [2:23:46<9:53:00,  3.76s/it]2025-08-22:20:58:28,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2565/12032 [2:23:50<9:54:39,  3.77s/it]2025-08-22:20:58:32,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2566/12032 [2:23:53<9:54:59,  3.77s/it]2025-08-22:20:58:35,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2567/12032 [2:23:57<9:56:36,  3.78s/it]2025-08-22:20:58:39,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2568/12032 [2:24:01<9:56:26,  3.78s/it]2025-08-22:20:58:43,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2569/12032 [2:24:05<9:57:21,  3.79s/it]2025-08-22:20:58:47,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2570/12032 [2:24:09<9:56:54,  3.79s/it]2025-08-22:20:58:50,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2571/12032 [2:24:12<9:56:12,  3.78s/it]2025-08-22:20:58:54,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2572/12032 [2:24:15<9:14:53,  3.52s/it]2025-08-22:20:58:57,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2573/12032 [2:24:18<8:26:08,  3.21s/it]2025-08-22:20:59:00,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2574/12032 [2:24:21<8:44:25,  3.33s/it]2025-08-22:20:59:03,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2575/12032 [2:24:25<9:05:49,  3.46s/it]2025-08-22:20:59:07,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2576/12032 [2:24:29<9:14:26,  3.52s/it]2025-08-22:20:59:11,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2577/12032 [2:24:33<9:27:02,  3.60s/it]2025-08-22:20:59:14,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2578/12032 [2:24:36<9:35:40,  3.65s/it]2025-08-22:20:59:18,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2579/12032 [2:24:40<9:40:33,  3.68s/it]2025-08-22:20:59:22,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2580/12032 [2:24:44<9:45:17,  3.72s/it]2025-08-22:20:59:26,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2581/12032 [2:24:48<9:48:25,  3.74s/it]2025-08-22:20:59:30,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2582/12032 [2:24:52<9:50:32,  3.75s/it]2025-08-22:20:59:33,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2583/12032 [2:24:55<9:50:54,  3.75s/it]2025-08-22:20:59:37,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2584/12032 [2:24:59<9:51:43,  3.76s/it]2025-08-22:20:59:41,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2585/12032 [2:25:03<9:54:55,  3.78s/it]2025-08-22:20:59:45,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  21%|██▏       | 2586/12032 [2:25:07<9:56:00,  3.79s/it]2025-08-22:20:59:49,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2587/12032 [2:25:10<9:56:27,  3.79s/it]2025-08-22:20:59:52,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2588/12032 [2:25:14<9:56:35,  3.79s/it]2025-08-22:20:59:56,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2589/12032 [2:25:18<9:56:49,  3.79s/it]2025-08-22:21:00:00,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2590/12032 [2:25:22<9:58:58,  3.81s/it]2025-08-22:21:00:04,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2591/12032 [2:25:26<10:02:00,  3.83s/it]2025-08-22:21:00:08,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2592/12032 [2:25:30<10:02:51,  3.83s/it]2025-08-22:21:00:11,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2593/12032 [2:25:33<10:03:10,  3.83s/it]2025-08-22:21:00:15,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2594/12032 [2:25:37<10:01:56,  3.83s/it]2025-08-22:21:00:19,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2595/12032 [2:25:41<10:03:16,  3.84s/it]2025-08-22:21:00:23,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2596/12032 [2:25:45<10:02:43,  3.83s/it]2025-08-22:21:00:27,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2597/12032 [2:25:49<10:02:13,  3.83s/it]2025-08-22:21:00:31,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2598/12032 [2:25:53<10:01:22,  3.82s/it]2025-08-22:21:00:34,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2599/12032 [2:25:56<10:01:45,  3.83s/it]2025-08-22:21:00:38,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2600/12032 [2:26:00<10:00:57,  3.82s/it]2025-08-22:21:00:42,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2601/12032 [2:26:04<10:03:33,  3.84s/it]2025-08-22:21:00:46,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2602/12032 [2:26:08<10:04:41,  3.85s/it]2025-08-22:21:00:50,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2603/12032 [2:26:12<10:02:40,  3.83s/it]2025-08-22:21:00:54,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2604/12032 [2:26:16<10:02:39,  3.84s/it]2025-08-22:21:00:57,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2605/12032 [2:26:19<10:01:44,  3.83s/it]2025-08-22:21:01:01,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2606/12032 [2:26:23<10:04:09,  3.85s/it]2025-08-22:21:01:05,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2607/12032 [2:26:27<10:04:28,  3.85s/it]2025-08-22:21:01:09,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2608/12032 [2:26:31<10:03:58,  3.85s/it]2025-08-22:21:01:13,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2609/12032 [2:26:35<10:03:35,  3.84s/it]2025-08-22:21:01:17,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2610/12032 [2:26:39<10:03:47,  3.85s/it]2025-08-22:21:01:21,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2611/12032 [2:26:43<10:02:51,  3.84s/it]2025-08-22:21:01:24,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2612/12032 [2:26:46<10:02:47,  3.84s/it]2025-08-22:21:01:28,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2613/12032 [2:26:50<10:02:43,  3.84s/it]2025-08-22:21:01:32,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2614/12032 [2:26:54<10:01:08,  3.83s/it]2025-08-22:21:01:36,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2615/12032 [2:26:58<10:01:11,  3.83s/it]2025-08-22:21:01:40,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2616/12032 [2:27:02<10:03:10,  3.84s/it]2025-08-22:21:01:44,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2617/12032 [2:27:06<10:06:44,  3.87s/it]2025-08-22:21:01:47,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2618/12032 [2:27:09<10:03:26,  3.85s/it]2025-08-22:21:01:51,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2619/12032 [2:27:13<10:01:11,  3.83s/it]2025-08-22:21:01:55,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2620/12032 [2:27:17<10:00:35,  3.83s/it]2025-08-22:21:01:59,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2621/12032 [2:27:21<10:01:04,  3.83s/it]2025-08-22:21:02:03,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2622/12032 [2:27:25<10:01:43,  3.84s/it]2025-08-22:21:02:07,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2623/12032 [2:27:29<10:01:30,  3.84s/it]2025-08-22:21:02:10,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2624/12032 [2:27:32<10:02:58,  3.85s/it]2025-08-22:21:02:14,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2625/12032 [2:27:36<10:02:16,  3.84s/it]2025-08-22:21:02:18,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2626/12032 [2:27:40<10:01:27,  3.84s/it]2025-08-22:21:02:22,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2627/12032 [2:27:44<9:44:34,  3.73s/it] 2025-08-22:21:02:25,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2628/12032 [2:27:47<9:50:32,  3.77s/it]2025-08-22:21:02:29,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2629/12032 [2:27:51<9:53:05,  3.78s/it]2025-08-22:21:02:33,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2630/12032 [2:27:55<9:55:18,  3.80s/it]2025-08-22:21:02:37,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2631/12032 [2:27:59<9:56:37,  3.81s/it]2025-08-22:21:02:41,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2632/12032 [2:28:03<9:58:22,  3.82s/it]2025-08-22:21:02:45,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2633/12032 [2:28:07<9:58:15,  3.82s/it]2025-08-22:21:02:48,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2634/12032 [2:28:10<9:58:22,  3.82s/it]2025-08-22:21:02:52,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2635/12032 [2:28:14<9:57:59,  3.82s/it]2025-08-22:21:02:56,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2636/12032 [2:28:18<9:57:02,  3.81s/it]2025-08-22:21:03:00,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2637/12032 [2:28:22<9:58:36,  3.82s/it]2025-08-22:21:03:04,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2638/12032 [2:28:26<10:01:23,  3.84s/it]2025-08-22:21:03:08,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2639/12032 [2:28:30<9:59:18,  3.83s/it] 2025-08-22:21:03:11,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2640/12032 [2:28:32<8:33:53,  3.28s/it]2025-08-22:21:03:13,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2641/12032 [2:28:35<8:58:00,  3.44s/it]2025-08-22:21:03:17,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2642/12032 [2:28:39<9:20:32,  3.58s/it]2025-08-22:21:03:21,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2643/12032 [2:28:43<9:33:05,  3.66s/it]2025-08-22:21:03:25,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2644/12032 [2:28:47<9:39:06,  3.70s/it]2025-08-22:21:03:29,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2645/12032 [2:28:51<9:43:39,  3.73s/it]2025-08-22:21:03:33,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2646/12032 [2:28:55<9:49:07,  3.77s/it]2025-08-22:21:03:36,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2647/12032 [2:28:57<8:49:10,  3.38s/it]2025-08-22:21:03:39,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2648/12032 [2:28:59<7:54:36,  3.03s/it]2025-08-22:21:03:41,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2649/12032 [2:29:01<6:44:41,  2.59s/it]2025-08-22:21:03:43,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2650/12032 [2:29:05<7:41:06,  2.95s/it]2025-08-22:21:03:46,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2651/12032 [2:29:08<8:19:01,  3.19s/it]2025-08-22:21:03:50,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2652/12032 [2:29:10<7:09:02,  2.74s/it]2025-08-22:21:03:52,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2653/12032 [2:29:14<7:57:44,  3.06s/it]2025-08-22:21:03:56,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2654/12032 [2:29:16<7:02:28,  2.70s/it]2025-08-22:21:03:58,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2655/12032 [2:29:19<7:16:03,  2.79s/it]2025-08-22:21:04:01,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2656/12032 [2:29:23<8:02:35,  3.09s/it]2025-08-22:21:04:04,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2657/12032 [2:29:26<8:34:39,  3.29s/it]2025-08-22:21:04:08,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2658/12032 [2:29:30<9:01:13,  3.46s/it]2025-08-22:21:04:12,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2659/12032 [2:29:34<9:17:04,  3.57s/it]2025-08-22:21:04:16,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2660/12032 [2:29:38<9:28:40,  3.64s/it]2025-08-22:21:04:20,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2661/12032 [2:29:41<8:56:03,  3.43s/it]2025-08-22:21:04:23,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2662/12032 [2:29:45<9:13:10,  3.54s/it]2025-08-22:21:04:26,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2663/12032 [2:29:48<9:24:15,  3.61s/it]2025-08-22:21:04:30,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2664/12032 [2:29:52<9:33:36,  3.67s/it]2025-08-22:21:04:34,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2665/12032 [2:29:55<9:09:40,  3.52s/it]2025-08-22:21:04:37,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2666/12032 [2:29:58<8:33:30,  3.29s/it]2025-08-22:21:04:40,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2667/12032 [2:30:02<8:57:50,  3.45s/it]2025-08-22:21:04:44,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2668/12032 [2:30:05<8:43:37,  3.36s/it]2025-08-22:21:04:47,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2669/12032 [2:30:08<8:44:34,  3.36s/it]2025-08-22:21:04:50,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2670/12032 [2:30:12<9:05:45,  3.50s/it]2025-08-22:21:04:54,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2671/12032 [2:30:15<8:45:48,  3.37s/it]2025-08-22:21:04:57,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2672/12032 [2:30:18<8:21:10,  3.21s/it]2025-08-22:21:05:00,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2673/12032 [2:30:22<8:47:28,  3.38s/it]2025-08-22:21:05:04,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2674/12032 [2:30:26<9:05:06,  3.50s/it]2025-08-22:21:05:07,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2675/12032 [2:30:29<9:20:01,  3.59s/it]2025-08-22:21:05:11,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2676/12032 [2:30:32<8:29:47,  3.27s/it]2025-08-22:21:05:14,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2677/12032 [2:30:34<7:34:53,  2.92s/it]2025-08-22:21:05:16,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2678/12032 [2:30:35<6:03:11,  2.33s/it]2025-08-22:21:05:17,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2679/12032 [2:30:36<4:56:18,  1.90s/it]2025-08-22:21:05:18,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2680/12032 [2:30:40<6:26:55,  2.48s/it]2025-08-22:21:05:22,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2681/12032 [2:30:44<7:29:14,  2.88s/it]2025-08-22:21:05:25,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2682/12032 [2:30:47<8:12:03,  3.16s/it]2025-08-22:21:05:29,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2683/12032 [2:30:51<8:45:07,  3.37s/it]2025-08-22:21:05:33,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2684/12032 [2:30:55<9:02:02,  3.48s/it]2025-08-22:21:05:37,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2685/12032 [2:30:59<9:18:15,  3.58s/it]2025-08-22:21:05:41,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2686/12032 [2:31:03<9:31:15,  3.67s/it]2025-08-22:21:05:45,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2687/12032 [2:31:06<9:37:22,  3.71s/it]2025-08-22:21:05:48,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2688/12032 [2:31:10<9:42:11,  3.74s/it]2025-08-22:21:05:52,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2689/12032 [2:31:14<9:45:30,  3.76s/it]2025-08-22:21:05:56,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2690/12032 [2:31:18<9:49:18,  3.78s/it]2025-08-22:21:06:00,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2691/12032 [2:31:22<9:51:35,  3.80s/it]2025-08-22:21:06:04,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2692/12032 [2:31:26<9:50:54,  3.80s/it]2025-08-22:21:06:07,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2693/12032 [2:31:29<9:51:31,  3.80s/it]2025-08-22:21:06:11,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2694/12032 [2:31:33<9:33:03,  3.68s/it]2025-08-22:21:06:15,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2695/12032 [2:31:37<9:38:24,  3.72s/it]2025-08-22:21:06:18,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2696/12032 [2:31:40<9:41:33,  3.74s/it]2025-08-22:21:06:22,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2697/12032 [2:31:44<9:43:23,  3.75s/it]2025-08-22:21:06:26,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2698/12032 [2:31:48<9:45:36,  3.76s/it]2025-08-22:21:06:30,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2699/12032 [2:31:52<9:37:48,  3.71s/it]2025-08-22:21:06:33,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2700/12032 [2:31:53<7:55:17,  3.06s/it]2025-08-22:21:06:35,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2701/12032 [2:31:56<8:07:48,  3.14s/it]2025-08-22:21:06:38,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2702/12032 [2:32:00<8:40:17,  3.35s/it]2025-08-22:21:06:42,551 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2703/12032 [2:32:04<9:01:30,  3.48s/it]2025-08-22:21:06:46,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2704/12032 [2:32:08<9:15:36,  3.57s/it]2025-08-22:21:06:50,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2705/12032 [2:32:12<9:25:01,  3.63s/it]2025-08-22:21:06:53,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2706/12032 [2:32:15<9:33:34,  3.69s/it]2025-08-22:21:06:57,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  22%|██▏       | 2707/12032 [2:32:18<9:03:37,  3.50s/it]2025-08-22:21:07:00,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2708/12032 [2:32:22<9:19:00,  3.60s/it]2025-08-22:21:07:04,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2709/12032 [2:32:24<7:31:04,  2.90s/it]2025-08-22:21:07:05,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2710/12032 [2:32:27<7:59:00,  3.08s/it]2025-08-22:21:07:09,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2711/12032 [2:32:31<8:34:30,  3.31s/it]2025-08-22:21:07:13,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2712/12032 [2:32:33<8:00:59,  3.10s/it]2025-08-22:21:07:15,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2713/12032 [2:32:36<7:45:56,  3.00s/it]2025-08-22:21:07:18,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2714/12032 [2:32:40<8:23:05,  3.24s/it]2025-08-22:21:07:22,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2715/12032 [2:32:44<8:50:17,  3.41s/it]2025-08-22:21:07:26,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2716/12032 [2:32:47<8:31:07,  3.29s/it]2025-08-22:21:07:29,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2717/12032 [2:32:51<8:55:31,  3.45s/it]2025-08-22:21:07:33,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2718/12032 [2:32:55<9:15:55,  3.58s/it]2025-08-22:21:07:36,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2719/12032 [2:32:58<9:30:13,  3.67s/it]2025-08-22:21:07:40,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2720/12032 [2:33:02<9:37:11,  3.72s/it]2025-08-22:21:07:44,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2721/12032 [2:33:05<8:29:09,  3.28s/it]2025-08-22:21:07:46,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2722/12032 [2:33:08<8:55:57,  3.45s/it]2025-08-22:21:07:50,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2723/12032 [2:33:10<7:31:55,  2.91s/it]2025-08-22:21:07:52,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2724/12032 [2:33:14<8:14:07,  3.19s/it]2025-08-22:21:07:56,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2725/12032 [2:33:18<8:42:35,  3.37s/it]2025-08-22:21:08:00,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2726/12032 [2:33:21<8:27:22,  3.27s/it]2025-08-22:21:08:03,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2727/12032 [2:33:25<8:52:39,  3.43s/it]2025-08-22:21:08:06,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2728/12032 [2:33:28<9:11:31,  3.56s/it]2025-08-22:21:08:10,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2729/12032 [2:33:32<9:25:11,  3.65s/it]2025-08-22:21:08:14,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2730/12032 [2:33:35<8:31:33,  3.30s/it]2025-08-22:21:08:17,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2731/12032 [2:33:38<8:11:54,  3.17s/it]2025-08-22:21:08:19,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2732/12032 [2:33:41<8:40:23,  3.36s/it]2025-08-22:21:08:23,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2733/12032 [2:33:44<8:05:43,  3.13s/it]2025-08-22:21:08:26,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2734/12032 [2:33:47<8:09:05,  3.16s/it]2025-08-22:21:08:29,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2735/12032 [2:33:49<7:13:34,  2.80s/it]2025-08-22:21:08:31,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2736/12032 [2:33:51<6:36:07,  2.56s/it]2025-08-22:21:08:33,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2737/12032 [2:33:55<7:35:00,  2.94s/it]2025-08-22:21:08:37,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2738/12032 [2:33:59<8:06:21,  3.14s/it]2025-08-22:21:08:40,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2739/12032 [2:34:02<8:37:22,  3.34s/it]2025-08-22:21:08:44,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2740/12032 [2:34:06<8:28:51,  3.29s/it]2025-08-22:21:08:47,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2741/12032 [2:34:08<8:06:07,  3.14s/it]2025-08-22:21:08:50,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2742/12032 [2:34:12<8:37:34,  3.34s/it]2025-08-22:21:08:54,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2743/12032 [2:34:16<8:59:43,  3.49s/it]2025-08-22:21:08:58,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2744/12032 [2:34:20<9:13:46,  3.58s/it]2025-08-22:21:09:02,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2745/12032 [2:34:22<8:30:58,  3.30s/it]2025-08-22:21:09:04,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2746/12032 [2:34:26<8:54:33,  3.45s/it]2025-08-22:21:09:08,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2747/12032 [2:34:30<9:13:37,  3.58s/it]2025-08-22:21:09:12,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2748/12032 [2:34:34<9:11:27,  3.56s/it]2025-08-22:21:09:16,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2749/12032 [2:34:36<8:09:14,  3.16s/it]2025-08-22:21:09:18,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2750/12032 [2:34:40<8:39:05,  3.36s/it]2025-08-22:21:09:22,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2751/12032 [2:34:44<9:01:05,  3.50s/it]2025-08-22:21:09:25,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2752/12032 [2:34:47<9:16:27,  3.60s/it]2025-08-22:21:09:29,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2753/12032 [2:34:51<9:27:59,  3.67s/it]2025-08-22:21:09:33,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2754/12032 [2:34:55<9:36:19,  3.73s/it]2025-08-22:21:09:37,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2755/12032 [2:34:59<9:39:08,  3.75s/it]2025-08-22:21:09:41,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2756/12032 [2:35:03<9:42:19,  3.77s/it]2025-08-22:21:09:45,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2757/12032 [2:35:06<9:03:03,  3.51s/it]2025-08-22:21:09:47,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2758/12032 [2:35:09<9:18:50,  3.62s/it]2025-08-22:21:09:51,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2759/12032 [2:35:13<9:13:34,  3.58s/it]2025-08-22:21:09:55,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2760/12032 [2:35:17<9:24:21,  3.65s/it]2025-08-22:21:09:59,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2761/12032 [2:35:21<9:31:38,  3.70s/it]2025-08-22:21:10:02,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2762/12032 [2:35:21<7:17:37,  2.83s/it]2025-08-22:21:10:03,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2763/12032 [2:35:25<7:54:44,  3.07s/it]2025-08-22:21:10:07,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2764/12032 [2:35:28<7:47:57,  3.03s/it]2025-08-22:21:10:10,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2765/12032 [2:35:30<7:03:17,  2.74s/it]2025-08-22:21:10:12,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2766/12032 [2:35:32<6:47:28,  2.64s/it]2025-08-22:21:10:14,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2767/12032 [2:35:35<6:53:59,  2.68s/it]2025-08-22:21:10:17,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2768/12032 [2:35:39<7:47:25,  3.03s/it]2025-08-22:21:10:21,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2769/12032 [2:35:42<7:38:19,  2.97s/it]2025-08-22:21:10:24,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2770/12032 [2:35:44<7:08:24,  2.78s/it]2025-08-22:21:10:26,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2771/12032 [2:35:46<6:30:18,  2.53s/it]2025-08-22:21:10:28,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2772/12032 [2:35:49<6:39:32,  2.59s/it]2025-08-22:21:10:31,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2773/12032 [2:35:53<7:37:10,  2.96s/it]2025-08-22:21:10:35,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2774/12032 [2:35:57<8:18:26,  3.23s/it]2025-08-22:21:10:38,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2775/12032 [2:35:58<6:36:02,  2.57s/it]2025-08-22:21:10:39,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2776/12032 [2:36:01<7:33:37,  2.94s/it]2025-08-22:21:10:43,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2777/12032 [2:36:05<7:41:23,  2.99s/it]2025-08-22:21:10:46,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2778/12032 [2:36:08<8:19:46,  3.24s/it]2025-08-22:21:10:50,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2779/12032 [2:36:12<8:46:15,  3.41s/it]2025-08-22:21:10:54,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2780/12032 [2:36:16<9:05:50,  3.54s/it]2025-08-22:21:10:58,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2781/12032 [2:36:20<9:21:08,  3.64s/it]2025-08-22:21:11:02,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2782/12032 [2:36:22<8:25:36,  3.28s/it]2025-08-22:21:11:04,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2783/12032 [2:36:25<7:44:34,  3.01s/it]2025-08-22:21:11:07,037 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2784/12032 [2:36:26<6:41:37,  2.61s/it]2025-08-22:21:11:08,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2785/12032 [2:36:30<7:39:21,  2.98s/it]2025-08-22:21:11:12,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2786/12032 [2:36:34<8:18:11,  3.23s/it]2025-08-22:21:11:16,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2787/12032 [2:36:38<8:45:04,  3.41s/it]2025-08-22:21:11:20,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2788/12032 [2:36:40<7:42:44,  3.00s/it]2025-08-22:21:11:22,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2789/12032 [2:36:41<6:06:07,  2.38s/it]2025-08-22:21:11:23,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2790/12032 [2:36:43<5:42:33,  2.22s/it]2025-08-22:21:11:25,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2791/12032 [2:36:44<4:57:26,  1.93s/it]2025-08-22:21:11:26,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2792/12032 [2:36:46<5:04:28,  1.98s/it]2025-08-22:21:11:28,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2793/12032 [2:36:50<6:30:19,  2.53s/it]2025-08-22:21:11:32,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2794/12032 [2:36:52<5:50:05,  2.27s/it]2025-08-22:21:11:33,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2795/12032 [2:36:55<7:01:39,  2.74s/it]2025-08-22:21:11:37,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2796/12032 [2:36:59<7:52:40,  3.07s/it]2025-08-22:21:11:41,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2797/12032 [2:37:03<8:27:50,  3.30s/it]2025-08-22:21:11:45,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2798/12032 [2:37:06<8:04:33,  3.15s/it]2025-08-22:21:11:48,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2799/12032 [2:37:09<8:20:22,  3.25s/it]2025-08-22:21:11:51,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2800/12032 [2:37:13<8:46:29,  3.42s/it]2025-08-22:21:11:55,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2801/12032 [2:37:17<8:58:36,  3.50s/it]2025-08-22:21:11:59,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2802/12032 [2:37:21<9:13:27,  3.60s/it]2025-08-22:21:12:02,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2803/12032 [2:37:24<9:23:58,  3.67s/it]2025-08-22:21:12:06,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2804/12032 [2:37:27<8:41:43,  3.39s/it]2025-08-22:21:12:09,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2805/12032 [2:37:29<7:46:13,  3.03s/it]2025-08-22:21:12:11,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2806/12032 [2:37:33<8:22:17,  3.27s/it]2025-08-22:21:12:15,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2807/12032 [2:37:36<7:43:21,  3.01s/it]2025-08-22:21:12:17,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2808/12032 [2:37:36<5:59:51,  2.34s/it]2025-08-22:21:12:18,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2809/12032 [2:37:39<6:06:01,  2.38s/it]2025-08-22:21:12:21,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2810/12032 [2:37:42<6:17:27,  2.46s/it]2025-08-22:21:12:23,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2811/12032 [2:37:42<5:02:23,  1.97s/it]2025-08-22:21:12:24,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2812/12032 [2:37:44<4:50:07,  1.89s/it]2025-08-22:21:12:26,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2813/12032 [2:37:48<6:22:15,  2.49s/it]2025-08-22:21:12:30,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2814/12032 [2:37:52<7:24:24,  2.89s/it]2025-08-22:21:12:34,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2815/12032 [2:37:56<8:08:41,  3.18s/it]2025-08-22:21:12:37,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2816/12032 [2:37:58<7:15:01,  2.83s/it]2025-08-22:21:12:39,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2817/12032 [2:38:01<8:01:38,  3.14s/it]2025-08-22:21:12:43,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2818/12032 [2:38:05<8:36:33,  3.36s/it]2025-08-22:21:12:47,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2819/12032 [2:38:09<8:57:22,  3.50s/it]2025-08-22:21:12:51,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2820/12032 [2:38:13<9:10:44,  3.59s/it]2025-08-22:21:12:55,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2821/12032 [2:38:14<7:07:20,  2.78s/it]2025-08-22:21:12:56,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2822/12032 [2:38:15<6:10:31,  2.41s/it]2025-08-22:21:12:57,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2823/12032 [2:38:19<7:15:16,  2.84s/it]2025-08-22:21:13:01,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2824/12032 [2:38:23<7:54:55,  3.09s/it]2025-08-22:21:13:05,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2825/12032 [2:38:27<8:27:27,  3.31s/it]2025-08-22:21:13:09,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2826/12032 [2:38:30<8:26:24,  3.30s/it]2025-08-22:21:13:12,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  23%|██▎       | 2827/12032 [2:38:34<8:48:16,  3.44s/it]2025-08-22:21:13:16,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2828/12032 [2:38:36<7:32:04,  2.95s/it]2025-08-22:21:13:17,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2829/12032 [2:38:39<8:10:54,  3.20s/it]2025-08-22:21:13:21,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2830/12032 [2:38:42<7:41:08,  3.01s/it]2025-08-22:21:13:24,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2831/12032 [2:38:46<8:17:13,  3.24s/it]2025-08-22:21:13:28,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2832/12032 [2:38:50<8:42:57,  3.41s/it]2025-08-22:21:13:31,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2833/12032 [2:38:53<8:33:57,  3.35s/it]2025-08-22:21:13:35,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2834/12032 [2:38:56<8:04:40,  3.16s/it]2025-08-22:21:13:37,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2835/12032 [2:38:58<7:54:48,  3.10s/it]2025-08-22:21:13:40,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2836/12032 [2:39:02<8:26:53,  3.31s/it]2025-08-22:21:13:44,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2837/12032 [2:39:05<7:50:44,  3.07s/it]2025-08-22:21:13:47,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2838/12032 [2:39:06<6:45:19,  2.65s/it]2025-08-22:21:13:48,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2839/12032 [2:39:09<6:37:44,  2.60s/it]2025-08-22:21:13:51,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2840/12032 [2:39:13<7:31:40,  2.95s/it]2025-08-22:21:13:55,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2841/12032 [2:39:16<7:50:15,  3.07s/it]2025-08-22:21:13:58,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2842/12032 [2:39:18<7:00:27,  2.75s/it]2025-08-22:21:14:00,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2843/12032 [2:39:22<7:48:09,  3.06s/it]2025-08-22:21:14:04,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2844/12032 [2:39:25<8:01:25,  3.14s/it]2025-08-22:21:14:07,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2845/12032 [2:39:29<8:30:59,  3.34s/it]2025-08-22:21:14:11,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2846/12032 [2:39:33<8:51:42,  3.47s/it]2025-08-22:21:14:15,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2847/12032 [2:39:37<9:07:35,  3.58s/it]2025-08-22:21:14:18,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2848/12032 [2:39:40<8:49:47,  3.46s/it]2025-08-22:21:14:22,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2849/12032 [2:39:44<9:04:36,  3.56s/it]2025-08-22:21:14:25,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2850/12032 [2:39:47<9:15:03,  3.63s/it]2025-08-22:21:14:29,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2851/12032 [2:39:49<7:58:47,  3.13s/it]2025-08-22:21:14:31,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2852/12032 [2:39:53<8:30:13,  3.33s/it]2025-08-22:21:14:35,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2853/12032 [2:39:57<8:51:15,  3.47s/it]2025-08-22:21:14:39,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2854/12032 [2:40:01<9:06:17,  3.57s/it]2025-08-22:21:14:43,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2855/12032 [2:40:04<9:15:38,  3.63s/it]2025-08-22:21:14:46,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2856/12032 [2:40:06<7:53:54,  3.10s/it]2025-08-22:21:14:48,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▎       | 2857/12032 [2:40:10<8:18:43,  3.26s/it]2025-08-22:21:14:52,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2858/12032 [2:40:14<8:43:40,  3.42s/it]2025-08-22:21:14:56,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2859/12032 [2:40:18<9:02:24,  3.55s/it]2025-08-22:21:14:59,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2860/12032 [2:40:21<9:14:45,  3.63s/it]2025-08-22:21:15:03,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2861/12032 [2:40:25<9:22:34,  3.68s/it]2025-08-22:21:15:07,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2862/12032 [2:40:29<9:27:11,  3.71s/it]2025-08-22:21:15:11,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2863/12032 [2:40:33<9:31:36,  3.74s/it]2025-08-22:21:15:15,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2864/12032 [2:40:37<9:33:53,  3.76s/it]2025-08-22:21:15:18,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2865/12032 [2:40:40<9:04:19,  3.56s/it]2025-08-22:21:15:22,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2866/12032 [2:40:42<8:08:57,  3.20s/it]2025-08-22:21:15:24,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2867/12032 [2:40:45<7:40:15,  3.01s/it]2025-08-22:21:15:26,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2868/12032 [2:40:48<8:17:22,  3.26s/it]2025-08-22:21:15:30,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2869/12032 [2:40:52<8:42:35,  3.42s/it]2025-08-22:21:15:34,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2870/12032 [2:40:56<8:54:01,  3.50s/it]2025-08-22:21:15:38,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2871/12032 [2:41:00<9:08:05,  3.59s/it]2025-08-22:21:15:42,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2872/12032 [2:41:04<9:19:15,  3.66s/it]2025-08-22:21:15:45,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2873/12032 [2:41:07<9:24:56,  3.70s/it]2025-08-22:21:15:49,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2874/12032 [2:41:11<9:30:00,  3.73s/it]2025-08-22:21:15:53,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2875/12032 [2:41:15<9:33:42,  3.76s/it]2025-08-22:21:15:57,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2876/12032 [2:41:17<8:25:49,  3.31s/it]2025-08-22:21:15:59,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2877/12032 [2:41:21<8:47:36,  3.46s/it]2025-08-22:21:16:03,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2878/12032 [2:41:24<8:08:03,  3.20s/it]2025-08-22:21:16:06,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2879/12032 [2:41:26<7:15:55,  2.86s/it]2025-08-22:21:16:08,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2880/12032 [2:41:30<7:58:56,  3.14s/it]2025-08-22:21:16:11,868 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2881/12032 [2:41:32<7:28:34,  2.94s/it]2025-08-22:21:16:14,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2882/12032 [2:41:35<7:48:26,  3.07s/it]2025-08-22:21:16:17,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2883/12032 [2:41:37<6:35:22,  2.59s/it]2025-08-22:21:16:19,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2884/12032 [2:41:41<7:31:19,  2.96s/it]2025-08-22:21:16:23,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2885/12032 [2:41:44<8:09:31,  3.21s/it]2025-08-22:21:16:26,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2886/12032 [2:41:48<8:34:52,  3.38s/it]2025-08-22:21:16:30,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2887/12032 [2:41:52<8:55:31,  3.51s/it]2025-08-22:21:16:34,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2888/12032 [2:41:56<9:09:17,  3.60s/it]2025-08-22:21:16:38,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2889/12032 [2:42:00<9:21:00,  3.68s/it]2025-08-22:21:16:42,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2890/12032 [2:42:04<9:28:10,  3.73s/it]2025-08-22:21:16:45,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2891/12032 [2:42:07<9:33:33,  3.76s/it]2025-08-22:21:16:49,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2892/12032 [2:42:11<9:37:07,  3.79s/it]2025-08-22:21:16:53,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2893/12032 [2:42:15<9:42:01,  3.82s/it]2025-08-22:21:16:57,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2894/12032 [2:42:19<9:43:38,  3.83s/it]2025-08-22:21:17:01,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2895/12032 [2:42:23<9:46:39,  3.85s/it]2025-08-22:21:17:05,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2896/12032 [2:42:26<9:25:05,  3.71s/it]2025-08-22:21:17:08,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2897/12032 [2:42:30<9:31:22,  3.75s/it]2025-08-22:21:17:12,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2898/12032 [2:42:34<9:35:10,  3.78s/it]2025-08-22:21:17:16,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2899/12032 [2:42:37<8:39:55,  3.42s/it]2025-08-22:21:17:18,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2900/12032 [2:42:40<8:57:24,  3.53s/it]2025-08-22:21:17:22,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2901/12032 [2:42:44<8:49:21,  3.48s/it]2025-08-22:21:17:26,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2902/12032 [2:42:48<9:04:44,  3.58s/it]2025-08-22:21:17:29,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2903/12032 [2:42:51<9:15:25,  3.65s/it]2025-08-22:21:17:33,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2904/12032 [2:42:55<9:24:58,  3.71s/it]2025-08-22:21:17:37,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2905/12032 [2:42:59<9:29:59,  3.75s/it]2025-08-22:21:17:41,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2906/12032 [2:43:03<9:33:14,  3.77s/it]2025-08-22:21:17:45,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2907/12032 [2:43:06<9:15:46,  3.65s/it]2025-08-22:21:17:48,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2908/12032 [2:43:10<9:03:53,  3.58s/it]2025-08-22:21:17:51,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2909/12032 [2:43:12<7:54:02,  3.12s/it]2025-08-22:21:17:54,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2910/12032 [2:43:14<7:22:16,  2.91s/it]2025-08-22:21:17:56,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2911/12032 [2:43:18<8:04:41,  3.19s/it]2025-08-22:21:18:00,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2912/12032 [2:43:21<7:41:57,  3.04s/it]2025-08-22:21:18:02,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2913/12032 [2:43:22<6:16:04,  2.47s/it]2025-08-22:21:18:04,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2914/12032 [2:43:26<7:20:01,  2.90s/it]2025-08-22:21:18:08,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2915/12032 [2:43:29<7:39:15,  3.02s/it]2025-08-22:21:18:11,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2916/12032 [2:43:30<6:21:04,  2.51s/it]2025-08-22:21:18:12,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2917/12032 [2:43:34<7:20:53,  2.90s/it]2025-08-22:21:18:16,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2918/12032 [2:43:37<7:37:43,  3.01s/it]2025-08-22:21:18:19,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2919/12032 [2:43:40<7:32:36,  2.98s/it]2025-08-22:21:18:22,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2920/12032 [2:43:44<8:10:55,  3.23s/it]2025-08-22:21:18:26,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2921/12032 [2:43:48<8:38:03,  3.41s/it]2025-08-22:21:18:30,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2922/12032 [2:43:52<8:58:02,  3.54s/it]2025-08-22:21:18:34,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2923/12032 [2:43:56<9:11:37,  3.63s/it]2025-08-22:21:18:37,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2924/12032 [2:43:58<7:57:39,  3.15s/it]2025-08-22:21:18:40,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2925/12032 [2:44:01<8:24:00,  3.32s/it]2025-08-22:21:18:43,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2926/12032 [2:44:05<8:31:23,  3.37s/it]2025-08-22:21:18:47,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2927/12032 [2:44:07<7:38:57,  3.02s/it]2025-08-22:21:18:49,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2928/12032 [2:44:11<8:17:09,  3.28s/it]2025-08-22:21:18:53,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2929/12032 [2:44:15<8:41:43,  3.44s/it]2025-08-22:21:18:57,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2930/12032 [2:44:18<8:48:12,  3.48s/it]2025-08-22:21:19:00,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2931/12032 [2:44:22<8:54:40,  3.52s/it]2025-08-22:21:19:04,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2932/12032 [2:44:26<9:08:43,  3.62s/it]2025-08-22:21:19:08,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2933/12032 [2:44:29<8:38:52,  3.42s/it]2025-08-22:21:19:11,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2934/12032 [2:44:33<8:56:46,  3.54s/it]2025-08-22:21:19:14,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2935/12032 [2:44:36<9:10:40,  3.63s/it]2025-08-22:21:19:18,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2936/12032 [2:44:40<9:20:48,  3.70s/it]2025-08-22:21:19:22,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2937/12032 [2:44:42<7:46:45,  3.08s/it]2025-08-22:21:19:24,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2938/12032 [2:44:44<7:09:11,  2.83s/it]2025-08-22:21:19:26,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2939/12032 [2:44:48<7:54:58,  3.13s/it]2025-08-22:21:19:30,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2940/12032 [2:44:51<7:33:29,  2.99s/it]2025-08-22:21:19:33,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2941/12032 [2:44:53<7:20:43,  2.91s/it]2025-08-22:21:19:35,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2942/12032 [2:44:57<7:30:59,  2.98s/it]2025-08-22:21:19:38,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2943/12032 [2:45:00<8:09:31,  3.23s/it]2025-08-22:21:19:42,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2944/12032 [2:45:03<7:39:33,  3.03s/it]2025-08-22:21:19:45,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2945/12032 [2:45:07<8:18:37,  3.29s/it]2025-08-22:21:19:49,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2946/12032 [2:45:11<8:43:48,  3.46s/it]2025-08-22:21:19:53,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  24%|██▍       | 2947/12032 [2:45:14<8:59:30,  3.56s/it]2025-08-22:21:19:56,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2948/12032 [2:45:18<9:12:14,  3.65s/it]2025-08-22:21:20:00,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2949/12032 [2:45:22<9:25:53,  3.74s/it]2025-08-22:21:20:04,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2950/12032 [2:45:26<9:30:30,  3.77s/it]2025-08-22:21:20:08,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2951/12032 [2:45:30<9:32:57,  3.79s/it]2025-08-22:21:20:12,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2952/12032 [2:45:34<9:34:56,  3.80s/it]2025-08-22:21:20:16,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2953/12032 [2:45:37<9:07:20,  3.62s/it]2025-08-22:21:20:19,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2954/12032 [2:45:41<9:17:48,  3.69s/it]2025-08-22:21:20:23,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2955/12032 [2:45:45<9:26:04,  3.74s/it]2025-08-22:21:20:27,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2956/12032 [2:45:47<8:22:26,  3.32s/it]2025-08-22:21:20:29,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2957/12032 [2:45:50<7:57:37,  3.16s/it]2025-08-22:21:20:32,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2958/12032 [2:45:54<8:28:05,  3.36s/it]2025-08-22:21:20:35,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2959/12032 [2:45:57<8:50:46,  3.51s/it]2025-08-22:21:20:39,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2960/12032 [2:46:01<8:42:47,  3.46s/it]2025-08-22:21:20:43,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2961/12032 [2:46:04<8:30:19,  3.38s/it]2025-08-22:21:20:46,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2962/12032 [2:46:07<8:34:30,  3.40s/it]2025-08-22:21:20:49,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2963/12032 [2:46:11<8:52:50,  3.53s/it]2025-08-22:21:20:53,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2964/12032 [2:46:15<9:07:02,  3.62s/it]2025-08-22:21:20:57,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2965/12032 [2:46:19<9:14:40,  3.67s/it]2025-08-22:21:21:01,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2966/12032 [2:46:22<8:58:14,  3.56s/it]2025-08-22:21:21:04,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2967/12032 [2:46:25<8:13:09,  3.26s/it]2025-08-22:21:21:07,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2968/12032 [2:46:29<8:37:22,  3.42s/it]2025-08-22:21:21:10,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2969/12032 [2:46:31<8:10:55,  3.25s/it]2025-08-22:21:21:13,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2970/12032 [2:46:32<6:21:12,  2.52s/it]2025-08-22:21:21:14,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2971/12032 [2:46:34<5:26:31,  2.16s/it]2025-08-22:21:21:15,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2972/12032 [2:46:37<6:42:16,  2.66s/it]2025-08-22:21:21:19,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2973/12032 [2:46:41<7:33:43,  3.01s/it]2025-08-22:21:21:23,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2974/12032 [2:46:45<8:09:45,  3.24s/it]2025-08-22:21:21:27,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2975/12032 [2:46:49<8:36:29,  3.42s/it]2025-08-22:21:21:31,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2976/12032 [2:46:53<8:54:15,  3.54s/it]2025-08-22:21:21:35,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2977/12032 [2:46:57<9:07:05,  3.63s/it]2025-08-22:21:21:38,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2978/12032 [2:47:00<9:16:09,  3.69s/it]2025-08-22:21:21:42,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2979/12032 [2:47:03<8:44:51,  3.48s/it]2025-08-22:21:21:45,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2980/12032 [2:47:07<9:01:05,  3.59s/it]2025-08-22:21:21:49,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2981/12032 [2:47:09<7:43:54,  3.08s/it]2025-08-22:21:21:51,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2982/12032 [2:47:13<8:21:11,  3.32s/it]2025-08-22:21:21:55,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2983/12032 [2:47:17<8:43:43,  3.47s/it]2025-08-22:21:21:59,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2984/12032 [2:47:21<9:01:09,  3.59s/it]2025-08-22:21:22:02,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2985/12032 [2:47:25<9:14:27,  3.68s/it]2025-08-22:21:22:06,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2986/12032 [2:47:28<9:22:15,  3.73s/it]2025-08-22:21:22:10,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2987/12032 [2:47:32<9:27:08,  3.76s/it]2025-08-22:21:22:14,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2988/12032 [2:47:36<9:29:29,  3.78s/it]2025-08-22:21:22:18,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2989/12032 [2:47:39<9:04:07,  3.61s/it]2025-08-22:21:22:21,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2990/12032 [2:47:43<9:14:27,  3.68s/it]2025-08-22:21:22:25,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2991/12032 [2:47:46<9:01:35,  3.59s/it]2025-08-22:21:22:28,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2992/12032 [2:47:48<7:43:41,  3.08s/it]2025-08-22:21:22:30,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2993/12032 [2:47:51<7:03:43,  2.81s/it]2025-08-22:21:22:32,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2994/12032 [2:47:54<7:49:16,  3.12s/it]2025-08-22:21:22:36,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2995/12032 [2:47:56<6:55:08,  2.76s/it]2025-08-22:21:22:38,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2996/12032 [2:48:00<7:42:35,  3.07s/it]2025-08-22:21:22:42,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2997/12032 [2:48:02<6:35:14,  2.62s/it]2025-08-22:21:22:44,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2998/12032 [2:48:05<7:29:14,  2.98s/it]2025-08-22:21:22:47,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 2999/12032 [2:48:09<8:06:07,  3.23s/it]2025-08-22:21:22:51,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3000/12032 [2:48:13<8:32:17,  3.40s/it]2025-08-22:21:22:55,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3001/12032 [2:48:17<8:49:35,  3.52s/it]2025-08-22:21:22:59,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3002/12032 [2:48:18<6:56:52,  2.77s/it]2025-08-22:21:23:00,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3003/12032 [2:48:19<5:59:36,  2.39s/it]2025-08-22:21:23:01,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3004/12032 [2:48:23<6:32:34,  2.61s/it]2025-08-22:21:23:04,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3005/12032 [2:48:26<7:30:27,  2.99s/it]2025-08-22:21:23:08,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3006/12032 [2:48:30<8:08:21,  3.25s/it]2025-08-22:21:23:12,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▍       | 3007/12032 [2:48:34<8:35:57,  3.43s/it]2025-08-22:21:23:16,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3008/12032 [2:48:37<8:24:00,  3.35s/it]2025-08-22:21:23:19,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3009/12032 [2:48:41<8:48:33,  3.51s/it]2025-08-22:21:23:23,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3010/12032 [2:48:45<9:00:04,  3.59s/it]2025-08-22:21:23:27,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3011/12032 [2:48:49<9:12:56,  3.68s/it]2025-08-22:21:23:31,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3012/12032 [2:48:51<8:21:25,  3.34s/it]2025-08-22:21:23:33,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3013/12032 [2:48:53<7:24:56,  2.96s/it]2025-08-22:21:23:35,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3014/12032 [2:48:57<8:01:36,  3.20s/it]2025-08-22:21:23:39,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3015/12032 [2:49:01<8:32:55,  3.41s/it]2025-08-22:21:23:43,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3016/12032 [2:49:05<8:37:25,  3.44s/it]2025-08-22:21:23:46,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3017/12032 [2:49:09<8:56:32,  3.57s/it]2025-08-22:21:23:50,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3018/12032 [2:49:12<9:08:10,  3.65s/it]2025-08-22:21:23:54,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3019/12032 [2:49:16<9:15:16,  3.70s/it]2025-08-22:21:23:58,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3020/12032 [2:49:19<8:33:55,  3.42s/it]2025-08-22:21:24:01,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3021/12032 [2:49:20<6:50:37,  2.73s/it]2025-08-22:21:24:02,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3022/12032 [2:49:24<7:41:12,  3.07s/it]2025-08-22:21:24:06,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3023/12032 [2:49:28<8:18:20,  3.32s/it]2025-08-22:21:24:10,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3024/12032 [2:49:32<8:41:18,  3.47s/it]2025-08-22:21:24:13,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3025/12032 [2:49:35<8:57:04,  3.58s/it]2025-08-22:21:24:17,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3026/12032 [2:49:39<9:00:22,  3.60s/it]2025-08-22:21:24:21,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3027/12032 [2:49:41<7:56:22,  3.17s/it]2025-08-22:21:24:23,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3028/12032 [2:49:45<8:25:09,  3.37s/it]2025-08-22:21:24:27,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3029/12032 [2:49:48<7:57:59,  3.19s/it]2025-08-22:21:24:30,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3030/12032 [2:49:52<8:28:02,  3.39s/it]2025-08-22:21:24:34,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3031/12032 [2:49:56<8:47:07,  3.51s/it]2025-08-22:21:24:37,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3032/12032 [2:49:59<9:00:54,  3.61s/it]2025-08-22:21:24:41,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3033/12032 [2:50:03<8:47:24,  3.52s/it]2025-08-22:21:24:45,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3034/12032 [2:50:05<8:01:52,  3.21s/it]2025-08-22:21:24:47,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3035/12032 [2:50:08<7:35:25,  3.04s/it]2025-08-22:21:24:50,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3036/12032 [2:50:12<8:08:30,  3.26s/it]2025-08-22:21:24:53,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3037/12032 [2:50:15<8:15:19,  3.30s/it]2025-08-22:21:24:57,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3038/12032 [2:50:18<7:52:41,  3.15s/it]2025-08-22:21:25:00,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3039/12032 [2:50:20<6:54:02,  2.76s/it]2025-08-22:21:25:01,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3040/12032 [2:50:22<6:29:09,  2.60s/it]2025-08-22:21:25:04,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3041/12032 [2:50:26<7:23:19,  2.96s/it]2025-08-22:21:25:07,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3042/12032 [2:50:29<8:01:57,  3.22s/it]2025-08-22:21:25:11,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3043/12032 [2:50:33<8:28:19,  3.39s/it]2025-08-22:21:25:15,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3044/12032 [2:50:37<8:49:36,  3.54s/it]2025-08-22:21:25:19,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3045/12032 [2:50:41<9:02:37,  3.62s/it]2025-08-22:21:25:23,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3046/12032 [2:50:45<9:12:03,  3.69s/it]2025-08-22:21:25:27,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3047/12032 [2:50:49<9:18:22,  3.73s/it]2025-08-22:21:25:30,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3048/12032 [2:50:52<9:22:28,  3.76s/it]2025-08-22:21:25:34,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3049/12032 [2:50:56<9:16:34,  3.72s/it]2025-08-22:21:25:38,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3050/12032 [2:51:00<9:21:42,  3.75s/it]2025-08-22:21:25:42,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3051/12032 [2:51:03<8:55:20,  3.58s/it]2025-08-22:21:25:45,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3052/12032 [2:51:07<9:03:33,  3.63s/it]2025-08-22:21:25:49,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3053/12032 [2:51:09<7:39:18,  3.07s/it]2025-08-22:21:25:50,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3054/12032 [2:51:12<8:11:35,  3.29s/it]2025-08-22:21:25:54,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3055/12032 [2:51:16<8:22:02,  3.36s/it]2025-08-22:21:25:58,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3056/12032 [2:51:20<8:41:41,  3.49s/it]2025-08-22:21:26:02,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3057/12032 [2:51:23<8:55:25,  3.58s/it]2025-08-22:21:26:05,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3058/12032 [2:51:26<7:46:14,  3.12s/it]2025-08-22:21:26:07,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3059/12032 [2:51:29<8:16:03,  3.32s/it]2025-08-22:21:26:11,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3060/12032 [2:51:33<8:36:47,  3.46s/it]2025-08-22:21:26:15,443 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3061/12032 [2:51:37<8:52:14,  3.56s/it]2025-08-22:21:26:19,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3062/12032 [2:51:41<9:05:54,  3.65s/it]2025-08-22:21:26:23,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3063/12032 [2:51:45<9:13:00,  3.70s/it]2025-08-22:21:26:26,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3064/12032 [2:51:48<9:17:54,  3.73s/it]2025-08-22:21:26:30,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3065/12032 [2:51:52<9:03:04,  3.63s/it]2025-08-22:21:26:34,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3066/12032 [2:51:54<8:09:53,  3.28s/it]2025-08-22:21:26:36,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3067/12032 [2:51:56<6:53:50,  2.77s/it]2025-08-22:21:26:38,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  25%|██▌       | 3068/12032 [2:51:59<7:19:52,  2.94s/it]2025-08-22:21:26:41,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3069/12032 [2:52:01<6:23:03,  2.56s/it]2025-08-22:21:26:43,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3070/12032 [2:52:05<7:21:12,  2.95s/it]2025-08-22:21:26:47,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3071/12032 [2:52:08<7:50:11,  3.15s/it]2025-08-22:21:26:50,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3072/12032 [2:52:12<8:02:59,  3.23s/it]2025-08-22:21:26:54,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3073/12032 [2:52:15<8:19:33,  3.35s/it]2025-08-22:21:26:57,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3074/12032 [2:52:19<8:41:23,  3.49s/it]2025-08-22:21:27:01,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3075/12032 [2:52:21<7:14:14,  2.91s/it]2025-08-22:21:27:03,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3076/12032 [2:52:25<7:54:27,  3.18s/it]2025-08-22:21:27:06,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3077/12032 [2:52:27<7:28:06,  3.00s/it]2025-08-22:21:27:09,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3078/12032 [2:52:28<5:49:41,  2.34s/it]2025-08-22:21:27:10,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3079/12032 [2:52:30<5:16:02,  2.12s/it]2025-08-22:21:27:11,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3080/12032 [2:52:31<4:53:47,  1.97s/it]2025-08-22:21:27:13,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3081/12032 [2:52:35<6:16:58,  2.53s/it]2025-08-22:21:27:17,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3082/12032 [2:52:36<5:28:06,  2.20s/it]2025-08-22:21:27:18,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3083/12032 [2:52:40<6:12:23,  2.50s/it]2025-08-22:21:27:21,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3084/12032 [2:52:44<7:22:55,  2.97s/it]2025-08-22:21:27:26,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3085/12032 [2:52:45<6:14:51,  2.51s/it]2025-08-22:21:27:27,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3086/12032 [2:52:47<5:46:11,  2.32s/it]2025-08-22:21:27:29,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3087/12032 [2:52:49<5:09:55,  2.08s/it]2025-08-22:21:27:30,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3088/12032 [2:52:52<6:27:30,  2.60s/it]2025-08-22:21:27:34,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3089/12032 [2:52:56<7:21:01,  2.96s/it]2025-08-22:21:27:38,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3090/12032 [2:53:00<7:58:22,  3.21s/it]2025-08-22:21:27:42,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3091/12032 [2:53:02<7:21:05,  2.96s/it]2025-08-22:21:27:44,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3092/12032 [2:53:05<7:09:54,  2.89s/it]2025-08-22:21:27:47,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3093/12032 [2:53:09<7:50:36,  3.16s/it]2025-08-22:21:27:51,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3094/12032 [2:53:12<7:35:41,  3.06s/it]2025-08-22:21:27:53,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3095/12032 [2:53:15<8:08:25,  3.28s/it]2025-08-22:21:27:57,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3096/12032 [2:53:19<8:31:31,  3.43s/it]2025-08-22:21:28:01,574 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3097/12032 [2:53:20<6:42:10,  2.70s/it]2025-08-22:21:28:02,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3098/12032 [2:53:24<7:29:30,  3.02s/it]2025-08-22:21:28:06,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3099/12032 [2:53:26<6:42:03,  2.70s/it]2025-08-22:21:28:08,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3100/12032 [2:53:28<6:08:40,  2.48s/it]2025-08-22:21:28:10,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3101/12032 [2:53:32<7:09:25,  2.88s/it]2025-08-22:21:28:14,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3102/12032 [2:53:36<7:49:23,  3.15s/it]2025-08-22:21:28:17,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3103/12032 [2:53:37<6:14:16,  2.51s/it]2025-08-22:21:28:18,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3104/12032 [2:53:38<5:33:19,  2.24s/it]2025-08-22:21:28:20,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3105/12032 [2:53:42<6:44:40,  2.72s/it]2025-08-22:21:28:24,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3106/12032 [2:53:44<6:12:59,  2.51s/it]2025-08-22:21:28:26,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3107/12032 [2:53:48<7:08:05,  2.88s/it]2025-08-22:21:28:30,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3108/12032 [2:53:51<7:14:22,  2.92s/it]2025-08-22:21:28:33,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3109/12032 [2:53:55<7:52:30,  3.18s/it]2025-08-22:21:28:36,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3110/12032 [2:53:56<6:19:28,  2.55s/it]2025-08-22:21:28:37,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3111/12032 [2:53:59<7:16:11,  2.93s/it]2025-08-22:21:28:41,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3112/12032 [2:54:01<6:14:40,  2.52s/it]2025-08-22:21:28:43,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3113/12032 [2:54:05<7:09:49,  2.89s/it]2025-08-22:21:28:47,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3114/12032 [2:54:07<6:41:20,  2.70s/it]2025-08-22:21:28:49,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3115/12032 [2:54:08<5:37:44,  2.27s/it]2025-08-22:21:28:50,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3116/12032 [2:54:10<5:24:49,  2.19s/it]2025-08-22:21:28:52,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3117/12032 [2:54:13<5:31:26,  2.23s/it]2025-08-22:21:28:54,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3118/12032 [2:54:16<6:41:05,  2.70s/it]2025-08-22:21:28:58,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3119/12032 [2:54:18<5:43:39,  2.31s/it]2025-08-22:21:29:00,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3120/12032 [2:54:19<5:03:13,  2.04s/it]2025-08-22:21:29:01,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3121/12032 [2:54:23<6:16:54,  2.54s/it]2025-08-22:21:29:05,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3122/12032 [2:54:27<7:12:02,  2.91s/it]2025-08-22:21:29:09,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3123/12032 [2:54:28<5:54:11,  2.39s/it]2025-08-22:21:29:10,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3124/12032 [2:54:32<7:00:47,  2.83s/it]2025-08-22:21:29:14,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3125/12032 [2:54:36<7:43:15,  3.12s/it]2025-08-22:21:29:17,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3126/12032 [2:54:39<8:12:51,  3.32s/it]2025-08-22:21:29:21,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3127/12032 [2:54:43<8:32:46,  3.46s/it]2025-08-22:21:29:25,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3128/12032 [2:54:44<6:41:55,  2.71s/it]2025-08-22:21:29:26,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3129/12032 [2:54:48<7:29:24,  3.03s/it]2025-08-22:21:29:30,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3130/12032 [2:54:51<7:45:31,  3.14s/it]2025-08-22:21:29:33,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3131/12032 [2:54:55<8:00:47,  3.24s/it]2025-08-22:21:29:37,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3132/12032 [2:54:56<6:52:24,  2.78s/it]2025-08-22:21:29:38,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3133/12032 [2:55:00<7:35:33,  3.07s/it]2025-08-22:21:29:42,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3134/12032 [2:55:04<8:06:55,  3.28s/it]2025-08-22:21:29:46,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3135/12032 [2:55:08<8:30:21,  3.44s/it]2025-08-22:21:29:50,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3136/12032 [2:55:10<7:46:14,  3.14s/it]2025-08-22:21:29:52,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3137/12032 [2:55:14<8:14:26,  3.34s/it]2025-08-22:21:29:56,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3138/12032 [2:55:18<8:33:58,  3.47s/it]2025-08-22:21:30:00,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3139/12032 [2:55:19<6:51:48,  2.78s/it]2025-08-22:21:30:01,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3140/12032 [2:55:21<6:38:50,  2.69s/it]2025-08-22:21:30:03,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3141/12032 [2:55:24<6:48:00,  2.75s/it]2025-08-22:21:30:06,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3142/12032 [2:55:26<5:57:41,  2.41s/it]2025-08-22:21:30:08,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3143/12032 [2:55:28<5:42:43,  2.31s/it]2025-08-22:21:30:10,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3144/12032 [2:55:30<5:28:32,  2.22s/it]2025-08-22:21:30:12,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3145/12032 [2:55:34<6:40:03,  2.70s/it]2025-08-22:21:30:16,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3146/12032 [2:55:37<6:45:26,  2.74s/it]2025-08-22:21:30:18,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3147/12032 [2:55:40<6:58:31,  2.83s/it]2025-08-22:21:30:22,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3148/12032 [2:55:43<7:19:51,  2.97s/it]2025-08-22:21:30:25,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3149/12032 [2:55:44<5:39:52,  2.30s/it]2025-08-22:21:30:26,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3150/12032 [2:55:46<5:34:57,  2.26s/it]2025-08-22:21:30:28,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3151/12032 [2:55:50<6:41:12,  2.71s/it]2025-08-22:21:30:31,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3152/12032 [2:55:51<5:28:11,  2.22s/it]2025-08-22:21:30:33,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3153/12032 [2:55:52<4:28:17,  1.81s/it]2025-08-22:21:30:33,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3154/12032 [2:55:52<3:39:13,  1.48s/it]2025-08-22:21:30:34,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3155/12032 [2:55:56<5:23:28,  2.19s/it]2025-08-22:21:30:38,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3156/12032 [2:55:58<5:12:01,  2.11s/it]2025-08-22:21:30:40,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3157/12032 [2:56:00<5:17:55,  2.15s/it]2025-08-22:21:30:42,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▌       | 3158/12032 [2:56:03<5:54:47,  2.40s/it]2025-08-22:21:30:45,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3159/12032 [2:56:07<6:39:50,  2.70s/it]2025-08-22:21:30:49,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3160/12032 [2:56:10<7:26:58,  3.02s/it]2025-08-22:21:30:52,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3161/12032 [2:56:12<6:34:50,  2.67s/it]2025-08-22:21:30:54,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3162/12032 [2:56:16<7:23:00,  3.00s/it]2025-08-22:21:30:58,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3163/12032 [2:56:17<6:02:39,  2.45s/it]2025-08-22:21:30:59,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3164/12032 [2:56:21<7:00:31,  2.85s/it]2025-08-22:21:31:03,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3165/12032 [2:56:22<5:44:51,  2.33s/it]2025-08-22:21:31:04,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3166/12032 [2:56:24<5:12:19,  2.11s/it]2025-08-22:21:31:06,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3167/12032 [2:56:28<6:24:38,  2.60s/it]2025-08-22:21:31:09,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3168/12032 [2:56:31<7:15:47,  2.95s/it]2025-08-22:21:31:13,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3169/12032 [2:56:33<6:37:22,  2.69s/it]2025-08-22:21:31:15,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3170/12032 [2:56:37<7:26:19,  3.02s/it]2025-08-22:21:31:19,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3171/12032 [2:56:39<6:21:35,  2.58s/it]2025-08-22:21:31:21,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3172/12032 [2:56:40<5:09:51,  2.10s/it]2025-08-22:21:31:22,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3173/12032 [2:56:43<5:45:48,  2.34s/it]2025-08-22:21:31:24,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3174/12032 [2:56:43<4:39:09,  1.89s/it]2025-08-22:21:31:25,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3175/12032 [2:56:47<6:02:49,  2.46s/it]2025-08-22:21:31:29,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3176/12032 [2:56:49<5:22:05,  2.18s/it]2025-08-22:21:31:31,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3177/12032 [2:56:53<6:32:22,  2.66s/it]2025-08-22:21:31:34,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3178/12032 [2:56:56<6:58:19,  2.83s/it]2025-08-22:21:31:38,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3179/12032 [2:57:00<7:40:12,  3.12s/it]2025-08-22:21:31:41,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3180/12032 [2:57:03<8:09:29,  3.32s/it]2025-08-22:21:31:45,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3181/12032 [2:57:07<8:29:09,  3.45s/it]2025-08-22:21:31:49,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3182/12032 [2:57:10<7:46:32,  3.16s/it]2025-08-22:21:31:51,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3183/12032 [2:57:13<8:13:29,  3.35s/it]2025-08-22:21:31:55,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3184/12032 [2:57:17<8:33:14,  3.48s/it]2025-08-22:21:31:59,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3185/12032 [2:57:21<8:47:22,  3.58s/it]2025-08-22:21:32:03,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3186/12032 [2:57:23<7:49:57,  3.19s/it]2025-08-22:21:32:05,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3187/12032 [2:57:25<6:48:29,  2.77s/it]2025-08-22:21:32:07,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  26%|██▋       | 3188/12032 [2:57:28<7:01:02,  2.86s/it]2025-08-22:21:32:10,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3189/12032 [2:57:32<7:41:19,  3.13s/it]2025-08-22:21:32:14,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3190/12032 [2:57:35<8:02:42,  3.28s/it]2025-08-22:21:32:17,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3191/12032 [2:57:39<8:25:47,  3.43s/it]2025-08-22:21:32:21,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3192/12032 [2:57:43<8:44:43,  3.56s/it]2025-08-22:21:32:25,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3193/12032 [2:57:46<8:22:15,  3.41s/it]2025-08-22:21:32:28,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3194/12032 [2:57:49<8:17:50,  3.38s/it]2025-08-22:21:32:31,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3195/12032 [2:57:51<7:06:47,  2.90s/it]2025-08-22:21:32:33,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3196/12032 [2:57:52<5:36:08,  2.28s/it]2025-08-22:21:32:34,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3197/12032 [2:57:56<6:45:45,  2.76s/it]2025-08-22:21:32:38,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3198/12032 [2:57:59<6:37:30,  2.70s/it]2025-08-22:21:32:40,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3199/12032 [2:58:00<5:44:37,  2.34s/it]2025-08-22:21:32:42,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3200/12032 [2:58:04<6:47:32,  2.77s/it]2025-08-22:21:32:46,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3201/12032 [2:58:07<6:47:52,  2.77s/it]2025-08-22:21:32:48,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3202/12032 [2:58:08<5:43:49,  2.34s/it]2025-08-22:21:32:50,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3203/12032 [2:58:09<5:02:24,  2.06s/it]2025-08-22:21:32:51,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3204/12032 [2:58:13<6:21:04,  2.59s/it]2025-08-22:21:32:55,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3205/12032 [2:58:17<7:14:17,  2.95s/it]2025-08-22:21:32:59,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3206/12032 [2:58:19<6:50:46,  2.79s/it]2025-08-22:21:33:01,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3207/12032 [2:58:23<7:35:14,  3.10s/it]2025-08-22:21:33:05,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3208/12032 [2:58:24<6:01:57,  2.46s/it]2025-08-22:21:33:06,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3209/12032 [2:58:26<5:39:58,  2.31s/it]2025-08-22:21:33:08,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3210/12032 [2:58:30<6:45:05,  2.76s/it]2025-08-22:21:33:12,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3211/12032 [2:58:33<6:54:38,  2.82s/it]2025-08-22:21:33:15,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3212/12032 [2:58:37<7:38:31,  3.12s/it]2025-08-22:21:33:19,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3213/12032 [2:58:40<8:08:42,  3.32s/it]2025-08-22:21:33:22,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3214/12032 [2:58:44<8:28:42,  3.46s/it]2025-08-22:21:33:26,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3215/12032 [2:58:47<7:48:26,  3.19s/it]2025-08-22:21:33:29,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3216/12032 [2:58:50<8:01:19,  3.28s/it]2025-08-22:21:33:32,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3217/12032 [2:58:54<8:26:29,  3.45s/it]2025-08-22:21:33:36,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3218/12032 [2:58:58<8:42:34,  3.56s/it]2025-08-22:21:33:40,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3219/12032 [2:59:01<7:58:03,  3.25s/it]2025-08-22:21:33:42,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3220/12032 [2:59:04<8:21:17,  3.41s/it]2025-08-22:21:33:46,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3221/12032 [2:59:08<8:20:47,  3.41s/it]2025-08-22:21:33:50,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3222/12032 [2:59:08<6:25:15,  2.62s/it]2025-08-22:21:33:50,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3223/12032 [2:59:10<5:16:25,  2.16s/it]2025-08-22:21:33:51,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3224/12032 [2:59:12<5:39:58,  2.32s/it]2025-08-22:21:33:54,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3225/12032 [2:59:16<6:46:36,  2.77s/it]2025-08-22:21:33:58,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3226/12032 [2:59:19<7:11:55,  2.94s/it]2025-08-22:21:34:01,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3227/12032 [2:59:22<6:53:02,  2.81s/it]2025-08-22:21:34:04,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3228/12032 [2:59:24<6:00:44,  2.46s/it]2025-08-22:21:34:05,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3229/12032 [2:59:27<7:01:34,  2.87s/it]2025-08-22:21:34:09,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3230/12032 [2:59:31<7:46:40,  3.18s/it]2025-08-22:21:34:13,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3231/12032 [2:59:35<8:13:14,  3.36s/it]2025-08-22:21:34:17,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3232/12032 [2:59:38<7:36:50,  3.11s/it]2025-08-22:21:34:19,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3233/12032 [2:59:40<7:02:22,  2.88s/it]2025-08-22:21:34:22,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3234/12032 [2:59:42<6:25:09,  2.63s/it]2025-08-22:21:34:24,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3235/12032 [2:59:43<5:28:56,  2.24s/it]2025-08-22:21:34:25,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3236/12032 [2:59:47<6:38:07,  2.72s/it]2025-08-22:21:34:29,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3237/12032 [2:59:51<7:22:43,  3.02s/it]2025-08-22:21:34:33,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3238/12032 [2:59:54<7:43:16,  3.16s/it]2025-08-22:21:34:36,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3239/12032 [2:59:56<6:30:59,  2.67s/it]2025-08-22:21:34:38,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3240/12032 [3:00:00<7:21:11,  3.01s/it]2025-08-22:21:34:42,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3241/12032 [3:00:01<6:24:09,  2.62s/it]2025-08-22:21:34:43,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3242/12032 [3:00:03<5:35:24,  2.29s/it]2025-08-22:21:34:45,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3243/12032 [3:00:07<6:43:17,  2.75s/it]2025-08-22:21:34:49,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3244/12032 [3:00:11<7:28:56,  3.07s/it]2025-08-22:21:34:52,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3245/12032 [3:00:14<7:31:31,  3.08s/it]2025-08-22:21:34:56,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3246/12032 [3:00:17<8:03:13,  3.30s/it]2025-08-22:21:34:59,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3247/12032 [3:00:19<6:48:32,  2.79s/it]2025-08-22:21:35:01,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3248/12032 [3:00:20<5:22:58,  2.21s/it]2025-08-22:21:35:02,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3249/12032 [3:00:21<4:34:27,  1.87s/it]2025-08-22:21:35:03,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3250/12032 [3:00:25<5:58:34,  2.45s/it]2025-08-22:21:35:07,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3251/12032 [3:00:28<6:42:38,  2.75s/it]2025-08-22:21:35:10,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3252/12032 [3:00:30<6:13:33,  2.55s/it]2025-08-22:21:35:12,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3253/12032 [3:00:34<7:07:41,  2.92s/it]2025-08-22:21:35:16,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3254/12032 [3:00:38<7:33:51,  3.10s/it]2025-08-22:21:35:20,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3255/12032 [3:00:41<8:03:11,  3.30s/it]2025-08-22:21:35:23,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3256/12032 [3:00:44<7:47:09,  3.19s/it]2025-08-22:21:35:26,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3257/12032 [3:00:48<8:12:39,  3.37s/it]2025-08-22:21:35:30,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3258/12032 [3:00:50<7:05:43,  2.91s/it]2025-08-22:21:35:32,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3259/12032 [3:00:54<7:44:10,  3.17s/it]2025-08-22:21:35:36,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3260/12032 [3:00:56<7:11:52,  2.95s/it]2025-08-22:21:35:38,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3261/12032 [3:01:00<7:41:41,  3.16s/it]2025-08-22:21:35:42,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3262/12032 [3:01:02<6:40:32,  2.74s/it]2025-08-22:21:35:43,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3263/12032 [3:01:04<6:20:56,  2.61s/it]2025-08-22:21:35:46,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3264/12032 [3:01:07<6:51:47,  2.82s/it]2025-08-22:21:35:49,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3265/12032 [3:01:11<7:32:17,  3.10s/it]2025-08-22:21:35:53,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3266/12032 [3:01:15<8:01:29,  3.30s/it]2025-08-22:21:35:57,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3267/12032 [3:01:17<7:00:22,  2.88s/it]2025-08-22:21:35:58,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3268/12032 [3:01:19<6:30:26,  2.67s/it]2025-08-22:21:36:01,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3269/12032 [3:01:22<7:06:21,  2.92s/it]2025-08-22:21:36:04,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3270/12032 [3:01:24<5:59:09,  2.46s/it]2025-08-22:21:36:06,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3271/12032 [3:01:25<5:12:24,  2.14s/it]2025-08-22:21:36:07,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3272/12032 [3:01:26<4:22:08,  1.80s/it]2025-08-22:21:36:08,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3273/12032 [3:01:29<5:27:40,  2.24s/it]2025-08-22:21:36:11,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3274/12032 [3:01:33<6:33:53,  2.70s/it]2025-08-22:21:36:15,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3275/12032 [3:01:37<7:19:29,  3.01s/it]2025-08-22:21:36:19,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3276/12032 [3:01:39<6:20:08,  2.60s/it]2025-08-22:21:36:20,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3277/12032 [3:01:40<5:36:12,  2.30s/it]2025-08-22:21:36:22,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3278/12032 [3:01:44<6:39:34,  2.74s/it]2025-08-22:21:36:26,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3279/12032 [3:01:48<7:24:26,  3.05s/it]2025-08-22:21:36:30,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3280/12032 [3:01:51<7:54:55,  3.26s/it]2025-08-22:21:36:33,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3281/12032 [3:01:55<8:11:31,  3.37s/it]2025-08-22:21:36:37,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3282/12032 [3:01:57<7:05:50,  2.92s/it]2025-08-22:21:36:39,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3283/12032 [3:01:58<5:23:40,  2.22s/it]2025-08-22:21:36:39,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3284/12032 [3:01:58<4:27:43,  1.84s/it]2025-08-22:21:36:40,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3285/12032 [3:02:00<4:22:59,  1.80s/it]2025-08-22:21:36:42,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3286/12032 [3:02:04<5:35:55,  2.30s/it]2025-08-22:21:36:45,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3287/12032 [3:02:07<6:14:34,  2.57s/it]2025-08-22:21:36:49,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3288/12032 [3:02:11<7:06:42,  2.93s/it]2025-08-22:21:36:52,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3289/12032 [3:02:14<7:21:11,  3.03s/it]2025-08-22:21:36:56,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3290/12032 [3:02:18<7:56:20,  3.27s/it]2025-08-22:21:37:00,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3291/12032 [3:02:20<7:04:09,  2.91s/it]2025-08-22:21:37:02,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3292/12032 [3:02:23<7:29:45,  3.09s/it]2025-08-22:21:37:05,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3293/12032 [3:02:24<6:00:59,  2.48s/it]2025-08-22:21:37:06,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3294/12032 [3:02:28<6:58:21,  2.87s/it]2025-08-22:21:37:10,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3295/12032 [3:02:31<7:16:26,  3.00s/it]2025-08-22:21:37:13,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3296/12032 [3:02:34<6:56:49,  2.86s/it]2025-08-22:21:37:16,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3297/12032 [3:02:37<6:47:27,  2.80s/it]2025-08-22:21:37:18,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3298/12032 [3:02:39<6:46:15,  2.79s/it]2025-08-22:21:37:21,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3299/12032 [3:02:40<5:18:54,  2.19s/it]2025-08-22:21:37:22,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3300/12032 [3:02:43<5:30:58,  2.27s/it]2025-08-22:21:37:24,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3301/12032 [3:02:46<6:36:13,  2.72s/it]2025-08-22:21:37:28,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3302/12032 [3:02:50<7:21:55,  3.04s/it]2025-08-22:21:37:32,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3303/12032 [3:02:53<6:55:11,  2.85s/it]2025-08-22:21:37:34,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3304/12032 [3:02:56<7:35:20,  3.13s/it]2025-08-22:21:37:38,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3305/12032 [3:03:00<7:38:08,  3.15s/it]2025-08-22:21:37:41,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3306/12032 [3:03:02<7:10:22,  2.96s/it]2025-08-22:21:37:44,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3307/12032 [3:03:06<7:44:51,  3.20s/it]2025-08-22:21:37:48,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  27%|██▋       | 3308/12032 [3:03:10<8:08:49,  3.36s/it]2025-08-22:21:37:51,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3309/12032 [3:03:11<6:22:30,  2.63s/it]2025-08-22:21:37:52,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3310/12032 [3:03:13<6:15:54,  2.59s/it]2025-08-22:21:37:55,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3311/12032 [3:03:16<6:27:47,  2.67s/it]2025-08-22:21:37:58,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3312/12032 [3:03:20<7:17:40,  3.01s/it]2025-08-22:21:38:02,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3313/12032 [3:03:22<6:53:43,  2.85s/it]2025-08-22:21:38:04,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3314/12032 [3:03:24<6:25:19,  2.65s/it]2025-08-22:21:38:06,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3315/12032 [3:03:28<7:12:59,  2.98s/it]2025-08-22:21:38:10,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3316/12032 [3:03:31<7:07:03,  2.94s/it]2025-08-22:21:38:13,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3317/12032 [3:03:33<6:16:23,  2.59s/it]2025-08-22:21:38:15,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3318/12032 [3:03:36<7:07:32,  2.94s/it]2025-08-22:21:38:18,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3319/12032 [3:03:40<7:46:25,  3.21s/it]2025-08-22:21:38:22,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3320/12032 [3:03:44<8:02:55,  3.33s/it]2025-08-22:21:38:26,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3321/12032 [3:03:48<8:22:17,  3.46s/it]2025-08-22:21:38:30,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3322/12032 [3:03:50<7:15:59,  3.00s/it]2025-08-22:21:38:31,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3323/12032 [3:03:53<7:18:29,  3.02s/it]2025-08-22:21:38:35,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3324/12032 [3:03:54<6:07:09,  2.53s/it]2025-08-22:21:38:36,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3325/12032 [3:03:58<7:01:23,  2.90s/it]2025-08-22:21:38:40,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3326/12032 [3:04:00<6:38:49,  2.75s/it]2025-08-22:21:38:42,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3327/12032 [3:04:01<5:33:12,  2.30s/it]2025-08-22:21:38:43,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3328/12032 [3:04:05<6:36:54,  2.74s/it]2025-08-22:21:38:47,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3329/12032 [3:04:07<5:59:18,  2.48s/it]2025-08-22:21:38:49,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3330/12032 [3:04:10<6:16:35,  2.60s/it]2025-08-22:21:38:52,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3331/12032 [3:04:11<5:26:11,  2.25s/it]2025-08-22:21:38:53,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3332/12032 [3:04:15<6:23:16,  2.64s/it]2025-08-22:21:38:57,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3333/12032 [3:04:19<7:11:39,  2.98s/it]2025-08-22:21:39:01,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3334/12032 [3:04:23<7:46:20,  3.22s/it]2025-08-22:21:39:04,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3335/12032 [3:04:24<6:50:29,  2.83s/it]2025-08-22:21:39:06,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3336/12032 [3:04:27<6:42:14,  2.78s/it]2025-08-22:21:39:09,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3337/12032 [3:04:31<7:25:23,  3.07s/it]2025-08-22:21:39:13,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3338/12032 [3:04:35<7:55:32,  3.28s/it]2025-08-22:21:39:16,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3339/12032 [3:04:38<7:39:26,  3.17s/it]2025-08-22:21:39:19,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3340/12032 [3:04:41<7:38:41,  3.17s/it]2025-08-22:21:39:23,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3341/12032 [3:04:42<6:29:32,  2.69s/it]2025-08-22:21:39:24,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3342/12032 [3:04:46<7:16:42,  3.02s/it]2025-08-22:21:39:28,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3343/12032 [3:04:50<7:47:55,  3.23s/it]2025-08-22:21:39:32,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3344/12032 [3:04:53<7:31:42,  3.12s/it]2025-08-22:21:39:34,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3345/12032 [3:04:56<7:58:02,  3.30s/it]2025-08-22:21:39:38,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3346/12032 [3:05:00<8:18:24,  3.44s/it]2025-08-22:21:39:42,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3347/12032 [3:05:04<8:32:19,  3.54s/it]2025-08-22:21:39:46,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3348/12032 [3:05:06<7:11:48,  2.98s/it]2025-08-22:21:39:47,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3349/12032 [3:05:08<7:07:35,  2.95s/it]2025-08-22:21:39:50,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3350/12032 [3:05:12<7:42:41,  3.20s/it]2025-08-22:21:39:54,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3351/12032 [3:05:16<8:07:54,  3.37s/it]2025-08-22:21:39:58,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3352/12032 [3:05:18<7:00:31,  2.91s/it]2025-08-22:21:40:00,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3353/12032 [3:05:19<6:00:01,  2.49s/it]2025-08-22:21:40:01,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3354/12032 [3:05:23<6:55:15,  2.87s/it]2025-08-22:21:40:05,456 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3355/12032 [3:05:27<7:34:25,  3.14s/it]2025-08-22:21:40:09,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3356/12032 [3:05:29<6:50:12,  2.84s/it]2025-08-22:21:40:11,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3357/12032 [3:05:33<7:30:13,  3.11s/it]2025-08-22:21:40:15,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3358/12032 [3:05:37<7:59:36,  3.32s/it]2025-08-22:21:40:18,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3359/12032 [3:05:40<8:19:43,  3.46s/it]2025-08-22:21:40:22,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3360/12032 [3:05:42<7:06:39,  2.95s/it]2025-08-22:21:40:24,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3361/12032 [3:05:43<5:38:11,  2.34s/it]2025-08-22:21:40:25,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3362/12032 [3:05:47<6:42:13,  2.78s/it]2025-08-22:21:40:29,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3363/12032 [3:05:51<7:24:48,  3.08s/it]2025-08-22:21:40:32,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3364/12032 [3:05:54<7:56:28,  3.30s/it]2025-08-22:21:40:36,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3365/12032 [3:05:56<6:50:40,  2.84s/it]2025-08-22:21:40:38,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3366/12032 [3:06:00<7:33:50,  3.14s/it]2025-08-22:21:40:42,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3367/12032 [3:06:04<8:00:25,  3.33s/it]2025-08-22:21:40:46,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3368/12032 [3:06:06<6:53:11,  2.86s/it]2025-08-22:21:40:47,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3369/12032 [3:06:09<7:33:14,  3.14s/it]2025-08-22:21:40:51,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3370/12032 [3:06:11<6:41:33,  2.78s/it]2025-08-22:21:40:53,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3371/12032 [3:06:15<7:27:05,  3.10s/it]2025-08-22:21:40:57,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3372/12032 [3:06:19<7:55:53,  3.30s/it]2025-08-22:21:41:01,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3373/12032 [3:06:20<6:38:03,  2.76s/it]2025-08-22:21:41:02,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3374/12032 [3:06:23<6:22:20,  2.65s/it]2025-08-22:21:41:05,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3375/12032 [3:06:25<5:53:17,  2.45s/it]2025-08-22:21:41:07,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3376/12032 [3:06:28<6:08:06,  2.55s/it]2025-08-22:21:41:09,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3377/12032 [3:06:31<7:00:39,  2.92s/it]2025-08-22:21:41:13,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3378/12032 [3:06:35<7:37:48,  3.17s/it]2025-08-22:21:41:17,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3379/12032 [3:06:37<6:59:21,  2.91s/it]2025-08-22:21:41:19,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3380/12032 [3:06:41<7:37:06,  3.17s/it]2025-08-22:21:41:23,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3381/12032 [3:06:45<8:02:45,  3.35s/it]2025-08-22:21:41:27,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3382/12032 [3:06:47<7:04:18,  2.94s/it]2025-08-22:21:41:29,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3383/12032 [3:06:48<6:00:32,  2.50s/it]2025-08-22:21:41:30,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3384/12032 [3:06:51<5:50:59,  2.44s/it]2025-08-22:21:41:33,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3385/12032 [3:06:54<6:39:46,  2.77s/it]2025-08-22:21:41:36,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3386/12032 [3:06:58<7:24:54,  3.09s/it]2025-08-22:21:41:40,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3387/12032 [3:06:59<6:00:45,  2.50s/it]2025-08-22:21:41:41,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3388/12032 [3:07:03<6:57:07,  2.90s/it]2025-08-22:21:41:45,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3389/12032 [3:07:05<6:05:55,  2.54s/it]2025-08-22:21:41:47,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3390/12032 [3:07:09<7:00:25,  2.92s/it]2025-08-22:21:41:50,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3391/12032 [3:07:12<7:37:26,  3.18s/it]2025-08-22:21:41:54,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3392/12032 [3:07:16<8:04:21,  3.36s/it]2025-08-22:21:41:58,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3393/12032 [3:07:20<8:25:22,  3.51s/it]2025-08-22:21:42:02,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3394/12032 [3:07:24<8:37:50,  3.60s/it]2025-08-22:21:42:06,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3395/12032 [3:07:25<7:06:23,  2.96s/it]2025-08-22:21:42:07,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3396/12032 [3:07:29<7:26:52,  3.10s/it]2025-08-22:21:42:11,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3397/12032 [3:07:32<7:53:04,  3.29s/it]2025-08-22:21:42:14,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3398/12032 [3:07:35<7:28:46,  3.12s/it]2025-08-22:21:42:17,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3399/12032 [3:07:39<7:59:51,  3.34s/it]2025-08-22:21:42:21,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3400/12032 [3:07:42<7:32:50,  3.15s/it]2025-08-22:21:42:24,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3401/12032 [3:07:45<7:24:08,  3.09s/it]2025-08-22:21:42:26,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3402/12032 [3:07:48<7:53:49,  3.29s/it]2025-08-22:21:42:30,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3403/12032 [3:07:50<6:43:55,  2.81s/it]2025-08-22:21:42:32,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3404/12032 [3:07:54<7:25:52,  3.10s/it]2025-08-22:21:42:36,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3405/12032 [3:07:57<7:25:11,  3.10s/it]2025-08-22:21:42:39,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3406/12032 [3:07:59<6:58:56,  2.91s/it]2025-08-22:21:42:41,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3407/12032 [3:08:01<6:15:18,  2.61s/it]2025-08-22:21:42:43,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3408/12032 [3:08:05<7:06:10,  2.96s/it]2025-08-22:21:42:47,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3409/12032 [3:08:07<6:33:09,  2.74s/it]2025-08-22:21:42:49,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3410/12032 [3:08:08<5:21:21,  2.24s/it]2025-08-22:21:42:50,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3411/12032 [3:08:12<6:28:41,  2.71s/it]2025-08-22:21:42:54,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3412/12032 [3:08:16<7:14:53,  3.03s/it]2025-08-22:21:42:58,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3413/12032 [3:08:20<7:48:35,  3.26s/it]2025-08-22:21:43:02,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3414/12032 [3:08:24<8:12:08,  3.43s/it]2025-08-22:21:43:05,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3415/12032 [3:08:26<7:19:10,  3.06s/it]2025-08-22:21:43:08,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3416/12032 [3:08:28<6:28:58,  2.71s/it]2025-08-22:21:43:10,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3417/12032 [3:08:30<6:30:33,  2.72s/it]2025-08-22:21:43:12,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3418/12032 [3:08:32<5:50:19,  2.44s/it]2025-08-22:21:43:14,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3419/12032 [3:08:34<5:17:44,  2.21s/it]2025-08-22:21:43:16,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3420/12032 [3:08:35<4:49:20,  2.02s/it]2025-08-22:21:43:17,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3421/12032 [3:08:37<4:20:10,  1.81s/it]2025-08-22:21:43:19,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3422/12032 [3:08:39<4:23:33,  1.84s/it]2025-08-22:21:43:21,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3423/12032 [3:08:40<4:12:48,  1.76s/it]2025-08-22:21:43:22,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3424/12032 [3:08:42<4:27:27,  1.86s/it]2025-08-22:21:43:24,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3425/12032 [3:08:45<4:40:04,  1.95s/it]2025-08-22:21:43:26,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3426/12032 [3:08:47<4:49:09,  2.02s/it]2025-08-22:21:43:29,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3427/12032 [3:08:49<5:13:39,  2.19s/it]2025-08-22:21:43:31,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3428/12032 [3:08:53<6:26:24,  2.69s/it]2025-08-22:21:43:35,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  28%|██▊       | 3429/12032 [3:08:56<6:31:04,  2.73s/it]2025-08-22:21:43:38,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3430/12032 [3:08:58<5:53:25,  2.47s/it]2025-08-22:21:43:40,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3431/12032 [3:09:00<5:23:07,  2.25s/it]2025-08-22:21:43:41,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3432/12032 [3:09:03<6:31:50,  2.73s/it]2025-08-22:21:43:45,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3433/12032 [3:09:05<5:21:34,  2.24s/it]2025-08-22:21:43:46,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3434/12032 [3:09:08<6:28:43,  2.71s/it]2025-08-22:21:43:50,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3435/12032 [3:09:12<7:15:43,  3.04s/it]2025-08-22:21:43:54,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3436/12032 [3:09:16<7:49:27,  3.28s/it]2025-08-22:21:43:58,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3437/12032 [3:09:20<8:11:08,  3.43s/it]2025-08-22:21:44:02,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3438/12032 [3:09:21<6:35:06,  2.76s/it]2025-08-22:21:44:03,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3439/12032 [3:09:25<7:18:27,  3.06s/it]2025-08-22:21:44:07,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3440/12032 [3:09:27<6:35:19,  2.76s/it]2025-08-22:21:44:09,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3441/12032 [3:09:29<5:57:09,  2.49s/it]2025-08-22:21:44:11,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3442/12032 [3:09:31<5:47:21,  2.43s/it]2025-08-22:21:44:13,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3443/12032 [3:09:33<5:15:46,  2.21s/it]2025-08-22:21:44:14,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3444/12032 [3:09:36<6:06:48,  2.56s/it]2025-08-22:21:44:18,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3445/12032 [3:09:39<6:30:01,  2.73s/it]2025-08-22:21:44:21,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3446/12032 [3:09:43<7:15:22,  3.04s/it]2025-08-22:21:44:25,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3447/12032 [3:09:45<6:45:01,  2.83s/it]2025-08-22:21:44:27,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3448/12032 [3:09:47<5:49:57,  2.45s/it]2025-08-22:21:44:29,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3449/12032 [3:09:49<5:24:16,  2.27s/it]2025-08-22:21:44:30,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3450/12032 [3:09:51<5:19:41,  2.24s/it]2025-08-22:21:44:33,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3451/12032 [3:09:54<5:57:27,  2.50s/it]2025-08-22:21:44:36,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3452/12032 [3:09:56<5:27:25,  2.29s/it]2025-08-22:21:44:38,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3453/12032 [3:10:00<6:31:57,  2.74s/it]2025-08-22:21:44:41,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3454/12032 [3:10:03<7:16:44,  3.05s/it]2025-08-22:21:44:45,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3455/12032 [3:10:05<6:20:54,  2.66s/it]2025-08-22:21:44:47,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3456/12032 [3:10:08<6:50:44,  2.87s/it]2025-08-22:21:44:50,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3457/12032 [3:10:10<5:43:25,  2.40s/it]2025-08-22:21:44:52,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3458/12032 [3:10:13<6:26:23,  2.70s/it]2025-08-22:21:44:55,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▊       | 3459/12032 [3:10:17<7:12:33,  3.03s/it]2025-08-22:21:44:59,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3460/12032 [3:10:20<7:13:06,  3.03s/it]2025-08-22:21:45:02,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3461/12032 [3:10:22<6:45:03,  2.84s/it]2025-08-22:21:45:04,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3462/12032 [3:10:24<5:59:18,  2.52s/it]2025-08-22:21:45:06,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3463/12032 [3:10:27<6:05:05,  2.56s/it]2025-08-22:21:45:09,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3464/12032 [3:10:31<7:01:07,  2.95s/it]2025-08-22:21:45:12,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3465/12032 [3:10:33<6:34:31,  2.76s/it]2025-08-22:21:45:15,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3466/12032 [3:10:36<7:02:47,  2.96s/it]2025-08-22:21:45:18,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3467/12032 [3:10:40<7:15:05,  3.05s/it]2025-08-22:21:45:21,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3468/12032 [3:10:43<7:47:06,  3.27s/it]2025-08-22:21:45:25,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3469/12032 [3:10:46<7:18:17,  3.07s/it]2025-08-22:21:45:28,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3470/12032 [3:10:48<6:47:47,  2.86s/it]2025-08-22:21:45:30,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3471/12032 [3:10:51<6:53:29,  2.90s/it]2025-08-22:21:45:33,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3472/12032 [3:10:53<6:11:33,  2.60s/it]2025-08-22:21:45:35,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3473/12032 [3:10:57<6:41:41,  2.82s/it]2025-08-22:21:45:38,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3474/12032 [3:10:58<5:50:53,  2.46s/it]2025-08-22:21:45:40,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3475/12032 [3:11:01<5:59:50,  2.52s/it]2025-08-22:21:45:43,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3476/12032 [3:11:05<6:53:08,  2.90s/it]2025-08-22:21:45:47,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3477/12032 [3:11:08<7:30:36,  3.16s/it]2025-08-22:21:45:50,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3478/12032 [3:11:12<8:00:24,  3.37s/it]2025-08-22:21:45:54,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3479/12032 [3:11:16<8:19:04,  3.50s/it]2025-08-22:21:45:58,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3480/12032 [3:11:20<8:30:25,  3.58s/it]2025-08-22:21:46:02,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3481/12032 [3:11:24<8:38:21,  3.64s/it]2025-08-22:21:46:05,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3482/12032 [3:11:27<8:42:31,  3.67s/it]2025-08-22:21:46:09,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3483/12032 [3:11:31<8:47:13,  3.70s/it]2025-08-22:21:46:13,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3484/12032 [3:11:35<8:50:58,  3.73s/it]2025-08-22:21:46:17,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3485/12032 [3:11:37<7:31:12,  3.17s/it]2025-08-22:21:46:19,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3486/12032 [3:11:38<6:25:44,  2.71s/it]2025-08-22:21:46:20,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3487/12032 [3:11:41<6:14:37,  2.63s/it]2025-08-22:21:46:23,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3488/12032 [3:11:45<7:06:57,  3.00s/it]2025-08-22:21:46:27,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3489/12032 [3:11:47<6:27:50,  2.72s/it]2025-08-22:21:46:29,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3490/12032 [3:11:50<7:03:33,  2.98s/it]2025-08-22:21:46:32,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3491/12032 [3:11:54<7:38:03,  3.22s/it]2025-08-22:21:46:36,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3492/12032 [3:11:58<8:01:48,  3.39s/it]2025-08-22:21:46:40,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3493/12032 [3:12:02<8:18:58,  3.51s/it]2025-08-22:21:46:44,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3494/12032 [3:12:06<8:30:39,  3.59s/it]2025-08-22:21:46:47,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3495/12032 [3:12:07<7:05:41,  2.99s/it]2025-08-22:21:46:49,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3496/12032 [3:12:11<7:29:07,  3.16s/it]2025-08-22:21:46:53,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3497/12032 [3:12:12<6:16:38,  2.65s/it]2025-08-22:21:46:54,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3498/12032 [3:12:16<7:04:50,  2.99s/it]2025-08-22:21:46:58,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3499/12032 [3:12:19<7:09:56,  3.02s/it]2025-08-22:21:47:01,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3500/12032 [3:12:23<7:41:44,  3.25s/it]2025-08-22:21:47:05,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3501/12032 [3:12:27<8:04:34,  3.41s/it]2025-08-22:21:47:08,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3502/12032 [3:12:28<6:57:52,  2.94s/it]2025-08-22:21:47:10,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3503/12032 [3:12:31<6:59:54,  2.95s/it]2025-08-22:21:47:13,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3504/12032 [3:12:32<5:39:19,  2.39s/it]2025-08-22:21:47:14,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3505/12032 [3:12:36<6:37:18,  2.80s/it]2025-08-22:21:47:18,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3506/12032 [3:12:39<6:18:19,  2.66s/it]2025-08-22:21:47:20,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3507/12032 [3:12:40<5:38:41,  2.38s/it]2025-08-22:21:47:22,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3508/12032 [3:12:43<6:05:04,  2.57s/it]2025-08-22:21:47:25,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3509/12032 [3:12:47<6:42:46,  2.84s/it]2025-08-22:21:47:29,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3510/12032 [3:12:49<6:15:30,  2.64s/it]2025-08-22:21:47:31,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3511/12032 [3:12:53<7:06:02,  3.00s/it]2025-08-22:21:47:35,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3512/12032 [3:12:57<7:39:18,  3.23s/it]2025-08-22:21:47:38,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3513/12032 [3:13:00<8:01:46,  3.39s/it]2025-08-22:21:47:42,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3514/12032 [3:13:04<8:18:12,  3.51s/it]2025-08-22:21:47:46,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3515/12032 [3:13:07<7:57:00,  3.36s/it]2025-08-22:21:47:49,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3516/12032 [3:13:09<6:33:38,  2.77s/it]2025-08-22:21:47:50,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3517/12032 [3:13:10<5:38:29,  2.39s/it]2025-08-22:21:47:52,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3518/12032 [3:13:14<6:40:18,  2.82s/it]2025-08-22:21:47:56,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3519/12032 [3:13:15<5:21:26,  2.27s/it]2025-08-22:21:47:57,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3520/12032 [3:13:16<4:24:27,  1.86s/it]2025-08-22:21:47:58,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3521/12032 [3:13:19<5:11:05,  2.19s/it]2025-08-22:21:48:01,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3522/12032 [3:13:22<5:48:38,  2.46s/it]2025-08-22:21:48:04,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3523/12032 [3:13:24<5:48:27,  2.46s/it]2025-08-22:21:48:06,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3524/12032 [3:13:26<5:10:13,  2.19s/it]2025-08-22:21:48:08,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3525/12032 [3:13:30<6:19:56,  2.68s/it]2025-08-22:21:48:11,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3526/12032 [3:13:32<6:24:46,  2.71s/it]2025-08-22:21:48:14,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3527/12032 [3:13:36<6:44:12,  2.85s/it]2025-08-22:21:48:17,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3528/12032 [3:13:40<7:33:14,  3.20s/it]2025-08-22:21:48:21,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3529/12032 [3:13:44<8:05:00,  3.42s/it]2025-08-22:21:48:25,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3530/12032 [3:13:44<6:17:11,  2.66s/it]2025-08-22:21:48:26,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3531/12032 [3:13:48<7:10:36,  3.04s/it]2025-08-22:21:48:30,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3532/12032 [3:13:52<7:41:55,  3.26s/it]2025-08-22:21:48:34,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3533/12032 [3:13:55<7:25:22,  3.14s/it]2025-08-22:21:48:37,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3534/12032 [3:13:59<7:51:55,  3.33s/it]2025-08-22:21:48:41,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3535/12032 [3:14:03<8:13:56,  3.49s/it]2025-08-22:21:48:44,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3536/12032 [3:14:04<6:25:32,  2.72s/it]2025-08-22:21:48:45,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3537/12032 [3:14:06<5:56:06,  2.52s/it]2025-08-22:21:48:47,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3538/12032 [3:14:09<6:49:06,  2.89s/it]2025-08-22:21:48:51,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3539/12032 [3:14:13<7:26:49,  3.16s/it]2025-08-22:21:48:55,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3540/12032 [3:14:17<7:52:27,  3.34s/it]2025-08-22:21:48:59,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3541/12032 [3:14:18<6:36:36,  2.80s/it]2025-08-22:21:49:00,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3542/12032 [3:14:20<5:48:08,  2.46s/it]2025-08-22:21:49:02,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3543/12032 [3:14:21<4:39:16,  1.97s/it]2025-08-22:21:49:03,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3544/12032 [3:14:23<4:23:02,  1.86s/it]2025-08-22:21:49:04,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3545/12032 [3:14:26<5:34:38,  2.37s/it]2025-08-22:21:49:08,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3546/12032 [3:14:27<4:22:52,  1.86s/it]2025-08-22:21:49:09,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3547/12032 [3:14:29<4:51:00,  2.06s/it]2025-08-22:21:49:11,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3548/12032 [3:14:33<6:06:48,  2.59s/it]2025-08-22:21:49:15,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  29%|██▉       | 3549/12032 [3:14:37<6:58:30,  2.96s/it]2025-08-22:21:49:19,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3550/12032 [3:14:41<7:32:22,  3.20s/it]2025-08-22:21:49:23,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3551/12032 [3:14:44<7:55:45,  3.37s/it]2025-08-22:21:49:26,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3552/12032 [3:14:48<8:17:15,  3.52s/it]2025-08-22:21:49:30,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3553/12032 [3:14:52<8:27:53,  3.59s/it]2025-08-22:21:49:34,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3554/12032 [3:14:55<7:40:11,  3.26s/it]2025-08-22:21:49:36,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3555/12032 [3:14:58<8:03:09,  3.42s/it]2025-08-22:21:49:40,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3556/12032 [3:15:02<8:19:14,  3.53s/it]2025-08-22:21:49:44,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3557/12032 [3:15:06<8:29:43,  3.61s/it]2025-08-22:21:49:48,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3558/12032 [3:15:10<8:39:14,  3.68s/it]2025-08-22:21:49:52,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3559/12032 [3:15:14<8:44:51,  3.72s/it]2025-08-22:21:49:55,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3560/12032 [3:15:17<8:20:38,  3.55s/it]2025-08-22:21:49:59,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3561/12032 [3:15:18<6:32:19,  2.78s/it]2025-08-22:21:50:00,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3562/12032 [3:15:19<5:23:05,  2.29s/it]2025-08-22:21:50:01,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3563/12032 [3:15:23<6:20:53,  2.70s/it]2025-08-22:21:50:04,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3564/12032 [3:15:25<6:15:29,  2.66s/it]2025-08-22:21:50:07,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3565/12032 [3:15:28<6:05:03,  2.59s/it]2025-08-22:21:50:09,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3566/12032 [3:15:31<6:31:24,  2.77s/it]2025-08-22:21:50:13,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3567/12032 [3:15:34<6:36:57,  2.81s/it]2025-08-22:21:50:15,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3568/12032 [3:15:37<6:41:16,  2.84s/it]2025-08-22:21:50:18,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3569/12032 [3:15:39<6:20:04,  2.69s/it]2025-08-22:21:50:21,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3570/12032 [3:15:43<7:05:46,  3.02s/it]2025-08-22:21:50:25,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3571/12032 [3:15:45<6:53:37,  2.93s/it]2025-08-22:21:50:27,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3572/12032 [3:15:49<7:29:34,  3.19s/it]2025-08-22:21:50:31,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3573/12032 [3:15:53<7:55:16,  3.37s/it]2025-08-22:21:50:35,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3574/12032 [3:15:55<6:41:51,  2.85s/it]2025-08-22:21:50:36,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3575/12032 [3:15:58<7:21:30,  3.13s/it]2025-08-22:21:50:40,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3576/12032 [3:16:02<7:49:27,  3.33s/it]2025-08-22:21:50:44,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3577/12032 [3:16:06<8:06:24,  3.45s/it]2025-08-22:21:50:48,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3578/12032 [3:16:09<7:50:02,  3.34s/it]2025-08-22:21:50:51,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3579/12032 [3:16:13<8:10:30,  3.48s/it]2025-08-22:21:50:55,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3580/12032 [3:16:15<6:57:03,  2.96s/it]2025-08-22:21:50:56,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3581/12032 [3:16:18<7:32:04,  3.21s/it]2025-08-22:21:51:00,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3582/12032 [3:16:20<6:40:08,  2.84s/it]2025-08-22:21:51:02,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3583/12032 [3:16:24<7:19:49,  3.12s/it]2025-08-22:21:51:06,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3584/12032 [3:16:27<7:04:57,  3.02s/it]2025-08-22:21:51:09,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3585/12032 [3:16:30<6:50:18,  2.91s/it]2025-08-22:21:51:11,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3586/12032 [3:16:33<7:11:51,  3.07s/it]2025-08-22:21:51:15,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3587/12032 [3:16:37<7:41:41,  3.28s/it]2025-08-22:21:51:19,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3588/12032 [3:16:41<8:02:27,  3.43s/it]2025-08-22:21:51:22,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3589/12032 [3:16:43<7:22:31,  3.14s/it]2025-08-22:21:51:25,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3590/12032 [3:16:47<7:52:03,  3.36s/it]2025-08-22:21:51:29,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3591/12032 [3:16:50<7:43:19,  3.29s/it]2025-08-22:21:51:32,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3592/12032 [3:16:54<8:03:45,  3.44s/it]2025-08-22:21:51:36,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3593/12032 [3:16:56<7:08:04,  3.04s/it]2025-08-22:21:51:38,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3594/12032 [3:16:59<6:50:21,  2.92s/it]2025-08-22:21:51:40,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3595/12032 [3:17:00<5:56:38,  2.54s/it]2025-08-22:21:51:42,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3596/12032 [3:17:03<6:02:47,  2.58s/it]2025-08-22:21:51:45,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3597/12032 [3:17:07<6:53:51,  2.94s/it]2025-08-22:21:51:49,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3598/12032 [3:17:10<7:18:37,  3.12s/it]2025-08-22:21:51:52,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3599/12032 [3:17:12<6:22:13,  2.72s/it]2025-08-22:21:51:54,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3600/12032 [3:17:13<5:18:06,  2.26s/it]2025-08-22:21:51:55,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3601/12032 [3:17:15<5:15:41,  2.25s/it]2025-08-22:21:51:57,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3602/12032 [3:17:17<4:59:01,  2.13s/it]2025-08-22:21:51:59,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3603/12032 [3:17:21<6:08:05,  2.62s/it]2025-08-22:21:52:03,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3604/12032 [3:17:24<6:21:00,  2.71s/it]2025-08-22:21:52:06,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3605/12032 [3:17:25<5:20:30,  2.28s/it]2025-08-22:21:52:07,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3606/12032 [3:17:29<6:24:14,  2.74s/it]2025-08-22:21:52:11,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3607/12032 [3:17:30<5:22:29,  2.30s/it]2025-08-22:21:52:12,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3608/12032 [3:17:34<6:10:04,  2.64s/it]2025-08-22:21:52:16,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|██▉       | 3609/12032 [3:17:35<4:59:09,  2.13s/it]2025-08-22:21:52:17,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3610/12032 [3:17:38<6:09:37,  2.63s/it]2025-08-22:21:52:20,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3611/12032 [3:17:42<6:57:53,  2.98s/it]2025-08-22:21:52:24,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3612/12032 [3:17:43<5:29:01,  2.34s/it]2025-08-22:21:52:25,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3613/12032 [3:17:47<6:29:35,  2.78s/it]2025-08-22:21:52:29,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3614/12032 [3:17:49<6:03:12,  2.59s/it]2025-08-22:21:52:31,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3615/12032 [3:17:51<5:34:26,  2.38s/it]2025-08-22:21:52:33,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3616/12032 [3:17:52<4:35:25,  1.96s/it]2025-08-22:21:52:34,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3617/12032 [3:17:53<4:13:45,  1.81s/it]2025-08-22:21:52:35,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3618/12032 [3:17:55<4:01:08,  1.72s/it]2025-08-22:21:52:37,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3619/12032 [3:17:56<3:44:23,  1.60s/it]2025-08-22:21:52:38,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3620/12032 [3:17:58<4:05:57,  1.75s/it]2025-08-22:21:52:40,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3621/12032 [3:18:01<4:29:52,  1.93s/it]2025-08-22:21:52:43,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3622/12032 [3:18:02<3:56:49,  1.69s/it]2025-08-22:21:52:44,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3623/12032 [3:18:06<5:25:10,  2.32s/it]2025-08-22:21:52:47,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3624/12032 [3:18:09<6:27:07,  2.76s/it]2025-08-22:21:52:51,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3625/12032 [3:18:13<7:09:46,  3.07s/it]2025-08-22:21:52:55,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3626/12032 [3:18:14<5:53:15,  2.52s/it]2025-08-22:21:52:56,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3627/12032 [3:18:18<6:38:59,  2.85s/it]2025-08-22:21:53:00,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3628/12032 [3:18:22<7:09:36,  3.07s/it]2025-08-22:21:53:03,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3629/12032 [3:18:25<7:39:55,  3.28s/it]2025-08-22:21:53:07,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3630/12032 [3:18:29<8:01:13,  3.44s/it]2025-08-22:21:53:11,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3631/12032 [3:18:31<7:08:58,  3.06s/it]2025-08-22:21:53:13,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3632/12032 [3:18:34<7:07:25,  3.05s/it]2025-08-22:21:53:16,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3633/12032 [3:18:37<6:37:24,  2.84s/it]2025-08-22:21:53:19,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3634/12032 [3:18:40<7:04:39,  3.03s/it]2025-08-22:21:53:22,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3635/12032 [3:18:44<7:35:53,  3.26s/it]2025-08-22:21:53:26,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3636/12032 [3:18:46<6:58:24,  2.99s/it]2025-08-22:21:53:28,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3637/12032 [3:18:50<7:32:37,  3.24s/it]2025-08-22:21:53:32,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3638/12032 [3:18:53<7:29:22,  3.21s/it]2025-08-22:21:53:35,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3639/12032 [3:18:55<6:22:19,  2.73s/it]2025-08-22:21:53:37,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3640/12032 [3:18:59<7:06:19,  3.05s/it]2025-08-22:21:53:41,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3641/12032 [3:19:03<7:39:43,  3.29s/it]2025-08-22:21:53:44,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3642/12032 [3:19:05<6:53:13,  2.96s/it]2025-08-22:21:53:47,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3643/12032 [3:19:09<7:26:54,  3.20s/it]2025-08-22:21:53:50,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3644/12032 [3:19:12<7:51:09,  3.37s/it]2025-08-22:21:53:54,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3645/12032 [3:19:14<6:52:51,  2.95s/it]2025-08-22:21:53:56,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3646/12032 [3:19:17<6:42:28,  2.88s/it]2025-08-22:21:53:59,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3647/12032 [3:19:19<6:22:05,  2.73s/it]2025-08-22:21:54:01,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3648/12032 [3:19:22<6:11:32,  2.66s/it]2025-08-22:21:54:04,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3649/12032 [3:19:26<6:58:00,  2.99s/it]2025-08-22:21:54:07,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3650/12032 [3:19:28<6:33:08,  2.81s/it]2025-08-22:21:54:10,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3651/12032 [3:19:32<7:10:40,  3.08s/it]2025-08-22:21:54:14,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3652/12032 [3:19:35<7:01:04,  3.01s/it]2025-08-22:21:54:16,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3653/12032 [3:19:38<7:23:43,  3.18s/it]2025-08-22:21:54:20,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3654/12032 [3:19:42<7:48:41,  3.36s/it]2025-08-22:21:54:24,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3655/12032 [3:19:45<7:39:28,  3.29s/it]2025-08-22:21:54:27,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3656/12032 [3:19:48<7:09:09,  3.07s/it]2025-08-22:21:54:30,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3657/12032 [3:19:50<6:42:41,  2.88s/it]2025-08-22:21:54:32,446 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3658/12032 [3:19:52<6:08:10,  2.64s/it]2025-08-22:21:54:34,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3659/12032 [3:19:56<6:38:15,  2.85s/it]2025-08-22:21:54:37,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3660/12032 [3:19:57<5:38:57,  2.43s/it]2025-08-22:21:54:39,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3661/12032 [3:19:59<5:28:36,  2.36s/it]2025-08-22:21:54:41,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3662/12032 [3:20:03<6:29:39,  2.79s/it]2025-08-22:21:54:45,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3663/12032 [3:20:07<7:08:08,  3.07s/it]2025-08-22:21:54:49,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3664/12032 [3:20:10<7:18:35,  3.14s/it]2025-08-22:21:54:52,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3665/12032 [3:20:14<7:44:53,  3.33s/it]2025-08-22:21:54:56,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3666/12032 [3:20:18<8:02:15,  3.46s/it]2025-08-22:21:54:59,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3667/12032 [3:20:21<8:15:53,  3.56s/it]2025-08-22:21:55:03,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3668/12032 [3:20:23<7:03:09,  3.04s/it]2025-08-22:21:55:05,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  30%|███       | 3669/12032 [3:20:27<7:35:29,  3.27s/it]2025-08-22:21:55:09,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3670/12032 [3:20:29<6:57:46,  3.00s/it]2025-08-22:21:55:11,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3671/12032 [3:20:33<7:06:54,  3.06s/it]2025-08-22:21:55:14,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3672/12032 [3:20:35<6:25:54,  2.77s/it]2025-08-22:21:55:16,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3673/12032 [3:20:38<7:07:51,  3.07s/it]2025-08-22:21:55:20,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3674/12032 [3:20:42<7:37:44,  3.29s/it]2025-08-22:21:55:24,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3675/12032 [3:20:44<6:31:22,  2.81s/it]2025-08-22:21:55:26,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3676/12032 [3:20:48<7:12:36,  3.11s/it]2025-08-22:21:55:30,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3677/12032 [3:20:49<5:58:27,  2.57s/it]2025-08-22:21:55:31,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3678/12032 [3:20:53<6:49:17,  2.94s/it]2025-08-22:21:55:35,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3679/12032 [3:20:54<5:37:54,  2.43s/it]2025-08-22:21:55:36,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3680/12032 [3:20:58<6:33:48,  2.83s/it]2025-08-22:21:55:40,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3681/12032 [3:21:01<7:00:27,  3.02s/it]2025-08-22:21:55:43,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3682/12032 [3:21:03<6:07:39,  2.64s/it]2025-08-22:21:55:45,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3683/12032 [3:21:07<6:54:29,  2.98s/it]2025-08-22:21:55:49,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3684/12032 [3:21:11<7:27:32,  3.22s/it]2025-08-22:21:55:52,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3685/12032 [3:21:13<6:53:57,  2.98s/it]2025-08-22:21:55:55,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3686/12032 [3:21:14<5:27:50,  2.36s/it]2025-08-22:21:55:56,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3687/12032 [3:21:18<6:26:53,  2.78s/it]2025-08-22:21:55:59,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3688/12032 [3:21:21<7:07:38,  3.08s/it]2025-08-22:21:56:03,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3689/12032 [3:21:25<7:37:08,  3.29s/it]2025-08-22:21:56:07,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3690/12032 [3:21:29<7:57:03,  3.43s/it]2025-08-22:21:56:11,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3691/12032 [3:21:31<7:11:44,  3.11s/it]2025-08-22:21:56:13,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3692/12032 [3:21:34<6:45:29,  2.92s/it]2025-08-22:21:56:16,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3693/12032 [3:21:38<7:21:30,  3.18s/it]2025-08-22:21:56:19,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3694/12032 [3:21:41<7:46:37,  3.36s/it]2025-08-22:21:56:23,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3695/12032 [3:21:45<8:04:33,  3.49s/it]2025-08-22:21:56:27,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3696/12032 [3:21:49<8:17:24,  3.58s/it]2025-08-22:21:56:31,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3697/12032 [3:21:53<8:21:06,  3.61s/it]2025-08-22:21:56:34,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3698/12032 [3:21:54<6:36:55,  2.86s/it]2025-08-22:21:56:36,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3699/12032 [3:21:57<7:04:38,  3.06s/it]2025-08-22:21:56:39,574 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3700/12032 [3:22:01<7:34:32,  3.27s/it]2025-08-22:21:56:43,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3701/12032 [3:22:05<7:58:29,  3.45s/it]2025-08-22:21:56:47,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3702/12032 [3:22:07<7:06:37,  3.07s/it]2025-08-22:21:56:49,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3703/12032 [3:22:11<7:40:08,  3.31s/it]2025-08-22:21:56:53,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3704/12032 [3:22:14<7:13:44,  3.12s/it]2025-08-22:21:56:55,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3705/12032 [3:22:17<7:05:15,  3.06s/it]2025-08-22:21:56:58,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3706/12032 [3:22:19<6:23:44,  2.77s/it]2025-08-22:21:57:00,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3707/12032 [3:22:22<7:05:59,  3.07s/it]2025-08-22:21:57:04,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3708/12032 [3:22:24<5:53:04,  2.55s/it]2025-08-22:21:57:06,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3709/12032 [3:22:25<4:54:42,  2.12s/it]2025-08-22:21:57:07,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3710/12032 [3:22:29<6:02:55,  2.62s/it]2025-08-22:21:57:10,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3711/12032 [3:22:31<5:44:17,  2.48s/it]2025-08-22:21:57:13,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3712/12032 [3:22:34<6:25:04,  2.78s/it]2025-08-22:21:57:16,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3713/12032 [3:22:38<6:57:06,  3.01s/it]2025-08-22:21:57:20,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3714/12032 [3:22:42<7:30:35,  3.25s/it]2025-08-22:21:57:23,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3715/12032 [3:22:45<7:54:05,  3.42s/it]2025-08-22:21:57:27,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3716/12032 [3:22:49<8:09:46,  3.53s/it]2025-08-22:21:57:31,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3717/12032 [3:22:53<8:23:06,  3.63s/it]2025-08-22:21:57:35,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3718/12032 [3:22:57<8:29:45,  3.68s/it]2025-08-22:21:57:39,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3719/12032 [3:22:59<7:20:32,  3.18s/it]2025-08-22:21:57:41,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3720/12032 [3:23:02<7:00:55,  3.04s/it]2025-08-22:21:57:43,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3721/12032 [3:23:05<7:35:07,  3.29s/it]2025-08-22:21:57:47,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3722/12032 [3:23:09<7:56:13,  3.44s/it]2025-08-22:21:57:51,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3723/12032 [3:23:12<7:26:15,  3.22s/it]2025-08-22:21:57:54,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3724/12032 [3:23:15<7:14:12,  3.14s/it]2025-08-22:21:57:57,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3725/12032 [3:23:17<6:32:54,  2.84s/it]2025-08-22:21:57:59,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3726/12032 [3:23:20<6:55:34,  3.00s/it]2025-08-22:21:58:02,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3727/12032 [3:23:22<6:08:11,  2.66s/it]2025-08-22:21:58:04,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3728/12032 [3:23:25<6:12:09,  2.69s/it]2025-08-22:21:58:07,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3729/12032 [3:23:29<7:01:48,  3.05s/it]2025-08-22:21:58:11,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3730/12032 [3:23:33<7:32:54,  3.27s/it]2025-08-22:21:58:15,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3731/12032 [3:23:36<7:31:04,  3.26s/it]2025-08-22:21:58:18,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3732/12032 [3:23:39<7:13:37,  3.13s/it]2025-08-22:21:58:21,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3733/12032 [3:23:43<7:45:21,  3.36s/it]2025-08-22:21:58:25,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3734/12032 [3:23:45<7:12:28,  3.13s/it]2025-08-22:21:58:27,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3735/12032 [3:23:47<6:20:55,  2.75s/it]2025-08-22:21:58:29,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3736/12032 [3:23:51<7:05:01,  3.07s/it]2025-08-22:21:58:33,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3737/12032 [3:23:55<7:35:10,  3.29s/it]2025-08-22:21:58:37,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3738/12032 [3:23:57<6:47:31,  2.95s/it]2025-08-22:21:58:39,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3739/12032 [3:23:59<6:14:55,  2.71s/it]2025-08-22:21:58:41,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3740/12032 [3:24:03<7:07:31,  3.09s/it]2025-08-22:21:58:45,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3741/12032 [3:24:07<7:44:58,  3.36s/it]2025-08-22:21:58:49,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3742/12032 [3:24:10<7:18:21,  3.17s/it]2025-08-22:21:58:52,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3743/12032 [3:24:14<7:54:50,  3.44s/it]2025-08-22:21:58:56,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3744/12032 [3:24:16<6:57:16,  3.02s/it]2025-08-22:21:58:58,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3745/12032 [3:24:18<6:30:10,  2.82s/it]2025-08-22:21:59:00,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3746/12032 [3:24:21<6:42:38,  2.92s/it]2025-08-22:21:59:03,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3747/12032 [3:24:25<7:20:03,  3.19s/it]2025-08-22:21:59:07,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3748/12032 [3:24:28<6:44:29,  2.93s/it]2025-08-22:21:59:09,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3749/12032 [3:24:31<7:20:22,  3.19s/it]2025-08-22:21:59:13,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3750/12032 [3:24:35<7:46:17,  3.38s/it]2025-08-22:21:59:17,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3751/12032 [3:24:37<6:22:05,  2.77s/it]2025-08-22:21:59:18,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3752/12032 [3:24:38<5:46:28,  2.51s/it]2025-08-22:21:59:20,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3753/12032 [3:24:42<6:37:04,  2.88s/it]2025-08-22:21:59:24,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3754/12032 [3:24:45<6:32:18,  2.84s/it]2025-08-22:21:59:27,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3755/12032 [3:24:47<6:15:29,  2.72s/it]2025-08-22:21:59:29,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3756/12032 [3:24:48<5:07:19,  2.23s/it]2025-08-22:21:59:30,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3757/12032 [3:24:52<6:12:47,  2.70s/it]2025-08-22:21:59:34,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3758/12032 [3:24:56<6:56:01,  3.02s/it]2025-08-22:21:59:38,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███       | 3759/12032 [3:25:00<7:27:13,  3.24s/it]2025-08-22:21:59:42,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3760/12032 [3:25:04<7:48:29,  3.40s/it]2025-08-22:21:59:45,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3761/12032 [3:25:07<8:04:50,  3.52s/it]2025-08-22:21:59:49,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3762/12032 [3:25:10<7:35:30,  3.30s/it]2025-08-22:21:59:52,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3763/12032 [3:25:13<7:13:04,  3.14s/it]2025-08-22:21:59:55,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3764/12032 [3:25:15<6:15:41,  2.73s/it]2025-08-22:21:59:56,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3765/12032 [3:25:18<6:57:55,  3.03s/it]2025-08-22:22:00:00,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3766/12032 [3:25:20<6:17:31,  2.74s/it]2025-08-22:22:00:02,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3767/12032 [3:25:24<7:00:05,  3.05s/it]2025-08-22:22:00:06,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3768/12032 [3:25:25<5:33:43,  2.42s/it]2025-08-22:22:00:07,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3769/12032 [3:25:27<5:28:34,  2.39s/it]2025-08-22:22:00:09,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3770/12032 [3:25:30<5:37:43,  2.45s/it]2025-08-22:22:00:12,443 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3771/12032 [3:25:34<6:32:14,  2.85s/it]2025-08-22:22:00:16,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3772/12032 [3:25:38<7:09:40,  3.12s/it]2025-08-22:22:00:19,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3773/12032 [3:25:40<6:33:12,  2.86s/it]2025-08-22:22:00:22,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3774/12032 [3:25:44<7:10:13,  3.13s/it]2025-08-22:22:00:25,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3775/12032 [3:25:47<7:36:47,  3.32s/it]2025-08-22:22:00:29,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3776/12032 [3:25:51<7:53:46,  3.44s/it]2025-08-22:22:00:33,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3777/12032 [3:25:55<8:06:49,  3.54s/it]2025-08-22:22:00:37,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3778/12032 [3:25:57<7:10:01,  3.13s/it]2025-08-22:22:00:39,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3779/12032 [3:25:59<6:02:59,  2.64s/it]2025-08-22:22:00:40,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3780/12032 [3:26:02<6:54:29,  3.01s/it]2025-08-22:22:00:44,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3781/12032 [3:26:06<7:25:32,  3.24s/it]2025-08-22:22:00:48,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3782/12032 [3:26:10<7:47:00,  3.40s/it]2025-08-22:22:00:52,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3783/12032 [3:26:14<8:03:39,  3.52s/it]2025-08-22:22:00:56,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3784/12032 [3:26:17<7:41:25,  3.36s/it]2025-08-22:22:00:59,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3785/12032 [3:26:21<8:03:37,  3.52s/it]2025-08-22:22:01:02,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3786/12032 [3:26:23<6:58:49,  3.05s/it]2025-08-22:22:01:04,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3787/12032 [3:26:26<7:06:34,  3.10s/it]2025-08-22:22:01:08,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3788/12032 [3:26:30<7:36:54,  3.33s/it]2025-08-22:22:01:12,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3789/12032 [3:26:33<7:30:30,  3.28s/it]2025-08-22:22:01:15,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  31%|███▏      | 3790/12032 [3:26:35<6:46:58,  2.96s/it]2025-08-22:22:01:17,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3791/12032 [3:26:37<6:19:01,  2.76s/it]2025-08-22:22:01:19,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3792/12032 [3:26:39<5:50:16,  2.55s/it]2025-08-22:22:01:21,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3793/12032 [3:26:41<4:57:51,  2.17s/it]2025-08-22:22:01:23,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3794/12032 [3:26:43<4:44:47,  2.07s/it]2025-08-22:22:01:24,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3795/12032 [3:26:45<5:06:00,  2.23s/it]2025-08-22:22:01:27,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3796/12032 [3:26:49<6:13:27,  2.72s/it]2025-08-22:22:01:31,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3797/12032 [3:26:51<5:29:52,  2.40s/it]2025-08-22:22:01:33,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3798/12032 [3:26:54<6:28:11,  2.83s/it]2025-08-22:22:01:36,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3799/12032 [3:26:58<7:11:24,  3.14s/it]2025-08-22:22:01:40,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3800/12032 [3:27:02<7:42:18,  3.37s/it]2025-08-22:22:01:44,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3801/12032 [3:27:06<8:04:03,  3.53s/it]2025-08-22:22:01:48,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3802/12032 [3:27:08<7:03:22,  3.09s/it]2025-08-22:22:01:50,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3803/12032 [3:27:12<7:36:46,  3.33s/it]2025-08-22:22:01:54,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3804/12032 [3:27:16<7:55:07,  3.46s/it]2025-08-22:22:01:58,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3805/12032 [3:27:18<7:14:37,  3.17s/it]2025-08-22:22:02:00,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3806/12032 [3:27:21<6:42:05,  2.93s/it]2025-08-22:22:02:03,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3807/12032 [3:27:23<6:24:01,  2.80s/it]2025-08-22:22:02:05,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3808/12032 [3:27:26<6:30:54,  2.85s/it]2025-08-22:22:02:08,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3809/12032 [3:27:28<5:52:50,  2.57s/it]2025-08-22:22:02:10,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3810/12032 [3:27:32<6:43:58,  2.95s/it]2025-08-22:22:02:14,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3811/12032 [3:27:36<7:19:13,  3.21s/it]2025-08-22:22:02:18,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3812/12032 [3:27:37<6:12:58,  2.72s/it]2025-08-22:22:02:19,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3813/12032 [3:27:41<6:56:48,  3.04s/it]2025-08-22:22:02:23,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3814/12032 [3:27:45<7:26:58,  3.26s/it]2025-08-22:22:02:27,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3815/12032 [3:27:49<7:47:18,  3.41s/it]2025-08-22:22:02:31,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3816/12032 [3:27:52<8:02:15,  3.52s/it]2025-08-22:22:02:34,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3817/12032 [3:27:54<6:54:20,  3.03s/it]2025-08-22:22:02:36,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3818/12032 [3:27:58<7:24:55,  3.25s/it]2025-08-22:22:02:40,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3819/12032 [3:28:00<6:12:32,  2.72s/it]2025-08-22:22:02:41,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3820/12032 [3:28:02<6:06:38,  2.68s/it]2025-08-22:22:02:44,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3821/12032 [3:28:04<5:18:44,  2.33s/it]2025-08-22:22:02:46,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3822/12032 [3:28:07<6:17:59,  2.76s/it]2025-08-22:22:02:49,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3823/12032 [3:28:11<7:00:06,  3.07s/it]2025-08-22:22:02:53,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3824/12032 [3:28:14<6:25:56,  2.82s/it]2025-08-22:22:02:55,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3825/12032 [3:28:17<7:04:16,  3.10s/it]2025-08-22:22:02:59,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3826/12032 [3:28:19<6:22:10,  2.79s/it]2025-08-22:22:03:01,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3827/12032 [3:28:21<5:40:05,  2.49s/it]2025-08-22:22:03:03,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3828/12032 [3:28:24<5:44:33,  2.52s/it]2025-08-22:22:03:06,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3829/12032 [3:28:27<6:34:45,  2.89s/it]2025-08-22:22:03:09,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3830/12032 [3:28:31<7:13:12,  3.17s/it]2025-08-22:22:03:13,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3831/12032 [3:28:35<7:39:04,  3.36s/it]2025-08-22:22:03:17,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3832/12032 [3:28:38<7:38:17,  3.35s/it]2025-08-22:22:03:20,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3833/12032 [3:28:40<6:12:27,  2.73s/it]2025-08-22:22:03:22,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3834/12032 [3:28:43<6:34:22,  2.89s/it]2025-08-22:22:03:25,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3835/12032 [3:28:47<7:11:01,  3.15s/it]2025-08-22:22:03:29,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3836/12032 [3:28:51<7:36:45,  3.34s/it]2025-08-22:22:03:32,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3837/12032 [3:28:53<7:15:36,  3.19s/it]2025-08-22:22:03:35,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3838/12032 [3:28:57<7:41:15,  3.38s/it]2025-08-22:22:03:39,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3839/12032 [3:29:01<8:02:30,  3.53s/it]2025-08-22:22:03:43,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3840/12032 [3:29:05<8:13:48,  3.62s/it]2025-08-22:22:03:47,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3841/12032 [3:29:09<8:24:41,  3.70s/it]2025-08-22:22:03:51,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3842/12032 [3:29:11<7:43:41,  3.40s/it]2025-08-22:22:03:53,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3843/12032 [3:29:15<8:01:12,  3.53s/it]2025-08-22:22:03:57,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3844/12032 [3:29:18<7:14:30,  3.18s/it]2025-08-22:22:03:59,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3845/12032 [3:29:21<7:37:45,  3.35s/it]2025-08-22:22:04:03,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3846/12032 [3:29:25<7:28:19,  3.29s/it]2025-08-22:22:04:06,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3847/12032 [3:29:27<7:04:57,  3.12s/it]2025-08-22:22:04:09,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3848/12032 [3:29:28<5:42:26,  2.51s/it]2025-08-22:22:04:10,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3849/12032 [3:29:29<4:37:55,  2.04s/it]2025-08-22:22:04:11,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3850/12032 [3:29:33<5:50:13,  2.57s/it]2025-08-22:22:04:15,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3851/12032 [3:29:35<5:12:13,  2.29s/it]2025-08-22:22:04:17,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3852/12032 [3:29:36<4:41:27,  2.06s/it]2025-08-22:22:04:18,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3853/12032 [3:29:40<5:52:40,  2.59s/it]2025-08-22:22:04:22,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3854/12032 [3:29:44<6:40:59,  2.94s/it]2025-08-22:22:04:26,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3855/12032 [3:29:48<7:14:47,  3.19s/it]2025-08-22:22:04:29,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3856/12032 [3:29:51<7:03:43,  3.11s/it]2025-08-22:22:04:32,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3857/12032 [3:29:54<7:32:10,  3.32s/it]2025-08-22:22:04:36,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3858/12032 [3:29:58<7:53:00,  3.47s/it]2025-08-22:22:04:40,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3859/12032 [3:30:02<7:48:53,  3.44s/it]2025-08-22:22:04:43,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3860/12032 [3:30:05<8:02:16,  3.54s/it]2025-08-22:22:04:47,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3861/12032 [3:30:07<6:49:27,  3.01s/it]2025-08-22:22:04:49,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3862/12032 [3:30:11<7:22:32,  3.25s/it]2025-08-22:22:04:53,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3863/12032 [3:30:14<6:59:11,  3.08s/it]2025-08-22:22:04:55,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3864/12032 [3:30:16<6:16:27,  2.77s/it]2025-08-22:22:04:57,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3865/12032 [3:30:18<6:10:08,  2.72s/it]2025-08-22:22:05:00,566 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3866/12032 [3:30:20<5:45:38,  2.54s/it]2025-08-22:22:05:02,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3867/12032 [3:30:24<6:34:53,  2.90s/it]2025-08-22:22:05:06,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3868/12032 [3:30:28<7:11:16,  3.17s/it]2025-08-22:22:05:10,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3869/12032 [3:30:32<7:37:28,  3.36s/it]2025-08-22:22:05:14,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3870/12032 [3:30:33<6:33:28,  2.89s/it]2025-08-22:22:05:15,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3871/12032 [3:30:37<7:08:56,  3.15s/it]2025-08-22:22:05:19,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3872/12032 [3:30:40<6:51:40,  3.03s/it]2025-08-22:22:05:22,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3873/12032 [3:30:42<6:19:11,  2.79s/it]2025-08-22:22:05:24,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3874/12032 [3:30:46<6:58:10,  3.08s/it]2025-08-22:22:05:28,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3875/12032 [3:30:50<7:27:47,  3.29s/it]2025-08-22:22:05:32,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3876/12032 [3:30:54<7:46:51,  3.43s/it]2025-08-22:22:05:35,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3877/12032 [3:30:54<5:56:25,  2.62s/it]2025-08-22:22:05:36,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3878/12032 [3:30:56<5:03:19,  2.23s/it]2025-08-22:22:05:37,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3879/12032 [3:30:58<5:04:08,  2.24s/it]2025-08-22:22:05:40,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3880/12032 [3:30:59<4:29:17,  1.98s/it]2025-08-22:22:05:41,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3881/12032 [3:31:00<3:54:54,  1.73s/it]2025-08-22:22:05:42,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3882/12032 [3:31:03<4:21:23,  1.92s/it]2025-08-22:22:05:45,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3883/12032 [3:31:04<3:59:40,  1.76s/it]2025-08-22:22:05:46,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3884/12032 [3:31:06<4:18:15,  1.90s/it]2025-08-22:22:05:48,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3885/12032 [3:31:10<5:34:23,  2.46s/it]2025-08-22:22:05:52,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3886/12032 [3:31:13<5:46:49,  2.55s/it]2025-08-22:22:05:55,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3887/12032 [3:31:15<5:27:24,  2.41s/it]2025-08-22:22:05:57,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3888/12032 [3:31:17<5:29:09,  2.43s/it]2025-08-22:22:05:59,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3889/12032 [3:31:21<6:28:05,  2.86s/it]2025-08-22:22:06:03,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3890/12032 [3:31:25<7:05:47,  3.14s/it]2025-08-22:22:06:07,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3891/12032 [3:31:28<6:52:37,  3.04s/it]2025-08-22:22:06:10,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3892/12032 [3:31:30<6:19:25,  2.80s/it]2025-08-22:22:06:12,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3893/12032 [3:31:33<6:19:46,  2.80s/it]2025-08-22:22:06:15,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3894/12032 [3:31:34<5:11:28,  2.30s/it]2025-08-22:22:06:16,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3895/12032 [3:31:36<4:52:19,  2.16s/it]2025-08-22:22:06:18,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3896/12032 [3:31:37<4:01:45,  1.78s/it]2025-08-22:22:06:19,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3897/12032 [3:31:38<3:45:18,  1.66s/it]2025-08-22:22:06:20,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3898/12032 [3:31:42<5:13:00,  2.31s/it]2025-08-22:22:06:24,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3899/12032 [3:31:46<6:14:33,  2.76s/it]2025-08-22:22:06:28,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3900/12032 [3:31:50<6:57:14,  3.08s/it]2025-08-22:22:06:31,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3901/12032 [3:31:53<7:25:33,  3.29s/it]2025-08-22:22:06:35,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3902/12032 [3:31:57<7:45:30,  3.44s/it]2025-08-22:22:06:39,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3903/12032 [3:32:01<7:59:54,  3.54s/it]2025-08-22:22:06:43,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3904/12032 [3:32:05<8:09:05,  3.61s/it]2025-08-22:22:06:47,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3905/12032 [3:32:09<8:15:42,  3.66s/it]2025-08-22:22:06:50,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3906/12032 [3:32:12<8:20:34,  3.70s/it]2025-08-22:22:06:54,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3907/12032 [3:32:14<6:51:59,  3.04s/it]2025-08-22:22:06:56,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3908/12032 [3:32:18<7:21:46,  3.26s/it]2025-08-22:22:06:59,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3909/12032 [3:32:21<7:42:40,  3.42s/it]2025-08-22:22:07:03,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  32%|███▏      | 3910/12032 [3:32:25<7:56:12,  3.52s/it]2025-08-22:22:07:07,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3911/12032 [3:32:29<8:07:41,  3.60s/it]2025-08-22:22:07:11,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3912/12032 [3:32:33<8:24:24,  3.73s/it]2025-08-22:22:07:15,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3913/12032 [3:32:37<8:25:48,  3.74s/it]2025-08-22:22:07:19,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3914/12032 [3:32:40<8:27:28,  3.75s/it]2025-08-22:22:07:22,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3915/12032 [3:32:44<8:29:02,  3.76s/it]2025-08-22:22:07:26,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3916/12032 [3:32:48<8:31:03,  3.78s/it]2025-08-22:22:07:30,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3917/12032 [3:32:50<7:25:01,  3.29s/it]2025-08-22:22:07:32,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3918/12032 [3:32:54<7:45:05,  3.44s/it]2025-08-22:22:07:36,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3919/12032 [3:32:57<7:27:47,  3.31s/it]2025-08-22:22:07:39,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3920/12032 [3:33:01<7:46:49,  3.45s/it]2025-08-22:22:07:43,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3921/12032 [3:33:05<8:00:42,  3.56s/it]2025-08-22:22:07:46,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3922/12032 [3:33:08<8:10:03,  3.63s/it]2025-08-22:22:07:50,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3923/12032 [3:33:12<8:15:54,  3.67s/it]2025-08-22:22:07:54,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3924/12032 [3:33:16<8:22:23,  3.72s/it]2025-08-22:22:07:58,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3925/12032 [3:33:20<8:27:18,  3.75s/it]2025-08-22:22:08:02,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3926/12032 [3:33:24<8:27:53,  3.76s/it]2025-08-22:22:08:05,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3927/12032 [3:33:27<7:59:27,  3.55s/it]2025-08-22:22:08:09,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3928/12032 [3:33:30<8:08:04,  3.61s/it]2025-08-22:22:08:12,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3929/12032 [3:33:34<8:14:28,  3.66s/it]2025-08-22:22:08:16,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3930/12032 [3:33:38<8:18:35,  3.69s/it]2025-08-22:22:08:20,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3931/12032 [3:33:42<8:22:47,  3.72s/it]2025-08-22:22:08:24,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3932/12032 [3:33:46<8:28:16,  3.76s/it]2025-08-22:22:08:27,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3933/12032 [3:33:50<8:32:44,  3.80s/it]2025-08-22:22:08:31,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3934/12032 [3:33:53<8:32:15,  3.80s/it]2025-08-22:22:08:35,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3935/12032 [3:33:57<8:33:03,  3.80s/it]2025-08-22:22:08:39,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3936/12032 [3:34:00<7:37:04,  3.39s/it]2025-08-22:22:08:41,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3937/12032 [3:34:03<7:53:25,  3.51s/it]2025-08-22:22:08:45,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3938/12032 [3:34:07<8:06:09,  3.60s/it]2025-08-22:22:08:49,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3939/12032 [3:34:11<8:14:03,  3.66s/it]2025-08-22:22:08:53,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3940/12032 [3:34:15<8:20:03,  3.71s/it]2025-08-22:22:08:57,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3941/12032 [3:34:19<8:23:36,  3.73s/it]2025-08-22:22:09:00,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3942/12032 [3:34:22<8:26:54,  3.76s/it]2025-08-22:22:09:04,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3943/12032 [3:34:26<8:28:29,  3.77s/it]2025-08-22:22:09:08,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3944/12032 [3:34:30<8:29:18,  3.78s/it]2025-08-22:22:09:12,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3945/12032 [3:34:34<8:30:28,  3.79s/it]2025-08-22:22:09:16,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3946/12032 [3:34:38<8:31:01,  3.79s/it]2025-08-22:22:09:19,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3947/12032 [3:34:41<8:25:12,  3.75s/it]2025-08-22:22:09:23,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3948/12032 [3:34:45<8:27:04,  3.76s/it]2025-08-22:22:09:27,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3949/12032 [3:34:49<8:29:17,  3.78s/it]2025-08-22:22:09:31,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3950/12032 [3:34:53<8:29:57,  3.79s/it]2025-08-22:22:09:35,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3951/12032 [3:34:56<8:30:21,  3.79s/it]2025-08-22:22:09:38,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3952/12032 [3:35:00<8:30:00,  3.79s/it]2025-08-22:22:09:42,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3953/12032 [3:35:04<8:29:42,  3.79s/it]2025-08-22:22:09:46,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3954/12032 [3:35:08<8:29:38,  3.79s/it]2025-08-22:22:09:50,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3955/12032 [3:35:12<8:29:03,  3.78s/it]2025-08-22:22:09:53,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3956/12032 [3:35:15<8:29:18,  3.78s/it]2025-08-22:22:09:57,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3957/12032 [3:35:19<8:31:09,  3.80s/it]2025-08-22:22:10:01,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3958/12032 [3:35:23<8:29:33,  3.79s/it]2025-08-22:22:10:05,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3959/12032 [3:35:27<8:31:25,  3.80s/it]2025-08-22:22:10:09,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3960/12032 [3:35:31<8:31:17,  3.80s/it]2025-08-22:22:10:12,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3961/12032 [3:35:34<8:30:20,  3.79s/it]2025-08-22:22:10:16,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3962/12032 [3:35:36<7:07:23,  3.18s/it]2025-08-22:22:10:18,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3963/12032 [3:35:40<7:32:53,  3.37s/it]2025-08-22:22:10:22,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3964/12032 [3:35:44<7:50:18,  3.50s/it]2025-08-22:22:10:26,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3965/12032 [3:35:45<6:05:08,  2.72s/it]2025-08-22:22:10:26,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3966/12032 [3:35:46<4:53:04,  2.18s/it]2025-08-22:22:10:27,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3967/12032 [3:35:47<4:13:20,  1.88s/it]2025-08-22:22:10:29,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3968/12032 [3:35:50<4:48:58,  2.15s/it]2025-08-22:22:10:31,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3969/12032 [3:35:50<3:49:53,  1.71s/it]2025-08-22:22:10:32,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3970/12032 [3:35:54<5:13:49,  2.34s/it]2025-08-22:22:10:36,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3971/12032 [3:35:58<6:12:37,  2.77s/it]2025-08-22:22:10:40,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3972/12032 [3:36:02<6:53:37,  3.08s/it]2025-08-22:22:10:43,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3973/12032 [3:36:05<7:20:54,  3.28s/it]2025-08-22:22:10:47,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3974/12032 [3:36:09<7:40:52,  3.43s/it]2025-08-22:22:10:51,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3975/12032 [3:36:13<7:57:03,  3.55s/it]2025-08-22:22:10:55,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3976/12032 [3:36:17<8:10:04,  3.65s/it]2025-08-22:22:10:59,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3977/12032 [3:36:21<8:16:48,  3.70s/it]2025-08-22:22:11:02,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3978/12032 [3:36:24<8:20:10,  3.73s/it]2025-08-22:22:11:06,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3979/12032 [3:36:27<7:27:13,  3.33s/it]2025-08-22:22:11:09,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3980/12032 [3:36:31<7:47:25,  3.48s/it]2025-08-22:22:11:13,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3981/12032 [3:36:34<8:00:08,  3.58s/it]2025-08-22:22:11:16,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3982/12032 [3:36:38<8:10:59,  3.66s/it]2025-08-22:22:11:20,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3983/12032 [3:36:41<7:11:43,  3.22s/it]2025-08-22:22:11:22,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3984/12032 [3:36:44<7:35:53,  3.40s/it]2025-08-22:22:11:26,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3985/12032 [3:36:48<7:51:36,  3.52s/it]2025-08-22:22:11:30,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3986/12032 [3:36:52<8:02:37,  3.60s/it]2025-08-22:22:11:34,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3987/12032 [3:36:56<8:11:38,  3.67s/it]2025-08-22:22:11:38,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3988/12032 [3:37:00<8:17:39,  3.71s/it]2025-08-22:22:11:41,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3989/12032 [3:37:03<8:21:30,  3.74s/it]2025-08-22:22:11:45,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3990/12032 [3:37:07<8:21:58,  3.75s/it]2025-08-22:22:11:49,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3991/12032 [3:37:10<7:38:59,  3.42s/it]2025-08-22:22:11:52,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3992/12032 [3:37:14<7:53:07,  3.53s/it]2025-08-22:22:11:55,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3993/12032 [3:37:17<8:04:31,  3.62s/it]2025-08-22:22:11:59,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3994/12032 [3:37:21<8:10:38,  3.66s/it]2025-08-22:22:12:03,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3995/12032 [3:37:25<8:14:39,  3.69s/it]2025-08-22:22:12:07,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3996/12032 [3:37:29<8:18:18,  3.72s/it]2025-08-22:22:12:11,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3997/12032 [3:37:33<8:22:15,  3.75s/it]2025-08-22:22:12:14,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3998/12032 [3:37:36<8:26:20,  3.78s/it]2025-08-22:22:12:18,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 3999/12032 [3:37:40<8:25:57,  3.78s/it]2025-08-22:22:12:22,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4000/12032 [3:37:44<8:25:21,  3.78s/it]2025-08-22:22:12:26,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4001/12032 [3:37:48<8:24:48,  3.77s/it]2025-08-22:22:12:30,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4002/12032 [3:37:52<8:26:22,  3.78s/it]2025-08-22:22:12:33,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4003/12032 [3:37:55<8:29:01,  3.80s/it]2025-08-22:22:12:37,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4004/12032 [3:37:59<8:27:11,  3.79s/it]2025-08-22:22:12:41,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4005/12032 [3:38:03<8:27:09,  3.79s/it]2025-08-22:22:12:45,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4006/12032 [3:38:07<8:27:08,  3.79s/it]2025-08-22:22:12:49,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4007/12032 [3:38:10<8:26:44,  3.79s/it]2025-08-22:22:12:52,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4008/12032 [3:38:14<8:25:40,  3.78s/it]2025-08-22:22:12:56,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4009/12032 [3:38:18<8:28:38,  3.80s/it]2025-08-22:22:13:00,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4010/12032 [3:38:22<8:28:29,  3.80s/it]2025-08-22:22:13:04,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4011/12032 [3:38:26<8:25:52,  3.78s/it]2025-08-22:22:13:07,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4012/12032 [3:38:29<8:24:25,  3.77s/it]2025-08-22:22:13:11,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4013/12032 [3:38:33<8:24:29,  3.77s/it]2025-08-22:22:13:15,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4014/12032 [3:38:37<8:26:27,  3.79s/it]2025-08-22:22:13:19,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4015/12032 [3:38:41<8:26:54,  3.79s/it]2025-08-22:22:13:23,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4016/12032 [3:38:45<8:25:32,  3.78s/it]2025-08-22:22:13:26,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4017/12032 [3:38:48<8:25:06,  3.78s/it]2025-08-22:22:13:30,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4018/12032 [3:38:52<8:23:58,  3.77s/it]2025-08-22:22:13:34,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4019/12032 [3:38:56<8:24:03,  3.77s/it]2025-08-22:22:13:38,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4020/12032 [3:38:59<7:56:49,  3.57s/it]2025-08-22:22:13:41,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4021/12032 [3:39:03<8:06:56,  3.65s/it]2025-08-22:22:13:45,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4022/12032 [3:39:07<8:13:18,  3.70s/it]2025-08-22:22:13:48,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4023/12032 [3:39:10<8:19:05,  3.74s/it]2025-08-22:22:13:52,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4024/12032 [3:39:14<8:22:41,  3.77s/it]2025-08-22:22:13:56,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4025/12032 [3:39:18<8:26:21,  3.79s/it]2025-08-22:22:14:00,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4026/12032 [3:39:22<8:32:55,  3.84s/it]2025-08-22:22:14:04,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4027/12032 [3:39:25<8:08:23,  3.66s/it]2025-08-22:22:14:07,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4028/12032 [3:39:29<8:16:31,  3.72s/it]2025-08-22:22:14:11,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4029/12032 [3:39:33<8:20:54,  3.76s/it]2025-08-22:22:14:15,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  33%|███▎      | 4030/12032 [3:39:37<8:24:24,  3.78s/it]2025-08-22:22:14:19,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4031/12032 [3:39:41<8:31:11,  3.83s/it]2025-08-22:22:14:23,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4032/12032 [3:39:45<8:33:36,  3.85s/it]2025-08-22:22:14:27,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4033/12032 [3:39:49<8:34:21,  3.86s/it]2025-08-22:22:14:30,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4034/12032 [3:39:52<8:33:51,  3.85s/it]2025-08-22:22:14:34,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4035/12032 [3:39:56<8:33:25,  3.85s/it]2025-08-22:22:14:38,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4036/12032 [3:40:00<8:31:33,  3.84s/it]2025-08-22:22:14:42,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4037/12032 [3:40:02<7:14:05,  3.26s/it]2025-08-22:22:14:44,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4038/12032 [3:40:06<7:34:51,  3.41s/it]2025-08-22:22:14:48,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4039/12032 [3:40:10<7:50:32,  3.53s/it]2025-08-22:22:14:51,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4040/12032 [3:40:13<8:01:42,  3.62s/it]2025-08-22:22:14:55,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4041/12032 [3:40:17<7:46:34,  3.50s/it]2025-08-22:22:14:58,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4042/12032 [3:40:17<6:00:05,  2.70s/it]2025-08-22:22:14:59,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4043/12032 [3:40:21<6:47:20,  3.06s/it]2025-08-22:22:15:03,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4044/12032 [3:40:25<7:18:04,  3.29s/it]2025-08-22:22:15:07,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4045/12032 [3:40:29<7:37:27,  3.44s/it]2025-08-22:22:15:11,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4046/12032 [3:40:33<7:52:24,  3.55s/it]2025-08-22:22:15:15,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4047/12032 [3:40:37<8:04:08,  3.64s/it]2025-08-22:22:15:18,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4048/12032 [3:40:40<8:11:40,  3.69s/it]2025-08-22:22:15:22,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4049/12032 [3:40:44<8:16:20,  3.73s/it]2025-08-22:22:15:26,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4050/12032 [3:40:48<8:18:35,  3.75s/it]2025-08-22:22:15:30,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4051/12032 [3:40:52<8:21:36,  3.77s/it]2025-08-22:22:15:34,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4052/12032 [3:40:56<8:22:50,  3.78s/it]2025-08-22:22:15:38,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4053/12032 [3:41:00<8:25:01,  3.80s/it]2025-08-22:22:15:41,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4054/12032 [3:41:03<8:23:49,  3.79s/it]2025-08-22:22:15:45,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4055/12032 [3:41:07<8:23:13,  3.79s/it]2025-08-22:22:15:49,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4056/12032 [3:41:11<8:26:25,  3.81s/it]2025-08-22:22:15:53,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4057/12032 [3:41:15<8:25:38,  3.80s/it]2025-08-22:22:15:57,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4058/12032 [3:41:18<8:24:33,  3.80s/it]2025-08-22:22:16:00,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4059/12032 [3:41:22<8:23:08,  3.79s/it]2025-08-22:22:16:04,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▎      | 4060/12032 [3:41:26<8:25:38,  3.81s/it]2025-08-22:22:16:08,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4061/12032 [3:41:30<8:26:16,  3.81s/it]2025-08-22:22:16:12,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4062/12032 [3:41:34<8:25:00,  3.80s/it]2025-08-22:22:16:16,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4063/12032 [3:41:38<8:24:22,  3.80s/it]2025-08-22:22:16:19,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4064/12032 [3:41:41<8:23:42,  3.79s/it]2025-08-22:22:16:23,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4065/12032 [3:41:45<8:23:26,  3.79s/it]2025-08-22:22:16:27,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4066/12032 [3:41:49<8:23:06,  3.79s/it]2025-08-22:22:16:31,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4067/12032 [3:41:53<8:23:52,  3.80s/it]2025-08-22:22:16:35,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4068/12032 [3:41:56<8:23:43,  3.80s/it]2025-08-22:22:16:38,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4069/12032 [3:42:00<8:25:47,  3.81s/it]2025-08-22:22:16:42,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4070/12032 [3:42:04<8:26:23,  3.82s/it]2025-08-22:22:16:46,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4071/12032 [3:42:08<8:25:18,  3.81s/it]2025-08-22:22:16:50,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4072/12032 [3:42:12<8:26:19,  3.82s/it]2025-08-22:22:16:54,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4073/12032 [3:42:16<8:25:54,  3.81s/it]2025-08-22:22:16:57,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4074/12032 [3:42:19<8:25:11,  3.81s/it]2025-08-22:22:17:01,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4075/12032 [3:42:23<8:00:38,  3.62s/it]2025-08-22:22:17:04,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4076/12032 [3:42:26<7:43:23,  3.49s/it]2025-08-22:22:17:08,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4077/12032 [3:42:30<7:54:02,  3.58s/it]2025-08-22:22:17:11,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4078/12032 [3:42:33<7:35:58,  3.44s/it]2025-08-22:22:17:14,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4079/12032 [3:42:36<7:48:34,  3.54s/it]2025-08-22:22:17:18,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4080/12032 [3:42:40<8:00:30,  3.63s/it]2025-08-22:22:17:22,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4081/12032 [3:42:44<7:55:20,  3.59s/it]2025-08-22:22:17:26,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4082/12032 [3:42:48<8:02:50,  3.64s/it]2025-08-22:22:17:29,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4083/12032 [3:42:51<8:07:45,  3.68s/it]2025-08-22:22:17:33,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4084/12032 [3:42:55<8:11:56,  3.71s/it]2025-08-22:22:17:37,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4085/12032 [3:42:59<8:16:37,  3.75s/it]2025-08-22:22:17:41,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4086/12032 [3:43:00<6:46:40,  3.07s/it]2025-08-22:22:17:42,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4087/12032 [3:43:04<7:15:36,  3.29s/it]2025-08-22:22:17:46,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4088/12032 [3:43:08<7:35:41,  3.44s/it]2025-08-22:22:17:50,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4089/12032 [3:43:12<7:52:25,  3.57s/it]2025-08-22:22:17:54,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4090/12032 [3:43:16<8:01:59,  3.64s/it]2025-08-22:22:17:58,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4091/12032 [3:43:19<8:07:52,  3.69s/it]2025-08-22:22:18:01,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4092/12032 [3:43:23<8:12:54,  3.72s/it]2025-08-22:22:18:05,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4093/12032 [3:43:27<8:14:11,  3.73s/it]2025-08-22:22:18:09,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4094/12032 [3:43:31<8:15:27,  3.74s/it]2025-08-22:22:18:13,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4095/12032 [3:43:35<8:19:19,  3.77s/it]2025-08-22:22:18:16,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4096/12032 [3:43:38<8:18:52,  3.77s/it]2025-08-22:22:18:20,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4097/12032 [3:43:42<8:20:38,  3.79s/it]2025-08-22:22:18:24,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4098/12032 [3:43:46<8:21:27,  3.79s/it]2025-08-22:22:18:28,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4099/12032 [3:43:50<8:22:28,  3.80s/it]2025-08-22:22:18:32,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4100/12032 [3:43:54<8:22:59,  3.80s/it]2025-08-22:22:18:36,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4101/12032 [3:43:57<8:21:56,  3.80s/it]2025-08-22:22:18:39,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4102/12032 [3:44:01<8:22:24,  3.80s/it]2025-08-22:22:18:43,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4103/12032 [3:44:05<8:21:44,  3.80s/it]2025-08-22:22:18:47,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4104/12032 [3:44:09<8:22:00,  3.80s/it]2025-08-22:22:18:51,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4105/12032 [3:44:13<8:23:12,  3.81s/it]2025-08-22:22:18:55,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4106/12032 [3:44:16<8:22:32,  3.80s/it]2025-08-22:22:18:58,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4107/12032 [3:44:20<8:23:44,  3.81s/it]2025-08-22:22:19:02,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4108/12032 [3:44:24<8:23:02,  3.81s/it]2025-08-22:22:19:06,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4109/12032 [3:44:25<6:24:38,  2.91s/it]2025-08-22:22:19:07,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4110/12032 [3:44:26<4:59:56,  2.27s/it]2025-08-22:22:19:08,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4111/12032 [3:44:26<3:57:50,  1.80s/it]2025-08-22:22:19:08,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4112/12032 [3:44:30<5:16:34,  2.40s/it]2025-08-22:22:19:12,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4113/12032 [3:44:34<6:11:34,  2.82s/it]2025-08-22:22:19:16,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4114/12032 [3:44:38<6:49:41,  3.10s/it]2025-08-22:22:19:20,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4115/12032 [3:44:42<7:16:59,  3.31s/it]2025-08-22:22:19:23,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4116/12032 [3:44:45<7:36:03,  3.46s/it]2025-08-22:22:19:27,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4117/12032 [3:44:49<7:49:52,  3.56s/it]2025-08-22:22:19:31,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4118/12032 [3:44:53<7:59:25,  3.63s/it]2025-08-22:22:19:35,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4119/12032 [3:44:57<8:04:17,  3.67s/it]2025-08-22:22:19:39,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4120/12032 [3:45:01<8:09:39,  3.71s/it]2025-08-22:22:19:42,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4121/12032 [3:45:04<8:11:07,  3.72s/it]2025-08-22:22:19:46,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4122/12032 [3:45:08<8:14:17,  3.75s/it]2025-08-22:22:19:50,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4123/12032 [3:45:12<8:16:02,  3.76s/it]2025-08-22:22:19:54,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4124/12032 [3:45:16<8:16:28,  3.77s/it]2025-08-22:22:19:58,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4125/12032 [3:45:19<8:16:14,  3.77s/it]2025-08-22:22:20:01,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4126/12032 [3:45:23<8:20:22,  3.80s/it]2025-08-22:22:20:05,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4127/12032 [3:45:27<8:20:57,  3.80s/it]2025-08-22:22:20:09,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4128/12032 [3:45:31<8:20:31,  3.80s/it]2025-08-22:22:20:13,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4129/12032 [3:45:34<8:00:03,  3.64s/it]2025-08-22:22:20:16,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4130/12032 [3:45:38<8:05:27,  3.69s/it]2025-08-22:22:20:20,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4131/12032 [3:45:41<7:33:34,  3.44s/it]2025-08-22:22:20:23,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4132/12032 [3:45:45<7:46:25,  3.54s/it]2025-08-22:22:20:26,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4133/12032 [3:45:48<7:57:45,  3.63s/it]2025-08-22:22:20:30,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4134/12032 [3:45:52<8:07:52,  3.71s/it]2025-08-22:22:20:34,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4135/12032 [3:45:54<6:52:18,  3.13s/it]2025-08-22:22:20:36,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4136/12032 [3:45:58<7:17:55,  3.33s/it]2025-08-22:22:20:40,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4137/12032 [3:46:02<7:35:59,  3.47s/it]2025-08-22:22:20:44,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4138/12032 [3:46:03<6:24:57,  2.93s/it]2025-08-22:22:20:45,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4139/12032 [3:46:07<7:00:05,  3.19s/it]2025-08-22:22:20:49,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4140/12032 [3:46:11<7:24:54,  3.38s/it]2025-08-22:22:20:53,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4141/12032 [3:46:15<7:40:53,  3.50s/it]2025-08-22:22:20:57,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4142/12032 [3:46:19<7:51:33,  3.59s/it]2025-08-22:22:21:00,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4143/12032 [3:46:22<8:00:57,  3.66s/it]2025-08-22:22:21:04,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4144/12032 [3:46:26<8:08:11,  3.71s/it]2025-08-22:22:21:08,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4145/12032 [3:46:30<8:09:31,  3.72s/it]2025-08-22:22:21:12,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4146/12032 [3:46:34<8:10:26,  3.73s/it]2025-08-22:22:21:16,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4147/12032 [3:46:37<8:10:47,  3.73s/it]2025-08-22:22:21:19,828 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4148/12032 [3:46:41<8:14:00,  3.76s/it]2025-08-22:22:21:23,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4149/12032 [3:46:45<8:15:36,  3.77s/it]2025-08-22:22:21:27,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4150/12032 [3:46:49<8:15:39,  3.77s/it]2025-08-22:22:21:31,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  34%|███▍      | 4151/12032 [3:46:53<8:16:46,  3.78s/it]2025-08-22:22:21:35,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4152/12032 [3:46:56<8:18:00,  3.79s/it]2025-08-22:22:21:38,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4153/12032 [3:47:00<8:18:56,  3.80s/it]2025-08-22:22:21:42,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4154/12032 [3:47:04<8:22:10,  3.82s/it]2025-08-22:22:21:46,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4155/12032 [3:47:08<8:20:52,  3.82s/it]2025-08-22:22:21:50,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4156/12032 [3:47:09<6:45:14,  3.09s/it]2025-08-22:22:21:51,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4157/12032 [3:47:11<5:42:39,  2.61s/it]2025-08-22:22:21:53,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4158/12032 [3:47:12<4:58:24,  2.27s/it]2025-08-22:22:21:54,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4159/12032 [3:47:16<5:57:58,  2.73s/it]2025-08-22:22:21:58,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4160/12032 [3:47:20<6:41:14,  3.06s/it]2025-08-22:22:22:02,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4161/12032 [3:47:24<7:14:15,  3.31s/it]2025-08-22:22:22:06,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4162/12032 [3:47:28<7:36:22,  3.48s/it]2025-08-22:22:22:10,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4163/12032 [3:47:32<7:47:38,  3.57s/it]2025-08-22:22:22:13,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4164/12032 [3:47:35<7:55:18,  3.62s/it]2025-08-22:22:22:17,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4165/12032 [3:47:39<8:04:04,  3.69s/it]2025-08-22:22:22:21,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4166/12032 [3:47:43<8:08:53,  3.73s/it]2025-08-22:22:22:25,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4167/12032 [3:47:47<8:10:51,  3.74s/it]2025-08-22:22:22:29,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4168/12032 [3:47:50<7:37:00,  3.49s/it]2025-08-22:22:22:31,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4169/12032 [3:47:53<7:48:57,  3.58s/it]2025-08-22:22:22:35,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4170/12032 [3:47:57<8:00:56,  3.67s/it]2025-08-22:22:22:39,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4171/12032 [3:48:01<8:09:35,  3.74s/it]2025-08-22:22:22:43,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4172/12032 [3:48:05<8:11:54,  3.75s/it]2025-08-22:22:22:47,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4173/12032 [3:48:09<8:14:52,  3.78s/it]2025-08-22:22:22:51,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4174/12032 [3:48:13<8:15:53,  3.79s/it]2025-08-22:22:22:54,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4175/12032 [3:48:16<8:18:21,  3.81s/it]2025-08-22:22:22:58,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4176/12032 [3:48:18<6:47:15,  3.11s/it]2025-08-22:22:23:00,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4177/12032 [3:48:22<7:15:23,  3.33s/it]2025-08-22:22:23:04,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4178/12032 [3:48:26<7:33:07,  3.46s/it]2025-08-22:22:23:07,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4179/12032 [3:48:29<7:46:07,  3.56s/it]2025-08-22:22:23:11,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4180/12032 [3:48:30<5:54:27,  2.71s/it]2025-08-22:22:23:12,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4181/12032 [3:48:32<5:42:41,  2.62s/it]2025-08-22:22:23:14,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4182/12032 [3:48:34<4:48:56,  2.21s/it]2025-08-22:22:23:16,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4183/12032 [3:48:35<4:11:01,  1.92s/it]2025-08-22:22:23:17,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4184/12032 [3:48:36<3:30:37,  1.61s/it]2025-08-22:22:23:18,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4185/12032 [3:48:40<5:00:58,  2.30s/it]2025-08-22:22:23:22,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4186/12032 [3:48:41<4:27:10,  2.04s/it]2025-08-22:22:23:23,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4187/12032 [3:48:42<3:44:18,  1.72s/it]2025-08-22:22:23:24,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4188/12032 [3:48:46<5:08:11,  2.36s/it]2025-08-22:22:23:28,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4189/12032 [3:48:50<6:04:32,  2.79s/it]2025-08-22:22:23:32,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4190/12032 [3:48:54<6:45:05,  3.10s/it]2025-08-22:22:23:35,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4191/12032 [3:48:57<7:11:40,  3.30s/it]2025-08-22:22:23:39,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4192/12032 [3:49:01<7:34:41,  3.48s/it]2025-08-22:22:23:43,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4193/12032 [3:49:05<7:50:28,  3.60s/it]2025-08-22:22:23:47,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4194/12032 [3:49:09<7:58:08,  3.66s/it]2025-08-22:22:23:51,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4195/12032 [3:49:13<8:03:50,  3.70s/it]2025-08-22:22:23:55,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4196/12032 [3:49:17<8:07:15,  3.73s/it]2025-08-22:22:23:58,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4197/12032 [3:49:20<8:09:41,  3.75s/it]2025-08-22:22:24:02,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4198/12032 [3:49:22<6:32:09,  3.00s/it]2025-08-22:22:24:04,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4199/12032 [3:49:25<7:02:34,  3.24s/it]2025-08-22:22:24:07,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4200/12032 [3:49:29<7:22:56,  3.39s/it]2025-08-22:22:24:11,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4201/12032 [3:49:33<7:38:34,  3.51s/it]2025-08-22:22:24:15,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4202/12032 [3:49:37<7:50:45,  3.61s/it]2025-08-22:22:24:19,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4203/12032 [3:49:38<6:26:31,  2.96s/it]2025-08-22:22:24:20,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4204/12032 [3:49:42<7:00:13,  3.22s/it]2025-08-22:22:24:24,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4205/12032 [3:49:46<7:24:13,  3.41s/it]2025-08-22:22:24:28,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4206/12032 [3:49:50<7:40:28,  3.53s/it]2025-08-22:22:24:32,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4207/12032 [3:49:54<7:51:34,  3.62s/it]2025-08-22:22:24:35,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4208/12032 [3:49:57<7:59:24,  3.68s/it]2025-08-22:22:24:39,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4209/12032 [3:50:01<8:05:32,  3.72s/it]2025-08-22:22:24:43,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4210/12032 [3:50:05<8:09:03,  3.75s/it]2025-08-22:22:24:47,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▍      | 4211/12032 [3:50:08<7:46:49,  3.58s/it]2025-08-22:22:24:50,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4212/12032 [3:50:12<7:54:55,  3.64s/it]2025-08-22:22:24:54,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4213/12032 [3:50:16<8:01:23,  3.69s/it]2025-08-22:22:24:58,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4214/12032 [3:50:20<8:01:58,  3.70s/it]2025-08-22:22:25:01,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4215/12032 [3:50:23<8:07:13,  3.74s/it]2025-08-22:22:25:05,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4216/12032 [3:50:27<8:09:50,  3.76s/it]2025-08-22:22:25:09,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4217/12032 [3:50:31<8:10:38,  3.77s/it]2025-08-22:22:25:13,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4218/12032 [3:50:35<8:12:04,  3.78s/it]2025-08-22:22:25:17,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4219/12032 [3:50:39<8:13:40,  3.79s/it]2025-08-22:22:25:20,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4220/12032 [3:50:42<8:14:29,  3.80s/it]2025-08-22:22:25:24,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4221/12032 [3:50:46<8:13:03,  3.79s/it]2025-08-22:22:25:28,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4222/12032 [3:50:50<8:13:19,  3.79s/it]2025-08-22:22:25:32,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4223/12032 [3:50:54<8:14:34,  3.80s/it]2025-08-22:22:25:36,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4224/12032 [3:50:57<8:02:23,  3.71s/it]2025-08-22:22:25:39,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4225/12032 [3:51:01<8:06:35,  3.74s/it]2025-08-22:22:25:43,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4226/12032 [3:51:05<8:09:51,  3.77s/it]2025-08-22:22:25:47,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4227/12032 [3:51:09<8:12:02,  3.78s/it]2025-08-22:22:25:51,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4228/12032 [3:51:13<8:12:32,  3.79s/it]2025-08-22:22:25:54,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4229/12032 [3:51:16<8:11:25,  3.78s/it]2025-08-22:22:25:58,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4230/12032 [3:51:20<8:10:54,  3.78s/it]2025-08-22:22:26:02,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4231/12032 [3:51:24<8:09:36,  3.77s/it]2025-08-22:22:26:06,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4232/12032 [3:51:28<8:08:58,  3.76s/it]2025-08-22:22:26:09,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4233/12032 [3:51:28<6:17:41,  2.91s/it]2025-08-22:22:26:10,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4234/12032 [3:51:31<5:51:19,  2.70s/it]2025-08-22:22:26:13,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4235/12032 [3:51:34<6:33:13,  3.03s/it]2025-08-22:22:26:16,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4236/12032 [3:51:38<7:02:56,  3.26s/it]2025-08-22:22:26:20,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4237/12032 [3:51:42<7:24:50,  3.42s/it]2025-08-22:22:26:24,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4238/12032 [3:51:46<7:38:18,  3.53s/it]2025-08-22:22:26:28,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4239/12032 [3:51:49<7:15:52,  3.36s/it]2025-08-22:22:26:31,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4240/12032 [3:51:53<7:34:58,  3.50s/it]2025-08-22:22:26:35,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4241/12032 [3:51:56<7:45:44,  3.59s/it]2025-08-22:22:26:38,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4242/12032 [3:52:00<7:52:39,  3.64s/it]2025-08-22:22:26:42,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4243/12032 [3:52:04<7:58:32,  3.69s/it]2025-08-22:22:26:46,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4244/12032 [3:52:08<8:02:06,  3.71s/it]2025-08-22:22:26:50,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4245/12032 [3:52:12<8:04:54,  3.74s/it]2025-08-22:22:26:53,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4246/12032 [3:52:15<8:05:59,  3.75s/it]2025-08-22:22:26:57,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4247/12032 [3:52:19<8:13:55,  3.81s/it]2025-08-22:22:27:01,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4248/12032 [3:52:23<8:12:40,  3.80s/it]2025-08-22:22:27:05,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4249/12032 [3:52:27<8:13:17,  3.80s/it]2025-08-22:22:27:09,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4250/12032 [3:52:30<7:59:40,  3.70s/it]2025-08-22:22:27:12,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4251/12032 [3:52:34<8:03:52,  3.73s/it]2025-08-22:22:27:16,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4252/12032 [3:52:38<8:06:24,  3.75s/it]2025-08-22:22:27:20,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4253/12032 [3:52:39<6:29:52,  3.01s/it]2025-08-22:22:27:21,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4254/12032 [3:52:43<6:59:06,  3.23s/it]2025-08-22:22:27:25,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4255/12032 [3:52:47<7:20:19,  3.40s/it]2025-08-22:22:27:29,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4256/12032 [3:52:51<7:36:49,  3.52s/it]2025-08-22:22:27:32,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4257/12032 [3:52:54<7:46:23,  3.60s/it]2025-08-22:22:27:36,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4258/12032 [3:52:58<7:55:43,  3.67s/it]2025-08-22:22:27:40,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4259/12032 [3:53:02<8:00:27,  3.71s/it]2025-08-22:22:27:44,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4260/12032 [3:53:06<8:06:23,  3.75s/it]2025-08-22:22:27:48,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4261/12032 [3:53:10<8:07:53,  3.77s/it]2025-08-22:22:27:51,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4262/12032 [3:53:12<7:24:43,  3.43s/it]2025-08-22:22:27:54,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4263/12032 [3:53:13<5:50:54,  2.71s/it]2025-08-22:22:27:55,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4264/12032 [3:53:14<4:40:46,  2.17s/it]2025-08-22:22:27:56,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4265/12032 [3:53:16<4:28:39,  2.08s/it]2025-08-22:22:27:58,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4266/12032 [3:53:17<3:58:59,  1.85s/it]2025-08-22:22:27:59,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4267/12032 [3:53:21<5:14:53,  2.43s/it]2025-08-22:22:28:03,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4268/12032 [3:53:25<6:08:03,  2.84s/it]2025-08-22:22:28:07,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4269/12032 [3:53:28<5:58:57,  2.77s/it]2025-08-22:22:28:09,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4270/12032 [3:53:31<6:38:10,  3.08s/it]2025-08-22:22:28:13,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  35%|███▌      | 4271/12032 [3:53:35<7:04:37,  3.28s/it]2025-08-22:22:28:17,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4272/12032 [3:53:39<7:24:32,  3.44s/it]2025-08-22:22:28:21,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4273/12032 [3:53:43<7:37:51,  3.54s/it]2025-08-22:22:28:25,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4274/12032 [3:53:47<7:48:35,  3.62s/it]2025-08-22:22:28:28,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4275/12032 [3:53:50<7:56:26,  3.69s/it]2025-08-22:22:28:32,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4276/12032 [3:53:54<8:00:21,  3.72s/it]2025-08-22:22:28:36,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4277/12032 [3:53:58<8:03:39,  3.74s/it]2025-08-22:22:28:40,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4278/12032 [3:54:02<8:05:29,  3.76s/it]2025-08-22:22:28:44,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4279/12032 [3:54:06<8:06:50,  3.77s/it]2025-08-22:22:28:47,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4280/12032 [3:54:09<8:07:05,  3.77s/it]2025-08-22:22:28:51,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4281/12032 [3:54:13<8:08:34,  3.78s/it]2025-08-22:22:28:55,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4282/12032 [3:54:17<8:09:26,  3.79s/it]2025-08-22:22:28:59,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4283/12032 [3:54:21<8:11:56,  3.81s/it]2025-08-22:22:29:03,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4284/12032 [3:54:25<8:11:33,  3.81s/it]2025-08-22:22:29:06,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4285/12032 [3:54:28<8:10:02,  3.80s/it]2025-08-22:22:29:10,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4286/12032 [3:54:32<8:11:29,  3.81s/it]2025-08-22:22:29:14,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4287/12032 [3:54:36<8:09:29,  3.79s/it]2025-08-22:22:29:18,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4288/12032 [3:54:40<8:08:24,  3.78s/it]2025-08-22:22:29:22,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4289/12032 [3:54:44<8:10:25,  3.80s/it]2025-08-22:22:29:25,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4290/12032 [3:54:47<8:09:27,  3.79s/it]2025-08-22:22:29:29,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4291/12032 [3:54:51<8:08:22,  3.79s/it]2025-08-22:22:29:33,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4292/12032 [3:54:55<8:09:41,  3.80s/it]2025-08-22:22:29:37,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4293/12032 [3:54:59<8:10:10,  3.80s/it]2025-08-22:22:29:41,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4294/12032 [3:55:03<8:10:27,  3.80s/it]2025-08-22:22:29:44,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4295/12032 [3:55:06<8:08:41,  3.79s/it]2025-08-22:22:29:48,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4296/12032 [3:55:10<8:08:48,  3.79s/it]2025-08-22:22:29:52,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4297/12032 [3:55:14<8:08:30,  3.79s/it]2025-08-22:22:29:56,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4298/12032 [3:55:18<8:08:18,  3.79s/it]2025-08-22:22:30:00,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4299/12032 [3:55:21<7:56:20,  3.70s/it]2025-08-22:22:30:03,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4300/12032 [3:55:25<8:02:58,  3.75s/it]2025-08-22:22:30:07,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4301/12032 [3:55:29<8:03:26,  3.75s/it]2025-08-22:22:30:11,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4302/12032 [3:55:33<8:06:07,  3.77s/it]2025-08-22:22:30:14,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4303/12032 [3:55:36<8:06:26,  3.78s/it]2025-08-22:22:30:18,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4304/12032 [3:55:40<8:08:46,  3.79s/it]2025-08-22:22:30:22,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4305/12032 [3:55:44<8:07:10,  3.78s/it]2025-08-22:22:30:26,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4306/12032 [3:55:48<8:08:00,  3.79s/it]2025-08-22:22:30:30,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4307/12032 [3:55:52<8:08:52,  3.80s/it]2025-08-22:22:30:33,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4308/12032 [3:55:55<8:07:45,  3.79s/it]2025-08-22:22:30:37,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4309/12032 [3:55:59<8:09:02,  3.80s/it]2025-08-22:22:30:41,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4310/12032 [3:56:03<8:09:43,  3.81s/it]2025-08-22:22:30:45,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4311/12032 [3:56:07<8:07:56,  3.79s/it]2025-08-22:22:30:49,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4312/12032 [3:56:08<6:23:55,  2.98s/it]2025-08-22:22:30:50,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4313/12032 [3:56:11<6:40:39,  3.11s/it]2025-08-22:22:30:53,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4314/12032 [3:56:15<7:05:38,  3.31s/it]2025-08-22:22:30:57,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4315/12032 [3:56:19<7:24:00,  3.45s/it]2025-08-22:22:31:01,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4316/12032 [3:56:23<7:37:07,  3.55s/it]2025-08-22:22:31:04,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4317/12032 [3:56:27<7:50:57,  3.66s/it]2025-08-22:22:31:08,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4318/12032 [3:56:30<7:58:22,  3.72s/it]2025-08-22:22:31:12,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4319/12032 [3:56:34<8:03:13,  3.76s/it]2025-08-22:22:31:16,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4320/12032 [3:56:38<8:08:57,  3.80s/it]2025-08-22:22:31:20,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4321/12032 [3:56:42<8:14:37,  3.85s/it]2025-08-22:22:31:24,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4322/12032 [3:56:46<8:12:25,  3.83s/it]2025-08-22:22:31:28,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4323/12032 [3:56:50<8:11:28,  3.83s/it]2025-08-22:22:31:32,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4324/12032 [3:56:54<8:11:54,  3.83s/it]2025-08-22:22:31:35,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4325/12032 [3:56:57<8:10:35,  3.82s/it]2025-08-22:22:31:39,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4326/12032 [3:57:01<8:09:33,  3.81s/it]2025-08-22:22:31:43,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4327/12032 [3:57:05<8:07:00,  3.79s/it]2025-08-22:22:31:47,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4328/12032 [3:57:09<8:07:23,  3.80s/it]2025-08-22:22:31:51,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4329/12032 [3:57:13<8:11:57,  3.83s/it]2025-08-22:22:31:54,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4330/12032 [3:57:16<8:11:07,  3.83s/it]2025-08-22:22:31:58,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4331/12032 [3:57:20<8:09:34,  3.81s/it]2025-08-22:22:32:02,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4332/12032 [3:57:24<8:08:50,  3.81s/it]2025-08-22:22:32:06,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4333/12032 [3:57:28<8:09:44,  3.82s/it]2025-08-22:22:32:10,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4334/12032 [3:57:32<8:11:25,  3.83s/it]2025-08-22:22:32:14,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4335/12032 [3:57:34<7:19:41,  3.43s/it]2025-08-22:22:32:16,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4336/12032 [3:57:38<7:32:55,  3.53s/it]2025-08-22:22:32:20,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4337/12032 [3:57:42<7:42:08,  3.60s/it]2025-08-22:22:32:24,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4338/12032 [3:57:46<7:48:48,  3.66s/it]2025-08-22:22:32:27,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4339/12032 [3:57:49<7:53:24,  3.69s/it]2025-08-22:22:32:31,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4340/12032 [3:57:53<7:57:33,  3.73s/it]2025-08-22:22:32:35,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4341/12032 [3:57:57<7:59:43,  3.74s/it]2025-08-22:22:32:39,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4342/12032 [3:57:58<6:20:29,  2.97s/it]2025-08-22:22:32:40,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4343/12032 [3:57:59<5:01:46,  2.35s/it]2025-08-22:22:32:41,313 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4344/12032 [3:58:00<4:05:04,  1.91s/it]2025-08-22:22:32:42,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4345/12032 [3:58:01<3:36:25,  1.69s/it]2025-08-22:22:32:43,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4346/12032 [3:58:04<4:31:48,  2.12s/it]2025-08-22:22:32:46,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4347/12032 [3:58:05<3:51:51,  1.81s/it]2025-08-22:22:32:47,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4348/12032 [3:58:06<3:10:06,  1.48s/it]2025-08-22:22:32:48,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4349/12032 [3:58:09<4:18:49,  2.02s/it]2025-08-22:22:32:51,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4350/12032 [3:58:13<5:25:58,  2.55s/it]2025-08-22:22:32:55,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4351/12032 [3:58:16<5:36:27,  2.63s/it]2025-08-22:22:32:58,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4352/12032 [3:58:20<6:20:23,  2.97s/it]2025-08-22:22:33:01,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4353/12032 [3:58:23<6:52:18,  3.22s/it]2025-08-22:22:33:05,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4354/12032 [3:58:27<7:14:27,  3.40s/it]2025-08-22:22:33:09,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4355/12032 [3:58:31<7:30:23,  3.52s/it]2025-08-22:22:33:13,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4356/12032 [3:58:35<7:40:58,  3.60s/it]2025-08-22:22:33:17,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4357/12032 [3:58:39<7:47:51,  3.66s/it]2025-08-22:22:33:20,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4358/12032 [3:58:42<7:55:54,  3.72s/it]2025-08-22:22:33:24,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4359/12032 [3:58:45<7:05:02,  3.32s/it]2025-08-22:22:33:27,202 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4360/12032 [3:58:49<7:23:56,  3.47s/it]2025-08-22:22:33:31,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▌      | 4361/12032 [3:58:52<7:36:14,  3.57s/it]2025-08-22:22:33:34,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4362/12032 [3:58:56<7:45:00,  3.64s/it]2025-08-22:22:33:38,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4363/12032 [3:59:00<7:52:16,  3.69s/it]2025-08-22:22:33:42,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4364/12032 [3:59:04<7:56:31,  3.73s/it]2025-08-22:22:33:46,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4365/12032 [3:59:08<7:58:12,  3.74s/it]2025-08-22:22:33:50,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4366/12032 [3:59:11<8:00:36,  3.76s/it]2025-08-22:22:33:53,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4367/12032 [3:59:15<8:01:49,  3.77s/it]2025-08-22:22:33:57,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4368/12032 [3:59:17<6:59:31,  3.28s/it]2025-08-22:22:33:59,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4369/12032 [3:59:21<7:19:36,  3.44s/it]2025-08-22:22:34:03,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4370/12032 [3:59:25<7:37:11,  3.58s/it]2025-08-22:22:34:07,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4371/12032 [3:59:29<7:48:41,  3.67s/it]2025-08-22:22:34:11,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4372/12032 [3:59:33<7:52:47,  3.70s/it]2025-08-22:22:34:15,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4373/12032 [3:59:37<7:58:57,  3.75s/it]2025-08-22:22:34:19,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4374/12032 [3:59:41<8:06:54,  3.81s/it]2025-08-22:22:34:22,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4375/12032 [3:59:44<8:06:08,  3.81s/it]2025-08-22:22:34:26,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4376/12032 [3:59:48<8:06:24,  3.81s/it]2025-08-22:22:34:30,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4377/12032 [3:59:51<7:34:57,  3.57s/it]2025-08-22:22:34:33,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4378/12032 [3:59:55<7:46:03,  3.65s/it]2025-08-22:22:34:37,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4379/12032 [3:59:59<7:51:07,  3.69s/it]2025-08-22:22:34:41,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4380/12032 [4:00:03<7:54:21,  3.72s/it]2025-08-22:22:34:45,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4381/12032 [4:00:06<7:56:22,  3.74s/it]2025-08-22:22:34:48,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4382/12032 [4:00:10<7:57:27,  3.74s/it]2025-08-22:22:34:52,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4383/12032 [4:00:14<7:58:53,  3.76s/it]2025-08-22:22:34:56,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4384/12032 [4:00:18<8:04:51,  3.80s/it]2025-08-22:22:35:00,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4385/12032 [4:00:22<8:03:34,  3.79s/it]2025-08-22:22:35:04,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4386/12032 [4:00:24<7:19:53,  3.45s/it]2025-08-22:22:35:06,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4387/12032 [4:00:28<7:33:53,  3.56s/it]2025-08-22:22:35:10,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4388/12032 [4:00:32<7:46:08,  3.66s/it]2025-08-22:22:35:14,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4389/12032 [4:00:36<7:51:33,  3.70s/it]2025-08-22:22:35:18,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4390/12032 [4:00:40<7:56:32,  3.74s/it]2025-08-22:22:35:22,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  36%|███▋      | 4391/12032 [4:00:43<7:57:39,  3.75s/it]2025-08-22:22:35:25,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4392/12032 [4:00:47<8:02:44,  3.79s/it]2025-08-22:22:35:29,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4393/12032 [4:00:51<8:03:25,  3.80s/it]2025-08-22:22:35:33,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4394/12032 [4:00:55<8:05:32,  3.81s/it]2025-08-22:22:35:37,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4395/12032 [4:00:59<8:03:49,  3.80s/it]2025-08-22:22:35:41,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4396/12032 [4:01:03<8:02:24,  3.79s/it]2025-08-22:22:35:44,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4397/12032 [4:01:06<8:01:13,  3.78s/it]2025-08-22:22:35:48,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4398/12032 [4:01:10<8:00:49,  3.78s/it]2025-08-22:22:35:52,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4399/12032 [4:01:14<7:59:53,  3.77s/it]2025-08-22:22:35:56,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4400/12032 [4:01:18<8:00:23,  3.78s/it]2025-08-22:22:35:59,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4401/12032 [4:01:21<8:01:45,  3.79s/it]2025-08-22:22:36:03,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4402/12032 [4:01:25<8:01:04,  3.78s/it]2025-08-22:22:36:07,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4403/12032 [4:01:29<8:01:32,  3.79s/it]2025-08-22:22:36:11,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4404/12032 [4:01:33<8:03:21,  3.80s/it]2025-08-22:22:36:15,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4405/12032 [4:01:37<8:04:26,  3.81s/it]2025-08-22:22:36:18,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4406/12032 [4:01:40<8:02:22,  3.80s/it]2025-08-22:22:36:22,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4407/12032 [4:01:44<8:05:51,  3.82s/it]2025-08-22:22:36:26,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4408/12032 [4:01:48<8:04:23,  3.81s/it]2025-08-22:22:36:30,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4409/12032 [4:01:52<8:03:15,  3.80s/it]2025-08-22:22:36:34,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4410/12032 [4:01:55<7:28:48,  3.53s/it]2025-08-22:22:36:37,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4411/12032 [4:01:59<7:40:50,  3.63s/it]2025-08-22:22:36:40,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4412/12032 [4:02:02<7:45:33,  3.67s/it]2025-08-22:22:36:44,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4413/12032 [4:02:05<7:14:50,  3.42s/it]2025-08-22:22:36:47,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4414/12032 [4:02:09<7:27:11,  3.52s/it]2025-08-22:22:36:51,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4415/12032 [4:02:13<7:37:13,  3.60s/it]2025-08-22:22:36:55,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4416/12032 [4:02:17<7:42:31,  3.64s/it]2025-08-22:22:36:58,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4417/12032 [4:02:18<6:29:16,  3.07s/it]2025-08-22:22:37:00,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4418/12032 [4:02:20<5:25:57,  2.57s/it]2025-08-22:22:37:01,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4419/12032 [4:02:20<4:10:43,  1.98s/it]2025-08-22:22:37:02,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4420/12032 [4:02:24<5:20:11,  2.52s/it]2025-08-22:22:37:06,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4421/12032 [4:02:28<6:07:21,  2.90s/it]2025-08-22:22:37:10,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4422/12032 [4:02:32<6:42:07,  3.17s/it]2025-08-22:22:37:13,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4423/12032 [4:02:35<7:05:54,  3.36s/it]2025-08-22:22:37:17,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4424/12032 [4:02:39<7:24:13,  3.50s/it]2025-08-22:22:37:21,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4425/12032 [4:02:43<7:34:18,  3.58s/it]2025-08-22:22:37:25,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4426/12032 [4:02:47<7:43:41,  3.66s/it]2025-08-22:22:37:29,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4427/12032 [4:02:51<7:50:01,  3.71s/it]2025-08-22:22:37:33,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4428/12032 [4:02:54<7:20:10,  3.47s/it]2025-08-22:22:37:35,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4429/12032 [4:02:57<7:31:37,  3.56s/it]2025-08-22:22:37:39,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4430/12032 [4:03:01<7:38:58,  3.62s/it]2025-08-22:22:37:43,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4431/12032 [4:03:05<7:43:39,  3.66s/it]2025-08-22:22:37:47,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4432/12032 [4:03:09<7:48:44,  3.70s/it]2025-08-22:22:37:51,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4433/12032 [4:03:12<7:52:05,  3.73s/it]2025-08-22:22:37:54,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4434/12032 [4:03:16<7:53:26,  3.74s/it]2025-08-22:22:37:58,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4435/12032 [4:03:20<7:54:54,  3.75s/it]2025-08-22:22:38:02,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4436/12032 [4:03:24<7:57:16,  3.77s/it]2025-08-22:22:38:06,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4437/12032 [4:03:28<7:59:36,  3.79s/it]2025-08-22:22:38:10,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4438/12032 [4:03:31<8:01:02,  3.80s/it]2025-08-22:22:38:13,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4439/12032 [4:03:35<8:00:43,  3.80s/it]2025-08-22:22:38:17,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4440/12032 [4:03:39<7:56:13,  3.76s/it]2025-08-22:22:38:21,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4441/12032 [4:03:43<7:57:06,  3.77s/it]2025-08-22:22:38:25,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4442/12032 [4:03:47<7:57:06,  3.77s/it]2025-08-22:22:38:28,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4443/12032 [4:03:50<7:58:49,  3.79s/it]2025-08-22:22:38:32,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4444/12032 [4:03:52<6:30:35,  3.09s/it]2025-08-22:22:38:34,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4445/12032 [4:03:56<6:56:00,  3.29s/it]2025-08-22:22:38:37,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4446/12032 [4:03:59<7:15:12,  3.44s/it]2025-08-22:22:38:41,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4447/12032 [4:04:03<7:28:32,  3.55s/it]2025-08-22:22:38:45,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4448/12032 [4:04:07<7:38:26,  3.63s/it]2025-08-22:22:38:49,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4449/12032 [4:04:11<7:45:06,  3.68s/it]2025-08-22:22:38:53,120 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4450/12032 [4:04:15<7:48:20,  3.71s/it]2025-08-22:22:38:56,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4451/12032 [4:04:16<6:21:41,  3.02s/it]2025-08-22:22:38:58,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4452/12032 [4:04:20<6:50:39,  3.25s/it]2025-08-22:22:39:02,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4453/12032 [4:04:24<7:09:45,  3.40s/it]2025-08-22:22:39:05,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4454/12032 [4:04:27<7:24:45,  3.52s/it]2025-08-22:22:39:09,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4455/12032 [4:04:31<7:35:25,  3.61s/it]2025-08-22:22:39:13,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4456/12032 [4:04:35<7:41:33,  3.66s/it]2025-08-22:22:39:17,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4457/12032 [4:04:39<7:46:36,  3.70s/it]2025-08-22:22:39:21,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4458/12032 [4:04:42<7:51:27,  3.73s/it]2025-08-22:22:39:24,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4459/12032 [4:04:46<7:52:38,  3.74s/it]2025-08-22:22:39:28,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4460/12032 [4:04:50<7:55:10,  3.77s/it]2025-08-22:22:39:32,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4461/12032 [4:04:53<7:29:46,  3.56s/it]2025-08-22:22:39:35,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4462/12032 [4:04:57<7:39:07,  3.64s/it]2025-08-22:22:39:39,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4463/12032 [4:05:01<7:44:59,  3.69s/it]2025-08-22:22:39:43,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4464/12032 [4:05:05<7:48:13,  3.71s/it]2025-08-22:22:39:46,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4465/12032 [4:05:08<7:52:57,  3.75s/it]2025-08-22:22:39:50,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4466/12032 [4:05:12<7:52:56,  3.75s/it]2025-08-22:22:39:54,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4467/12032 [4:05:16<7:52:37,  3.75s/it]2025-08-22:22:39:58,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4468/12032 [4:05:20<7:54:26,  3.76s/it]2025-08-22:22:40:02,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4469/12032 [4:05:22<7:08:50,  3.40s/it]2025-08-22:22:40:04,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4470/12032 [4:05:26<7:29:25,  3.57s/it]2025-08-22:22:40:08,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4471/12032 [4:05:30<7:38:39,  3.64s/it]2025-08-22:22:40:12,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4472/12032 [4:05:34<7:43:24,  3.68s/it]2025-08-22:22:40:16,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4473/12032 [4:05:38<7:46:25,  3.70s/it]2025-08-22:22:40:19,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4474/12032 [4:05:41<7:50:10,  3.73s/it]2025-08-22:22:40:23,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4475/12032 [4:05:45<7:52:30,  3.75s/it]2025-08-22:22:40:27,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4476/12032 [4:05:49<7:54:47,  3.77s/it]2025-08-22:22:40:31,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4477/12032 [4:05:53<7:54:44,  3.77s/it]2025-08-22:22:40:35,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4478/12032 [4:05:55<7:06:00,  3.38s/it]2025-08-22:22:40:37,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4479/12032 [4:05:59<7:20:52,  3.50s/it]2025-08-22:22:40:41,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4480/12032 [4:06:03<7:31:19,  3.59s/it]2025-08-22:22:40:45,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4481/12032 [4:06:07<7:38:15,  3.64s/it]2025-08-22:22:40:48,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4482/12032 [4:06:10<7:43:30,  3.68s/it]2025-08-22:22:40:52,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4483/12032 [4:06:14<7:46:26,  3.71s/it]2025-08-22:22:40:56,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4484/12032 [4:06:18<7:48:33,  3.72s/it]2025-08-22:22:41:00,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4485/12032 [4:06:22<7:50:57,  3.74s/it]2025-08-22:22:41:03,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4486/12032 [4:06:25<7:53:52,  3.77s/it]2025-08-22:22:41:07,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4487/12032 [4:06:29<7:53:34,  3.77s/it]2025-08-22:22:41:11,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4488/12032 [4:06:33<7:53:28,  3.77s/it]2025-08-22:22:41:15,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4489/12032 [4:06:37<7:54:10,  3.77s/it]2025-08-22:22:41:19,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4490/12032 [4:06:41<7:54:11,  3.77s/it]2025-08-22:22:41:22,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4491/12032 [4:06:44<7:53:52,  3.77s/it]2025-08-22:22:41:26,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4492/12032 [4:06:48<7:52:55,  3.76s/it]2025-08-22:22:41:30,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4493/12032 [4:06:49<6:18:10,  3.01s/it]2025-08-22:22:41:31,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4494/12032 [4:06:53<6:45:12,  3.23s/it]2025-08-22:22:41:35,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4495/12032 [4:06:54<5:32:46,  2.65s/it]2025-08-22:22:41:36,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4496/12032 [4:06:56<4:41:16,  2.24s/it]2025-08-22:22:41:37,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4497/12032 [4:06:57<4:19:32,  2.07s/it]2025-08-22:22:41:39,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4498/12032 [4:06:58<3:34:01,  1.70s/it]2025-08-22:22:41:40,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4499/12032 [4:07:02<4:55:38,  2.35s/it]2025-08-22:22:41:44,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4500/12032 [4:07:06<5:48:41,  2.78s/it]2025-08-22:22:41:48,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4501/12032 [4:07:10<6:25:19,  3.07s/it]2025-08-22:22:41:51,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4502/12032 [4:07:13<6:51:57,  3.28s/it]2025-08-22:22:41:55,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4503/12032 [4:07:17<7:15:06,  3.47s/it]2025-08-22:22:41:59,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4504/12032 [4:07:21<7:28:06,  3.57s/it]2025-08-22:22:42:03,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4505/12032 [4:07:25<7:37:11,  3.64s/it]2025-08-22:22:42:07,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4506/12032 [4:07:29<7:42:01,  3.68s/it]2025-08-22:22:42:10,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4507/12032 [4:07:33<7:49:43,  3.75s/it]2025-08-22:22:42:14,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4508/12032 [4:07:36<7:51:37,  3.76s/it]2025-08-22:22:42:18,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4509/12032 [4:07:40<7:51:51,  3.76s/it]2025-08-22:22:42:22,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4510/12032 [4:07:44<7:53:14,  3.77s/it]2025-08-22:22:42:26,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  37%|███▋      | 4511/12032 [4:07:48<7:52:41,  3.77s/it]2025-08-22:22:42:29,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4512/12032 [4:07:51<7:53:49,  3.78s/it]2025-08-22:22:42:33,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4513/12032 [4:07:55<7:36:36,  3.64s/it]2025-08-22:22:42:37,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4514/12032 [4:07:59<7:41:54,  3.69s/it]2025-08-22:22:42:40,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4515/12032 [4:08:02<7:47:19,  3.73s/it]2025-08-22:22:42:44,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4516/12032 [4:08:06<7:51:33,  3.76s/it]2025-08-22:22:42:48,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4517/12032 [4:08:10<7:52:39,  3.77s/it]2025-08-22:22:42:52,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4518/12032 [4:08:14<7:53:30,  3.78s/it]2025-08-22:22:42:56,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4519/12032 [4:08:18<7:53:46,  3.78s/it]2025-08-22:22:42:59,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4520/12032 [4:08:20<6:49:26,  3.27s/it]2025-08-22:22:43:02,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4521/12032 [4:08:23<7:07:50,  3.42s/it]2025-08-22:22:43:05,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4522/12032 [4:08:27<6:59:52,  3.35s/it]2025-08-22:22:43:08,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4523/12032 [4:08:30<7:17:11,  3.49s/it]2025-08-22:22:43:12,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4524/12032 [4:08:34<7:27:03,  3.57s/it]2025-08-22:22:43:16,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4525/12032 [4:08:38<7:34:41,  3.63s/it]2025-08-22:22:43:20,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4526/12032 [4:08:42<7:40:32,  3.68s/it]2025-08-22:22:43:24,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4527/12032 [4:08:46<7:44:25,  3.71s/it]2025-08-22:22:43:27,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4528/12032 [4:08:49<7:49:07,  3.75s/it]2025-08-22:22:43:31,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4529/12032 [4:08:53<7:50:20,  3.76s/it]2025-08-22:22:43:35,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4530/12032 [4:08:57<7:49:43,  3.76s/it]2025-08-22:22:43:39,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4531/12032 [4:09:01<7:50:58,  3.77s/it]2025-08-22:22:43:43,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4532/12032 [4:09:03<7:11:57,  3.46s/it]2025-08-22:22:43:45,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4533/12032 [4:09:07<7:24:50,  3.56s/it]2025-08-22:22:43:49,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4534/12032 [4:09:11<7:31:13,  3.61s/it]2025-08-22:22:43:53,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4535/12032 [4:09:15<7:38:16,  3.67s/it]2025-08-22:22:43:57,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4536/12032 [4:09:19<7:42:13,  3.70s/it]2025-08-22:22:44:00,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4537/12032 [4:09:22<7:45:47,  3.73s/it]2025-08-22:22:44:04,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4538/12032 [4:09:26<7:47:54,  3.75s/it]2025-08-22:22:44:08,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4539/12032 [4:09:30<7:49:33,  3.76s/it]2025-08-22:22:44:12,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4540/12032 [4:09:34<7:49:27,  3.76s/it]2025-08-22:22:44:16,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4541/12032 [4:09:37<7:49:20,  3.76s/it]2025-08-22:22:44:19,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4542/12032 [4:09:41<7:35:49,  3.65s/it]2025-08-22:22:44:23,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4543/12032 [4:09:45<7:41:17,  3.70s/it]2025-08-22:22:44:27,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4544/12032 [4:09:48<7:43:10,  3.71s/it]2025-08-22:22:44:30,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4545/12032 [4:09:52<7:46:32,  3.74s/it]2025-08-22:22:44:34,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4546/12032 [4:09:56<7:48:00,  3.75s/it]2025-08-22:22:44:38,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4547/12032 [4:10:00<7:48:38,  3.76s/it]2025-08-22:22:44:42,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4548/12032 [4:10:04<7:48:45,  3.76s/it]2025-08-22:22:44:45,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4549/12032 [4:10:07<7:49:19,  3.76s/it]2025-08-22:22:44:49,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4550/12032 [4:10:11<7:48:50,  3.76s/it]2025-08-22:22:44:53,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4551/12032 [4:10:15<7:50:14,  3.77s/it]2025-08-22:22:44:57,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4552/12032 [4:10:19<7:50:05,  3.77s/it]2025-08-22:22:45:00,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4553/12032 [4:10:22<7:50:06,  3.77s/it]2025-08-22:22:45:04,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4554/12032 [4:10:26<7:49:54,  3.77s/it]2025-08-22:22:45:08,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4555/12032 [4:10:29<7:23:50,  3.56s/it]2025-08-22:22:45:11,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4556/12032 [4:10:33<7:32:50,  3.63s/it]2025-08-22:22:45:15,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4557/12032 [4:10:37<7:38:20,  3.68s/it]2025-08-22:22:45:19,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4558/12032 [4:10:41<7:42:11,  3.71s/it]2025-08-22:22:45:22,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4559/12032 [4:10:44<7:43:57,  3.73s/it]2025-08-22:22:45:26,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4560/12032 [4:10:48<7:46:04,  3.74s/it]2025-08-22:22:45:30,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4561/12032 [4:10:52<7:47:19,  3.75s/it]2025-08-22:22:45:34,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4562/12032 [4:10:56<7:48:20,  3.76s/it]2025-08-22:22:45:38,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4563/12032 [4:10:59<7:47:56,  3.76s/it]2025-08-22:22:45:41,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4564/12032 [4:11:03<7:48:52,  3.77s/it]2025-08-22:22:45:45,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4565/12032 [4:11:07<7:50:24,  3.78s/it]2025-08-22:22:45:49,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4566/12032 [4:11:11<7:48:46,  3.77s/it]2025-08-22:22:45:53,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4567/12032 [4:11:15<7:50:10,  3.78s/it]2025-08-22:22:45:56,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4568/12032 [4:11:18<7:51:35,  3.79s/it]2025-08-22:22:46:00,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4569/12032 [4:11:22<7:36:20,  3.67s/it]2025-08-22:22:46:04,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4570/12032 [4:11:26<7:41:49,  3.71s/it]2025-08-22:22:46:07,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4571/12032 [4:11:27<6:07:05,  2.95s/it]2025-08-22:22:46:09,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4572/12032 [4:11:29<5:50:49,  2.82s/it]2025-08-22:22:46:11,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4573/12032 [4:11:30<4:42:32,  2.27s/it]2025-08-22:22:46:12,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4574/12032 [4:11:32<4:35:06,  2.21s/it]2025-08-22:22:46:14,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4575/12032 [4:11:36<5:34:36,  2.69s/it]2025-08-22:22:46:18,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4576/12032 [4:11:40<6:16:33,  3.03s/it]2025-08-22:22:46:22,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4577/12032 [4:11:44<6:43:57,  3.25s/it]2025-08-22:22:46:26,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4578/12032 [4:11:47<6:48:00,  3.28s/it]2025-08-22:22:46:29,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4579/12032 [4:11:51<7:06:41,  3.44s/it]2025-08-22:22:46:33,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4580/12032 [4:11:55<7:20:15,  3.54s/it]2025-08-22:22:46:37,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4581/12032 [4:11:59<7:28:58,  3.62s/it]2025-08-22:22:46:40,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4582/12032 [4:12:02<7:35:00,  3.66s/it]2025-08-22:22:46:44,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4583/12032 [4:12:06<7:37:45,  3.69s/it]2025-08-22:22:46:48,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4584/12032 [4:12:10<7:42:10,  3.72s/it]2025-08-22:22:46:52,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4585/12032 [4:12:14<7:43:30,  3.73s/it]2025-08-22:22:46:55,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4586/12032 [4:12:17<7:44:22,  3.74s/it]2025-08-22:22:46:59,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4587/12032 [4:12:20<6:47:50,  3.29s/it]2025-08-22:22:47:01,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4588/12032 [4:12:23<7:05:20,  3.43s/it]2025-08-22:22:47:05,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4589/12032 [4:12:27<7:18:32,  3.54s/it]2025-08-22:22:47:09,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4590/12032 [4:12:31<7:29:08,  3.62s/it]2025-08-22:22:47:13,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4591/12032 [4:12:35<7:35:29,  3.67s/it]2025-08-22:22:47:17,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4592/12032 [4:12:38<7:32:46,  3.65s/it]2025-08-22:22:47:20,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4593/12032 [4:12:42<7:38:24,  3.70s/it]2025-08-22:22:47:24,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4594/12032 [4:12:46<7:47:14,  3.77s/it]2025-08-22:22:47:28,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4595/12032 [4:12:50<7:50:04,  3.79s/it]2025-08-22:22:47:32,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4596/12032 [4:12:54<7:51:19,  3.80s/it]2025-08-22:22:47:36,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4597/12032 [4:12:57<7:48:50,  3.78s/it]2025-08-22:22:47:39,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4598/12032 [4:13:01<7:52:24,  3.81s/it]2025-08-22:22:47:43,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4599/12032 [4:13:05<7:54:09,  3.83s/it]2025-08-22:22:47:47,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4600/12032 [4:13:09<7:55:22,  3.84s/it]2025-08-22:22:47:51,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4601/12032 [4:13:13<7:53:01,  3.82s/it]2025-08-22:22:47:55,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4602/12032 [4:13:17<7:51:41,  3.81s/it]2025-08-22:22:47:59,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4603/12032 [4:13:19<7:01:27,  3.40s/it]2025-08-22:22:48:01,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4604/12032 [4:13:23<7:16:10,  3.52s/it]2025-08-22:22:48:05,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4605/12032 [4:13:26<7:17:46,  3.54s/it]2025-08-22:22:48:08,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4606/12032 [4:13:30<7:26:07,  3.60s/it]2025-08-22:22:48:12,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4607/12032 [4:13:34<7:31:57,  3.65s/it]2025-08-22:22:48:16,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4608/12032 [4:13:38<7:36:59,  3.69s/it]2025-08-22:22:48:20,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4609/12032 [4:13:42<7:41:39,  3.73s/it]2025-08-22:22:48:23,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4610/12032 [4:13:45<7:46:27,  3.77s/it]2025-08-22:22:48:27,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4611/12032 [4:13:49<7:47:19,  3.78s/it]2025-08-22:22:48:31,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4612/12032 [4:13:53<7:48:26,  3.79s/it]2025-08-22:22:48:35,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4613/12032 [4:13:57<7:48:13,  3.79s/it]2025-08-22:22:48:39,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4614/12032 [4:14:01<7:48:39,  3.79s/it]2025-08-22:22:48:43,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4615/12032 [4:14:05<7:49:48,  3.80s/it]2025-08-22:22:48:46,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4616/12032 [4:14:08<7:49:29,  3.80s/it]2025-08-22:22:48:50,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4617/12032 [4:14:12<7:52:44,  3.83s/it]2025-08-22:22:48:54,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4618/12032 [4:14:16<7:52:00,  3.82s/it]2025-08-22:22:48:58,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4619/12032 [4:14:20<7:53:38,  3.83s/it]2025-08-22:22:49:02,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4620/12032 [4:14:24<7:55:15,  3.85s/it]2025-08-22:22:49:06,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4621/12032 [4:14:28<7:54:44,  3.84s/it]2025-08-22:22:49:09,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4622/12032 [4:14:31<7:54:57,  3.85s/it]2025-08-22:22:49:13,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4623/12032 [4:14:35<7:54:10,  3.84s/it]2025-08-22:22:49:17,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4624/12032 [4:14:39<7:52:40,  3.83s/it]2025-08-22:22:49:21,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4625/12032 [4:14:43<7:51:39,  3.82s/it]2025-08-22:22:49:25,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4626/12032 [4:14:47<7:50:01,  3.81s/it]2025-08-22:22:49:28,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4627/12032 [4:14:50<7:48:26,  3.80s/it]2025-08-22:22:49:32,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4628/12032 [4:14:54<7:47:43,  3.79s/it]2025-08-22:22:49:36,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4629/12032 [4:14:58<7:47:30,  3.79s/it]2025-08-22:22:49:40,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4630/12032 [4:15:02<7:47:09,  3.79s/it]2025-08-22:22:49:44,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4631/12032 [4:15:06<7:54:05,  3.84s/it]2025-08-22:22:49:48,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  38%|███▊      | 4632/12032 [4:15:07<6:22:27,  3.10s/it]2025-08-22:22:49:49,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4633/12032 [4:15:11<6:49:19,  3.32s/it]2025-08-22:22:49:53,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4634/12032 [4:15:15<7:07:42,  3.47s/it]2025-08-22:22:49:57,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4635/12032 [4:15:19<7:20:41,  3.57s/it]2025-08-22:22:50:00,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4636/12032 [4:15:22<7:32:49,  3.67s/it]2025-08-22:22:50:04,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4637/12032 [4:15:26<7:37:04,  3.71s/it]2025-08-22:22:50:08,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4638/12032 [4:15:30<7:39:08,  3.73s/it]2025-08-22:22:50:12,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4639/12032 [4:15:34<7:41:28,  3.75s/it]2025-08-22:22:50:16,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4640/12032 [4:15:38<7:41:46,  3.75s/it]2025-08-22:22:50:19,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4641/12032 [4:15:41<7:42:21,  3.75s/it]2025-08-22:22:50:23,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4642/12032 [4:15:45<7:45:45,  3.78s/it]2025-08-22:22:50:27,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4643/12032 [4:15:49<7:47:28,  3.80s/it]2025-08-22:22:50:31,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4644/12032 [4:15:53<7:46:48,  3.79s/it]2025-08-22:22:50:35,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4645/12032 [4:15:57<7:48:17,  3.80s/it]2025-08-22:22:50:38,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4646/12032 [4:16:00<7:48:41,  3.81s/it]2025-08-22:22:50:42,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4647/12032 [4:16:04<7:49:50,  3.82s/it]2025-08-22:22:50:46,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4648/12032 [4:16:08<7:49:24,  3.81s/it]2025-08-22:22:50:50,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4649/12032 [4:16:12<7:49:41,  3.82s/it]2025-08-22:22:50:54,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4650/12032 [4:16:15<7:40:24,  3.74s/it]2025-08-22:22:50:57,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4651/12032 [4:16:19<7:42:03,  3.76s/it]2025-08-22:22:51:01,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4652/12032 [4:16:20<5:53:07,  2.87s/it]2025-08-22:22:51:02,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4653/12032 [4:16:23<5:41:26,  2.78s/it]2025-08-22:22:51:04,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4654/12032 [4:16:24<4:48:15,  2.34s/it]2025-08-22:22:51:06,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4655/12032 [4:16:25<4:08:29,  2.02s/it]2025-08-22:22:51:07,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4656/12032 [4:16:27<4:16:15,  2.08s/it]2025-08-22:22:51:09,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4657/12032 [4:16:29<3:52:10,  1.89s/it]2025-08-22:22:51:11,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4658/12032 [4:16:33<5:02:19,  2.46s/it]2025-08-22:22:51:15,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4659/12032 [4:16:36<5:51:46,  2.86s/it]2025-08-22:22:51:18,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4660/12032 [4:16:40<6:27:29,  3.15s/it]2025-08-22:22:51:22,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4661/12032 [4:16:44<6:52:20,  3.36s/it]2025-08-22:22:51:26,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▊      | 4662/12032 [4:16:48<7:08:33,  3.49s/it]2025-08-22:22:51:30,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4663/12032 [4:16:52<7:20:28,  3.59s/it]2025-08-22:22:51:34,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4664/12032 [4:16:56<7:28:27,  3.65s/it]2025-08-22:22:51:37,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4665/12032 [4:16:59<7:34:51,  3.70s/it]2025-08-22:22:51:41,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4666/12032 [4:17:03<7:39:19,  3.74s/it]2025-08-22:22:51:45,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4667/12032 [4:17:07<7:40:45,  3.75s/it]2025-08-22:22:51:49,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4668/12032 [4:17:11<7:42:12,  3.77s/it]2025-08-22:22:51:53,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4669/12032 [4:17:15<7:42:22,  3.77s/it]2025-08-22:22:51:56,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4670/12032 [4:17:18<7:46:26,  3.80s/it]2025-08-22:22:52:00,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4671/12032 [4:17:22<7:46:29,  3.80s/it]2025-08-22:22:52:04,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4672/12032 [4:17:26<7:46:11,  3.80s/it]2025-08-22:22:52:08,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4673/12032 [4:17:30<7:48:46,  3.82s/it]2025-08-22:22:52:12,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4674/12032 [4:17:34<7:45:44,  3.80s/it]2025-08-22:22:52:16,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4675/12032 [4:17:37<7:44:56,  3.79s/it]2025-08-22:22:52:19,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4676/12032 [4:17:41<7:44:55,  3.79s/it]2025-08-22:22:52:23,574 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4677/12032 [4:17:45<7:44:06,  3.79s/it]2025-08-22:22:52:27,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4678/12032 [4:17:48<7:32:44,  3.69s/it]2025-08-22:22:52:30,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4679/12032 [4:17:52<7:33:56,  3.70s/it]2025-08-22:22:52:34,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4680/12032 [4:17:56<7:36:14,  3.72s/it]2025-08-22:22:52:38,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4681/12032 [4:18:00<7:39:31,  3.75s/it]2025-08-22:22:52:42,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4682/12032 [4:18:04<7:39:26,  3.75s/it]2025-08-22:22:52:45,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4683/12032 [4:18:07<7:43:32,  3.78s/it]2025-08-22:22:52:49,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4684/12032 [4:18:11<7:43:54,  3.79s/it]2025-08-22:22:52:53,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4685/12032 [4:18:15<7:42:02,  3.77s/it]2025-08-22:22:52:57,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4686/12032 [4:18:19<7:40:21,  3.76s/it]2025-08-22:22:53:01,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4687/12032 [4:18:22<7:42:03,  3.77s/it]2025-08-22:22:53:04,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4688/12032 [4:18:26<7:43:09,  3.78s/it]2025-08-22:22:53:08,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4689/12032 [4:18:30<7:44:35,  3.80s/it]2025-08-22:22:53:12,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4690/12032 [4:18:34<7:45:04,  3.80s/it]2025-08-22:22:53:16,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4691/12032 [4:18:36<6:51:31,  3.36s/it]2025-08-22:22:53:18,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4692/12032 [4:18:40<7:08:28,  3.50s/it]2025-08-22:22:53:22,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4693/12032 [4:18:44<7:21:06,  3.61s/it]2025-08-22:22:53:26,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4694/12032 [4:18:48<7:28:29,  3.67s/it]2025-08-22:22:53:30,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4695/12032 [4:18:52<7:33:21,  3.71s/it]2025-08-22:22:53:33,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4696/12032 [4:18:55<7:37:37,  3.74s/it]2025-08-22:22:53:37,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4697/12032 [4:18:59<7:38:22,  3.75s/it]2025-08-22:22:53:41,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4698/12032 [4:19:03<7:40:49,  3.77s/it]2025-08-22:22:53:45,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4699/12032 [4:19:07<7:44:33,  3.80s/it]2025-08-22:22:53:49,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4700/12032 [4:19:11<7:42:48,  3.79s/it]2025-08-22:22:53:52,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4701/12032 [4:19:14<7:43:01,  3.79s/it]2025-08-22:22:53:56,725 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4702/12032 [4:19:18<7:24:33,  3.64s/it]2025-08-22:22:54:00,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4703/12032 [4:19:22<7:32:06,  3.70s/it]2025-08-22:22:54:03,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4704/12032 [4:19:25<7:33:29,  3.71s/it]2025-08-22:22:54:07,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4705/12032 [4:19:29<7:36:10,  3.74s/it]2025-08-22:22:54:11,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4706/12032 [4:19:33<7:37:13,  3.74s/it]2025-08-22:22:54:15,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4707/12032 [4:19:37<7:42:05,  3.79s/it]2025-08-22:22:54:19,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4708/12032 [4:19:41<7:45:19,  3.81s/it]2025-08-22:22:54:22,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4709/12032 [4:19:44<7:43:35,  3.80s/it]2025-08-22:22:54:26,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4710/12032 [4:19:48<7:43:20,  3.80s/it]2025-08-22:22:54:30,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4711/12032 [4:19:52<7:42:52,  3.79s/it]2025-08-22:22:54:34,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4712/12032 [4:19:56<7:42:10,  3.79s/it]2025-08-22:22:54:38,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4713/12032 [4:19:59<7:41:51,  3.79s/it]2025-08-22:22:54:41,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4714/12032 [4:20:03<7:41:03,  3.78s/it]2025-08-22:22:54:45,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4715/12032 [4:20:07<7:41:18,  3.78s/it]2025-08-22:22:54:49,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4716/12032 [4:20:11<7:40:10,  3.77s/it]2025-08-22:22:54:53,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4717/12032 [4:20:15<7:40:29,  3.78s/it]2025-08-22:22:54:56,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4718/12032 [4:20:18<7:41:32,  3.79s/it]2025-08-22:22:55:00,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4719/12032 [4:20:22<7:41:05,  3.78s/it]2025-08-22:22:55:04,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4720/12032 [4:20:26<7:40:18,  3.78s/it]2025-08-22:22:55:08,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4721/12032 [4:20:30<7:41:28,  3.79s/it]2025-08-22:22:55:12,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4722/12032 [4:20:34<7:42:21,  3.79s/it]2025-08-22:22:55:15,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4723/12032 [4:20:37<7:41:05,  3.79s/it]2025-08-22:22:55:19,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4724/12032 [4:20:41<7:41:43,  3.79s/it]2025-08-22:22:55:23,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4725/12032 [4:20:45<7:41:01,  3.79s/it]2025-08-22:22:55:27,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4726/12032 [4:20:49<7:40:33,  3.78s/it]2025-08-22:22:55:30,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4727/12032 [4:20:49<5:50:33,  2.88s/it]2025-08-22:22:55:31,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4728/12032 [4:20:50<4:44:36,  2.34s/it]2025-08-22:22:55:32,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4729/12032 [4:20:54<5:35:41,  2.76s/it]2025-08-22:22:55:36,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4730/12032 [4:20:55<4:30:13,  2.22s/it]2025-08-22:22:55:37,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4731/12032 [4:20:56<3:42:23,  1.83s/it]2025-08-22:22:55:38,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4732/12032 [4:20:57<3:04:58,  1.52s/it]2025-08-22:22:55:39,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4733/12032 [4:21:00<3:44:57,  1.85s/it]2025-08-22:22:55:41,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4734/12032 [4:21:01<3:28:41,  1.72s/it]2025-08-22:22:55:43,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4735/12032 [4:21:03<3:26:35,  1.70s/it]2025-08-22:22:55:44,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4736/12032 [4:21:06<4:42:45,  2.33s/it]2025-08-22:22:55:48,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4737/12032 [4:21:10<5:36:14,  2.77s/it]2025-08-22:22:55:52,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4738/12032 [4:21:14<6:13:28,  3.07s/it]2025-08-22:22:55:56,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4739/12032 [4:21:18<6:39:10,  3.28s/it]2025-08-22:22:56:00,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4740/12032 [4:21:21<6:50:35,  3.38s/it]2025-08-22:22:56:03,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4741/12032 [4:21:25<7:03:40,  3.49s/it]2025-08-22:22:56:07,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4742/12032 [4:21:29<7:19:31,  3.62s/it]2025-08-22:22:56:11,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4743/12032 [4:21:33<7:26:18,  3.67s/it]2025-08-22:22:56:15,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4744/12032 [4:21:37<7:29:21,  3.70s/it]2025-08-22:22:56:18,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4745/12032 [4:21:38<6:20:30,  3.13s/it]2025-08-22:22:56:20,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4746/12032 [4:21:42<6:43:47,  3.33s/it]2025-08-22:22:56:24,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4747/12032 [4:21:46<6:59:30,  3.46s/it]2025-08-22:22:56:28,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4748/12032 [4:21:50<7:13:03,  3.57s/it]2025-08-22:22:56:32,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4749/12032 [4:21:54<7:22:14,  3.64s/it]2025-08-22:22:56:35,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4750/12032 [4:21:57<7:27:32,  3.69s/it]2025-08-22:22:56:39,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4751/12032 [4:22:01<7:31:21,  3.72s/it]2025-08-22:22:56:43,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  39%|███▉      | 4752/12032 [4:22:05<7:32:05,  3.73s/it]2025-08-22:22:56:47,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4753/12032 [4:22:09<7:34:10,  3.74s/it]2025-08-22:22:56:51,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4754/12032 [4:22:12<7:35:56,  3.76s/it]2025-08-22:22:56:54,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4755/12032 [4:22:16<7:37:32,  3.77s/it]2025-08-22:22:56:58,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4756/12032 [4:22:20<7:39:56,  3.79s/it]2025-08-22:22:57:02,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4757/12032 [4:22:24<7:39:10,  3.79s/it]2025-08-22:22:57:06,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4758/12032 [4:22:27<7:13:16,  3.57s/it]2025-08-22:22:57:09,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4759/12032 [4:22:31<7:23:06,  3.66s/it]2025-08-22:22:57:13,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4760/12032 [4:22:35<7:28:40,  3.70s/it]2025-08-22:22:57:16,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4761/12032 [4:22:38<7:31:44,  3.73s/it]2025-08-22:22:57:20,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4762/12032 [4:22:42<7:33:00,  3.74s/it]2025-08-22:22:57:24,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4763/12032 [4:22:46<7:33:59,  3.75s/it]2025-08-22:22:57:28,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4764/12032 [4:22:50<7:35:35,  3.76s/it]2025-08-22:22:57:32,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4765/12032 [4:22:54<7:36:32,  3.77s/it]2025-08-22:22:57:35,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4766/12032 [4:22:57<7:37:16,  3.78s/it]2025-08-22:22:57:39,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4767/12032 [4:23:01<7:37:25,  3.78s/it]2025-08-22:22:57:43,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4768/12032 [4:23:05<7:36:27,  3.77s/it]2025-08-22:22:57:47,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4769/12032 [4:23:09<7:40:18,  3.80s/it]2025-08-22:22:57:51,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4770/12032 [4:23:12<7:38:34,  3.79s/it]2025-08-22:22:57:54,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4771/12032 [4:23:16<7:40:23,  3.80s/it]2025-08-22:22:57:58,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4772/12032 [4:23:20<7:39:44,  3.80s/it]2025-08-22:22:58:02,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4773/12032 [4:23:22<6:29:58,  3.22s/it]2025-08-22:22:58:04,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4774/12032 [4:23:26<6:51:19,  3.40s/it]2025-08-22:22:58:08,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4775/12032 [4:23:29<6:51:55,  3.41s/it]2025-08-22:22:58:11,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4776/12032 [4:23:33<7:05:58,  3.52s/it]2025-08-22:22:58:15,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4777/12032 [4:23:37<7:14:10,  3.59s/it]2025-08-22:22:58:19,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4778/12032 [4:23:41<7:21:51,  3.65s/it]2025-08-22:22:58:22,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4779/12032 [4:23:44<7:26:35,  3.69s/it]2025-08-22:22:58:26,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4780/12032 [4:23:48<7:32:22,  3.74s/it]2025-08-22:22:58:30,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4781/12032 [4:23:52<7:33:15,  3.75s/it]2025-08-22:22:58:34,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4782/12032 [4:23:56<7:34:29,  3.76s/it]2025-08-22:22:58:38,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4783/12032 [4:23:57<6:14:21,  3.10s/it]2025-08-22:22:58:39,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4784/12032 [4:24:01<6:38:52,  3.30s/it]2025-08-22:22:58:43,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4785/12032 [4:24:05<6:57:56,  3.46s/it]2025-08-22:22:58:47,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4786/12032 [4:24:09<7:09:26,  3.56s/it]2025-08-22:22:58:51,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4787/12032 [4:24:10<5:47:34,  2.88s/it]2025-08-22:22:58:52,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4788/12032 [4:24:14<6:20:45,  3.15s/it]2025-08-22:22:58:56,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4789/12032 [4:24:18<6:42:12,  3.33s/it]2025-08-22:22:58:59,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4790/12032 [4:24:21<6:57:48,  3.46s/it]2025-08-22:22:59:03,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4791/12032 [4:24:25<7:10:06,  3.56s/it]2025-08-22:22:59:07,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4792/12032 [4:24:29<7:16:17,  3.62s/it]2025-08-22:22:59:11,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4793/12032 [4:24:33<7:22:20,  3.67s/it]2025-08-22:22:59:14,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4794/12032 [4:24:36<7:28:45,  3.72s/it]2025-08-22:22:59:18,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4795/12032 [4:24:40<7:29:53,  3.73s/it]2025-08-22:22:59:22,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4796/12032 [4:24:44<7:33:17,  3.76s/it]2025-08-22:22:59:26,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4797/12032 [4:24:45<6:00:34,  2.99s/it]2025-08-22:22:59:27,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4798/12032 [4:24:46<4:29:00,  2.23s/it]2025-08-22:22:59:28,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4799/12032 [4:24:47<3:44:48,  1.86s/it]2025-08-22:22:59:29,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4800/12032 [4:24:51<4:55:53,  2.45s/it]2025-08-22:22:59:32,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4801/12032 [4:24:54<5:45:41,  2.87s/it]2025-08-22:22:59:36,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4802/12032 [4:24:58<6:19:06,  3.15s/it]2025-08-22:22:59:40,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4803/12032 [4:25:02<6:42:07,  3.34s/it]2025-08-22:22:59:44,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4804/12032 [4:25:06<6:59:17,  3.48s/it]2025-08-22:22:59:48,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4805/12032 [4:25:09<7:07:56,  3.55s/it]2025-08-22:22:59:51,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4806/12032 [4:25:13<7:15:40,  3.62s/it]2025-08-22:22:59:55,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4807/12032 [4:25:17<7:22:28,  3.67s/it]2025-08-22:22:59:59,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4808/12032 [4:25:21<7:28:11,  3.72s/it]2025-08-22:23:00:03,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4809/12032 [4:25:25<7:34:50,  3.78s/it]2025-08-22:23:00:07,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4810/12032 [4:25:29<7:36:47,  3.80s/it]2025-08-22:23:00:10,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4811/12032 [4:25:32<7:36:13,  3.79s/it]2025-08-22:23:00:14,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|███▉      | 4812/12032 [4:25:36<7:36:24,  3.79s/it]2025-08-22:23:00:18,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4813/12032 [4:25:40<7:39:50,  3.82s/it]2025-08-22:23:00:22,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4814/12032 [4:25:44<7:40:48,  3.83s/it]2025-08-22:23:00:26,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4815/12032 [4:25:48<7:40:06,  3.83s/it]2025-08-22:23:00:30,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4816/12032 [4:25:52<7:37:32,  3.80s/it]2025-08-22:23:00:33,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4817/12032 [4:25:55<7:38:16,  3.81s/it]2025-08-22:23:00:37,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4818/12032 [4:25:59<7:38:52,  3.82s/it]2025-08-22:23:00:41,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4819/12032 [4:26:03<7:38:27,  3.81s/it]2025-08-22:23:00:45,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4820/12032 [4:26:07<7:36:19,  3.80s/it]2025-08-22:23:00:49,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4821/12032 [4:26:11<7:36:06,  3.80s/it]2025-08-22:23:00:52,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4822/12032 [4:26:14<7:07:35,  3.56s/it]2025-08-22:23:00:55,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4823/12032 [4:26:17<7:16:52,  3.64s/it]2025-08-22:23:00:59,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4824/12032 [4:26:21<7:22:27,  3.68s/it]2025-08-22:23:01:03,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4825/12032 [4:26:25<7:25:32,  3.71s/it]2025-08-22:23:01:07,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4826/12032 [4:26:29<7:28:29,  3.73s/it]2025-08-22:23:01:11,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4827/12032 [4:26:33<7:30:24,  3.75s/it]2025-08-22:23:01:14,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4828/12032 [4:26:36<7:15:06,  3.62s/it]2025-08-22:23:01:18,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4829/12032 [4:26:40<7:22:57,  3.69s/it]2025-08-22:23:01:22,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4830/12032 [4:26:44<7:27:35,  3.73s/it]2025-08-22:23:01:25,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4831/12032 [4:26:47<7:31:27,  3.76s/it]2025-08-22:23:01:29,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4832/12032 [4:26:51<7:32:26,  3.77s/it]2025-08-22:23:01:33,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4833/12032 [4:26:55<7:35:52,  3.80s/it]2025-08-22:23:01:37,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4834/12032 [4:26:59<7:37:40,  3.82s/it]2025-08-22:23:01:41,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4835/12032 [4:27:03<7:40:21,  3.84s/it]2025-08-22:23:01:45,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4836/12032 [4:27:07<7:39:35,  3.83s/it]2025-08-22:23:01:48,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4837/12032 [4:27:10<7:37:32,  3.82s/it]2025-08-22:23:01:52,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4838/12032 [4:27:14<7:36:32,  3.81s/it]2025-08-22:23:01:56,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4839/12032 [4:27:18<7:34:48,  3.79s/it]2025-08-22:23:02:00,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4840/12032 [4:27:22<7:36:18,  3.81s/it]2025-08-22:23:02:04,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4841/12032 [4:27:26<7:36:17,  3.81s/it]2025-08-22:23:02:07,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4842/12032 [4:27:29<7:36:16,  3.81s/it]2025-08-22:23:02:11,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4843/12032 [4:27:33<7:35:19,  3.80s/it]2025-08-22:23:02:15,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4844/12032 [4:27:37<7:34:52,  3.80s/it]2025-08-22:23:02:19,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4845/12032 [4:27:41<7:35:28,  3.80s/it]2025-08-22:23:02:23,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4846/12032 [4:27:45<7:36:01,  3.81s/it]2025-08-22:23:02:26,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4847/12032 [4:27:48<7:36:40,  3.81s/it]2025-08-22:23:02:30,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4848/12032 [4:27:52<7:35:01,  3.80s/it]2025-08-22:23:02:34,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4849/12032 [4:27:56<7:33:51,  3.79s/it]2025-08-22:23:02:38,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4850/12032 [4:28:00<7:35:46,  3.81s/it]2025-08-22:23:02:42,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4851/12032 [4:28:04<7:33:42,  3.79s/it]2025-08-22:23:02:45,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4852/12032 [4:28:07<7:33:50,  3.79s/it]2025-08-22:23:02:49,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4853/12032 [4:28:11<7:33:39,  3.79s/it]2025-08-22:23:02:53,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4854/12032 [4:28:15<7:33:55,  3.79s/it]2025-08-22:23:02:57,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4855/12032 [4:28:19<7:34:14,  3.80s/it]2025-08-22:23:03:01,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4856/12032 [4:28:22<7:33:05,  3.79s/it]2025-08-22:23:03:04,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4857/12032 [4:28:26<7:31:51,  3.78s/it]2025-08-22:23:03:08,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4858/12032 [4:28:30<7:30:36,  3.77s/it]2025-08-22:23:03:12,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4859/12032 [4:28:34<7:31:45,  3.78s/it]2025-08-22:23:03:16,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4860/12032 [4:28:38<7:32:20,  3.78s/it]2025-08-22:23:03:19,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4861/12032 [4:28:41<7:29:39,  3.76s/it]2025-08-22:23:03:23,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4862/12032 [4:28:43<6:18:14,  3.17s/it]2025-08-22:23:03:25,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4863/12032 [4:28:44<5:16:03,  2.65s/it]2025-08-22:23:03:26,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4864/12032 [4:28:46<4:27:30,  2.24s/it]2025-08-22:23:03:28,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4865/12032 [4:28:47<3:58:17,  1.99s/it]2025-08-22:23:03:29,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4866/12032 [4:28:48<3:23:29,  1.70s/it]2025-08-22:23:03:30,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4867/12032 [4:28:52<4:23:16,  2.20s/it]2025-08-22:23:03:33,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4868/12032 [4:28:55<5:08:38,  2.58s/it]2025-08-22:23:03:37,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4869/12032 [4:28:59<5:50:33,  2.94s/it]2025-08-22:23:03:41,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4870/12032 [4:29:00<4:42:09,  2.36s/it]2025-08-22:23:03:42,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4871/12032 [4:29:04<5:32:05,  2.78s/it]2025-08-22:23:03:45,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  40%|████      | 4872/12032 [4:29:06<5:33:50,  2.80s/it]2025-08-22:23:03:48,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4873/12032 [4:29:08<4:47:16,  2.41s/it]2025-08-22:23:03:50,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4874/12032 [4:29:09<4:12:18,  2.11s/it]2025-08-22:23:03:51,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4875/12032 [4:29:11<4:09:30,  2.09s/it]2025-08-22:23:03:53,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4876/12032 [4:29:13<3:36:04,  1.81s/it]2025-08-22:23:03:54,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4877/12032 [4:29:16<4:45:22,  2.39s/it]2025-08-22:23:03:58,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4878/12032 [4:29:18<4:21:35,  2.19s/it]2025-08-22:23:04:00,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4879/12032 [4:29:20<3:56:17,  1.98s/it]2025-08-22:23:04:01,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4880/12032 [4:29:22<4:29:54,  2.26s/it]2025-08-22:23:04:04,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4881/12032 [4:29:24<4:17:03,  2.16s/it]2025-08-22:23:04:06,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4882/12032 [4:29:25<3:34:13,  1.80s/it]2025-08-22:23:04:07,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4883/12032 [4:29:28<4:08:57,  2.09s/it]2025-08-22:23:04:10,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4884/12032 [4:29:30<3:53:46,  1.96s/it]2025-08-22:23:04:12,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4885/12032 [4:29:31<3:20:04,  1.68s/it]2025-08-22:23:04:13,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4886/12032 [4:29:34<4:10:37,  2.10s/it]2025-08-22:23:04:16,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4887/12032 [4:29:36<4:12:20,  2.12s/it]2025-08-22:23:04:18,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4888/12032 [4:29:37<3:29:56,  1.76s/it]2025-08-22:23:04:19,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4889/12032 [4:29:38<3:14:54,  1.64s/it]2025-08-22:23:04:20,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4890/12032 [4:29:42<4:31:23,  2.28s/it]2025-08-22:23:04:24,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4891/12032 [4:29:44<4:09:41,  2.10s/it]2025-08-22:23:04:26,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4892/12032 [4:29:46<4:19:16,  2.18s/it]2025-08-22:23:04:28,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4893/12032 [4:29:49<4:56:01,  2.49s/it]2025-08-22:23:04:31,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4894/12032 [4:29:53<5:20:54,  2.70s/it]2025-08-22:23:04:34,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4895/12032 [4:29:56<5:48:14,  2.93s/it]2025-08-22:23:04:38,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4896/12032 [4:30:00<6:18:30,  3.18s/it]2025-08-22:23:04:42,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4897/12032 [4:30:04<6:38:36,  3.35s/it]2025-08-22:23:04:45,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4898/12032 [4:30:07<6:53:15,  3.48s/it]2025-08-22:23:04:49,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4899/12032 [4:30:11<7:06:41,  3.59s/it]2025-08-22:23:04:53,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4900/12032 [4:30:15<7:15:54,  3.67s/it]2025-08-22:23:04:57,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4901/12032 [4:30:18<6:37:30,  3.34s/it]2025-08-22:23:04:59,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4902/12032 [4:30:21<6:37:22,  3.34s/it]2025-08-22:23:05:03,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4903/12032 [4:30:25<6:47:08,  3.43s/it]2025-08-22:23:05:06,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4904/12032 [4:30:28<6:51:02,  3.46s/it]2025-08-22:23:05:10,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4905/12032 [4:30:32<7:02:24,  3.56s/it]2025-08-22:23:05:14,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4906/12032 [4:30:35<6:48:01,  3.44s/it]2025-08-22:23:05:17,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4907/12032 [4:30:39<7:00:02,  3.54s/it]2025-08-22:23:05:21,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4908/12032 [4:30:43<7:07:42,  3.60s/it]2025-08-22:23:05:24,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4909/12032 [4:30:44<5:56:35,  3.00s/it]2025-08-22:23:05:26,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4910/12032 [4:30:46<5:15:44,  2.66s/it]2025-08-22:23:05:28,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4911/12032 [4:30:48<4:43:32,  2.39s/it]2025-08-22:23:05:30,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4912/12032 [4:30:52<5:33:05,  2.81s/it]2025-08-22:23:05:33,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4913/12032 [4:30:55<5:48:51,  2.94s/it]2025-08-22:23:05:37,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4914/12032 [4:30:59<6:16:45,  3.18s/it]2025-08-22:23:05:40,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4915/12032 [4:31:02<6:31:24,  3.30s/it]2025-08-22:23:05:44,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4916/12032 [4:31:04<5:25:16,  2.74s/it]2025-08-22:23:05:45,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4917/12032 [4:31:05<4:26:08,  2.24s/it]2025-08-22:23:05:46,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4918/12032 [4:31:08<5:21:21,  2.71s/it]2025-08-22:23:05:50,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4919/12032 [4:31:12<6:02:19,  3.06s/it]2025-08-22:23:05:54,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4920/12032 [4:31:15<5:41:09,  2.88s/it]2025-08-22:23:05:57,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4921/12032 [4:31:17<5:32:03,  2.80s/it]2025-08-22:23:05:59,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4922/12032 [4:31:21<6:05:21,  3.08s/it]2025-08-22:23:06:03,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4923/12032 [4:31:24<5:45:25,  2.92s/it]2025-08-22:23:06:05,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4924/12032 [4:31:27<6:04:37,  3.08s/it]2025-08-22:23:06:09,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4925/12032 [4:31:28<4:54:57,  2.49s/it]2025-08-22:23:06:10,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4926/12032 [4:31:29<3:52:25,  1.96s/it]2025-08-22:23:06:11,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4927/12032 [4:31:30<3:21:07,  1.70s/it]2025-08-22:23:06:12,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4928/12032 [4:31:32<3:28:17,  1.76s/it]2025-08-22:23:06:14,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4929/12032 [4:31:34<3:32:24,  1.79s/it]2025-08-22:23:06:16,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4930/12032 [4:31:35<3:27:04,  1.75s/it]2025-08-22:23:06:17,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4931/12032 [4:31:37<3:13:29,  1.63s/it]2025-08-22:23:06:19,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4932/12032 [4:31:39<3:27:01,  1.75s/it]2025-08-22:23:06:21,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4933/12032 [4:31:40<3:00:42,  1.53s/it]2025-08-22:23:06:22,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4934/12032 [4:31:44<4:21:26,  2.21s/it]2025-08-22:23:06:26,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4935/12032 [4:31:47<5:17:07,  2.68s/it]2025-08-22:23:06:29,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4936/12032 [4:31:51<5:44:46,  2.92s/it]2025-08-22:23:06:33,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4937/12032 [4:31:53<5:21:43,  2.72s/it]2025-08-22:23:06:35,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4938/12032 [4:31:54<4:30:44,  2.29s/it]2025-08-22:23:06:36,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4939/12032 [4:31:56<4:13:50,  2.15s/it]2025-08-22:23:06:38,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4940/12032 [4:31:58<3:50:09,  1.95s/it]2025-08-22:23:06:40,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4941/12032 [4:32:00<4:07:50,  2.10s/it]2025-08-22:23:06:42,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4942/12032 [4:32:03<4:46:29,  2.42s/it]2025-08-22:23:06:45,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4943/12032 [4:32:07<5:32:54,  2.82s/it]2025-08-22:23:06:49,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4944/12032 [4:32:11<6:06:44,  3.10s/it]2025-08-22:23:06:53,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4945/12032 [4:32:13<5:33:32,  2.82s/it]2025-08-22:23:06:55,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4946/12032 [4:32:17<6:07:50,  3.11s/it]2025-08-22:23:06:59,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4947/12032 [4:32:18<4:50:35,  2.46s/it]2025-08-22:23:07:00,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4948/12032 [4:32:19<4:07:41,  2.10s/it]2025-08-22:23:07:01,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4949/12032 [4:32:23<5:06:51,  2.60s/it]2025-08-22:23:07:05,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4950/12032 [4:32:24<4:10:50,  2.13s/it]2025-08-22:23:07:06,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4951/12032 [4:32:25<3:41:43,  1.88s/it]2025-08-22:23:07:07,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4952/12032 [4:32:29<4:49:30,  2.45s/it]2025-08-22:23:07:11,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4953/12032 [4:32:30<4:07:59,  2.10s/it]2025-08-22:23:07:12,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4954/12032 [4:32:34<4:50:06,  2.46s/it]2025-08-22:23:07:15,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4955/12032 [4:32:35<4:02:59,  2.06s/it]2025-08-22:23:07:16,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4956/12032 [4:32:38<5:03:35,  2.57s/it]2025-08-22:23:07:20,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4957/12032 [4:32:42<5:46:21,  2.94s/it]2025-08-22:23:07:24,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4958/12032 [4:32:45<5:58:31,  3.04s/it]2025-08-22:23:07:27,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4959/12032 [4:32:46<4:37:48,  2.36s/it]2025-08-22:23:07:28,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4960/12032 [4:32:47<3:46:19,  1.92s/it]2025-08-22:23:07:29,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4961/12032 [4:32:49<3:26:56,  1.76s/it]2025-08-22:23:07:30,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4962/12032 [4:32:49<2:54:07,  1.48s/it]2025-08-22:23:07:31,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████      | 4963/12032 [4:32:52<3:49:58,  1.95s/it]2025-08-22:23:07:34,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4964/12032 [4:32:56<4:54:57,  2.50s/it]2025-08-22:23:07:38,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4965/12032 [4:33:00<5:39:10,  2.88s/it]2025-08-22:23:07:42,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4966/12032 [4:33:03<5:56:22,  3.03s/it]2025-08-22:23:07:45,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4967/12032 [4:33:07<6:23:00,  3.25s/it]2025-08-22:23:07:49,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4968/12032 [4:33:11<6:28:32,  3.30s/it]2025-08-22:23:07:52,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4969/12032 [4:33:14<6:45:25,  3.44s/it]2025-08-22:23:07:56,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4970/12032 [4:33:18<6:57:23,  3.55s/it]2025-08-22:23:08:00,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4971/12032 [4:33:22<7:06:11,  3.62s/it]2025-08-22:23:08:04,204 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4972/12032 [4:33:24<6:13:01,  3.17s/it]2025-08-22:23:08:06,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4973/12032 [4:33:26<5:26:59,  2.78s/it]2025-08-22:23:08:08,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4974/12032 [4:33:30<6:03:10,  3.09s/it]2025-08-22:23:08:11,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4975/12032 [4:33:33<6:27:39,  3.30s/it]2025-08-22:23:08:15,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4976/12032 [4:33:36<6:15:25,  3.19s/it]2025-08-22:23:08:18,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4977/12032 [4:33:40<6:38:11,  3.39s/it]2025-08-22:23:08:22,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4978/12032 [4:33:41<5:01:12,  2.56s/it]2025-08-22:23:08:23,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4979/12032 [4:33:42<3:53:28,  1.99s/it]2025-08-22:23:08:23,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4980/12032 [4:33:44<4:05:00,  2.08s/it]2025-08-22:23:08:26,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4981/12032 [4:33:48<5:05:03,  2.60s/it]2025-08-22:23:08:29,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4982/12032 [4:33:50<5:02:12,  2.57s/it]2025-08-22:23:08:32,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4983/12032 [4:33:53<5:23:07,  2.75s/it]2025-08-22:23:08:35,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4984/12032 [4:33:54<4:25:51,  2.26s/it]2025-08-22:23:08:36,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4985/12032 [4:33:56<3:44:21,  1.91s/it]2025-08-22:23:08:37,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4986/12032 [4:33:59<4:25:49,  2.26s/it]2025-08-22:23:08:40,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4987/12032 [4:34:00<3:57:49,  2.03s/it]2025-08-22:23:08:42,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4988/12032 [4:34:02<4:05:01,  2.09s/it]2025-08-22:23:08:44,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4989/12032 [4:34:06<5:07:07,  2.62s/it]2025-08-22:23:08:48,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4990/12032 [4:34:07<4:14:35,  2.17s/it]2025-08-22:23:08:49,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4991/12032 [4:34:08<3:40:04,  1.88s/it]2025-08-22:23:08:50,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4992/12032 [4:34:10<3:27:52,  1.77s/it]2025-08-22:23:08:52,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  41%|████▏     | 4993/12032 [4:34:14<4:38:48,  2.38s/it]2025-08-22:23:08:56,120 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4994/12032 [4:34:15<3:47:06,  1.94s/it]2025-08-22:23:08:57,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4995/12032 [4:34:17<4:16:55,  2.19s/it]2025-08-22:23:08:59,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4996/12032 [4:34:20<4:43:07,  2.41s/it]2025-08-22:23:09:02,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4997/12032 [4:34:21<3:54:31,  2.00s/it]2025-08-22:23:09:03,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4998/12032 [4:34:24<4:29:23,  2.30s/it]2025-08-22:23:09:06,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 4999/12032 [4:34:26<4:14:49,  2.17s/it]2025-08-22:23:09:08,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5000/12032 [4:34:28<3:53:49,  2.00s/it]2025-08-22:23:09:10,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5001/12032 [4:34:30<4:09:25,  2.13s/it]2025-08-22:23:09:12,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5002/12032 [4:34:33<4:11:03,  2.14s/it]2025-08-22:23:09:14,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5003/12032 [4:34:35<4:13:28,  2.16s/it]2025-08-22:23:09:17,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5004/12032 [4:34:36<3:33:01,  1.82s/it]2025-08-22:23:09:18,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5005/12032 [4:34:40<4:42:01,  2.41s/it]2025-08-22:23:09:21,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5006/12032 [4:34:41<4:05:45,  2.10s/it]2025-08-22:23:09:23,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5007/12032 [4:34:42<3:40:35,  1.88s/it]2025-08-22:23:09:24,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5008/12032 [4:34:43<3:03:29,  1.57s/it]2025-08-22:23:09:25,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5009/12032 [4:34:44<2:34:54,  1.32s/it]2025-08-22:23:09:26,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5010/12032 [4:34:48<4:02:10,  2.07s/it]2025-08-22:23:09:30,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5011/12032 [4:34:49<3:21:33,  1.72s/it]2025-08-22:23:09:30,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5012/12032 [4:34:52<4:27:51,  2.29s/it]2025-08-22:23:09:34,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5013/12032 [4:34:54<3:53:20,  1.99s/it]2025-08-22:23:09:35,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5014/12032 [4:34:55<3:18:18,  1.70s/it]2025-08-22:23:09:36,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5015/12032 [4:34:56<3:07:09,  1.60s/it]2025-08-22:23:09:38,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5016/12032 [4:34:57<2:50:45,  1.46s/it]2025-08-22:23:09:39,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5017/12032 [4:35:00<3:34:53,  1.84s/it]2025-08-22:23:09:42,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5018/12032 [4:35:03<4:37:39,  2.38s/it]2025-08-22:23:09:45,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5019/12032 [4:35:04<3:42:12,  1.90s/it]2025-08-22:23:09:46,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5020/12032 [4:35:08<4:48:21,  2.47s/it]2025-08-22:23:09:50,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5021/12032 [4:35:10<4:43:03,  2.42s/it]2025-08-22:23:09:52,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5022/12032 [4:35:11<3:52:33,  1.99s/it]2025-08-22:23:09:53,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5023/12032 [4:35:12<3:12:55,  1.65s/it]2025-08-22:23:09:54,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5024/12032 [4:35:13<2:41:38,  1.38s/it]2025-08-22:23:09:55,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5025/12032 [4:35:14<2:39:12,  1.36s/it]2025-08-22:23:09:56,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5026/12032 [4:35:18<4:03:27,  2.08s/it]2025-08-22:23:10:00,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5027/12032 [4:35:19<3:18:31,  1.70s/it]2025-08-22:23:10:01,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5028/12032 [4:35:22<4:14:28,  2.18s/it]2025-08-22:23:10:04,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5029/12032 [4:35:23<3:35:57,  1.85s/it]2025-08-22:23:10:05,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5030/12032 [4:35:24<3:16:10,  1.68s/it]2025-08-22:23:10:06,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5031/12032 [4:35:28<4:29:52,  2.31s/it]2025-08-22:23:10:10,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5032/12032 [4:35:30<4:12:22,  2.16s/it]2025-08-22:23:10:12,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5033/12032 [4:35:34<5:08:42,  2.65s/it]2025-08-22:23:10:16,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5034/12032 [4:35:37<5:11:28,  2.67s/it]2025-08-22:23:10:18,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5035/12032 [4:35:40<5:49:42,  3.00s/it]2025-08-22:23:10:22,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5036/12032 [4:35:43<5:48:55,  2.99s/it]2025-08-22:23:10:25,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5037/12032 [4:35:45<5:20:52,  2.75s/it]2025-08-22:23:10:27,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5038/12032 [4:35:48<5:16:19,  2.71s/it]2025-08-22:23:10:30,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5039/12032 [4:35:50<4:55:19,  2.53s/it]2025-08-22:23:10:32,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5040/12032 [4:35:54<5:38:49,  2.91s/it]2025-08-22:23:10:36,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5041/12032 [4:35:58<6:11:01,  3.18s/it]2025-08-22:23:10:40,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5042/12032 [4:36:02<6:31:44,  3.36s/it]2025-08-22:23:10:43,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5043/12032 [4:36:05<6:24:06,  3.30s/it]2025-08-22:23:10:47,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5044/12032 [4:36:08<6:09:32,  3.17s/it]2025-08-22:23:10:49,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5045/12032 [4:36:11<6:29:49,  3.35s/it]2025-08-22:23:10:53,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5046/12032 [4:36:15<6:34:20,  3.39s/it]2025-08-22:23:10:57,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5047/12032 [4:36:19<6:49:16,  3.52s/it]2025-08-22:23:11:01,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5048/12032 [4:36:23<7:01:00,  3.62s/it]2025-08-22:23:11:04,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5049/12032 [4:36:24<5:43:28,  2.95s/it]2025-08-22:23:11:06,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5050/12032 [4:36:26<5:00:38,  2.58s/it]2025-08-22:23:11:07,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5051/12032 [4:36:29<5:25:00,  2.79s/it]2025-08-22:23:11:11,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5052/12032 [4:36:31<5:01:12,  2.59s/it]2025-08-22:23:11:13,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5053/12032 [4:36:33<4:50:13,  2.50s/it]2025-08-22:23:11:15,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5054/12032 [4:36:34<3:50:21,  1.98s/it]2025-08-22:23:11:16,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5055/12032 [4:36:38<4:48:47,  2.48s/it]2025-08-22:23:11:20,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5056/12032 [4:36:42<5:35:43,  2.89s/it]2025-08-22:23:11:23,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5057/12032 [4:36:43<4:29:57,  2.32s/it]2025-08-22:23:11:24,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5058/12032 [4:36:45<4:33:48,  2.36s/it]2025-08-22:23:11:27,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5059/12032 [4:36:49<5:20:18,  2.76s/it]2025-08-22:23:11:31,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5060/12032 [4:36:50<4:30:46,  2.33s/it]2025-08-22:23:11:32,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5061/12032 [4:36:52<4:15:05,  2.20s/it]2025-08-22:23:11:34,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5062/12032 [4:36:53<3:27:15,  1.78s/it]2025-08-22:23:11:35,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5063/12032 [4:36:57<4:37:43,  2.39s/it]2025-08-22:23:11:38,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5064/12032 [4:36:57<3:41:07,  1.90s/it]2025-08-22:23:11:39,663 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5065/12032 [4:36:58<3:06:53,  1.61s/it]2025-08-22:23:11:40,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5066/12032 [4:36:59<2:49:15,  1.46s/it]2025-08-22:23:11:41,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5067/12032 [4:37:03<4:09:43,  2.15s/it]2025-08-22:23:11:45,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5068/12032 [4:37:07<5:07:50,  2.65s/it]2025-08-22:23:11:49,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5069/12032 [4:37:08<4:03:26,  2.10s/it]2025-08-22:23:11:50,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5070/12032 [4:37:11<5:00:56,  2.59s/it]2025-08-22:23:11:53,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5071/12032 [4:37:15<5:45:00,  2.97s/it]2025-08-22:23:11:57,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5072/12032 [4:37:18<5:47:02,  2.99s/it]2025-08-22:23:12:00,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5073/12032 [4:37:21<5:39:57,  2.93s/it]2025-08-22:23:12:03,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5074/12032 [4:37:23<4:55:31,  2.55s/it]2025-08-22:23:12:05,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5075/12032 [4:37:24<4:16:45,  2.21s/it]2025-08-22:23:12:06,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5076/12032 [4:37:25<3:38:12,  1.88s/it]2025-08-22:23:12:07,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5077/12032 [4:37:28<4:14:50,  2.20s/it]2025-08-22:23:12:10,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5078/12032 [4:37:30<3:44:56,  1.94s/it]2025-08-22:23:12:11,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5079/12032 [4:37:31<3:40:16,  1.90s/it]2025-08-22:23:12:13,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5080/12032 [4:37:35<4:46:38,  2.47s/it]2025-08-22:23:12:17,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5081/12032 [4:37:38<4:38:43,  2.41s/it]2025-08-22:23:12:19,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5082/12032 [4:37:38<3:30:19,  1.82s/it]2025-08-22:23:12:20,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5083/12032 [4:37:40<3:21:10,  1.74s/it]2025-08-22:23:12:21,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5084/12032 [4:37:41<3:06:46,  1.61s/it]2025-08-22:23:12:23,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5085/12032 [4:37:42<3:01:43,  1.57s/it]2025-08-22:23:12:24,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5086/12032 [4:37:44<2:50:00,  1.47s/it]2025-08-22:23:12:25,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5087/12032 [4:37:45<3:01:48,  1.57s/it]2025-08-22:23:12:27,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5088/12032 [4:37:49<4:18:09,  2.23s/it]2025-08-22:23:12:31,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5089/12032 [4:37:53<5:11:53,  2.70s/it]2025-08-22:23:12:35,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5090/12032 [4:37:57<5:48:43,  3.01s/it]2025-08-22:23:12:38,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5091/12032 [4:38:00<6:14:35,  3.24s/it]2025-08-22:23:12:42,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5092/12032 [4:38:04<6:32:25,  3.39s/it]2025-08-22:23:12:46,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5093/12032 [4:38:07<5:59:30,  3.11s/it]2025-08-22:23:12:48,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5094/12032 [4:38:10<6:21:47,  3.30s/it]2025-08-22:23:12:52,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5095/12032 [4:38:14<6:38:28,  3.45s/it]2025-08-22:23:12:56,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5096/12032 [4:38:18<6:50:43,  3.55s/it]2025-08-22:23:13:00,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5097/12032 [4:38:22<6:58:41,  3.62s/it]2025-08-22:23:13:04,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5098/12032 [4:38:26<7:03:50,  3.67s/it]2025-08-22:23:13:07,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5099/12032 [4:38:27<5:48:46,  3.02s/it]2025-08-22:23:13:09,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5100/12032 [4:38:31<6:15:55,  3.25s/it]2025-08-22:23:13:13,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5101/12032 [4:38:35<6:34:44,  3.42s/it]2025-08-22:23:13:16,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5102/12032 [4:38:38<6:47:27,  3.53s/it]2025-08-22:23:13:20,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5103/12032 [4:38:42<6:56:12,  3.60s/it]2025-08-22:23:13:24,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5104/12032 [4:38:46<7:03:23,  3.67s/it]2025-08-22:23:13:28,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5105/12032 [4:38:50<7:06:52,  3.70s/it]2025-08-22:23:13:32,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5106/12032 [4:38:53<6:39:18,  3.46s/it]2025-08-22:23:13:35,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5107/12032 [4:38:56<6:21:15,  3.30s/it]2025-08-22:23:13:37,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5108/12032 [4:38:59<6:37:47,  3.45s/it]2025-08-22:23:13:41,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5109/12032 [4:39:03<6:33:27,  3.41s/it]2025-08-22:23:13:45,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5110/12032 [4:39:06<6:45:24,  3.51s/it]2025-08-22:23:13:48,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5111/12032 [4:39:10<6:53:55,  3.59s/it]2025-08-22:23:13:52,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5112/12032 [4:39:14<6:59:34,  3.64s/it]2025-08-22:23:13:56,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  42%|████▏     | 5113/12032 [4:39:18<7:05:13,  3.69s/it]2025-08-22:23:14:00,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5114/12032 [4:39:22<7:08:16,  3.71s/it]2025-08-22:23:14:03,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5115/12032 [4:39:25<7:09:28,  3.73s/it]2025-08-22:23:14:07,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5116/12032 [4:39:29<7:07:01,  3.70s/it]2025-08-22:23:14:11,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5117/12032 [4:39:33<7:08:42,  3.72s/it]2025-08-22:23:14:15,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5118/12032 [4:39:37<7:10:47,  3.74s/it]2025-08-22:23:14:18,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5119/12032 [4:39:38<5:44:48,  2.99s/it]2025-08-22:23:14:20,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5120/12032 [4:39:39<4:47:14,  2.49s/it]2025-08-22:23:14:21,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5121/12032 [4:39:40<3:48:53,  1.99s/it]2025-08-22:23:14:22,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5122/12032 [4:39:44<4:52:58,  2.54s/it]2025-08-22:23:14:26,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5123/12032 [4:39:48<5:36:13,  2.92s/it]2025-08-22:23:14:29,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5124/12032 [4:39:49<4:43:34,  2.46s/it]2025-08-22:23:14:31,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5125/12032 [4:39:50<4:03:53,  2.12s/it]2025-08-22:23:14:32,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5126/12032 [4:39:52<3:49:17,  1.99s/it]2025-08-22:23:14:34,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5127/12032 [4:39:54<3:39:35,  1.91s/it]2025-08-22:23:14:35,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5128/12032 [4:39:55<3:31:33,  1.84s/it]2025-08-22:23:14:37,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5129/12032 [4:39:57<3:15:49,  1.70s/it]2025-08-22:23:14:39,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5130/12032 [4:39:58<2:50:46,  1.48s/it]2025-08-22:23:14:40,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5131/12032 [4:40:02<4:11:47,  2.19s/it]2025-08-22:23:14:43,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5132/12032 [4:40:02<3:29:31,  1.82s/it]2025-08-22:23:14:44,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5133/12032 [4:40:04<3:02:29,  1.59s/it]2025-08-22:23:14:45,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5134/12032 [4:40:07<4:18:26,  2.25s/it]2025-08-22:23:14:49,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5135/12032 [4:40:09<3:46:30,  1.97s/it]2025-08-22:23:14:50,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5136/12032 [4:40:12<4:49:10,  2.52s/it]2025-08-22:23:14:54,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5137/12032 [4:40:16<5:31:25,  2.88s/it]2025-08-22:23:14:58,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5138/12032 [4:40:17<4:33:28,  2.38s/it]2025-08-22:23:14:59,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5139/12032 [4:40:21<5:25:33,  2.83s/it]2025-08-22:23:15:03,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5140/12032 [4:40:22<4:28:00,  2.33s/it]2025-08-22:23:15:04,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5141/12032 [4:40:23<3:29:39,  1.83s/it]2025-08-22:23:15:05,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5142/12032 [4:40:24<3:01:02,  1.58s/it]2025-08-22:23:15:06,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5143/12032 [4:40:28<4:15:41,  2.23s/it]2025-08-22:23:15:10,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5144/12032 [4:40:31<4:57:58,  2.60s/it]2025-08-22:23:15:13,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5145/12032 [4:40:34<5:14:31,  2.74s/it]2025-08-22:23:15:16,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5146/12032 [4:40:38<5:47:17,  3.03s/it]2025-08-22:23:15:20,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5147/12032 [4:40:40<4:56:27,  2.58s/it]2025-08-22:23:15:21,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5148/12032 [4:40:43<5:37:01,  2.94s/it]2025-08-22:23:15:25,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5149/12032 [4:40:44<4:32:53,  2.38s/it]2025-08-22:23:15:26,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5150/12032 [4:40:45<3:43:56,  1.95s/it]2025-08-22:23:15:27,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5151/12032 [4:40:47<3:24:47,  1.79s/it]2025-08-22:23:15:29,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5152/12032 [4:40:48<3:14:18,  1.69s/it]2025-08-22:23:15:30,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5153/12032 [4:40:52<4:11:51,  2.20s/it]2025-08-22:23:15:33,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5154/12032 [4:40:53<3:31:45,  1.85s/it]2025-08-22:23:15:35,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5155/12032 [4:40:54<3:11:13,  1.67s/it]2025-08-22:23:15:36,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5156/12032 [4:40:55<2:51:27,  1.50s/it]2025-08-22:23:15:37,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5157/12032 [4:40:59<4:09:34,  2.18s/it]2025-08-22:23:15:41,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5158/12032 [4:41:00<3:35:44,  1.88s/it]2025-08-22:23:15:42,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5159/12032 [4:41:01<3:15:34,  1.71s/it]2025-08-22:23:15:43,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5160/12032 [4:41:03<3:09:26,  1.65s/it]2025-08-22:23:15:45,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5161/12032 [4:41:04<2:54:10,  1.52s/it]2025-08-22:23:15:46,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5162/12032 [4:41:05<2:42:26,  1.42s/it]2025-08-22:23:15:47,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5163/12032 [4:41:09<4:01:41,  2.11s/it]2025-08-22:23:15:51,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5164/12032 [4:41:13<5:00:18,  2.62s/it]2025-08-22:23:15:55,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5165/12032 [4:41:17<5:40:33,  2.98s/it]2025-08-22:23:15:58,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5166/12032 [4:41:20<6:09:37,  3.23s/it]2025-08-22:23:16:02,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5167/12032 [4:41:24<6:29:27,  3.40s/it]2025-08-22:23:16:06,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5168/12032 [4:41:28<6:43:37,  3.53s/it]2025-08-22:23:16:10,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5169/12032 [4:41:32<6:52:13,  3.60s/it]2025-08-22:23:16:14,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5170/12032 [4:41:34<6:21:19,  3.33s/it]2025-08-22:23:16:16,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5171/12032 [4:41:37<5:38:28,  2.96s/it]2025-08-22:23:16:18,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5172/12032 [4:41:38<4:54:21,  2.57s/it]2025-08-22:23:16:20,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5173/12032 [4:41:42<5:33:37,  2.92s/it]2025-08-22:23:16:24,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5174/12032 [4:41:46<6:02:43,  3.17s/it]2025-08-22:23:16:28,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5175/12032 [4:41:48<5:30:47,  2.89s/it]2025-08-22:23:16:30,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5176/12032 [4:41:50<5:11:50,  2.73s/it]2025-08-22:23:16:32,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5177/12032 [4:41:54<5:48:53,  3.05s/it]2025-08-22:23:16:36,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5178/12032 [4:41:56<5:08:34,  2.70s/it]2025-08-22:23:16:38,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5179/12032 [4:41:58<4:33:46,  2.40s/it]2025-08-22:23:16:40,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5180/12032 [4:42:01<5:20:45,  2.81s/it]2025-08-22:23:16:43,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5181/12032 [4:42:05<5:34:07,  2.93s/it]2025-08-22:23:16:47,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5182/12032 [4:42:06<4:32:23,  2.39s/it]2025-08-22:23:16:48,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5183/12032 [4:42:07<4:00:09,  2.10s/it]2025-08-22:23:16:49,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5184/12032 [4:42:08<3:25:29,  1.80s/it]2025-08-22:23:16:50,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5185/12032 [4:42:12<4:32:20,  2.39s/it]2025-08-22:23:16:54,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5186/12032 [4:42:15<5:06:28,  2.69s/it]2025-08-22:23:16:57,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5187/12032 [4:42:17<4:09:58,  2.19s/it]2025-08-22:23:16:58,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5188/12032 [4:42:17<3:15:59,  1.72s/it]2025-08-22:23:16:59,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5189/12032 [4:42:19<3:28:18,  1.83s/it]2025-08-22:23:17:01,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5190/12032 [4:42:22<4:01:16,  2.12s/it]2025-08-22:23:17:04,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5191/12032 [4:42:26<4:59:24,  2.63s/it]2025-08-22:23:17:08,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5192/12032 [4:42:28<4:51:30,  2.56s/it]2025-08-22:23:17:10,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5193/12032 [4:42:30<4:09:29,  2.19s/it]2025-08-22:23:17:11,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5194/12032 [4:42:30<3:27:15,  1.82s/it]2025-08-22:23:17:12,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5195/12032 [4:42:31<2:54:31,  1.53s/it]2025-08-22:23:17:13,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5196/12032 [4:42:32<2:40:29,  1.41s/it]2025-08-22:23:17:14,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5197/12032 [4:42:33<2:25:13,  1.27s/it]2025-08-22:23:17:15,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5198/12032 [4:42:36<2:58:46,  1.57s/it]2025-08-22:23:17:18,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5199/12032 [4:42:39<4:12:50,  2.22s/it]2025-08-22:23:17:21,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5200/12032 [4:42:43<5:06:04,  2.69s/it]2025-08-22:23:17:25,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5201/12032 [4:42:45<4:30:05,  2.37s/it]2025-08-22:23:17:27,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5202/12032 [4:42:46<3:44:31,  1.97s/it]2025-08-22:23:17:28,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5203/12032 [4:42:48<3:49:42,  2.02s/it]2025-08-22:23:17:30,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5204/12032 [4:42:49<3:12:31,  1.69s/it]2025-08-22:23:17:31,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5205/12032 [4:42:52<3:49:13,  2.01s/it]2025-08-22:23:17:34,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5206/12032 [4:42:53<3:16:39,  1.73s/it]2025-08-22:23:17:35,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5207/12032 [4:42:54<2:59:48,  1.58s/it]2025-08-22:23:17:36,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5208/12032 [4:42:55<2:37:41,  1.39s/it]2025-08-22:23:17:37,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5209/12032 [4:42:56<2:38:48,  1.40s/it]2025-08-22:23:17:38,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5210/12032 [4:42:58<2:32:33,  1.34s/it]2025-08-22:23:17:39,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5211/12032 [4:42:59<2:38:35,  1.39s/it]2025-08-22:23:17:41,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5212/12032 [4:43:00<2:20:26,  1.24s/it]2025-08-22:23:17:42,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5213/12032 [4:43:04<3:47:18,  2.00s/it]2025-08-22:23:17:46,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5214/12032 [4:43:06<3:44:59,  1.98s/it]2025-08-22:23:17:48,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5215/12032 [4:43:10<4:48:26,  2.54s/it]2025-08-22:23:17:51,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5216/12032 [4:43:13<5:30:25,  2.91s/it]2025-08-22:23:17:55,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5217/12032 [4:43:16<5:23:46,  2.85s/it]2025-08-22:23:17:58,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5218/12032 [4:43:20<5:57:00,  3.14s/it]2025-08-22:23:18:02,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5219/12032 [4:43:24<6:19:05,  3.34s/it]2025-08-22:23:18:05,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5220/12032 [4:43:27<6:34:35,  3.48s/it]2025-08-22:23:18:09,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5221/12032 [4:43:31<6:47:07,  3.59s/it]2025-08-22:23:18:13,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5222/12032 [4:43:34<6:02:35,  3.19s/it]2025-08-22:23:18:15,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5223/12032 [4:43:36<5:38:44,  2.98s/it]2025-08-22:23:18:18,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5224/12032 [4:43:40<5:59:37,  3.17s/it]2025-08-22:23:18:21,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5225/12032 [4:43:43<6:14:56,  3.30s/it]2025-08-22:23:18:25,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5226/12032 [4:43:47<6:32:07,  3.46s/it]2025-08-22:23:18:29,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5227/12032 [4:43:51<6:44:31,  3.57s/it]2025-08-22:23:18:33,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5228/12032 [4:43:55<6:52:54,  3.64s/it]2025-08-22:23:18:37,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5229/12032 [4:43:59<6:59:12,  3.70s/it]2025-08-22:23:18:40,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5230/12032 [4:44:02<7:02:38,  3.73s/it]2025-08-22:23:18:44,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5231/12032 [4:44:06<7:05:06,  3.75s/it]2025-08-22:23:18:48,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5232/12032 [4:44:10<7:06:56,  3.77s/it]2025-08-22:23:18:52,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  43%|████▎     | 5233/12032 [4:44:14<7:08:56,  3.79s/it]2025-08-22:23:18:56,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5234/12032 [4:44:18<7:09:22,  3.79s/it]2025-08-22:23:18:59,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5235/12032 [4:44:21<7:10:05,  3.80s/it]2025-08-22:23:19:03,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5236/12032 [4:44:22<5:27:04,  2.89s/it]2025-08-22:23:19:04,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5237/12032 [4:44:23<4:15:10,  2.25s/it]2025-08-22:23:19:05,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5238/12032 [4:44:27<5:14:19,  2.78s/it]2025-08-22:23:19:09,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5239/12032 [4:44:28<4:22:04,  2.31s/it]2025-08-22:23:19:10,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5240/12032 [4:44:29<3:37:20,  1.92s/it]2025-08-22:23:19:11,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5241/12032 [4:44:32<4:22:17,  2.32s/it]2025-08-22:23:19:14,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5242/12032 [4:44:35<4:41:26,  2.49s/it]2025-08-22:23:19:17,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5243/12032 [4:44:39<5:25:46,  2.88s/it]2025-08-22:23:19:21,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5244/12032 [4:44:40<4:20:21,  2.30s/it]2025-08-22:23:19:22,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5245/12032 [4:44:41<3:35:44,  1.91s/it]2025-08-22:23:19:23,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5246/12032 [4:44:42<3:09:46,  1.68s/it]2025-08-22:23:19:24,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5247/12032 [4:44:44<3:20:56,  1.78s/it]2025-08-22:23:19:26,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5248/12032 [4:44:46<3:39:23,  1.94s/it]2025-08-22:23:19:28,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5249/12032 [4:44:48<3:09:42,  1.68s/it]2025-08-22:23:19:29,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5250/12032 [4:44:50<3:45:33,  2.00s/it]2025-08-22:23:19:32,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5251/12032 [4:44:51<3:04:42,  1.63s/it]2025-08-22:23:19:33,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5252/12032 [4:44:54<3:34:19,  1.90s/it]2025-08-22:23:19:35,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5253/12032 [4:44:57<4:39:27,  2.47s/it]2025-08-22:23:19:39,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5254/12032 [4:45:01<5:24:28,  2.87s/it]2025-08-22:23:19:43,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5255/12032 [4:45:02<4:17:27,  2.28s/it]2025-08-22:23:19:44,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5256/12032 [4:45:03<3:17:31,  1.75s/it]2025-08-22:23:19:44,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5257/12032 [4:45:03<2:41:17,  1.43s/it]2025-08-22:23:19:45,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5258/12032 [4:45:04<2:25:08,  1.29s/it]2025-08-22:23:19:46,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5259/12032 [4:45:05<2:11:31,  1.17s/it]2025-08-22:23:19:47,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5260/12032 [4:45:06<2:00:48,  1.07s/it]2025-08-22:23:19:48,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5261/12032 [4:45:10<3:35:15,  1.91s/it]2025-08-22:23:19:52,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5262/12032 [4:45:11<3:12:07,  1.70s/it]2025-08-22:23:19:53,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▎     | 5263/12032 [4:45:14<3:39:46,  1.95s/it]2025-08-22:23:19:55,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5264/12032 [4:45:15<3:10:09,  1.69s/it]2025-08-22:23:19:57,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5265/12032 [4:45:18<4:22:02,  2.32s/it]2025-08-22:23:20:00,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5266/12032 [4:45:20<3:39:02,  1.94s/it]2025-08-22:23:20:01,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5267/12032 [4:45:20<3:05:00,  1.64s/it]2025-08-22:23:20:02,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5268/12032 [4:45:21<2:38:36,  1.41s/it]2025-08-22:23:20:03,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5269/12032 [4:45:23<2:41:25,  1.43s/it]2025-08-22:23:20:05,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5270/12032 [4:45:24<2:38:22,  1.41s/it]2025-08-22:23:20:06,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5271/12032 [4:45:28<3:59:26,  2.12s/it]2025-08-22:23:20:10,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5272/12032 [4:45:31<4:18:25,  2.29s/it]2025-08-22:23:20:12,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5273/12032 [4:45:32<3:35:59,  1.92s/it]2025-08-22:23:20:14,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5274/12032 [4:45:34<3:43:49,  1.99s/it]2025-08-22:23:20:16,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5275/12032 [4:45:36<3:55:21,  2.09s/it]2025-08-22:23:20:18,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5276/12032 [4:45:38<3:35:44,  1.92s/it]2025-08-22:23:20:20,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5277/12032 [4:45:40<3:40:09,  1.96s/it]2025-08-22:23:20:22,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5278/12032 [4:45:41<3:13:51,  1.72s/it]2025-08-22:23:20:23,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5279/12032 [4:45:43<3:25:13,  1.82s/it]2025-08-22:23:20:25,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5280/12032 [4:45:44<3:12:29,  1.71s/it]2025-08-22:23:20:26,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5281/12032 [4:45:46<2:58:01,  1.58s/it]2025-08-22:23:20:28,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5282/12032 [4:45:47<3:01:21,  1.61s/it]2025-08-22:23:20:29,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5283/12032 [4:45:49<3:09:06,  1.68s/it]2025-08-22:23:20:31,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5284/12032 [4:45:50<2:46:35,  1.48s/it]2025-08-22:23:20:32,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5285/12032 [4:45:53<3:20:35,  1.78s/it]2025-08-22:23:20:35,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5286/12032 [4:45:55<3:34:53,  1.91s/it]2025-08-22:23:20:37,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5287/12032 [4:45:58<4:16:48,  2.28s/it]2025-08-22:23:20:40,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5288/12032 [4:46:01<4:47:03,  2.55s/it]2025-08-22:23:20:43,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5289/12032 [4:46:02<3:59:15,  2.13s/it]2025-08-22:23:20:44,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5290/12032 [4:46:05<4:05:53,  2.19s/it]2025-08-22:23:20:47,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5291/12032 [4:46:06<3:47:11,  2.02s/it]2025-08-22:23:20:48,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5292/12032 [4:46:10<4:45:32,  2.54s/it]2025-08-22:23:20:52,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5293/12032 [4:46:14<5:26:58,  2.91s/it]2025-08-22:23:20:56,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5294/12032 [4:46:18<5:54:58,  3.16s/it]2025-08-22:23:20:59,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5295/12032 [4:46:21<6:17:47,  3.36s/it]2025-08-22:23:21:03,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5296/12032 [4:46:25<6:31:56,  3.49s/it]2025-08-22:23:21:07,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5297/12032 [4:46:28<6:20:23,  3.39s/it]2025-08-22:23:21:10,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5298/12032 [4:46:32<6:11:39,  3.31s/it]2025-08-22:23:21:13,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5299/12032 [4:46:34<5:49:38,  3.12s/it]2025-08-22:23:21:16,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5300/12032 [4:46:38<6:15:50,  3.35s/it]2025-08-22:23:21:20,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5301/12032 [4:46:42<6:29:56,  3.48s/it]2025-08-22:23:21:24,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5302/12032 [4:46:45<6:07:40,  3.28s/it]2025-08-22:23:21:27,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5303/12032 [4:46:47<5:41:46,  3.05s/it]2025-08-22:23:21:29,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5304/12032 [4:46:49<5:10:07,  2.77s/it]2025-08-22:23:21:31,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5305/12032 [4:46:53<5:43:56,  3.07s/it]2025-08-22:23:21:35,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5306/12032 [4:46:57<6:09:49,  3.30s/it]2025-08-22:23:21:39,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5307/12032 [4:47:01<6:28:02,  3.46s/it]2025-08-22:23:21:43,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5308/12032 [4:47:05<6:41:46,  3.59s/it]2025-08-22:23:21:46,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5309/12032 [4:47:08<6:49:24,  3.65s/it]2025-08-22:23:21:50,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5310/12032 [4:47:12<6:55:59,  3.71s/it]2025-08-22:23:21:54,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5311/12032 [4:47:15<6:16:59,  3.37s/it]2025-08-22:23:21:57,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5312/12032 [4:47:19<6:33:15,  3.51s/it]2025-08-22:23:22:01,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5313/12032 [4:47:23<6:42:43,  3.60s/it]2025-08-22:23:22:04,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5314/12032 [4:47:24<5:41:23,  3.05s/it]2025-08-22:23:22:06,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5315/12032 [4:47:25<4:38:48,  2.49s/it]2025-08-22:23:22:07,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5316/12032 [4:47:26<3:45:11,  2.01s/it]2025-08-22:23:22:08,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5317/12032 [4:47:29<3:56:11,  2.11s/it]2025-08-22:23:22:11,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5318/12032 [4:47:30<3:14:13,  1.74s/it]2025-08-22:23:22:11,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5319/12032 [4:47:31<3:01:17,  1.62s/it]2025-08-22:23:22:13,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5320/12032 [4:47:32<2:41:16,  1.44s/it]2025-08-22:23:22:14,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5321/12032 [4:47:36<4:01:32,  2.16s/it]2025-08-22:23:22:18,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5322/12032 [4:47:38<3:49:19,  2.05s/it]2025-08-22:23:22:19,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5323/12032 [4:47:41<4:49:14,  2.59s/it]2025-08-22:23:22:23,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5324/12032 [4:47:42<3:53:55,  2.09s/it]2025-08-22:23:22:24,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5325/12032 [4:47:43<3:14:53,  1.74s/it]2025-08-22:23:22:25,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5326/12032 [4:47:47<4:15:59,  2.29s/it]2025-08-22:23:22:29,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5327/12032 [4:47:48<3:31:41,  1.89s/it]2025-08-22:23:22:30,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5328/12032 [4:47:52<4:36:15,  2.47s/it]2025-08-22:23:22:33,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5329/12032 [4:47:55<5:21:18,  2.88s/it]2025-08-22:23:22:37,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5330/12032 [4:47:56<4:18:16,  2.31s/it]2025-08-22:23:22:38,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5331/12032 [4:47:58<3:41:37,  1.98s/it]2025-08-22:23:22:40,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5332/12032 [4:47:59<3:27:42,  1.86s/it]2025-08-22:23:22:41,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5333/12032 [4:48:01<3:23:37,  1.82s/it]2025-08-22:23:22:43,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5334/12032 [4:48:02<2:57:55,  1.59s/it]2025-08-22:23:22:44,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5335/12032 [4:48:06<4:09:37,  2.24s/it]2025-08-22:23:22:48,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5336/12032 [4:48:08<4:19:37,  2.33s/it]2025-08-22:23:22:50,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5337/12032 [4:48:09<3:40:21,  1.97s/it]2025-08-22:23:22:51,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5338/12032 [4:48:11<3:22:23,  1.81s/it]2025-08-22:23:22:53,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5339/12032 [4:48:12<2:59:52,  1.61s/it]2025-08-22:23:22:54,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5340/12032 [4:48:13<2:38:00,  1.42s/it]2025-08-22:23:22:55,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5341/12032 [4:48:14<2:24:54,  1.30s/it]2025-08-22:23:22:56,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5342/12032 [4:48:16<2:46:32,  1.49s/it]2025-08-22:23:22:58,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5343/12032 [4:48:20<4:04:23,  2.19s/it]2025-08-22:23:23:02,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5344/12032 [4:48:24<4:59:46,  2.69s/it]2025-08-22:23:23:05,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5345/12032 [4:48:27<5:36:34,  3.02s/it]2025-08-22:23:23:09,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5346/12032 [4:48:30<5:28:54,  2.95s/it]2025-08-22:23:23:12,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5347/12032 [4:48:34<5:56:06,  3.20s/it]2025-08-22:23:23:16,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5348/12032 [4:48:38<6:16:57,  3.38s/it]2025-08-22:23:23:20,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5349/12032 [4:48:42<6:30:32,  3.51s/it]2025-08-22:23:23:23,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5350/12032 [4:48:45<6:39:21,  3.59s/it]2025-08-22:23:23:27,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5351/12032 [4:48:48<6:22:34,  3.44s/it]2025-08-22:23:23:30,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5352/12032 [4:48:51<5:41:02,  3.06s/it]2025-08-22:23:23:32,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5353/12032 [4:48:54<6:05:41,  3.29s/it]2025-08-22:23:23:36,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  44%|████▍     | 5354/12032 [4:48:58<6:23:27,  3.45s/it]2025-08-22:23:23:40,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5355/12032 [4:49:02<6:19:14,  3.41s/it]2025-08-22:23:23:43,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5356/12032 [4:49:05<6:31:29,  3.52s/it]2025-08-22:23:23:47,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5357/12032 [4:49:09<6:41:20,  3.61s/it]2025-08-22:23:23:51,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5358/12032 [4:49:13<6:52:18,  3.71s/it]2025-08-22:23:23:55,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5359/12032 [4:49:17<6:57:13,  3.75s/it]2025-08-22:23:23:59,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5360/12032 [4:49:21<6:58:45,  3.77s/it]2025-08-22:23:24:03,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5361/12032 [4:49:25<7:00:58,  3.79s/it]2025-08-22:23:24:06,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5362/12032 [4:49:28<7:01:41,  3.79s/it]2025-08-22:23:24:10,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5363/12032 [4:49:32<6:46:54,  3.66s/it]2025-08-22:23:24:14,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5364/12032 [4:49:35<6:33:50,  3.54s/it]2025-08-22:23:24:17,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5365/12032 [4:49:36<5:19:10,  2.87s/it]2025-08-22:23:24:18,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5366/12032 [4:49:40<5:49:48,  3.15s/it]2025-08-22:23:24:22,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5367/12032 [4:49:44<6:11:14,  3.34s/it]2025-08-22:23:24:26,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5368/12032 [4:49:47<6:01:50,  3.26s/it]2025-08-22:23:24:29,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5369/12032 [4:49:51<6:19:18,  3.42s/it]2025-08-22:23:24:33,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5370/12032 [4:49:54<6:01:57,  3.26s/it]2025-08-22:23:24:36,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5371/12032 [4:49:56<5:22:01,  2.90s/it]2025-08-22:23:24:38,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5372/12032 [4:50:00<5:52:31,  3.18s/it]2025-08-22:23:24:41,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5373/12032 [4:50:01<4:54:22,  2.65s/it]2025-08-22:23:24:43,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5374/12032 [4:50:02<4:11:55,  2.27s/it]2025-08-22:23:24:44,717 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5375/12032 [4:50:06<4:43:20,  2.55s/it]2025-08-22:23:24:47,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5376/12032 [4:50:07<4:19:30,  2.34s/it]2025-08-22:23:24:49,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5377/12032 [4:50:11<4:44:12,  2.56s/it]2025-08-22:23:24:52,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5378/12032 [4:50:14<5:31:10,  2.99s/it]2025-08-22:23:24:56,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5379/12032 [4:50:15<4:23:43,  2.38s/it]2025-08-22:23:24:57,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5380/12032 [4:50:17<4:02:19,  2.19s/it]2025-08-22:23:24:59,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5381/12032 [4:50:19<4:01:18,  2.18s/it]2025-08-22:23:25:01,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5382/12032 [4:50:20<3:22:39,  1.83s/it]2025-08-22:23:25:02,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5383/12032 [4:50:21<2:49:05,  1.53s/it]2025-08-22:23:25:03,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5384/12032 [4:50:24<3:43:23,  2.02s/it]2025-08-22:23:25:06,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5385/12032 [4:50:28<4:36:03,  2.49s/it]2025-08-22:23:25:10,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5386/12032 [4:50:29<3:41:42,  2.00s/it]2025-08-22:23:25:11,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5387/12032 [4:50:30<3:30:22,  1.90s/it]2025-08-22:23:25:12,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5388/12032 [4:50:31<2:52:55,  1.56s/it]2025-08-22:23:25:13,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5389/12032 [4:50:32<2:19:55,  1.26s/it]2025-08-22:23:25:14,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5390/12032 [4:50:33<2:33:51,  1.39s/it]2025-08-22:23:25:15,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5391/12032 [4:50:34<2:17:38,  1.24s/it]2025-08-22:23:25:16,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5392/12032 [4:50:36<2:15:39,  1.23s/it]2025-08-22:23:25:17,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5393/12032 [4:50:39<3:40:24,  1.99s/it]2025-08-22:23:25:21,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5394/12032 [4:50:41<3:33:50,  1.93s/it]2025-08-22:23:25:23,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5395/12032 [4:50:45<4:34:23,  2.48s/it]2025-08-22:23:25:27,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5396/12032 [4:50:49<5:19:10,  2.89s/it]2025-08-22:23:25:31,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5397/12032 [4:50:52<5:48:06,  3.15s/it]2025-08-22:23:25:34,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5398/12032 [4:50:56<6:08:47,  3.34s/it]2025-08-22:23:25:38,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5399/12032 [4:51:00<6:22:53,  3.46s/it]2025-08-22:23:25:42,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5400/12032 [4:51:04<6:33:31,  3.56s/it]2025-08-22:23:25:46,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5401/12032 [4:51:08<6:40:23,  3.62s/it]2025-08-22:23:25:49,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5402/12032 [4:51:11<6:26:43,  3.50s/it]2025-08-22:23:25:53,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5403/12032 [4:51:13<5:56:47,  3.23s/it]2025-08-22:23:25:55,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5404/12032 [4:51:16<5:44:50,  3.12s/it]2025-08-22:23:25:58,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5405/12032 [4:51:20<6:07:23,  3.33s/it]2025-08-22:23:26:02,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5406/12032 [4:51:24<6:23:06,  3.47s/it]2025-08-22:23:26:06,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5407/12032 [4:51:27<5:59:39,  3.26s/it]2025-08-22:23:26:08,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5408/12032 [4:51:30<6:15:57,  3.41s/it]2025-08-22:23:26:12,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5409/12032 [4:51:34<6:28:30,  3.52s/it]2025-08-22:23:26:16,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5410/12032 [4:51:38<6:36:55,  3.60s/it]2025-08-22:23:26:20,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5411/12032 [4:51:42<6:42:35,  3.65s/it]2025-08-22:23:26:24,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5412/12032 [4:51:44<6:01:10,  3.27s/it]2025-08-22:23:26:26,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5413/12032 [4:51:48<6:17:58,  3.43s/it]2025-08-22:23:26:30,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▍     | 5414/12032 [4:51:52<6:29:51,  3.53s/it]2025-08-22:23:26:34,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5415/12032 [4:51:55<6:38:05,  3.61s/it]2025-08-22:23:26:37,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5416/12032 [4:51:59<6:44:59,  3.67s/it]2025-08-22:23:26:41,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5417/12032 [4:52:03<6:48:33,  3.71s/it]2025-08-22:23:26:45,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5418/12032 [4:52:07<6:54:24,  3.76s/it]2025-08-22:23:26:49,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5419/12032 [4:52:11<6:55:48,  3.77s/it]2025-08-22:23:26:53,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5420/12032 [4:52:15<6:56:16,  3.78s/it]2025-08-22:23:26:56,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5421/12032 [4:52:18<6:57:59,  3.79s/it]2025-08-22:23:27:00,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5422/12032 [4:52:21<6:12:54,  3.38s/it]2025-08-22:23:27:03,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5423/12032 [4:52:22<4:57:49,  2.70s/it]2025-08-22:23:27:04,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5424/12032 [4:52:26<5:33:43,  3.03s/it]2025-08-22:23:27:08,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5425/12032 [4:52:28<5:10:25,  2.82s/it]2025-08-22:23:27:10,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5426/12032 [4:52:32<5:43:15,  3.12s/it]2025-08-22:23:27:14,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5427/12032 [4:52:36<6:07:01,  3.33s/it]2025-08-22:23:27:18,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5428/12032 [4:52:38<5:17:20,  2.88s/it]2025-08-22:23:27:19,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5429/12032 [4:52:39<4:18:06,  2.35s/it]2025-08-22:23:27:20,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5430/12032 [4:52:40<3:36:56,  1.97s/it]2025-08-22:23:27:22,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5431/12032 [4:52:44<4:37:26,  2.52s/it]2025-08-22:23:27:25,868 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5432/12032 [4:52:47<5:18:51,  2.90s/it]2025-08-22:23:27:29,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5433/12032 [4:52:48<4:18:23,  2.35s/it]2025-08-22:23:27:30,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5434/12032 [4:52:50<3:56:51,  2.15s/it]2025-08-22:23:27:32,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5435/12032 [4:52:54<4:53:01,  2.67s/it]2025-08-22:23:27:36,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5436/12032 [4:52:58<5:29:52,  3.00s/it]2025-08-22:23:27:40,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5437/12032 [4:53:00<4:58:17,  2.71s/it]2025-08-22:23:27:42,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5438/12032 [4:53:04<5:34:05,  3.04s/it]2025-08-22:23:27:45,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5439/12032 [4:53:05<4:32:24,  2.48s/it]2025-08-22:23:27:47,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5440/12032 [4:53:09<5:15:20,  2.87s/it]2025-08-22:23:27:50,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5441/12032 [4:53:10<4:44:29,  2.59s/it]2025-08-22:23:27:52,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5442/12032 [4:53:12<3:57:15,  2.16s/it]2025-08-22:23:27:53,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5443/12032 [4:53:13<3:37:13,  1.98s/it]2025-08-22:23:27:55,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5444/12032 [4:53:15<3:19:02,  1.81s/it]2025-08-22:23:27:56,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5445/12032 [4:53:17<3:31:59,  1.93s/it]2025-08-22:23:27:59,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5446/12032 [4:53:18<3:21:27,  1.84s/it]2025-08-22:23:28:00,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5447/12032 [4:53:22<4:26:39,  2.43s/it]2025-08-22:23:28:04,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5448/12032 [4:53:23<3:32:33,  1.94s/it]2025-08-22:23:28:05,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5449/12032 [4:53:25<3:24:11,  1.86s/it]2025-08-22:23:28:07,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5450/12032 [4:53:25<2:42:30,  1.48s/it]2025-08-22:23:28:07,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5451/12032 [4:53:27<2:40:57,  1.47s/it]2025-08-22:23:28:09,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5452/12032 [4:53:29<3:18:58,  1.81s/it]2025-08-22:23:28:11,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5453/12032 [4:53:31<3:00:37,  1.65s/it]2025-08-22:23:28:12,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5454/12032 [4:53:31<2:33:44,  1.40s/it]2025-08-22:23:28:13,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5455/12032 [4:53:34<3:17:00,  1.80s/it]2025-08-22:23:28:16,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5456/12032 [4:53:37<4:05:19,  2.24s/it]2025-08-22:23:28:19,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5457/12032 [4:53:38<3:15:12,  1.78s/it]2025-08-22:23:28:20,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5458/12032 [4:53:41<4:06:21,  2.25s/it]2025-08-22:23:28:23,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5459/12032 [4:53:43<3:31:35,  1.93s/it]2025-08-22:23:28:25,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5460/12032 [4:53:45<3:31:48,  1.93s/it]2025-08-22:23:28:26,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5461/12032 [4:53:46<3:24:44,  1.87s/it]2025-08-22:23:28:28,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5462/12032 [4:53:48<3:08:03,  1.72s/it]2025-08-22:23:28:30,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5463/12032 [4:53:51<4:16:40,  2.34s/it]2025-08-22:23:28:33,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5464/12032 [4:53:55<5:03:43,  2.77s/it]2025-08-22:23:28:37,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5465/12032 [4:53:58<5:15:10,  2.88s/it]2025-08-22:23:28:40,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5466/12032 [4:54:01<5:20:26,  2.93s/it]2025-08-22:23:28:43,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5467/12032 [4:54:03<4:34:26,  2.51s/it]2025-08-22:23:28:45,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5468/12032 [4:54:07<5:17:14,  2.90s/it]2025-08-22:23:28:49,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5469/12032 [4:54:11<5:46:45,  3.17s/it]2025-08-22:23:28:52,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5470/12032 [4:54:13<5:32:09,  3.04s/it]2025-08-22:23:28:55,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5471/12032 [4:54:17<5:56:45,  3.26s/it]2025-08-22:23:28:59,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5472/12032 [4:54:21<6:15:31,  3.43s/it]2025-08-22:23:29:03,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5473/12032 [4:54:25<6:27:25,  3.54s/it]2025-08-22:23:29:07,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  45%|████▌     | 5474/12032 [4:54:29<6:36:41,  3.63s/it]2025-08-22:23:29:10,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5475/12032 [4:54:32<6:40:09,  3.66s/it]2025-08-22:23:29:14,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5476/12032 [4:54:36<6:45:09,  3.71s/it]2025-08-22:23:29:18,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5477/12032 [4:54:37<5:15:24,  2.89s/it]2025-08-22:23:29:19,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5478/12032 [4:54:38<4:11:55,  2.31s/it]2025-08-22:23:29:20,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5479/12032 [4:54:39<3:27:22,  1.90s/it]2025-08-22:23:29:21,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5480/12032 [4:54:43<4:29:31,  2.47s/it]2025-08-22:23:29:25,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5481/12032 [4:54:47<5:12:52,  2.87s/it]2025-08-22:23:29:28,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5482/12032 [4:54:50<5:18:35,  2.92s/it]2025-08-22:23:29:31,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5483/12032 [4:54:52<5:01:57,  2.77s/it]2025-08-22:23:29:34,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5484/12032 [4:54:55<5:15:57,  2.90s/it]2025-08-22:23:29:37,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5485/12032 [4:54:59<5:44:35,  3.16s/it]2025-08-22:23:29:41,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5486/12032 [4:55:03<6:04:41,  3.34s/it]2025-08-22:23:29:45,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5487/12032 [4:55:07<6:19:10,  3.48s/it]2025-08-22:23:29:48,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5488/12032 [4:55:08<5:08:03,  2.82s/it]2025-08-22:23:29:50,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5489/12032 [4:55:12<5:40:03,  3.12s/it]2025-08-22:23:29:54,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5490/12032 [4:55:15<6:01:06,  3.31s/it]2025-08-22:23:29:57,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5491/12032 [4:55:18<5:33:16,  3.06s/it]2025-08-22:23:30:00,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5492/12032 [4:55:22<5:57:27,  3.28s/it]2025-08-22:23:30:04,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5493/12032 [4:55:23<4:37:20,  2.54s/it]2025-08-22:23:30:04,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5494/12032 [4:55:26<5:16:57,  2.91s/it]2025-08-22:23:30:08,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5495/12032 [4:55:30<5:44:14,  3.16s/it]2025-08-22:23:30:12,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5496/12032 [4:55:33<5:27:14,  3.00s/it]2025-08-22:23:30:15,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5497/12032 [4:55:34<4:32:15,  2.50s/it]2025-08-22:23:30:16,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5498/12032 [4:55:35<3:40:34,  2.03s/it]2025-08-22:23:30:17,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5499/12032 [4:55:36<3:07:06,  1.72s/it]2025-08-22:23:30:18,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5500/12032 [4:55:40<4:14:02,  2.33s/it]2025-08-22:23:30:22,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5501/12032 [4:55:42<4:27:56,  2.46s/it]2025-08-22:23:30:24,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5502/12032 [4:55:46<5:09:48,  2.85s/it]2025-08-22:23:30:28,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5503/12032 [4:55:47<4:10:43,  2.30s/it]2025-08-22:23:30:29,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5504/12032 [4:55:51<4:58:37,  2.74s/it]2025-08-22:23:30:33,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5505/12032 [4:55:52<3:45:56,  2.08s/it]2025-08-22:23:30:33,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5506/12032 [4:55:53<3:19:04,  1.83s/it]2025-08-22:23:30:35,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5507/12032 [4:55:54<3:08:47,  1.74s/it]2025-08-22:23:30:36,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5508/12032 [4:55:55<2:43:55,  1.51s/it]2025-08-22:23:30:37,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5509/12032 [4:55:59<3:57:40,  2.19s/it]2025-08-22:23:30:41,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5510/12032 [4:56:01<3:38:43,  2.01s/it]2025-08-22:23:30:42,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5511/12032 [4:56:02<3:02:32,  1.68s/it]2025-08-22:23:30:43,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5512/12032 [4:56:05<4:06:59,  2.27s/it]2025-08-22:23:30:47,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5513/12032 [4:56:09<4:46:25,  2.64s/it]2025-08-22:23:30:51,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5514/12032 [4:56:10<4:17:01,  2.37s/it]2025-08-22:23:30:52,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5515/12032 [4:56:14<5:03:37,  2.80s/it]2025-08-22:23:30:56,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5516/12032 [4:56:16<4:26:55,  2.46s/it]2025-08-22:23:30:58,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5517/12032 [4:56:17<3:44:41,  2.07s/it]2025-08-22:23:30:59,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5518/12032 [4:56:18<3:13:54,  1.79s/it]2025-08-22:23:31:00,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5519/12032 [4:56:20<3:03:33,  1.69s/it]2025-08-22:23:31:01,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5520/12032 [4:56:23<4:11:07,  2.31s/it]2025-08-22:23:31:05,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5521/12032 [4:56:27<4:43:48,  2.62s/it]2025-08-22:23:31:09,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5522/12032 [4:56:30<4:54:40,  2.72s/it]2025-08-22:23:31:12,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5523/12032 [4:56:33<5:29:41,  3.04s/it]2025-08-22:23:31:15,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5524/12032 [4:56:37<5:53:56,  3.26s/it]2025-08-22:23:31:19,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5525/12032 [4:56:41<6:03:23,  3.35s/it]2025-08-22:23:31:23,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5526/12032 [4:56:45<6:16:45,  3.47s/it]2025-08-22:23:31:26,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5527/12032 [4:56:48<6:27:52,  3.58s/it]2025-08-22:23:31:30,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5528/12032 [4:56:52<6:35:07,  3.65s/it]2025-08-22:23:31:34,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5529/12032 [4:56:56<6:41:34,  3.71s/it]2025-08-22:23:31:38,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5530/12032 [4:56:58<5:43:04,  3.17s/it]2025-08-22:23:31:40,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5531/12032 [4:57:02<6:00:07,  3.32s/it]2025-08-22:23:31:43,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5532/12032 [4:57:06<6:18:08,  3.49s/it]2025-08-22:23:31:47,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5533/12032 [4:57:09<6:27:28,  3.58s/it]2025-08-22:23:31:51,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5534/12032 [4:57:12<5:53:10,  3.26s/it]2025-08-22:23:31:54,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5535/12032 [4:57:14<5:31:29,  3.06s/it]2025-08-22:23:31:56,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5536/12032 [4:57:18<5:57:40,  3.30s/it]2025-08-22:23:32:00,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5537/12032 [4:57:21<5:40:17,  3.14s/it]2025-08-22:23:32:03,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5538/12032 [4:57:25<6:02:50,  3.35s/it]2025-08-22:23:32:07,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5539/12032 [4:57:29<6:16:15,  3.48s/it]2025-08-22:23:32:11,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5540/12032 [4:57:32<6:26:54,  3.58s/it]2025-08-22:23:32:14,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5541/12032 [4:57:36<6:33:49,  3.64s/it]2025-08-22:23:32:18,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5542/12032 [4:57:39<6:07:32,  3.40s/it]2025-08-22:23:32:21,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5543/12032 [4:57:43<6:19:48,  3.51s/it]2025-08-22:23:32:25,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5544/12032 [4:57:47<6:27:26,  3.58s/it]2025-08-22:23:32:28,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5545/12032 [4:57:50<6:25:41,  3.57s/it]2025-08-22:23:32:32,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5546/12032 [4:57:54<6:33:07,  3.64s/it]2025-08-22:23:32:36,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5547/12032 [4:57:58<6:37:01,  3.67s/it]2025-08-22:23:32:40,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5548/12032 [4:58:00<5:53:54,  3.27s/it]2025-08-22:23:32:42,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5549/12032 [4:58:02<5:12:29,  2.89s/it]2025-08-22:23:32:44,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5550/12032 [4:58:06<5:42:06,  3.17s/it]2025-08-22:23:32:48,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5551/12032 [4:58:10<6:01:04,  3.34s/it]2025-08-22:23:32:51,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5552/12032 [4:58:13<5:49:50,  3.24s/it]2025-08-22:23:32:54,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5553/12032 [4:58:14<4:58:36,  2.77s/it]2025-08-22:23:32:56,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5554/12032 [4:58:18<5:20:46,  2.97s/it]2025-08-22:23:33:00,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5555/12032 [4:58:20<5:12:00,  2.89s/it]2025-08-22:23:33:02,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5556/12032 [4:58:23<5:16:01,  2.93s/it]2025-08-22:23:33:05,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5557/12032 [4:58:26<4:54:53,  2.73s/it]2025-08-22:23:33:08,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5558/12032 [4:58:29<5:26:16,  3.02s/it]2025-08-22:23:33:11,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5559/12032 [4:58:31<4:27:30,  2.48s/it]2025-08-22:23:33:12,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5560/12032 [4:58:32<3:39:43,  2.04s/it]2025-08-22:23:33:13,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5561/12032 [4:58:33<3:25:15,  1.90s/it]2025-08-22:23:33:15,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5562/12032 [4:58:37<4:24:32,  2.45s/it]2025-08-22:23:33:19,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5563/12032 [4:58:41<5:06:50,  2.85s/it]2025-08-22:23:33:23,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▌     | 5564/12032 [4:58:44<5:19:22,  2.96s/it]2025-08-22:23:33:26,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5565/12032 [4:58:47<5:07:25,  2.85s/it]2025-08-22:23:33:28,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5566/12032 [4:58:47<4:02:09,  2.25s/it]2025-08-22:23:33:29,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5567/12032 [4:58:48<3:22:32,  1.88s/it]2025-08-22:23:33:30,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5568/12032 [4:58:50<3:09:13,  1.76s/it]2025-08-22:23:33:32,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5569/12032 [4:58:51<2:41:34,  1.50s/it]2025-08-22:23:33:33,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5570/12032 [4:58:52<2:25:47,  1.35s/it]2025-08-22:23:33:34,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5571/12032 [4:58:53<2:18:58,  1.29s/it]2025-08-22:23:33:35,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5572/12032 [4:58:57<3:40:08,  2.04s/it]2025-08-22:23:33:39,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5573/12032 [4:59:00<4:35:19,  2.56s/it]2025-08-22:23:33:42,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5574/12032 [4:59:02<4:09:24,  2.32s/it]2025-08-22:23:33:44,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5575/12032 [4:59:04<3:56:02,  2.19s/it]2025-08-22:23:33:46,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5576/12032 [4:59:05<3:18:08,  1.84s/it]2025-08-22:23:33:47,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5577/12032 [4:59:09<4:19:04,  2.41s/it]2025-08-22:23:33:51,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5578/12032 [4:59:10<3:50:14,  2.14s/it]2025-08-22:23:33:52,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5579/12032 [4:59:13<3:54:17,  2.18s/it]2025-08-22:23:33:55,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5580/12032 [4:59:14<3:29:51,  1.95s/it]2025-08-22:23:33:56,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5581/12032 [4:59:15<3:09:37,  1.76s/it]2025-08-22:23:33:57,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5582/12032 [4:59:19<4:13:43,  2.36s/it]2025-08-22:23:34:01,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5583/12032 [4:59:23<4:58:43,  2.78s/it]2025-08-22:23:34:05,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5584/12032 [4:59:27<5:29:27,  3.07s/it]2025-08-22:23:34:09,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5585/12032 [4:59:28<4:34:58,  2.56s/it]2025-08-22:23:34:10,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5586/12032 [4:59:32<5:12:54,  2.91s/it]2025-08-22:23:34:14,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5587/12032 [4:59:33<4:03:02,  2.26s/it]2025-08-22:23:34:14,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5588/12032 [4:59:34<3:28:04,  1.94s/it]2025-08-22:23:34:16,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5589/12032 [4:59:37<4:27:09,  2.49s/it]2025-08-22:23:34:19,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5590/12032 [4:59:39<3:45:03,  2.10s/it]2025-08-22:23:34:21,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5591/12032 [4:59:42<4:29:04,  2.51s/it]2025-08-22:23:34:24,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5592/12032 [4:59:43<3:51:04,  2.15s/it]2025-08-22:23:34:25,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5593/12032 [4:59:44<3:09:39,  1.77s/it]2025-08-22:23:34:26,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  46%|████▋     | 5594/12032 [4:59:46<3:11:54,  1.79s/it]2025-08-22:23:34:28,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5595/12032 [4:59:50<4:08:15,  2.31s/it]2025-08-22:23:34:32,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5596/12032 [4:59:52<4:06:39,  2.30s/it]2025-08-22:23:34:34,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5597/12032 [4:59:53<3:35:57,  2.01s/it]2025-08-22:23:34:35,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5598/12032 [4:59:55<3:09:38,  1.77s/it]2025-08-22:23:34:36,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5599/12032 [4:59:55<2:39:57,  1.49s/it]2025-08-22:23:34:37,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5600/12032 [4:59:57<2:36:49,  1.46s/it]2025-08-22:23:34:39,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5601/12032 [4:59:58<2:26:58,  1.37s/it]2025-08-22:23:34:40,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5602/12032 [5:00:02<3:44:16,  2.09s/it]2025-08-22:23:34:44,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5603/12032 [5:00:05<4:37:23,  2.59s/it]2025-08-22:23:34:47,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5604/12032 [5:00:09<5:13:36,  2.93s/it]2025-08-22:23:34:51,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5605/12032 [5:00:13<5:41:42,  3.19s/it]2025-08-22:23:34:55,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5606/12032 [5:00:16<5:44:56,  3.22s/it]2025-08-22:23:34:58,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5607/12032 [5:00:20<6:03:33,  3.40s/it]2025-08-22:23:35:02,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5608/12032 [5:00:23<5:58:32,  3.35s/it]2025-08-22:23:35:05,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5609/12032 [5:00:27<6:11:41,  3.47s/it]2025-08-22:23:35:09,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5610/12032 [5:00:30<5:58:36,  3.35s/it]2025-08-22:23:35:12,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5611/12032 [5:00:33<5:44:55,  3.22s/it]2025-08-22:23:35:15,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5612/12032 [5:00:37<6:02:28,  3.39s/it]2025-08-22:23:35:19,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5613/12032 [5:00:41<6:14:14,  3.50s/it]2025-08-22:23:35:22,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5614/12032 [5:00:44<6:22:46,  3.58s/it]2025-08-22:23:35:26,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5615/12032 [5:00:48<6:28:35,  3.63s/it]2025-08-22:23:35:30,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5616/12032 [5:00:50<5:17:09,  2.97s/it]2025-08-22:23:35:31,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5617/12032 [5:00:52<4:49:21,  2.71s/it]2025-08-22:23:35:33,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5618/12032 [5:00:54<4:37:42,  2.60s/it]2025-08-22:23:35:36,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5619/12032 [5:00:55<3:55:28,  2.20s/it]2025-08-22:23:35:37,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5620/12032 [5:00:56<3:14:44,  1.82s/it]2025-08-22:23:35:38,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5621/12032 [5:01:00<4:18:21,  2.42s/it]2025-08-22:23:35:42,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5622/12032 [5:01:03<4:27:24,  2.50s/it]2025-08-22:23:35:45,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5623/12032 [5:01:04<3:49:49,  2.15s/it]2025-08-22:23:35:46,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5624/12032 [5:01:06<3:37:08,  2.03s/it]2025-08-22:23:35:48,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5625/12032 [5:01:09<4:22:12,  2.46s/it]2025-08-22:23:35:51,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5626/12032 [5:01:11<4:07:24,  2.32s/it]2025-08-22:23:35:53,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5627/12032 [5:01:12<3:24:54,  1.92s/it]2025-08-22:23:35:54,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5628/12032 [5:01:13<3:00:24,  1.69s/it]2025-08-22:23:35:55,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5629/12032 [5:01:14<2:34:26,  1.45s/it]2025-08-22:23:35:56,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5630/12032 [5:01:15<2:14:33,  1.26s/it]2025-08-22:23:35:57,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5631/12032 [5:01:16<2:07:15,  1.19s/it]2025-08-22:23:35:58,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5632/12032 [5:01:17<2:12:43,  1.24s/it]2025-08-22:23:35:59,797 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5633/12032 [5:01:18<1:50:40,  1.04s/it]2025-08-22:23:36:00,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5634/12032 [5:01:20<2:36:27,  1.47s/it]2025-08-22:23:36:02,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5635/12032 [5:01:21<2:17:56,  1.29s/it]2025-08-22:23:36:03,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5636/12032 [5:01:22<2:08:47,  1.21s/it]2025-08-22:23:36:04,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5637/12032 [5:01:24<2:18:32,  1.30s/it]2025-08-22:23:36:06,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5638/12032 [5:01:28<3:38:07,  2.05s/it]2025-08-22:23:36:10,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5639/12032 [5:01:32<4:36:29,  2.59s/it]2025-08-22:23:36:13,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5640/12032 [5:01:35<5:15:13,  2.96s/it]2025-08-22:23:36:17,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5641/12032 [5:01:38<4:54:32,  2.77s/it]2025-08-22:23:36:20,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5642/12032 [5:01:40<4:54:05,  2.76s/it]2025-08-22:23:36:22,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5643/12032 [5:01:41<3:56:07,  2.22s/it]2025-08-22:23:36:23,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5644/12032 [5:01:45<4:45:34,  2.68s/it]2025-08-22:23:36:27,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5645/12032 [5:01:49<5:20:01,  3.01s/it]2025-08-22:23:36:31,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5646/12032 [5:01:52<5:23:48,  3.04s/it]2025-08-22:23:36:34,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5647/12032 [5:01:56<5:48:16,  3.27s/it]2025-08-22:23:36:38,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5648/12032 [5:02:00<6:04:47,  3.43s/it]2025-08-22:23:36:41,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5649/12032 [5:02:02<5:46:22,  3.26s/it]2025-08-22:23:36:44,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5650/12032 [5:02:06<6:06:16,  3.44s/it]2025-08-22:23:36:48,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5651/12032 [5:02:10<6:19:23,  3.57s/it]2025-08-22:23:36:52,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5652/12032 [5:02:12<5:34:29,  3.15s/it]2025-08-22:23:36:54,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5653/12032 [5:02:16<5:54:53,  3.34s/it]2025-08-22:23:36:58,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5654/12032 [5:02:20<6:08:58,  3.47s/it]2025-08-22:23:37:02,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5655/12032 [5:02:23<6:03:03,  3.42s/it]2025-08-22:23:37:05,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5656/12032 [5:02:27<6:14:48,  3.53s/it]2025-08-22:23:37:09,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5657/12032 [5:02:31<6:14:30,  3.52s/it]2025-08-22:23:37:12,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5658/12032 [5:02:34<6:22:01,  3.60s/it]2025-08-22:23:37:16,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5659/12032 [5:02:38<6:27:50,  3.65s/it]2025-08-22:23:37:20,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5660/12032 [5:02:41<5:48:21,  3.28s/it]2025-08-22:23:37:22,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5661/12032 [5:02:44<6:05:31,  3.44s/it]2025-08-22:23:37:26,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5662/12032 [5:02:46<5:04:08,  2.86s/it]2025-08-22:23:37:28,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5663/12032 [5:02:47<4:07:44,  2.33s/it]2025-08-22:23:37:29,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5664/12032 [5:02:49<3:58:46,  2.25s/it]2025-08-22:23:37:31,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5665/12032 [5:02:51<4:00:03,  2.26s/it]2025-08-22:23:37:33,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5666/12032 [5:02:53<3:51:40,  2.18s/it]2025-08-22:23:37:35,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5667/12032 [5:02:54<3:16:14,  1.85s/it]2025-08-22:23:37:36,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5668/12032 [5:02:56<3:12:25,  1.81s/it]2025-08-22:23:37:38,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5669/12032 [5:03:00<4:17:14,  2.43s/it]2025-08-22:23:37:42,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5670/12032 [5:03:04<5:01:24,  2.84s/it]2025-08-22:23:37:46,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5671/12032 [5:03:08<5:32:16,  3.13s/it]2025-08-22:23:37:49,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5672/12032 [5:03:11<5:33:48,  3.15s/it]2025-08-22:23:37:53,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5673/12032 [5:03:13<5:00:29,  2.84s/it]2025-08-22:23:37:55,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5674/12032 [5:03:14<4:00:03,  2.27s/it]2025-08-22:23:37:56,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5675/12032 [5:03:17<4:31:07,  2.56s/it]2025-08-22:23:37:59,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5676/12032 [5:03:21<5:13:42,  2.96s/it]2025-08-22:23:38:03,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5677/12032 [5:03:25<5:41:46,  3.23s/it]2025-08-22:23:38:07,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5678/12032 [5:03:27<4:56:48,  2.80s/it]2025-08-22:23:38:08,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5679/12032 [5:03:31<5:33:01,  3.15s/it]2025-08-22:23:38:12,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5680/12032 [5:03:33<5:11:47,  2.95s/it]2025-08-22:23:38:15,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5681/12032 [5:03:37<5:30:18,  3.12s/it]2025-08-22:23:38:18,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5682/12032 [5:03:40<5:30:20,  3.12s/it]2025-08-22:23:38:22,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5683/12032 [5:03:44<5:53:46,  3.34s/it]2025-08-22:23:38:25,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5684/12032 [5:03:47<6:11:33,  3.51s/it]2025-08-22:23:38:29,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5685/12032 [5:03:49<5:17:50,  3.00s/it]2025-08-22:23:38:31,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5686/12032 [5:03:53<5:44:51,  3.26s/it]2025-08-22:23:38:35,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5687/12032 [5:03:54<4:29:25,  2.55s/it]2025-08-22:23:38:36,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5688/12032 [5:03:55<3:35:56,  2.04s/it]2025-08-22:23:38:37,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5689/12032 [5:03:59<4:33:36,  2.59s/it]2025-08-22:23:38:41,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5690/12032 [5:04:03<5:16:27,  2.99s/it]2025-08-22:23:38:45,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5691/12032 [5:04:07<5:46:15,  3.28s/it]2025-08-22:23:38:48,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5692/12032 [5:04:11<6:10:16,  3.50s/it]2025-08-22:23:38:52,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5693/12032 [5:04:15<6:28:19,  3.68s/it]2025-08-22:23:38:57,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5694/12032 [5:04:18<6:03:43,  3.44s/it]2025-08-22:23:38:59,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5695/12032 [5:04:22<6:18:49,  3.59s/it]2025-08-22:23:39:03,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5696/12032 [5:04:25<6:27:29,  3.67s/it]2025-08-22:23:39:07,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5697/12032 [5:04:28<5:37:57,  3.20s/it]2025-08-22:23:39:09,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5698/12032 [5:04:29<4:30:36,  2.56s/it]2025-08-22:23:39:10,923 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5699/12032 [5:04:32<5:02:13,  2.86s/it]2025-08-22:23:39:14,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5700/12032 [5:04:36<5:33:05,  3.16s/it]2025-08-22:23:39:18,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5701/12032 [5:04:40<5:56:30,  3.38s/it]2025-08-22:23:39:22,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5702/12032 [5:04:44<6:10:34,  3.51s/it]2025-08-22:23:39:26,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5703/12032 [5:04:48<6:22:53,  3.63s/it]2025-08-22:23:39:29,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5704/12032 [5:04:51<6:28:30,  3.68s/it]2025-08-22:23:39:33,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5705/12032 [5:04:55<6:35:05,  3.75s/it]2025-08-22:23:39:37,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5706/12032 [5:04:59<6:40:46,  3.80s/it]2025-08-22:23:39:41,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5707/12032 [5:05:03<6:43:25,  3.83s/it]2025-08-22:23:39:45,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5708/12032 [5:05:07<6:41:31,  3.81s/it]2025-08-22:23:39:49,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5709/12032 [5:05:11<6:40:17,  3.80s/it]2025-08-22:23:39:53,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5710/12032 [5:05:14<6:41:12,  3.81s/it]2025-08-22:23:39:56,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5711/12032 [5:05:18<6:41:58,  3.82s/it]2025-08-22:23:40:00,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5712/12032 [5:05:21<6:02:57,  3.45s/it]2025-08-22:23:40:03,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5713/12032 [5:05:23<5:13:06,  2.97s/it]2025-08-22:23:40:05,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5714/12032 [5:05:25<4:44:59,  2.71s/it]2025-08-22:23:40:07,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  47%|████▋     | 5715/12032 [5:05:29<5:19:56,  3.04s/it]2025-08-22:23:40:11,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5716/12032 [5:05:32<5:43:59,  3.27s/it]2025-08-22:23:40:14,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5717/12032 [5:05:36<6:00:50,  3.43s/it]2025-08-22:23:40:18,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5718/12032 [5:05:40<6:12:54,  3.54s/it]2025-08-22:23:40:22,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5719/12032 [5:05:43<5:39:55,  3.23s/it]2025-08-22:23:40:24,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5720/12032 [5:05:46<5:57:46,  3.40s/it]2025-08-22:23:40:28,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5721/12032 [5:05:49<5:35:19,  3.19s/it]2025-08-22:23:40:31,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5722/12032 [5:05:53<5:55:39,  3.38s/it]2025-08-22:23:40:35,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5723/12032 [5:05:54<4:50:22,  2.76s/it]2025-08-22:23:40:36,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5724/12032 [5:05:57<4:59:28,  2.85s/it]2025-08-22:23:40:39,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5725/12032 [5:06:01<5:23:12,  3.07s/it]2025-08-22:23:40:43,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5726/12032 [5:06:05<5:46:33,  3.30s/it]2025-08-22:23:40:47,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5727/12032 [5:06:06<4:43:32,  2.70s/it]2025-08-22:23:40:48,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5728/12032 [5:06:10<5:18:34,  3.03s/it]2025-08-22:23:40:52,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5729/12032 [5:06:14<5:46:17,  3.30s/it]2025-08-22:23:40:56,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5730/12032 [5:06:18<6:02:39,  3.45s/it]2025-08-22:23:40:59,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5731/12032 [5:06:21<6:15:20,  3.57s/it]2025-08-22:23:41:03,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5732/12032 [5:06:25<6:15:32,  3.58s/it]2025-08-22:23:41:07,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5733/12032 [5:06:28<5:45:05,  3.29s/it]2025-08-22:23:41:09,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5734/12032 [5:06:30<5:31:50,  3.16s/it]2025-08-22:23:41:12,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5735/12032 [5:06:34<5:51:40,  3.35s/it]2025-08-22:23:41:16,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5736/12032 [5:06:38<6:05:12,  3.48s/it]2025-08-22:23:41:20,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5737/12032 [5:06:42<6:14:05,  3.57s/it]2025-08-22:23:41:24,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5738/12032 [5:06:46<6:22:41,  3.65s/it]2025-08-22:23:41:27,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5739/12032 [5:06:49<6:27:09,  3.69s/it]2025-08-22:23:41:31,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5740/12032 [5:06:53<6:31:36,  3.73s/it]2025-08-22:23:41:35,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5741/12032 [5:06:57<6:33:56,  3.76s/it]2025-08-22:23:41:39,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5742/12032 [5:07:01<6:35:24,  3.77s/it]2025-08-22:23:41:43,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5743/12032 [5:07:04<6:24:27,  3.67s/it]2025-08-22:23:41:46,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5744/12032 [5:07:08<6:29:26,  3.72s/it]2025-08-22:23:41:50,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5745/12032 [5:07:12<6:32:14,  3.74s/it]2025-08-22:23:41:54,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5746/12032 [5:07:15<6:14:40,  3.58s/it]2025-08-22:23:41:57,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5747/12032 [5:07:17<5:31:44,  3.17s/it]2025-08-22:23:41:59,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5748/12032 [5:07:21<5:52:09,  3.36s/it]2025-08-22:23:42:03,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5749/12032 [5:07:25<6:06:09,  3.50s/it]2025-08-22:23:42:07,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5750/12032 [5:07:29<6:15:28,  3.59s/it]2025-08-22:23:42:11,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5751/12032 [5:07:33<6:24:25,  3.67s/it]2025-08-22:23:42:14,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5752/12032 [5:07:36<6:28:59,  3.72s/it]2025-08-22:23:42:18,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5753/12032 [5:07:40<6:30:47,  3.73s/it]2025-08-22:23:42:22,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5754/12032 [5:07:44<6:32:59,  3.76s/it]2025-08-22:23:42:26,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5755/12032 [5:07:46<5:38:50,  3.24s/it]2025-08-22:23:42:28,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5756/12032 [5:07:49<5:34:26,  3.20s/it]2025-08-22:23:42:31,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5757/12032 [5:07:53<5:56:14,  3.41s/it]2025-08-22:23:42:35,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5758/12032 [5:07:57<6:06:59,  3.51s/it]2025-08-22:23:42:39,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5759/12032 [5:08:01<6:18:12,  3.62s/it]2025-08-22:23:42:43,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5760/12032 [5:08:05<6:25:14,  3.69s/it]2025-08-22:23:42:46,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5761/12032 [5:08:08<6:31:55,  3.75s/it]2025-08-22:23:42:50,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5762/12032 [5:08:12<6:34:39,  3.78s/it]2025-08-22:23:42:54,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5763/12032 [5:08:16<6:41:33,  3.84s/it]2025-08-22:23:42:58,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5764/12032 [5:08:20<6:32:44,  3.76s/it]2025-08-22:23:43:02,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5765/12032 [5:08:23<6:25:28,  3.69s/it]2025-08-22:23:43:05,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5766/12032 [5:08:27<6:37:25,  3.81s/it]2025-08-22:23:43:09,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5767/12032 [5:08:30<6:13:06,  3.57s/it]2025-08-22:23:43:12,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5768/12032 [5:08:34<6:21:24,  3.65s/it]2025-08-22:23:43:16,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5769/12032 [5:08:36<5:09:30,  2.97s/it]2025-08-22:23:43:18,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5770/12032 [5:08:38<4:43:03,  2.71s/it]2025-08-22:23:43:20,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5771/12032 [5:08:39<4:03:02,  2.33s/it]2025-08-22:23:43:21,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5772/12032 [5:08:43<4:49:18,  2.77s/it]2025-08-22:23:43:25,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5773/12032 [5:08:47<5:22:04,  3.09s/it]2025-08-22:23:43:29,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5774/12032 [5:08:48<4:19:24,  2.49s/it]2025-08-22:23:43:30,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5775/12032 [5:08:52<5:00:31,  2.88s/it]2025-08-22:23:43:34,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5776/12032 [5:08:56<5:29:35,  3.16s/it]2025-08-22:23:43:37,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5777/12032 [5:08:58<5:10:26,  2.98s/it]2025-08-22:23:43:40,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5778/12032 [5:09:02<5:37:44,  3.24s/it]2025-08-22:23:43:44,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5779/12032 [5:09:06<5:57:52,  3.43s/it]2025-08-22:23:43:48,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5780/12032 [5:09:10<6:10:59,  3.56s/it]2025-08-22:23:43:52,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5781/12032 [5:09:13<5:53:59,  3.40s/it]2025-08-22:23:43:55,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5782/12032 [5:09:16<5:50:19,  3.36s/it]2025-08-22:23:43:58,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5783/12032 [5:09:19<5:37:07,  3.24s/it]2025-08-22:23:44:01,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5784/12032 [5:09:23<5:57:05,  3.43s/it]2025-08-22:23:44:05,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5785/12032 [5:09:27<6:11:13,  3.57s/it]2025-08-22:23:44:09,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5786/12032 [5:09:30<5:46:49,  3.33s/it]2025-08-22:23:44:11,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5787/12032 [5:09:33<6:01:13,  3.47s/it]2025-08-22:23:44:15,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5788/12032 [5:09:34<4:47:26,  2.76s/it]2025-08-22:23:44:16,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5789/12032 [5:09:38<5:20:21,  3.08s/it]2025-08-22:23:44:20,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5790/12032 [5:09:42<5:43:16,  3.30s/it]2025-08-22:23:44:24,385 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5791/12032 [5:09:44<4:55:29,  2.84s/it]2025-08-22:23:44:26,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5792/12032 [5:09:46<4:48:48,  2.78s/it]2025-08-22:23:44:28,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5793/12032 [5:09:50<5:22:38,  3.10s/it]2025-08-22:23:44:32,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5794/12032 [5:09:54<5:45:27,  3.32s/it]2025-08-22:23:44:36,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5795/12032 [5:09:58<6:02:19,  3.49s/it]2025-08-22:23:44:40,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5796/12032 [5:10:02<6:12:48,  3.59s/it]2025-08-22:23:44:44,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5797/12032 [5:10:06<6:19:15,  3.65s/it]2025-08-22:23:44:47,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5798/12032 [5:10:09<6:24:15,  3.70s/it]2025-08-22:23:44:51,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5799/12032 [5:10:13<6:28:15,  3.74s/it]2025-08-22:23:44:55,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5800/12032 [5:10:16<6:00:27,  3.47s/it]2025-08-22:23:44:58,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5801/12032 [5:10:20<5:58:32,  3.45s/it]2025-08-22:23:45:01,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5802/12032 [5:10:23<6:09:39,  3.56s/it]2025-08-22:23:45:05,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5803/12032 [5:10:27<6:17:06,  3.63s/it]2025-08-22:23:45:09,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5804/12032 [5:10:30<5:41:26,  3.29s/it]2025-08-22:23:45:11,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5805/12032 [5:10:33<5:57:14,  3.44s/it]2025-08-22:23:45:15,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5806/12032 [5:10:37<6:09:14,  3.56s/it]2025-08-22:23:45:19,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5807/12032 [5:10:40<5:30:32,  3.19s/it]2025-08-22:23:45:21,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5808/12032 [5:10:42<5:09:01,  2.98s/it]2025-08-22:23:45:24,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5809/12032 [5:10:46<5:35:04,  3.23s/it]2025-08-22:23:45:28,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5810/12032 [5:10:49<5:18:32,  3.07s/it]2025-08-22:23:45:30,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5811/12032 [5:10:52<5:41:18,  3.29s/it]2025-08-22:23:45:34,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5812/12032 [5:10:56<5:59:18,  3.47s/it]2025-08-22:23:45:38,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5813/12032 [5:11:00<6:07:16,  3.54s/it]2025-08-22:23:45:42,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5814/12032 [5:11:04<6:16:14,  3.63s/it]2025-08-22:23:45:46,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5815/12032 [5:11:08<6:24:24,  3.71s/it]2025-08-22:23:45:50,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5816/12032 [5:11:11<6:05:14,  3.53s/it]2025-08-22:23:45:53,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5817/12032 [5:11:15<6:17:03,  3.64s/it]2025-08-22:23:45:57,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5818/12032 [5:11:19<6:25:13,  3.72s/it]2025-08-22:23:46:00,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5819/12032 [5:11:21<5:41:17,  3.30s/it]2025-08-22:23:46:03,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5820/12032 [5:11:25<5:59:26,  3.47s/it]2025-08-22:23:46:07,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5821/12032 [5:11:27<5:19:55,  3.09s/it]2025-08-22:23:46:09,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5822/12032 [5:11:31<5:45:05,  3.33s/it]2025-08-22:23:46:13,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5823/12032 [5:11:35<6:01:34,  3.49s/it]2025-08-22:23:46:17,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5824/12032 [5:11:38<5:50:53,  3.39s/it]2025-08-22:23:46:20,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5825/12032 [5:11:39<4:50:41,  2.81s/it]2025-08-22:23:46:21,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5826/12032 [5:11:43<5:24:33,  3.14s/it]2025-08-22:23:46:25,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5827/12032 [5:11:46<5:17:54,  3.07s/it]2025-08-22:23:46:28,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5828/12032 [5:11:50<5:41:42,  3.30s/it]2025-08-22:23:46:32,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5829/12032 [5:11:54<5:57:49,  3.46s/it]2025-08-22:23:46:36,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5830/12032 [5:11:58<6:11:01,  3.59s/it]2025-08-22:23:46:40,117 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5831/12032 [5:12:00<5:41:32,  3.30s/it]2025-08-22:23:46:42,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5832/12032 [5:12:04<5:58:16,  3.47s/it]2025-08-22:23:46:46,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5833/12032 [5:12:07<5:31:38,  3.21s/it]2025-08-22:23:46:49,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5834/12032 [5:12:11<5:50:41,  3.39s/it]2025-08-22:23:46:53,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  48%|████▊     | 5835/12032 [5:12:15<6:03:26,  3.52s/it]2025-08-22:23:46:56,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5836/12032 [5:12:18<5:57:48,  3.46s/it]2025-08-22:23:47:00,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5837/12032 [5:12:22<6:08:40,  3.57s/it]2025-08-22:23:47:04,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5838/12032 [5:12:25<6:05:11,  3.54s/it]2025-08-22:23:47:07,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5839/12032 [5:12:29<6:13:42,  3.62s/it]2025-08-22:23:47:11,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5840/12032 [5:12:33<6:19:44,  3.68s/it]2025-08-22:23:47:15,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5841/12032 [5:12:37<6:26:01,  3.74s/it]2025-08-22:23:47:18,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5842/12032 [5:12:39<5:43:08,  3.33s/it]2025-08-22:23:47:21,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5843/12032 [5:12:43<5:51:42,  3.41s/it]2025-08-22:23:47:24,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5844/12032 [5:12:46<6:03:40,  3.53s/it]2025-08-22:23:47:28,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5845/12032 [5:12:50<6:14:16,  3.63s/it]2025-08-22:23:47:32,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5846/12032 [5:12:54<6:20:39,  3.69s/it]2025-08-22:23:47:36,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5847/12032 [5:12:55<5:02:01,  2.93s/it]2025-08-22:23:47:37,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5848/12032 [5:12:57<4:40:00,  2.72s/it]2025-08-22:23:47:39,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5849/12032 [5:13:01<5:09:48,  3.01s/it]2025-08-22:23:47:43,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5850/12032 [5:13:05<5:34:59,  3.25s/it]2025-08-22:23:47:47,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5851/12032 [5:13:09<5:52:26,  3.42s/it]2025-08-22:23:47:51,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5852/12032 [5:13:13<6:05:56,  3.55s/it]2025-08-22:23:47:55,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5853/12032 [5:13:16<6:13:55,  3.63s/it]2025-08-22:23:47:58,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5854/12032 [5:13:17<4:51:20,  2.83s/it]2025-08-22:23:47:59,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5855/12032 [5:13:21<5:21:37,  3.12s/it]2025-08-22:23:48:03,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5856/12032 [5:13:25<5:42:39,  3.33s/it]2025-08-22:23:48:07,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5857/12032 [5:13:29<5:58:18,  3.48s/it]2025-08-22:23:48:11,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5858/12032 [5:13:32<5:34:19,  3.25s/it]2025-08-22:23:48:13,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5859/12032 [5:13:35<5:52:26,  3.43s/it]2025-08-22:23:48:17,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5860/12032 [5:13:39<6:04:34,  3.54s/it]2025-08-22:23:48:21,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5861/12032 [5:13:43<6:12:47,  3.62s/it]2025-08-22:23:48:25,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5862/12032 [5:13:47<6:18:54,  3.68s/it]2025-08-22:23:48:29,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5863/12032 [5:13:51<6:23:23,  3.73s/it]2025-08-22:23:48:33,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5864/12032 [5:13:54<6:09:55,  3.60s/it]2025-08-22:23:48:36,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▊     | 5865/12032 [5:13:58<6:06:43,  3.57s/it]2025-08-22:23:48:39,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5866/12032 [5:13:59<4:48:47,  2.81s/it]2025-08-22:23:48:40,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5867/12032 [5:14:02<5:18:52,  3.10s/it]2025-08-22:23:48:44,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5868/12032 [5:14:06<5:37:32,  3.29s/it]2025-08-22:23:48:48,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5869/12032 [5:14:07<4:35:05,  2.68s/it]2025-08-22:23:48:49,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5870/12032 [5:14:11<5:10:10,  3.02s/it]2025-08-22:23:48:53,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5871/12032 [5:14:15<5:34:53,  3.26s/it]2025-08-22:23:48:57,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5872/12032 [5:14:19<5:52:00,  3.43s/it]2025-08-22:23:49:01,120 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5873/12032 [5:14:21<5:12:22,  3.04s/it]2025-08-22:23:49:03,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5874/12032 [5:14:25<5:36:12,  3.28s/it]2025-08-22:23:49:07,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5875/12032 [5:14:29<5:52:33,  3.44s/it]2025-08-22:23:49:10,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5876/12032 [5:14:32<6:03:36,  3.54s/it]2025-08-22:23:49:14,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5877/12032 [5:14:34<5:01:05,  2.94s/it]2025-08-22:23:49:16,202 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5878/12032 [5:14:36<4:27:46,  2.61s/it]2025-08-22:23:49:18,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5879/12032 [5:14:37<3:33:56,  2.09s/it]2025-08-22:23:49:18,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5880/12032 [5:14:39<3:49:57,  2.24s/it]2025-08-22:23:49:21,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5881/12032 [5:14:43<4:37:03,  2.70s/it]2025-08-22:23:49:25,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5882/12032 [5:14:44<3:47:32,  2.22s/it]2025-08-22:23:49:26,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5883/12032 [5:14:48<4:47:27,  2.80s/it]2025-08-22:23:49:30,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5884/12032 [5:14:52<5:27:21,  3.19s/it]2025-08-22:23:49:34,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5885/12032 [5:14:56<5:53:13,  3.45s/it]2025-08-22:23:49:38,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5886/12032 [5:14:58<4:59:25,  2.92s/it]2025-08-22:23:49:40,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5887/12032 [5:15:01<4:46:57,  2.80s/it]2025-08-22:23:49:42,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5888/12032 [5:15:04<5:18:41,  3.11s/it]2025-08-22:23:49:46,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5889/12032 [5:15:08<5:42:30,  3.35s/it]2025-08-22:23:49:50,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5890/12032 [5:15:11<5:16:49,  3.10s/it]2025-08-22:23:49:53,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5891/12032 [5:15:13<4:48:17,  2.82s/it]2025-08-22:23:49:55,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5892/12032 [5:15:17<5:18:32,  3.11s/it]2025-08-22:23:49:59,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5893/12032 [5:15:21<5:41:10,  3.33s/it]2025-08-22:23:50:02,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5894/12032 [5:15:23<5:02:23,  2.96s/it]2025-08-22:23:50:05,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5895/12032 [5:15:27<5:29:13,  3.22s/it]2025-08-22:23:50:08,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5896/12032 [5:15:30<5:46:55,  3.39s/it]2025-08-22:23:50:12,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5897/12032 [5:15:34<6:00:08,  3.52s/it]2025-08-22:23:50:16,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5898/12032 [5:15:38<6:09:37,  3.62s/it]2025-08-22:23:50:20,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5899/12032 [5:15:42<6:14:48,  3.67s/it]2025-08-22:23:50:24,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5900/12032 [5:15:46<6:20:02,  3.72s/it]2025-08-22:23:50:27,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5901/12032 [5:15:49<6:23:23,  3.75s/it]2025-08-22:23:50:31,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5902/12032 [5:15:53<6:25:08,  3.77s/it]2025-08-22:23:50:35,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5903/12032 [5:15:56<6:05:37,  3.58s/it]2025-08-22:23:50:38,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5904/12032 [5:16:00<6:12:42,  3.65s/it]2025-08-22:23:50:42,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5905/12032 [5:16:04<6:15:27,  3.68s/it]2025-08-22:23:50:46,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5906/12032 [5:16:07<5:42:55,  3.36s/it]2025-08-22:23:50:48,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5907/12032 [5:16:10<5:57:09,  3.50s/it]2025-08-22:23:50:52,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5908/12032 [5:16:14<6:06:19,  3.59s/it]2025-08-22:23:50:56,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5909/12032 [5:16:18<6:13:26,  3.66s/it]2025-08-22:23:51:00,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5910/12032 [5:16:22<6:18:15,  3.71s/it]2025-08-22:23:51:04,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5911/12032 [5:16:22<4:44:45,  2.79s/it]2025-08-22:23:51:04,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5912/12032 [5:16:24<3:51:05,  2.27s/it]2025-08-22:23:51:05,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5913/12032 [5:16:26<3:56:29,  2.32s/it]2025-08-22:23:51:08,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5914/12032 [5:16:29<4:07:34,  2.43s/it]2025-08-22:23:51:11,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5915/12032 [5:16:33<4:50:45,  2.85s/it]2025-08-22:23:51:14,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5916/12032 [5:16:36<5:21:55,  3.16s/it]2025-08-22:23:51:18,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5917/12032 [5:16:40<5:46:18,  3.40s/it]2025-08-22:23:51:22,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5918/12032 [5:16:42<5:05:29,  3.00s/it]2025-08-22:23:51:24,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5919/12032 [5:16:46<5:30:03,  3.24s/it]2025-08-22:23:51:28,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5920/12032 [5:16:50<5:47:32,  3.41s/it]2025-08-22:23:51:32,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5921/12032 [5:16:54<6:00:19,  3.54s/it]2025-08-22:23:51:36,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5922/12032 [5:16:58<6:08:40,  3.62s/it]2025-08-22:23:51:40,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5923/12032 [5:17:01<6:14:18,  3.68s/it]2025-08-22:23:51:43,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5924/12032 [5:17:05<6:20:21,  3.74s/it]2025-08-22:23:51:47,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5925/12032 [5:17:08<6:02:19,  3.56s/it]2025-08-22:23:51:50,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5926/12032 [5:17:12<6:09:51,  3.63s/it]2025-08-22:23:51:54,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5927/12032 [5:17:14<5:19:28,  3.14s/it]2025-08-22:23:51:56,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5928/12032 [5:17:18<5:32:07,  3.26s/it]2025-08-22:23:52:00,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5929/12032 [5:17:22<5:49:39,  3.44s/it]2025-08-22:23:52:04,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5930/12032 [5:17:26<6:03:19,  3.57s/it]2025-08-22:23:52:07,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5931/12032 [5:17:28<5:39:50,  3.34s/it]2025-08-22:23:52:10,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5932/12032 [5:17:32<5:56:32,  3.51s/it]2025-08-22:23:52:14,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5933/12032 [5:17:36<6:05:59,  3.60s/it]2025-08-22:23:52:18,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5934/12032 [5:17:40<6:14:05,  3.68s/it]2025-08-22:23:52:22,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5935/12032 [5:17:44<6:17:56,  3.72s/it]2025-08-22:23:52:26,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5936/12032 [5:17:46<5:35:15,  3.30s/it]2025-08-22:23:52:28,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5937/12032 [5:17:47<4:21:26,  2.57s/it]2025-08-22:23:52:29,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5938/12032 [5:17:51<4:58:54,  2.94s/it]2025-08-22:23:52:33,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5939/12032 [5:17:52<4:09:41,  2.46s/it]2025-08-22:23:52:34,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5940/12032 [5:17:55<4:26:49,  2.63s/it]2025-08-22:23:52:37,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5941/12032 [5:17:56<3:37:16,  2.14s/it]2025-08-22:23:52:38,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5942/12032 [5:18:00<4:28:19,  2.64s/it]2025-08-22:23:52:42,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5943/12032 [5:18:04<5:05:53,  3.01s/it]2025-08-22:23:52:46,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5944/12032 [5:18:08<5:29:48,  3.25s/it]2025-08-22:23:52:49,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5945/12032 [5:18:10<5:07:32,  3.03s/it]2025-08-22:23:52:52,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5946/12032 [5:18:13<5:17:19,  3.13s/it]2025-08-22:23:52:55,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5947/12032 [5:18:16<5:10:27,  3.06s/it]2025-08-22:23:52:58,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5948/12032 [5:18:20<5:34:49,  3.30s/it]2025-08-22:23:53:02,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5949/12032 [5:18:24<5:50:22,  3.46s/it]2025-08-22:23:53:06,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5950/12032 [5:18:28<6:01:45,  3.57s/it]2025-08-22:23:53:10,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5951/12032 [5:18:30<5:06:13,  3.02s/it]2025-08-22:23:53:11,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5952/12032 [5:18:33<5:30:55,  3.27s/it]2025-08-22:23:53:15,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5953/12032 [5:18:37<5:47:39,  3.43s/it]2025-08-22:23:53:19,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5954/12032 [5:18:41<6:01:53,  3.57s/it]2025-08-22:23:53:23,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  49%|████▉     | 5955/12032 [5:18:43<5:20:49,  3.17s/it]2025-08-22:23:53:25,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5956/12032 [5:18:45<4:31:38,  2.68s/it]2025-08-22:23:53:27,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5957/12032 [5:18:47<4:15:54,  2.53s/it]2025-08-22:23:53:29,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5958/12032 [5:18:50<4:25:48,  2.63s/it]2025-08-22:23:53:32,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5959/12032 [5:18:51<3:48:12,  2.25s/it]2025-08-22:23:53:33,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5960/12032 [5:18:55<4:36:24,  2.73s/it]2025-08-22:23:53:37,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5961/12032 [5:18:57<4:21:14,  2.58s/it]2025-08-22:23:53:39,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5962/12032 [5:19:01<5:00:53,  2.97s/it]2025-08-22:23:53:43,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5963/12032 [5:19:05<5:06:43,  3.03s/it]2025-08-22:23:53:46,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5964/12032 [5:19:08<5:09:44,  3.06s/it]2025-08-22:23:53:50,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5965/12032 [5:19:11<5:18:43,  3.15s/it]2025-08-22:23:53:53,363 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5966/12032 [5:19:15<5:39:17,  3.36s/it]2025-08-22:23:53:57,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5967/12032 [5:19:19<5:53:33,  3.50s/it]2025-08-22:23:54:01,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5968/12032 [5:19:22<6:03:00,  3.59s/it]2025-08-22:23:54:04,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5969/12032 [5:19:25<5:27:56,  3.25s/it]2025-08-22:23:54:07,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5970/12032 [5:19:29<5:46:13,  3.43s/it]2025-08-22:23:54:11,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5971/12032 [5:19:30<4:35:18,  2.73s/it]2025-08-22:23:54:12,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5972/12032 [5:19:32<4:24:03,  2.61s/it]2025-08-22:23:54:14,566 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5973/12032 [5:19:36<5:02:26,  2.99s/it]2025-08-22:23:54:18,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5974/12032 [5:19:40<5:27:01,  3.24s/it]2025-08-22:23:54:22,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5975/12032 [5:19:44<5:45:07,  3.42s/it]2025-08-22:23:54:26,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5976/12032 [5:19:46<5:12:55,  3.10s/it]2025-08-22:23:54:28,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5977/12032 [5:19:50<5:34:12,  3.31s/it]2025-08-22:23:54:32,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5978/12032 [5:19:53<5:21:14,  3.18s/it]2025-08-22:23:54:35,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5979/12032 [5:19:57<5:41:29,  3.38s/it]2025-08-22:23:54:38,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5980/12032 [5:20:01<5:55:57,  3.53s/it]2025-08-22:23:54:42,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5981/12032 [5:20:04<6:04:30,  3.61s/it]2025-08-22:23:54:46,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5982/12032 [5:20:08<6:10:57,  3.68s/it]2025-08-22:23:54:50,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5983/12032 [5:20:10<5:26:38,  3.24s/it]2025-08-22:23:54:52,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5984/12032 [5:20:13<4:52:52,  2.91s/it]2025-08-22:23:54:54,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5985/12032 [5:20:16<5:24:28,  3.22s/it]2025-08-22:23:54:58,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5986/12032 [5:20:19<4:49:20,  2.87s/it]2025-08-22:23:55:00,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5987/12032 [5:20:22<5:11:05,  3.09s/it]2025-08-22:23:55:04,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5988/12032 [5:20:26<5:28:30,  3.26s/it]2025-08-22:23:55:08,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5989/12032 [5:20:30<5:45:51,  3.43s/it]2025-08-22:23:55:11,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5990/12032 [5:20:33<5:54:31,  3.52s/it]2025-08-22:23:55:15,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5991/12032 [5:20:36<5:29:25,  3.27s/it]2025-08-22:23:55:18,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5992/12032 [5:20:39<5:21:53,  3.20s/it]2025-08-22:23:55:21,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5993/12032 [5:20:43<5:40:37,  3.38s/it]2025-08-22:23:55:25,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5994/12032 [5:20:47<5:55:56,  3.54s/it]2025-08-22:23:55:29,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5995/12032 [5:20:50<5:56:16,  3.54s/it]2025-08-22:23:55:32,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5996/12032 [5:20:54<6:05:55,  3.64s/it]2025-08-22:23:55:36,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5997/12032 [5:20:58<6:12:20,  3.70s/it]2025-08-22:23:55:40,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5998/12032 [5:21:02<6:16:58,  3.75s/it]2025-08-22:23:55:44,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 5999/12032 [5:21:06<6:19:42,  3.78s/it]2025-08-22:23:55:48,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6000/12032 [5:21:09<6:18:41,  3.77s/it]2025-08-22:23:55:51,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6001/12032 [5:21:11<5:03:25,  3.02s/it]2025-08-22:23:55:53,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6002/12032 [5:21:12<4:24:11,  2.63s/it]2025-08-22:23:55:54,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6003/12032 [5:21:15<4:06:40,  2.45s/it]2025-08-22:23:55:56,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6004/12032 [5:21:18<4:47:58,  2.87s/it]2025-08-22:23:56:00,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6005/12032 [5:21:22<5:16:04,  3.15s/it]2025-08-22:23:56:04,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6006/12032 [5:21:23<4:21:08,  2.60s/it]2025-08-22:23:56:05,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6007/12032 [5:21:27<4:56:55,  2.96s/it]2025-08-22:23:56:09,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6008/12032 [5:21:31<5:23:05,  3.22s/it]2025-08-22:23:56:13,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6009/12032 [5:21:35<5:41:36,  3.40s/it]2025-08-22:23:56:17,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6010/12032 [5:21:39<5:53:57,  3.53s/it]2025-08-22:23:56:21,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6011/12032 [5:21:42<5:41:12,  3.40s/it]2025-08-22:23:56:24,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6012/12032 [5:21:46<5:53:17,  3.52s/it]2025-08-22:23:56:27,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6013/12032 [5:21:48<5:21:01,  3.20s/it]2025-08-22:23:56:30,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6014/12032 [5:21:49<4:26:20,  2.66s/it]2025-08-22:23:56:31,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|████▉     | 6015/12032 [5:21:51<3:42:20,  2.22s/it]2025-08-22:23:56:33,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6016/12032 [5:21:53<3:41:33,  2.21s/it]2025-08-22:23:56:35,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6017/12032 [5:21:55<3:30:35,  2.10s/it]2025-08-22:23:56:37,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6018/12032 [5:21:57<3:43:11,  2.23s/it]2025-08-22:23:56:39,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6019/12032 [5:22:00<4:06:38,  2.46s/it]2025-08-22:23:56:42,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6020/12032 [5:22:02<3:34:34,  2.14s/it]2025-08-22:23:56:43,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6021/12032 [5:22:05<4:25:24,  2.65s/it]2025-08-22:23:56:47,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6022/12032 [5:22:09<5:01:47,  3.01s/it]2025-08-22:23:56:51,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6023/12032 [5:22:13<5:26:39,  3.26s/it]2025-08-22:23:56:55,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6024/12032 [5:22:17<5:43:37,  3.43s/it]2025-08-22:23:56:59,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6025/12032 [5:22:21<5:56:10,  3.56s/it]2025-08-22:23:57:03,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6026/12032 [5:22:25<6:04:04,  3.64s/it]2025-08-22:23:57:07,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6027/12032 [5:22:29<6:10:45,  3.70s/it]2025-08-22:23:57:10,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6028/12032 [5:22:32<6:14:31,  3.74s/it]2025-08-22:23:57:14,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6029/12032 [5:22:36<6:16:57,  3.77s/it]2025-08-22:23:57:18,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6030/12032 [5:22:39<5:50:24,  3.50s/it]2025-08-22:23:57:21,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6031/12032 [5:22:43<5:50:17,  3.50s/it]2025-08-22:23:57:24,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6032/12032 [5:22:46<6:02:22,  3.62s/it]2025-08-22:23:57:28,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6033/12032 [5:22:50<6:09:00,  3.69s/it]2025-08-22:23:57:32,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6034/12032 [5:22:54<6:13:12,  3.73s/it]2025-08-22:23:57:36,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6035/12032 [5:22:58<6:15:49,  3.76s/it]2025-08-22:23:57:40,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6036/12032 [5:23:00<5:12:34,  3.13s/it]2025-08-22:23:57:41,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6037/12032 [5:23:03<5:33:01,  3.33s/it]2025-08-22:23:57:45,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6038/12032 [5:23:07<5:47:31,  3.48s/it]2025-08-22:23:57:49,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6039/12032 [5:23:11<5:57:51,  3.58s/it]2025-08-22:23:57:53,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6040/12032 [5:23:15<6:05:11,  3.66s/it]2025-08-22:23:57:57,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6041/12032 [5:23:19<6:10:52,  3.71s/it]2025-08-22:23:58:01,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6042/12032 [5:23:21<5:34:59,  3.36s/it]2025-08-22:23:58:03,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6043/12032 [5:23:25<5:49:28,  3.50s/it]2025-08-22:23:58:07,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6044/12032 [5:23:29<5:59:19,  3.60s/it]2025-08-22:23:58:11,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6045/12032 [5:23:32<5:30:21,  3.31s/it]2025-08-22:23:58:13,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6046/12032 [5:23:34<4:58:05,  2.99s/it]2025-08-22:23:58:16,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6047/12032 [5:23:36<4:37:01,  2.78s/it]2025-08-22:23:58:18,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6048/12032 [5:23:40<5:11:48,  3.13s/it]2025-08-22:23:58:22,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6049/12032 [5:23:44<5:33:01,  3.34s/it]2025-08-22:23:58:26,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6050/12032 [5:23:48<5:48:27,  3.50s/it]2025-08-22:23:58:30,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6051/12032 [5:23:50<5:12:57,  3.14s/it]2025-08-22:23:58:32,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6052/12032 [5:23:54<5:34:02,  3.35s/it]2025-08-22:23:58:36,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6053/12032 [5:23:58<5:51:21,  3.53s/it]2025-08-22:23:58:40,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6054/12032 [5:24:01<5:37:52,  3.39s/it]2025-08-22:23:58:43,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6055/12032 [5:24:05<5:46:35,  3.48s/it]2025-08-22:23:58:46,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6056/12032 [5:24:08<5:56:28,  3.58s/it]2025-08-22:23:58:50,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6057/12032 [5:24:10<4:48:34,  2.90s/it]2025-08-22:23:58:52,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6058/12032 [5:24:13<5:08:23,  3.10s/it]2025-08-22:23:58:55,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6059/12032 [5:24:17<5:30:52,  3.32s/it]2025-08-22:23:58:59,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6060/12032 [5:24:21<5:46:59,  3.49s/it]2025-08-22:23:59:03,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6061/12032 [5:24:24<5:30:50,  3.32s/it]2025-08-22:23:59:06,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6062/12032 [5:24:25<4:21:38,  2.63s/it]2025-08-22:23:59:07,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6063/12032 [5:24:29<4:56:07,  2.98s/it]2025-08-22:23:59:11,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6064/12032 [5:24:32<5:16:55,  3.19s/it]2025-08-22:23:59:14,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6065/12032 [5:24:36<5:29:03,  3.31s/it]2025-08-22:23:59:18,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6066/12032 [5:24:40<5:43:37,  3.46s/it]2025-08-22:23:59:22,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6067/12032 [5:24:44<5:55:20,  3.57s/it]2025-08-22:23:59:26,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6068/12032 [5:24:46<5:32:31,  3.35s/it]2025-08-22:23:59:28,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6069/12032 [5:24:50<5:46:05,  3.48s/it]2025-08-22:23:59:32,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6070/12032 [5:24:52<5:07:07,  3.09s/it]2025-08-22:23:59:34,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6071/12032 [5:24:56<5:28:25,  3.31s/it]2025-08-22:23:59:38,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6072/12032 [5:24:59<5:25:50,  3.28s/it]2025-08-22:23:59:41,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6073/12032 [5:25:03<5:42:02,  3.44s/it]2025-08-22:23:59:45,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6074/12032 [5:25:07<5:53:32,  3.56s/it]2025-08-22:23:59:49,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6075/12032 [5:25:10<5:27:14,  3.30s/it]2025-08-22:23:59:52,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  50%|█████     | 6076/12032 [5:25:13<5:32:22,  3.35s/it]2025-08-22:23:59:55,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6077/12032 [5:25:17<5:48:47,  3.51s/it]2025-08-22:23:59:59,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6078/12032 [5:25:19<4:46:24,  2.89s/it]2025-08-23:00:00:00,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6079/12032 [5:25:20<3:56:44,  2.39s/it]2025-08-23:00:00:02,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6080/12032 [5:25:21<3:21:23,  2.03s/it]2025-08-23:00:00:03,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6081/12032 [5:25:24<3:58:03,  2.40s/it]2025-08-23:00:00:06,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6082/12032 [5:25:26<3:30:25,  2.12s/it]2025-08-23:00:00:08,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6083/12032 [5:25:29<4:10:26,  2.53s/it]2025-08-23:00:00:11,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6084/12032 [5:25:32<4:03:43,  2.46s/it]2025-08-23:00:00:13,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6085/12032 [5:25:34<4:06:30,  2.49s/it]2025-08-23:00:00:16,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6086/12032 [5:25:37<4:25:23,  2.68s/it]2025-08-23:00:00:19,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6087/12032 [5:25:41<4:53:00,  2.96s/it]2025-08-23:00:00:23,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6088/12032 [5:25:45<5:20:03,  3.23s/it]2025-08-23:00:00:27,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6089/12032 [5:25:49<5:37:12,  3.40s/it]2025-08-23:00:00:30,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6090/12032 [5:25:52<5:49:26,  3.53s/it]2025-08-23:00:00:34,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6091/12032 [5:25:55<5:33:39,  3.37s/it]2025-08-23:00:00:37,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6092/12032 [5:25:59<5:47:08,  3.51s/it]2025-08-23:00:00:41,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6093/12032 [5:26:03<5:56:33,  3.60s/it]2025-08-23:00:00:45,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6094/12032 [5:26:07<6:00:20,  3.64s/it]2025-08-23:00:00:49,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6095/12032 [5:26:10<5:50:40,  3.54s/it]2025-08-23:00:00:52,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6096/12032 [5:26:14<5:58:07,  3.62s/it]2025-08-23:00:00:56,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6097/12032 [5:26:18<6:03:38,  3.68s/it]2025-08-23:00:00:59,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6098/12032 [5:26:21<6:06:14,  3.70s/it]2025-08-23:00:01:03,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6099/12032 [5:26:24<5:41:16,  3.45s/it]2025-08-23:00:01:06,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6100/12032 [5:26:27<5:08:20,  3.12s/it]2025-08-23:00:01:08,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6101/12032 [5:26:30<5:30:13,  3.34s/it]2025-08-23:00:01:12,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6102/12032 [5:26:34<5:25:34,  3.29s/it]2025-08-23:00:01:15,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6103/12032 [5:26:36<5:06:05,  3.10s/it]2025-08-23:00:01:18,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6104/12032 [5:26:40<5:28:17,  3.32s/it]2025-08-23:00:01:22,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6105/12032 [5:26:44<5:39:37,  3.44s/it]2025-08-23:00:01:26,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6106/12032 [5:26:46<5:07:51,  3.12s/it]2025-08-23:00:01:28,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6107/12032 [5:26:49<5:13:00,  3.17s/it]2025-08-23:00:01:31,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6108/12032 [5:26:53<5:30:03,  3.34s/it]2025-08-23:00:01:35,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6109/12032 [5:26:57<5:43:46,  3.48s/it]2025-08-23:00:01:39,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6110/12032 [5:27:01<5:53:18,  3.58s/it]2025-08-23:00:01:43,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6111/12032 [5:27:03<5:05:55,  3.10s/it]2025-08-23:00:01:45,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6112/12032 [5:27:05<4:36:40,  2.80s/it]2025-08-23:00:01:47,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6113/12032 [5:27:09<5:06:50,  3.11s/it]2025-08-23:00:01:51,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6114/12032 [5:27:12<5:24:44,  3.29s/it]2025-08-23:00:01:54,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6115/12032 [5:27:15<4:52:37,  2.97s/it]2025-08-23:00:01:57,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6116/12032 [5:27:19<5:18:42,  3.23s/it]2025-08-23:00:02:00,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6117/12032 [5:27:22<5:12:21,  3.17s/it]2025-08-23:00:02:03,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6118/12032 [5:27:24<4:35:45,  2.80s/it]2025-08-23:00:02:05,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6119/12032 [5:27:27<5:01:37,  3.06s/it]2025-08-23:00:02:09,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6120/12032 [5:27:31<5:24:00,  3.29s/it]2025-08-23:00:02:13,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6121/12032 [5:27:35<5:38:36,  3.44s/it]2025-08-23:00:02:17,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6122/12032 [5:27:39<5:51:20,  3.57s/it]2025-08-23:00:02:20,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6123/12032 [5:27:42<5:59:16,  3.65s/it]2025-08-23:00:02:24,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6124/12032 [5:27:46<5:50:30,  3.56s/it]2025-08-23:00:02:28,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6125/12032 [5:27:49<5:33:08,  3.38s/it]2025-08-23:00:02:31,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6126/12032 [5:27:51<4:57:18,  3.02s/it]2025-08-23:00:02:33,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6127/12032 [5:27:55<5:19:40,  3.25s/it]2025-08-23:00:02:37,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6128/12032 [5:27:58<5:14:37,  3.20s/it]2025-08-23:00:02:40,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6129/12032 [5:28:01<5:21:43,  3.27s/it]2025-08-23:00:02:43,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6130/12032 [5:28:04<5:12:59,  3.18s/it]2025-08-23:00:02:46,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6131/12032 [5:28:08<5:25:30,  3.31s/it]2025-08-23:00:02:50,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6132/12032 [5:28:10<4:55:46,  3.01s/it]2025-08-23:00:02:52,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6133/12032 [5:28:14<5:20:31,  3.26s/it]2025-08-23:00:02:56,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6134/12032 [5:28:16<4:40:48,  2.86s/it]2025-08-23:00:02:58,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6135/12032 [5:28:18<4:28:27,  2.73s/it]2025-08-23:00:03:00,725 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6136/12032 [5:28:22<5:02:50,  3.08s/it]2025-08-23:00:03:04,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6137/12032 [5:28:24<4:17:47,  2.62s/it]2025-08-23:00:03:06,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6138/12032 [5:28:26<3:49:32,  2.34s/it]2025-08-23:00:03:07,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6139/12032 [5:28:29<4:33:25,  2.78s/it]2025-08-23:00:03:11,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6140/12032 [5:28:33<5:04:49,  3.10s/it]2025-08-23:00:03:15,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6141/12032 [5:28:37<5:17:42,  3.24s/it]2025-08-23:00:03:19,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6142/12032 [5:28:39<4:55:20,  3.01s/it]2025-08-23:00:03:21,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6143/12032 [5:28:43<5:20:20,  3.26s/it]2025-08-23:00:03:25,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6144/12032 [5:28:47<5:33:50,  3.40s/it]2025-08-23:00:03:29,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6145/12032 [5:28:50<5:26:13,  3.32s/it]2025-08-23:00:03:32,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6146/12032 [5:28:53<5:26:22,  3.33s/it]2025-08-23:00:03:35,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6147/12032 [5:28:56<4:55:48,  3.02s/it]2025-08-23:00:03:37,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6148/12032 [5:28:59<5:21:12,  3.28s/it]2025-08-23:00:03:41,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6149/12032 [5:29:03<5:37:12,  3.44s/it]2025-08-23:00:03:45,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6150/12032 [5:29:07<5:49:08,  3.56s/it]2025-08-23:00:03:49,446 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6151/12032 [5:29:11<5:55:25,  3.63s/it]2025-08-23:00:03:53,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6152/12032 [5:29:15<6:00:11,  3.68s/it]2025-08-23:00:03:57,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6153/12032 [5:29:17<5:27:34,  3.34s/it]2025-08-23:00:03:59,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6154/12032 [5:29:21<5:41:08,  3.48s/it]2025-08-23:00:04:03,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6155/12032 [5:29:25<5:51:49,  3.59s/it]2025-08-23:00:04:07,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6156/12032 [5:29:27<5:19:01,  3.26s/it]2025-08-23:00:04:09,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6157/12032 [5:29:30<5:09:49,  3.16s/it]2025-08-23:00:04:12,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6158/12032 [5:29:34<5:28:01,  3.35s/it]2025-08-23:00:04:16,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6159/12032 [5:29:38<5:41:35,  3.49s/it]2025-08-23:00:04:20,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6160/12032 [5:29:42<5:50:36,  3.58s/it]2025-08-23:00:04:24,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6161/12032 [5:29:44<5:03:09,  3.10s/it]2025-08-23:00:04:26,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6162/12032 [5:29:48<5:24:56,  3.32s/it]2025-08-23:00:04:29,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6163/12032 [5:29:51<5:39:48,  3.47s/it]2025-08-23:00:04:33,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6164/12032 [5:29:55<5:50:24,  3.58s/it]2025-08-23:00:04:37,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6165/12032 [5:29:58<5:37:38,  3.45s/it]2025-08-23:00:04:40,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████     | 6166/12032 [5:29:59<4:18:47,  2.65s/it]2025-08-23:00:04:41,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6167/12032 [5:30:03<4:45:15,  2.92s/it]2025-08-23:00:04:45,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6168/12032 [5:30:04<4:04:56,  2.51s/it]2025-08-23:00:04:46,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6169/12032 [5:30:05<3:24:31,  2.09s/it]2025-08-23:00:04:47,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6170/12032 [5:30:09<4:15:06,  2.61s/it]2025-08-23:00:04:51,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6171/12032 [5:30:11<3:54:33,  2.40s/it]2025-08-23:00:04:53,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6172/12032 [5:30:15<4:26:47,  2.73s/it]2025-08-23:00:04:56,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6173/12032 [5:30:18<4:58:06,  3.05s/it]2025-08-23:00:05:00,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6174/12032 [5:30:22<5:19:54,  3.28s/it]2025-08-23:00:05:04,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6175/12032 [5:30:26<5:37:55,  3.46s/it]2025-08-23:00:05:08,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6176/12032 [5:30:30<5:49:47,  3.58s/it]2025-08-23:00:05:12,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6177/12032 [5:30:34<6:00:50,  3.70s/it]2025-08-23:00:05:16,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6178/12032 [5:30:36<5:24:52,  3.33s/it]2025-08-23:00:05:18,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6179/12032 [5:30:40<5:40:11,  3.49s/it]2025-08-23:00:05:22,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6180/12032 [5:30:44<5:49:34,  3.58s/it]2025-08-23:00:05:26,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6181/12032 [5:30:47<5:35:31,  3.44s/it]2025-08-23:00:05:29,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6182/12032 [5:30:51<5:46:37,  3.56s/it]2025-08-23:00:05:33,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6183/12032 [5:30:55<5:54:22,  3.64s/it]2025-08-23:00:05:37,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6184/12032 [5:30:59<5:59:37,  3.69s/it]2025-08-23:00:05:40,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6185/12032 [5:31:02<6:05:32,  3.75s/it]2025-08-23:00:05:44,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6186/12032 [5:31:06<6:07:40,  3.77s/it]2025-08-23:00:05:48,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6187/12032 [5:31:10<6:10:10,  3.80s/it]2025-08-23:00:05:52,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6188/12032 [5:31:14<6:11:48,  3.82s/it]2025-08-23:00:05:56,381 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6189/12032 [5:31:16<5:28:03,  3.37s/it]2025-08-23:00:05:58,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6190/12032 [5:31:20<5:24:53,  3.34s/it]2025-08-23:00:06:01,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6191/12032 [5:31:23<5:31:49,  3.41s/it]2025-08-23:00:06:05,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6192/12032 [5:31:26<5:16:36,  3.25s/it]2025-08-23:00:06:08,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6193/12032 [5:31:29<5:20:32,  3.29s/it]2025-08-23:00:06:11,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6194/12032 [5:31:33<5:36:03,  3.45s/it]2025-08-23:00:06:15,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6195/12032 [5:31:37<5:46:26,  3.56s/it]2025-08-23:00:06:19,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  51%|█████▏    | 6196/12032 [5:31:41<5:53:55,  3.64s/it]2025-08-23:00:06:23,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6197/12032 [5:31:44<5:37:23,  3.47s/it]2025-08-23:00:06:26,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6198/12032 [5:31:48<5:46:51,  3.57s/it]2025-08-23:00:06:30,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6199/12032 [5:31:50<4:54:10,  3.03s/it]2025-08-23:00:06:31,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6200/12032 [5:31:52<4:49:02,  2.97s/it]2025-08-23:00:06:34,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6201/12032 [5:31:55<4:45:26,  2.94s/it]2025-08-23:00:06:37,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6202/12032 [5:31:59<4:56:44,  3.05s/it]2025-08-23:00:06:40,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6203/12032 [5:32:01<4:27:06,  2.75s/it]2025-08-23:00:06:42,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6204/12032 [5:32:04<4:58:49,  3.08s/it]2025-08-23:00:06:46,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6205/12032 [5:32:07<4:51:13,  3.00s/it]2025-08-23:00:06:49,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6206/12032 [5:32:11<5:13:39,  3.23s/it]2025-08-23:00:06:53,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6207/12032 [5:32:15<5:31:16,  3.41s/it]2025-08-23:00:06:57,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6208/12032 [5:32:19<5:45:58,  3.56s/it]2025-08-23:00:07:01,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6209/12032 [5:32:21<5:00:09,  3.09s/it]2025-08-23:00:07:03,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6210/12032 [5:32:24<4:52:37,  3.02s/it]2025-08-23:00:07:05,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6211/12032 [5:32:28<5:17:18,  3.27s/it]2025-08-23:00:07:09,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6212/12032 [5:32:31<5:30:49,  3.41s/it]2025-08-23:00:07:13,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6213/12032 [5:32:34<5:14:38,  3.24s/it]2025-08-23:00:07:16,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6214/12032 [5:32:38<5:31:35,  3.42s/it]2025-08-23:00:07:20,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6215/12032 [5:32:42<5:39:42,  3.50s/it]2025-08-23:00:07:23,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6216/12032 [5:32:44<5:03:31,  3.13s/it]2025-08-23:00:07:26,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6217/12032 [5:32:48<5:22:50,  3.33s/it]2025-08-23:00:07:30,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6218/12032 [5:32:51<5:18:36,  3.29s/it]2025-08-23:00:07:33,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6219/12032 [5:32:55<5:33:48,  3.45s/it]2025-08-23:00:07:37,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6220/12032 [5:32:56<4:28:53,  2.78s/it]2025-08-23:00:07:38,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6221/12032 [5:33:00<4:59:44,  3.09s/it]2025-08-23:00:07:42,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6222/12032 [5:33:04<5:20:00,  3.30s/it]2025-08-23:00:07:45,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6223/12032 [5:33:07<5:34:18,  3.45s/it]2025-08-23:00:07:49,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6224/12032 [5:33:10<5:13:59,  3.24s/it]2025-08-23:00:07:52,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6225/12032 [5:33:14<5:20:44,  3.31s/it]2025-08-23:00:07:55,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6226/12032 [5:33:17<5:36:45,  3.48s/it]2025-08-23:00:07:59,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6227/12032 [5:33:21<5:44:14,  3.56s/it]2025-08-23:00:08:03,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6228/12032 [5:33:24<5:23:00,  3.34s/it]2025-08-23:00:08:06,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6229/12032 [5:33:28<5:36:36,  3.48s/it]2025-08-23:00:08:10,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6230/12032 [5:33:31<5:35:10,  3.47s/it]2025-08-23:00:08:13,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6231/12032 [5:33:35<5:44:15,  3.56s/it]2025-08-23:00:08:17,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6232/12032 [5:33:39<5:52:54,  3.65s/it]2025-08-23:00:08:21,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6233/12032 [5:33:43<5:57:49,  3.70s/it]2025-08-23:00:08:25,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6234/12032 [5:33:47<6:01:17,  3.74s/it]2025-08-23:00:08:28,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6235/12032 [5:33:50<6:03:33,  3.76s/it]2025-08-23:00:08:32,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6236/12032 [5:33:53<5:34:35,  3.46s/it]2025-08-23:00:08:35,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6237/12032 [5:33:56<5:07:02,  3.18s/it]2025-08-23:00:08:37,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6238/12032 [5:33:58<4:52:21,  3.03s/it]2025-08-23:00:08:40,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6239/12032 [5:34:01<4:40:23,  2.90s/it]2025-08-23:00:08:43,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6240/12032 [5:34:05<5:06:49,  3.18s/it]2025-08-23:00:08:47,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6241/12032 [5:34:06<4:08:12,  2.57s/it]2025-08-23:00:08:48,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6242/12032 [5:34:10<4:43:24,  2.94s/it]2025-08-23:00:08:52,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6243/12032 [5:34:11<4:06:22,  2.55s/it]2025-08-23:00:08:53,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6244/12032 [5:34:14<4:03:12,  2.52s/it]2025-08-23:00:08:56,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6245/12032 [5:34:17<4:31:51,  2.82s/it]2025-08-23:00:08:59,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6246/12032 [5:34:18<3:44:27,  2.33s/it]2025-08-23:00:09:00,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6247/12032 [5:34:21<3:37:54,  2.26s/it]2025-08-23:00:09:02,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6248/12032 [5:34:22<3:08:09,  1.95s/it]2025-08-23:00:09:04,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6249/12032 [5:34:26<4:02:01,  2.51s/it]2025-08-23:00:09:07,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6250/12032 [5:34:29<4:14:17,  2.64s/it]2025-08-23:00:09:10,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6251/12032 [5:34:32<4:33:24,  2.84s/it]2025-08-23:00:09:14,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6252/12032 [5:34:33<3:54:17,  2.43s/it]2025-08-23:00:09:15,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6253/12032 [5:34:35<3:31:19,  2.19s/it]2025-08-23:00:09:17,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6254/12032 [5:34:39<4:18:32,  2.68s/it]2025-08-23:00:09:21,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6255/12032 [5:34:43<4:51:37,  3.03s/it]2025-08-23:00:09:25,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6256/12032 [5:34:46<4:55:12,  3.07s/it]2025-08-23:00:09:28,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6257/12032 [5:34:50<5:16:58,  3.29s/it]2025-08-23:00:09:31,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6258/12032 [5:34:53<5:14:58,  3.27s/it]2025-08-23:00:09:35,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6259/12032 [5:34:57<5:29:36,  3.43s/it]2025-08-23:00:09:39,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6260/12032 [5:35:01<5:41:38,  3.55s/it]2025-08-23:00:09:42,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6261/12032 [5:35:03<5:15:51,  3.28s/it]2025-08-23:00:09:45,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6262/12032 [5:35:07<5:31:19,  3.45s/it]2025-08-23:00:09:49,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6263/12032 [5:35:09<4:46:45,  2.98s/it]2025-08-23:00:09:51,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6264/12032 [5:35:12<4:38:44,  2.90s/it]2025-08-23:00:09:53,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6265/12032 [5:35:15<5:04:30,  3.17s/it]2025-08-23:00:09:57,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6266/12032 [5:35:19<5:18:58,  3.32s/it]2025-08-23:00:10:01,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6267/12032 [5:35:23<5:25:08,  3.38s/it]2025-08-23:00:10:04,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6268/12032 [5:35:26<5:37:54,  3.52s/it]2025-08-23:00:10:08,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6269/12032 [5:35:30<5:46:49,  3.61s/it]2025-08-23:00:10:12,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6270/12032 [5:35:34<5:43:08,  3.57s/it]2025-08-23:00:10:16,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6271/12032 [5:35:37<5:46:53,  3.61s/it]2025-08-23:00:10:19,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6272/12032 [5:35:41<5:52:42,  3.67s/it]2025-08-23:00:10:23,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6273/12032 [5:35:45<5:57:37,  3.73s/it]2025-08-23:00:10:27,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6274/12032 [5:35:49<6:00:00,  3.75s/it]2025-08-23:00:10:31,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6275/12032 [5:35:53<6:01:42,  3.77s/it]2025-08-23:00:10:35,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6276/12032 [5:35:57<6:02:37,  3.78s/it]2025-08-23:00:10:38,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6277/12032 [5:36:00<5:59:17,  3.75s/it]2025-08-23:00:10:42,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6278/12032 [5:36:03<5:46:05,  3.61s/it]2025-08-23:00:10:45,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6279/12032 [5:36:07<5:44:42,  3.60s/it]2025-08-23:00:10:49,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6280/12032 [5:36:11<5:50:46,  3.66s/it]2025-08-23:00:10:53,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6281/12032 [5:36:14<5:38:08,  3.53s/it]2025-08-23:00:10:56,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6282/12032 [5:36:18<5:46:20,  3.61s/it]2025-08-23:00:11:00,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6283/12032 [5:36:22<5:49:39,  3.65s/it]2025-08-23:00:11:03,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6284/12032 [5:36:23<4:45:48,  2.98s/it]2025-08-23:00:11:05,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6285/12032 [5:36:26<4:37:32,  2.90s/it]2025-08-23:00:11:08,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6286/12032 [5:36:29<4:34:51,  2.87s/it]2025-08-23:00:11:10,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6287/12032 [5:36:32<5:02:00,  3.15s/it]2025-08-23:00:11:14,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6288/12032 [5:36:36<5:20:54,  3.35s/it]2025-08-23:00:11:18,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6289/12032 [5:36:39<4:58:04,  3.11s/it]2025-08-23:00:11:21,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6290/12032 [5:36:42<5:01:57,  3.16s/it]2025-08-23:00:11:24,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6291/12032 [5:36:46<5:12:56,  3.27s/it]2025-08-23:00:11:27,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6292/12032 [5:36:49<5:30:18,  3.45s/it]2025-08-23:00:11:31,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6293/12032 [5:36:52<4:56:16,  3.10s/it]2025-08-23:00:11:34,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6294/12032 [5:36:56<5:18:47,  3.33s/it]2025-08-23:00:11:37,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6295/12032 [5:36:59<5:33:09,  3.48s/it]2025-08-23:00:11:41,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6296/12032 [5:37:03<5:43:11,  3.59s/it]2025-08-23:00:11:45,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6297/12032 [5:37:07<5:56:55,  3.73s/it]2025-08-23:00:11:49,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6298/12032 [5:37:11<6:08:17,  3.85s/it]2025-08-23:00:11:53,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6299/12032 [5:37:15<6:09:55,  3.87s/it]2025-08-23:00:11:57,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6300/12032 [5:37:19<6:09:00,  3.86s/it]2025-08-23:00:12:01,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6301/12032 [5:37:22<5:42:59,  3.59s/it]2025-08-23:00:12:04,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6302/12032 [5:37:24<4:54:04,  3.08s/it]2025-08-23:00:12:06,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6303/12032 [5:37:28<5:08:25,  3.23s/it]2025-08-23:00:12:09,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6304/12032 [5:37:31<5:26:36,  3.42s/it]2025-08-23:00:12:13,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6305/12032 [5:37:35<5:37:46,  3.54s/it]2025-08-23:00:12:17,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6306/12032 [5:37:39<5:45:44,  3.62s/it]2025-08-23:00:12:21,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6307/12032 [5:37:43<5:51:10,  3.68s/it]2025-08-23:00:12:25,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6308/12032 [5:37:47<5:55:01,  3.72s/it]2025-08-23:00:12:29,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6309/12032 [5:37:49<5:23:09,  3.39s/it]2025-08-23:00:12:31,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6310/12032 [5:37:53<5:36:19,  3.53s/it]2025-08-23:00:12:35,562 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6311/12032 [5:37:55<5:00:06,  3.15s/it]2025-08-23:00:12:37,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6312/12032 [5:37:56<3:58:41,  2.50s/it]2025-08-23:00:12:38,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6313/12032 [5:37:58<3:43:32,  2.35s/it]2025-08-23:00:12:40,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6314/12032 [5:38:02<4:25:48,  2.79s/it]2025-08-23:00:12:44,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6315/12032 [5:38:04<3:44:26,  2.36s/it]2025-08-23:00:12:45,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  52%|█████▏    | 6316/12032 [5:38:05<3:16:35,  2.06s/it]2025-08-23:00:12:47,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6317/12032 [5:38:09<4:02:06,  2.54s/it]2025-08-23:00:12:51,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6318/12032 [5:38:12<4:38:42,  2.93s/it]2025-08-23:00:12:54,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6319/12032 [5:38:16<5:01:08,  3.16s/it]2025-08-23:00:12:58,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6320/12032 [5:38:19<4:46:31,  3.01s/it]2025-08-23:00:13:01,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6321/12032 [5:38:22<5:04:13,  3.20s/it]2025-08-23:00:13:04,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6322/12032 [5:38:25<4:46:31,  3.01s/it]2025-08-23:00:13:07,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6323/12032 [5:38:26<3:57:34,  2.50s/it]2025-08-23:00:13:08,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6324/12032 [5:38:28<3:31:15,  2.22s/it]2025-08-23:00:13:10,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6325/12032 [5:38:32<4:16:21,  2.70s/it]2025-08-23:00:13:14,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6326/12032 [5:38:35<4:20:41,  2.74s/it]2025-08-23:00:13:16,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6327/12032 [5:38:38<4:46:47,  3.02s/it]2025-08-23:00:13:20,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6328/12032 [5:38:42<5:09:19,  3.25s/it]2025-08-23:00:13:24,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6329/12032 [5:38:46<5:25:28,  3.42s/it]2025-08-23:00:13:28,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6330/12032 [5:38:50<5:36:11,  3.54s/it]2025-08-23:00:13:32,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6331/12032 [5:38:52<5:11:38,  3.28s/it]2025-08-23:00:13:34,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6332/12032 [5:38:55<4:45:26,  3.00s/it]2025-08-23:00:13:37,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6333/12032 [5:38:58<5:03:17,  3.19s/it]2025-08-23:00:13:40,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6334/12032 [5:39:02<5:10:35,  3.27s/it]2025-08-23:00:13:44,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6335/12032 [5:39:06<5:25:42,  3.43s/it]2025-08-23:00:13:47,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6336/12032 [5:39:09<5:35:36,  3.54s/it]2025-08-23:00:13:51,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6337/12032 [5:39:11<4:35:03,  2.90s/it]2025-08-23:00:13:53,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6338/12032 [5:39:12<3:50:42,  2.43s/it]2025-08-23:00:13:54,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6339/12032 [5:39:14<3:29:58,  2.21s/it]2025-08-23:00:13:56,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6340/12032 [5:39:18<4:16:30,  2.70s/it]2025-08-23:00:14:00,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6341/12032 [5:39:21<4:32:22,  2.87s/it]2025-08-23:00:14:03,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6342/12032 [5:39:25<4:53:19,  3.09s/it]2025-08-23:00:14:06,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6343/12032 [5:39:28<5:13:54,  3.31s/it]2025-08-23:00:14:10,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6344/12032 [5:39:30<4:36:45,  2.92s/it]2025-08-23:00:14:12,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6345/12032 [5:39:33<4:26:19,  2.81s/it]2025-08-23:00:14:15,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6346/12032 [5:39:37<4:54:33,  3.11s/it]2025-08-23:00:14:19,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6347/12032 [5:39:41<5:14:07,  3.32s/it]2025-08-23:00:14:22,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6348/12032 [5:39:44<5:27:54,  3.46s/it]2025-08-23:00:14:26,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6349/12032 [5:39:48<5:37:44,  3.57s/it]2025-08-23:00:14:30,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6350/12032 [5:39:51<5:12:27,  3.30s/it]2025-08-23:00:14:33,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6351/12032 [5:39:55<5:28:40,  3.47s/it]2025-08-23:00:14:37,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6352/12032 [5:39:56<4:38:11,  2.94s/it]2025-08-23:00:14:38,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6353/12032 [5:40:00<5:02:57,  3.20s/it]2025-08-23:00:14:42,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6354/12032 [5:40:03<4:50:08,  3.07s/it]2025-08-23:00:14:45,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6355/12032 [5:40:07<5:12:05,  3.30s/it]2025-08-23:00:14:49,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6356/12032 [5:40:10<4:59:42,  3.17s/it]2025-08-23:00:14:52,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6357/12032 [5:40:12<4:48:43,  3.05s/it]2025-08-23:00:14:54,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6358/12032 [5:40:15<4:30:28,  2.86s/it]2025-08-23:00:14:57,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6359/12032 [5:40:19<4:57:29,  3.15s/it]2025-08-23:00:15:01,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6360/12032 [5:40:22<5:00:18,  3.18s/it]2025-08-23:00:15:04,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6361/12032 [5:40:26<5:19:41,  3.38s/it]2025-08-23:00:15:08,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6362/12032 [5:40:30<5:33:17,  3.53s/it]2025-08-23:00:15:12,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6363/12032 [5:40:33<5:37:38,  3.57s/it]2025-08-23:00:15:15,686 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6364/12032 [5:40:37<5:30:52,  3.50s/it]2025-08-23:00:15:19,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6365/12032 [5:40:41<5:40:24,  3.60s/it]2025-08-23:00:15:22,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6366/12032 [5:40:44<5:24:01,  3.43s/it]2025-08-23:00:15:25,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6367/12032 [5:40:47<5:36:50,  3.57s/it]2025-08-23:00:15:29,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6368/12032 [5:40:51<5:44:54,  3.65s/it]2025-08-23:00:15:33,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6369/12032 [5:40:55<5:49:55,  3.71s/it]2025-08-23:00:15:37,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6370/12032 [5:40:58<5:40:24,  3.61s/it]2025-08-23:00:15:40,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6371/12032 [5:41:01<5:19:49,  3.39s/it]2025-08-23:00:15:43,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6372/12032 [5:41:04<4:49:59,  3.07s/it]2025-08-23:00:15:46,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6373/12032 [5:41:07<4:59:26,  3.17s/it]2025-08-23:00:15:49,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6374/12032 [5:41:10<4:59:57,  3.18s/it]2025-08-23:00:15:52,663 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6375/12032 [5:41:12<4:27:02,  2.83s/it]2025-08-23:00:15:54,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6376/12032 [5:41:16<4:54:17,  3.12s/it]2025-08-23:00:15:58,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6377/12032 [5:41:20<5:14:14,  3.33s/it]2025-08-23:00:16:02,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6378/12032 [5:41:23<5:08:52,  3.28s/it]2025-08-23:00:16:05,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6379/12032 [5:41:27<5:14:17,  3.34s/it]2025-08-23:00:16:08,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6380/12032 [5:41:30<5:24:08,  3.44s/it]2025-08-23:00:16:12,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6381/12032 [5:41:33<4:50:28,  3.08s/it]2025-08-23:00:16:14,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6382/12032 [5:41:36<5:05:50,  3.25s/it]2025-08-23:00:16:18,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6383/12032 [5:41:40<5:21:35,  3.42s/it]2025-08-23:00:16:22,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6384/12032 [5:41:43<5:13:34,  3.33s/it]2025-08-23:00:16:25,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6385/12032 [5:41:46<5:00:27,  3.19s/it]2025-08-23:00:16:28,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6386/12032 [5:41:50<5:16:49,  3.37s/it]2025-08-23:00:16:32,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6387/12032 [5:41:53<5:14:39,  3.34s/it]2025-08-23:00:16:35,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6388/12032 [5:41:57<5:26:58,  3.48s/it]2025-08-23:00:16:39,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6389/12032 [5:42:01<5:35:33,  3.57s/it]2025-08-23:00:16:42,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6390/12032 [5:42:03<5:01:20,  3.20s/it]2025-08-23:00:16:45,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6391/12032 [5:42:06<5:03:34,  3.23s/it]2025-08-23:00:16:48,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6392/12032 [5:42:10<5:20:00,  3.40s/it]2025-08-23:00:16:52,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6393/12032 [5:42:14<5:30:26,  3.52s/it]2025-08-23:00:16:56,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6394/12032 [5:42:17<5:14:27,  3.35s/it]2025-08-23:00:16:59,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6395/12032 [5:42:21<5:26:38,  3.48s/it]2025-08-23:00:17:02,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6396/12032 [5:42:24<5:28:44,  3.50s/it]2025-08-23:00:17:06,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6397/12032 [5:42:28<5:36:47,  3.59s/it]2025-08-23:00:17:10,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6398/12032 [5:42:32<5:42:52,  3.65s/it]2025-08-23:00:17:14,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6399/12032 [5:42:35<5:46:48,  3.69s/it]2025-08-23:00:17:17,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6400/12032 [5:42:39<5:49:07,  3.72s/it]2025-08-23:00:17:21,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6401/12032 [5:42:42<5:13:54,  3.34s/it]2025-08-23:00:17:24,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6402/12032 [5:42:46<5:27:35,  3.49s/it]2025-08-23:00:17:27,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6403/12032 [5:42:49<5:19:09,  3.40s/it]2025-08-23:00:17:31,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6404/12032 [5:42:53<5:31:02,  3.53s/it]2025-08-23:00:17:34,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6405/12032 [5:42:56<5:41:16,  3.64s/it]2025-08-23:00:17:38,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6406/12032 [5:43:00<5:47:22,  3.70s/it]2025-08-23:00:17:42,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6407/12032 [5:43:04<5:58:19,  3.82s/it]2025-08-23:00:17:46,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6408/12032 [5:43:08<5:56:35,  3.80s/it]2025-08-23:00:17:50,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6409/12032 [5:43:10<5:06:53,  3.27s/it]2025-08-23:00:17:52,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6410/12032 [5:43:14<5:19:18,  3.41s/it]2025-08-23:00:17:56,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6411/12032 [5:43:18<5:30:23,  3.53s/it]2025-08-23:00:18:00,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6412/12032 [5:43:20<5:05:01,  3.26s/it]2025-08-23:00:18:02,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6413/12032 [5:43:24<5:21:44,  3.44s/it]2025-08-23:00:18:06,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6414/12032 [5:43:28<5:31:59,  3.55s/it]2025-08-23:00:18:10,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6415/12032 [5:43:32<5:38:44,  3.62s/it]2025-08-23:00:18:14,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6416/12032 [5:43:36<5:43:55,  3.67s/it]2025-08-23:00:18:17,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6417/12032 [5:43:40<5:50:11,  3.74s/it]2025-08-23:00:18:21,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6418/12032 [5:43:43<5:34:07,  3.57s/it]2025-08-23:00:18:25,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6419/12032 [5:43:47<5:40:56,  3.64s/it]2025-08-23:00:18:28,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6420/12032 [5:43:50<5:42:09,  3.66s/it]2025-08-23:00:18:32,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6421/12032 [5:43:54<5:46:02,  3.70s/it]2025-08-23:00:18:36,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6422/12032 [5:43:57<5:34:53,  3.58s/it]2025-08-23:00:18:39,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6423/12032 [5:44:01<5:40:19,  3.64s/it]2025-08-23:00:18:43,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6424/12032 [5:44:04<5:11:11,  3.33s/it]2025-08-23:00:18:46,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6425/12032 [5:44:07<5:23:40,  3.46s/it]2025-08-23:00:18:49,828 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6426/12032 [5:44:10<5:04:15,  3.26s/it]2025-08-23:00:18:52,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6427/12032 [5:44:13<5:02:52,  3.24s/it]2025-08-23:00:18:55,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6428/12032 [5:44:17<5:18:20,  3.41s/it]2025-08-23:00:18:59,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6429/12032 [5:44:21<5:15:22,  3.38s/it]2025-08-23:00:19:02,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6430/12032 [5:44:23<4:46:53,  3.07s/it]2025-08-23:00:19:05,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6431/12032 [5:44:27<5:07:32,  3.29s/it]2025-08-23:00:19:09,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6432/12032 [5:44:30<5:16:27,  3.39s/it]2025-08-23:00:19:12,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6433/12032 [5:44:34<5:27:33,  3.51s/it]2025-08-23:00:19:16,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6434/12032 [5:44:38<5:35:35,  3.60s/it]2025-08-23:00:19:20,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6435/12032 [5:44:42<5:41:22,  3.66s/it]2025-08-23:00:19:24,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6436/12032 [5:44:46<5:45:40,  3.71s/it]2025-08-23:00:19:27,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  53%|█████▎    | 6437/12032 [5:44:49<5:48:17,  3.74s/it]2025-08-23:00:19:31,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6438/12032 [5:44:53<5:49:48,  3.75s/it]2025-08-23:00:19:35,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6439/12032 [5:44:57<5:51:04,  3.77s/it]2025-08-23:00:19:39,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6440/12032 [5:45:01<5:45:28,  3.71s/it]2025-08-23:00:19:42,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6441/12032 [5:45:04<5:30:09,  3.54s/it]2025-08-23:00:19:46,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6442/12032 [5:45:07<5:37:09,  3.62s/it]2025-08-23:00:19:49,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6443/12032 [5:45:11<5:21:45,  3.45s/it]2025-08-23:00:19:52,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6444/12032 [5:45:14<5:30:21,  3.55s/it]2025-08-23:00:19:56,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6445/12032 [5:45:18<5:20:19,  3.44s/it]2025-08-23:00:19:59,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6446/12032 [5:45:21<5:30:21,  3.55s/it]2025-08-23:00:20:03,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6447/12032 [5:45:24<5:14:36,  3.38s/it]2025-08-23:00:20:06,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6448/12032 [5:45:28<5:27:19,  3.52s/it]2025-08-23:00:20:10,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6449/12032 [5:45:31<5:05:38,  3.28s/it]2025-08-23:00:20:13,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6450/12032 [5:45:33<4:44:05,  3.05s/it]2025-08-23:00:20:15,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6451/12032 [5:45:37<5:04:48,  3.28s/it]2025-08-23:00:20:19,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6452/12032 [5:45:40<4:55:43,  3.18s/it]2025-08-23:00:20:22,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6453/12032 [5:45:44<5:12:24,  3.36s/it]2025-08-23:00:20:26,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6454/12032 [5:45:47<4:50:58,  3.13s/it]2025-08-23:00:20:28,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6455/12032 [5:45:49<4:28:01,  2.88s/it]2025-08-23:00:20:31,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6456/12032 [5:45:53<4:53:30,  3.16s/it]2025-08-23:00:20:34,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6457/12032 [5:45:56<5:10:31,  3.34s/it]2025-08-23:00:20:38,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6458/12032 [5:45:59<5:01:21,  3.24s/it]2025-08-23:00:20:41,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6459/12032 [5:46:03<5:10:09,  3.34s/it]2025-08-23:00:20:45,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6460/12032 [5:46:06<4:47:32,  3.10s/it]2025-08-23:00:20:47,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6461/12032 [5:46:08<4:28:05,  2.89s/it]2025-08-23:00:20:50,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6462/12032 [5:46:12<4:53:29,  3.16s/it]2025-08-23:00:20:54,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6463/12032 [5:46:15<5:10:44,  3.35s/it]2025-08-23:00:20:57,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6464/12032 [5:46:18<4:57:10,  3.20s/it]2025-08-23:00:21:00,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6465/12032 [5:46:22<5:12:42,  3.37s/it]2025-08-23:00:21:04,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6466/12032 [5:46:24<4:25:11,  2.86s/it]2025-08-23:00:21:06,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▎    | 6467/12032 [5:46:27<4:33:32,  2.95s/it]2025-08-23:00:21:09,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6468/12032 [5:46:31<4:58:41,  3.22s/it]2025-08-23:00:21:13,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6469/12032 [5:46:34<4:46:10,  3.09s/it]2025-08-23:00:21:15,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6470/12032 [5:46:37<5:06:39,  3.31s/it]2025-08-23:00:21:19,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6471/12032 [5:46:41<5:21:03,  3.46s/it]2025-08-23:00:21:23,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6472/12032 [5:46:45<5:30:56,  3.57s/it]2025-08-23:00:21:27,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6473/12032 [5:46:49<5:37:49,  3.65s/it]2025-08-23:00:21:31,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6474/12032 [5:46:52<5:17:52,  3.43s/it]2025-08-23:00:21:34,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6475/12032 [5:46:53<4:17:27,  2.78s/it]2025-08-23:00:21:35,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6476/12032 [5:46:55<3:53:04,  2.52s/it]2025-08-23:00:21:37,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6477/12032 [5:46:56<3:21:24,  2.18s/it]2025-08-23:00:21:38,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6478/12032 [5:47:00<4:07:06,  2.67s/it]2025-08-23:00:21:42,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6479/12032 [5:47:02<3:50:07,  2.49s/it]2025-08-23:00:21:44,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6480/12032 [5:47:03<3:14:30,  2.10s/it]2025-08-23:00:21:45,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6481/12032 [5:47:06<3:39:38,  2.37s/it]2025-08-23:00:21:48,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6482/12032 [5:47:07<3:00:17,  1.95s/it]2025-08-23:00:21:49,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6483/12032 [5:47:09<2:38:01,  1.71s/it]2025-08-23:00:21:50,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6484/12032 [5:47:12<3:17:14,  2.13s/it]2025-08-23:00:21:53,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6485/12032 [5:47:15<3:57:33,  2.57s/it]2025-08-23:00:21:57,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6486/12032 [5:47:18<3:50:00,  2.49s/it]2025-08-23:00:21:59,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6487/12032 [5:47:20<3:47:59,  2.47s/it]2025-08-23:00:22:02,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6488/12032 [5:47:22<3:26:37,  2.24s/it]2025-08-23:00:22:03,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6489/12032 [5:47:25<4:01:27,  2.61s/it]2025-08-23:00:22:07,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6490/12032 [5:47:29<4:37:52,  3.01s/it]2025-08-23:00:22:11,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6491/12032 [5:47:33<5:00:25,  3.25s/it]2025-08-23:00:22:15,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6492/12032 [5:47:36<4:58:43,  3.24s/it]2025-08-23:00:22:18,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6493/12032 [5:47:38<4:31:36,  2.94s/it]2025-08-23:00:22:20,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6494/12032 [5:47:42<4:51:29,  3.16s/it]2025-08-23:00:22:24,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6495/12032 [5:47:46<5:08:22,  3.34s/it]2025-08-23:00:22:28,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6496/12032 [5:47:50<5:21:28,  3.48s/it]2025-08-23:00:22:31,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6497/12032 [5:47:53<5:32:21,  3.60s/it]2025-08-23:00:22:35,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6498/12032 [5:47:57<5:38:11,  3.67s/it]2025-08-23:00:22:39,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6499/12032 [5:48:01<5:42:02,  3.71s/it]2025-08-23:00:22:43,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6500/12032 [5:48:05<5:36:29,  3.65s/it]2025-08-23:00:22:46,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6501/12032 [5:48:08<5:25:31,  3.53s/it]2025-08-23:00:22:50,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6502/12032 [5:48:11<5:21:03,  3.48s/it]2025-08-23:00:22:53,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6503/12032 [5:48:15<5:26:23,  3.54s/it]2025-08-23:00:22:57,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6504/12032 [5:48:19<5:33:35,  3.62s/it]2025-08-23:00:23:01,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6505/12032 [5:48:21<5:03:15,  3.29s/it]2025-08-23:00:23:03,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6506/12032 [5:48:24<4:46:59,  3.12s/it]2025-08-23:00:23:06,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6507/12032 [5:48:28<5:06:24,  3.33s/it]2025-08-23:00:23:10,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6508/12032 [5:48:32<5:18:35,  3.46s/it]2025-08-23:00:23:13,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6509/12032 [5:48:35<5:09:23,  3.36s/it]2025-08-23:00:23:17,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6510/12032 [5:48:39<5:22:51,  3.51s/it]2025-08-23:00:23:20,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6511/12032 [5:48:42<5:32:08,  3.61s/it]2025-08-23:00:23:24,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6512/12032 [5:48:45<5:06:51,  3.34s/it]2025-08-23:00:23:27,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6513/12032 [5:48:48<5:07:40,  3.34s/it]2025-08-23:00:23:30,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6514/12032 [5:48:52<5:23:08,  3.51s/it]2025-08-23:00:23:34,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6515/12032 [5:48:55<4:56:57,  3.23s/it]2025-08-23:00:23:37,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6516/12032 [5:48:58<4:48:28,  3.14s/it]2025-08-23:00:23:40,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6517/12032 [5:49:02<5:10:29,  3.38s/it]2025-08-23:00:23:44,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6518/12032 [5:49:06<5:23:17,  3.52s/it]2025-08-23:00:23:47,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6519/12032 [5:49:10<5:33:24,  3.63s/it]2025-08-23:00:23:51,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6520/12032 [5:49:12<5:08:32,  3.36s/it]2025-08-23:00:23:54,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6521/12032 [5:49:16<5:22:57,  3.52s/it]2025-08-23:00:23:58,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6522/12032 [5:49:20<5:20:29,  3.49s/it]2025-08-23:00:24:01,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6523/12032 [5:49:23<5:30:51,  3.60s/it]2025-08-23:00:24:05,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6524/12032 [5:49:27<5:38:16,  3.68s/it]2025-08-23:00:24:09,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6525/12032 [5:49:30<5:12:24,  3.40s/it]2025-08-23:00:24:12,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6526/12032 [5:49:33<4:48:10,  3.14s/it]2025-08-23:00:24:14,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6527/12032 [5:49:34<4:10:46,  2.73s/it]2025-08-23:00:24:16,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6528/12032 [5:49:38<4:33:56,  2.99s/it]2025-08-23:00:24:20,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6529/12032 [5:49:42<4:56:37,  3.23s/it]2025-08-23:00:24:24,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6530/12032 [5:49:44<4:35:55,  3.01s/it]2025-08-23:00:24:26,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6531/12032 [5:49:48<4:58:35,  3.26s/it]2025-08-23:00:24:30,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6532/12032 [5:49:52<5:16:32,  3.45s/it]2025-08-23:00:24:34,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6533/12032 [5:49:56<5:27:02,  3.57s/it]2025-08-23:00:24:38,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6534/12032 [5:49:59<5:26:29,  3.56s/it]2025-08-23:00:24:41,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6535/12032 [5:50:02<4:49:37,  3.16s/it]2025-08-23:00:24:43,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6536/12032 [5:50:05<5:07:08,  3.35s/it]2025-08-23:00:24:47,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6537/12032 [5:50:09<5:20:42,  3.50s/it]2025-08-23:00:24:51,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6538/12032 [5:50:13<5:16:30,  3.46s/it]2025-08-23:00:24:54,923 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6539/12032 [5:50:16<5:26:20,  3.56s/it]2025-08-23:00:24:58,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6540/12032 [5:50:20<5:32:50,  3.64s/it]2025-08-23:00:25:02,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6541/12032 [5:50:24<5:38:01,  3.69s/it]2025-08-23:00:25:06,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6542/12032 [5:50:28<5:41:21,  3.73s/it]2025-08-23:00:25:10,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6543/12032 [5:50:32<5:44:14,  3.76s/it]2025-08-23:00:25:14,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6544/12032 [5:50:36<5:45:41,  3.78s/it]2025-08-23:00:25:17,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6545/12032 [5:50:38<5:09:23,  3.38s/it]2025-08-23:00:25:20,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6546/12032 [5:50:41<4:47:51,  3.15s/it]2025-08-23:00:25:22,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6547/12032 [5:50:42<3:57:38,  2.60s/it]2025-08-23:00:25:24,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6548/12032 [5:50:46<4:33:04,  2.99s/it]2025-08-23:00:25:28,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6549/12032 [5:50:49<4:31:39,  2.97s/it]2025-08-23:00:25:31,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6550/12032 [5:50:53<4:55:24,  3.23s/it]2025-08-23:00:25:34,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6551/12032 [5:50:56<5:14:30,  3.44s/it]2025-08-23:00:25:38,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6552/12032 [5:51:00<5:04:55,  3.34s/it]2025-08-23:00:25:41,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6553/12032 [5:51:03<5:17:52,  3.48s/it]2025-08-23:00:25:45,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6554/12032 [5:51:07<5:28:23,  3.60s/it]2025-08-23:00:25:49,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6555/12032 [5:51:09<4:41:41,  3.09s/it]2025-08-23:00:25:51,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6556/12032 [5:51:13<5:01:51,  3.31s/it]2025-08-23:00:25:55,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  54%|█████▍    | 6557/12032 [5:51:16<4:42:56,  3.10s/it]2025-08-23:00:25:57,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6558/12032 [5:51:19<5:03:17,  3.32s/it]2025-08-23:00:26:01,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6559/12032 [5:51:23<5:16:08,  3.47s/it]2025-08-23:00:26:05,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6560/12032 [5:51:27<5:25:46,  3.57s/it]2025-08-23:00:26:09,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6561/12032 [5:51:30<5:16:00,  3.47s/it]2025-08-23:00:26:12,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6562/12032 [5:51:31<4:10:34,  2.75s/it]2025-08-23:00:26:13,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6563/12032 [5:51:33<3:26:59,  2.27s/it]2025-08-23:00:26:14,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6564/12032 [5:51:36<3:49:59,  2.52s/it]2025-08-23:00:26:17,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6565/12032 [5:51:37<3:27:11,  2.27s/it]2025-08-23:00:26:19,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6566/12032 [5:51:40<3:48:19,  2.51s/it]2025-08-23:00:26:22,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6567/12032 [5:51:42<3:28:39,  2.29s/it]2025-08-23:00:26:24,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6568/12032 [5:51:45<3:40:59,  2.43s/it]2025-08-23:00:26:27,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6569/12032 [5:51:49<4:19:10,  2.85s/it]2025-08-23:00:26:31,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6570/12032 [5:51:53<4:48:13,  3.17s/it]2025-08-23:00:26:34,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6571/12032 [5:51:56<5:06:15,  3.36s/it]2025-08-23:00:26:38,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6572/12032 [5:52:00<5:14:25,  3.46s/it]2025-08-23:00:26:42,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6573/12032 [5:52:03<5:04:45,  3.35s/it]2025-08-23:00:26:45,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6574/12032 [5:52:07<5:02:41,  3.33s/it]2025-08-23:00:26:48,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6575/12032 [5:52:10<5:16:23,  3.48s/it]2025-08-23:00:26:52,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6576/12032 [5:52:14<5:26:36,  3.59s/it]2025-08-23:00:26:56,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6577/12032 [5:52:18<5:32:22,  3.66s/it]2025-08-23:00:27:00,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6578/12032 [5:52:22<5:37:21,  3.71s/it]2025-08-23:00:27:04,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6579/12032 [5:52:24<5:06:39,  3.37s/it]2025-08-23:00:27:06,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6580/12032 [5:52:27<4:47:53,  3.17s/it]2025-08-23:00:27:09,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6581/12032 [5:52:30<4:29:05,  2.96s/it]2025-08-23:00:27:11,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6582/12032 [5:52:33<4:32:34,  3.00s/it]2025-08-23:00:27:15,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6583/12032 [5:52:37<4:54:52,  3.25s/it]2025-08-23:00:27:18,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6584/12032 [5:52:40<5:10:32,  3.42s/it]2025-08-23:00:27:22,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6585/12032 [5:52:44<5:19:38,  3.52s/it]2025-08-23:00:27:26,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6586/12032 [5:52:48<5:27:36,  3.61s/it]2025-08-23:00:27:30,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6587/12032 [5:52:51<5:09:19,  3.41s/it]2025-08-23:00:27:33,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6588/12032 [5:52:54<5:04:27,  3.36s/it]2025-08-23:00:27:36,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6589/12032 [5:52:57<4:59:45,  3.30s/it]2025-08-23:00:27:39,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6590/12032 [5:53:01<5:14:04,  3.46s/it]2025-08-23:00:27:43,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6591/12032 [5:53:05<5:24:03,  3.57s/it]2025-08-23:00:27:47,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6592/12032 [5:53:08<5:14:35,  3.47s/it]2025-08-23:00:27:50,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6593/12032 [5:53:12<5:16:05,  3.49s/it]2025-08-23:00:27:54,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6594/12032 [5:53:16<5:25:51,  3.60s/it]2025-08-23:00:27:57,868 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6595/12032 [5:53:17<4:38:58,  3.08s/it]2025-08-23:00:27:59,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6596/12032 [5:53:21<5:00:06,  3.31s/it]2025-08-23:00:28:03,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6597/12032 [5:53:25<5:11:40,  3.44s/it]2025-08-23:00:28:07,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6598/12032 [5:53:29<5:22:26,  3.56s/it]2025-08-23:00:28:11,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6599/12032 [5:53:33<5:31:32,  3.66s/it]2025-08-23:00:28:15,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6600/12032 [5:53:37<5:36:08,  3.71s/it]2025-08-23:00:28:18,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6601/12032 [5:53:40<5:30:16,  3.65s/it]2025-08-23:00:28:22,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6602/12032 [5:53:43<5:20:55,  3.55s/it]2025-08-23:00:28:25,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6603/12032 [5:53:47<5:29:51,  3.65s/it]2025-08-23:00:28:29,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6604/12032 [5:53:51<5:35:53,  3.71s/it]2025-08-23:00:28:33,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6605/12032 [5:53:55<5:41:19,  3.77s/it]2025-08-23:00:28:37,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6606/12032 [5:53:59<5:43:04,  3.79s/it]2025-08-23:00:28:41,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6607/12032 [5:54:01<5:01:05,  3.33s/it]2025-08-23:00:28:43,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6608/12032 [5:54:05<5:14:04,  3.47s/it]2025-08-23:00:28:47,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6609/12032 [5:54:09<5:24:22,  3.59s/it]2025-08-23:00:28:51,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6610/12032 [5:54:10<4:22:52,  2.91s/it]2025-08-23:00:28:52,456 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6611/12032 [5:54:14<4:36:31,  3.06s/it]2025-08-23:00:28:55,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6612/12032 [5:54:17<4:55:46,  3.27s/it]2025-08-23:00:28:59,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6613/12032 [5:54:20<4:48:08,  3.19s/it]2025-08-23:00:29:02,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6614/12032 [5:54:22<4:20:13,  2.88s/it]2025-08-23:00:29:04,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6615/12032 [5:54:26<4:44:34,  3.15s/it]2025-08-23:00:29:08,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6616/12032 [5:54:30<4:50:18,  3.22s/it]2025-08-23:00:29:11,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▍    | 6617/12032 [5:54:33<4:50:09,  3.21s/it]2025-08-23:00:29:15,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6618/12032 [5:54:37<5:08:26,  3.42s/it]2025-08-23:00:29:19,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6619/12032 [5:54:39<4:47:24,  3.19s/it]2025-08-23:00:29:21,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6620/12032 [5:54:43<5:05:16,  3.38s/it]2025-08-23:00:29:25,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6621/12032 [5:54:46<5:00:01,  3.33s/it]2025-08-23:00:29:28,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6622/12032 [5:54:50<5:00:52,  3.34s/it]2025-08-23:00:29:32,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6623/12032 [5:54:54<5:13:58,  3.48s/it]2025-08-23:00:29:35,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6624/12032 [5:54:57<5:23:31,  3.59s/it]2025-08-23:00:29:39,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6625/12032 [5:55:00<5:05:53,  3.39s/it]2025-08-23:00:29:42,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6626/12032 [5:55:04<5:01:10,  3.34s/it]2025-08-23:00:29:45,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6627/12032 [5:55:06<4:24:21,  2.93s/it]2025-08-23:00:29:47,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6628/12032 [5:55:09<4:26:28,  2.96s/it]2025-08-23:00:29:50,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6629/12032 [5:55:13<4:52:50,  3.25s/it]2025-08-23:00:29:54,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6630/12032 [5:55:16<5:01:47,  3.35s/it]2025-08-23:00:29:58,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6631/12032 [5:55:20<5:14:51,  3.50s/it]2025-08-23:00:30:02,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6632/12032 [5:55:24<5:23:15,  3.59s/it]2025-08-23:00:30:06,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6633/12032 [5:55:27<5:13:15,  3.48s/it]2025-08-23:00:30:09,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6634/12032 [5:55:31<5:24:24,  3.61s/it]2025-08-23:00:30:13,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6635/12032 [5:55:35<5:30:08,  3.67s/it]2025-08-23:00:30:17,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6636/12032 [5:55:38<5:29:09,  3.66s/it]2025-08-23:00:30:20,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6637/12032 [5:55:42<5:19:44,  3.56s/it]2025-08-23:00:30:23,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6638/12032 [5:55:46<5:28:02,  3.65s/it]2025-08-23:00:30:27,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6639/12032 [5:55:49<5:33:01,  3.71s/it]2025-08-23:00:30:31,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6640/12032 [5:55:53<5:36:01,  3.74s/it]2025-08-23:00:30:35,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6641/12032 [5:55:57<5:38:19,  3.77s/it]2025-08-23:00:30:39,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6642/12032 [5:56:01<5:38:23,  3.77s/it]2025-08-23:00:30:43,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6643/12032 [5:56:05<5:40:00,  3.79s/it]2025-08-23:00:30:46,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6644/12032 [5:56:08<5:40:58,  3.80s/it]2025-08-23:00:30:50,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6645/12032 [5:56:12<5:41:53,  3.81s/it]2025-08-23:00:30:54,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6646/12032 [5:56:16<5:42:25,  3.81s/it]2025-08-23:00:30:58,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6647/12032 [5:56:19<5:23:01,  3.60s/it]2025-08-23:00:31:01,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6648/12032 [5:56:23<5:29:03,  3.67s/it]2025-08-23:00:31:05,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6649/12032 [5:56:26<5:12:50,  3.49s/it]2025-08-23:00:31:08,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6650/12032 [5:56:29<4:49:01,  3.22s/it]2025-08-23:00:31:11,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6651/12032 [5:56:32<5:05:20,  3.40s/it]2025-08-23:00:31:14,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6652/12032 [5:56:36<5:17:37,  3.54s/it]2025-08-23:00:31:18,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6653/12032 [5:56:39<4:59:14,  3.34s/it]2025-08-23:00:31:21,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6654/12032 [5:56:43<5:12:26,  3.49s/it]2025-08-23:00:31:25,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6655/12032 [5:56:44<4:13:07,  2.82s/it]2025-08-23:00:31:26,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6656/12032 [5:56:47<4:03:53,  2.72s/it]2025-08-23:00:31:29,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6657/12032 [5:56:48<3:36:00,  2.41s/it]2025-08-23:00:31:30,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6658/12032 [5:56:52<3:53:45,  2.61s/it]2025-08-23:00:31:33,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6659/12032 [5:56:54<3:57:43,  2.65s/it]2025-08-23:00:31:36,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6660/12032 [5:56:56<3:42:15,  2.48s/it]2025-08-23:00:31:38,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6661/12032 [5:57:00<4:06:38,  2.76s/it]2025-08-23:00:31:42,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6662/12032 [5:57:04<4:34:58,  3.07s/it]2025-08-23:00:31:45,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6663/12032 [5:57:07<4:40:40,  3.14s/it]2025-08-23:00:31:49,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6664/12032 [5:57:08<3:54:19,  2.62s/it]2025-08-23:00:31:50,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6665/12032 [5:57:11<4:00:45,  2.69s/it]2025-08-23:00:31:53,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6666/12032 [5:57:13<3:31:06,  2.36s/it]2025-08-23:00:31:55,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6667/12032 [5:57:15<3:17:28,  2.21s/it]2025-08-23:00:31:56,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6668/12032 [5:57:16<3:00:47,  2.02s/it]2025-08-23:00:31:58,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6669/12032 [5:57:18<3:00:00,  2.01s/it]2025-08-23:00:32:00,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6670/12032 [5:57:21<3:10:36,  2.13s/it]2025-08-23:00:32:02,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6671/12032 [5:57:23<3:19:13,  2.23s/it]2025-08-23:00:32:05,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6672/12032 [5:57:24<2:56:36,  1.98s/it]2025-08-23:00:32:06,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6673/12032 [5:57:26<2:40:05,  1.79s/it]2025-08-23:00:32:08,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6674/12032 [5:57:29<3:22:45,  2.27s/it]2025-08-23:00:32:11,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6675/12032 [5:57:30<2:52:49,  1.94s/it]2025-08-23:00:32:12,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6676/12032 [5:57:31<2:26:33,  1.64s/it]2025-08-23:00:32:13,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  55%|█████▌    | 6677/12032 [5:57:35<3:21:51,  2.26s/it]2025-08-23:00:32:17,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6678/12032 [5:57:38<3:36:22,  2.42s/it]2025-08-23:00:32:20,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6679/12032 [5:57:42<4:12:51,  2.83s/it]2025-08-23:00:32:23,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6680/12032 [5:57:45<4:38:17,  3.12s/it]2025-08-23:00:32:27,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6681/12032 [5:57:49<4:39:51,  3.14s/it]2025-08-23:00:32:30,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6682/12032 [5:57:52<4:36:55,  3.11s/it]2025-08-23:00:32:33,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6683/12032 [5:57:55<4:56:42,  3.33s/it]2025-08-23:00:32:37,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6684/12032 [5:57:59<5:11:14,  3.49s/it]2025-08-23:00:32:41,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6685/12032 [5:58:03<5:20:09,  3.59s/it]2025-08-23:00:32:45,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6686/12032 [5:58:07<5:26:47,  3.67s/it]2025-08-23:00:32:49,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6687/12032 [5:58:10<5:10:46,  3.49s/it]2025-08-23:00:32:52,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6688/12032 [5:58:14<5:19:51,  3.59s/it]2025-08-23:00:32:56,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6689/12032 [5:58:18<5:26:42,  3.67s/it]2025-08-23:00:33:00,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6690/12032 [5:58:22<5:30:31,  3.71s/it]2025-08-23:00:33:03,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6691/12032 [5:58:23<4:31:46,  3.05s/it]2025-08-23:00:33:05,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6692/12032 [5:58:27<4:48:51,  3.25s/it]2025-08-23:00:33:09,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6693/12032 [5:58:31<5:07:11,  3.45s/it]2025-08-23:00:33:13,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6694/12032 [5:58:35<5:18:36,  3.58s/it]2025-08-23:00:33:16,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6695/12032 [5:58:38<5:25:33,  3.66s/it]2025-08-23:00:33:20,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6696/12032 [5:58:42<5:30:15,  3.71s/it]2025-08-23:00:33:24,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6697/12032 [5:58:46<5:32:43,  3.74s/it]2025-08-23:00:33:28,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6698/12032 [5:58:50<5:34:18,  3.76s/it]2025-08-23:00:33:32,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6699/12032 [5:58:54<5:37:35,  3.80s/it]2025-08-23:00:33:36,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6700/12032 [5:58:57<5:14:39,  3.54s/it]2025-08-23:00:33:39,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6701/12032 [5:58:59<4:48:47,  3.25s/it]2025-08-23:00:33:41,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6702/12032 [5:59:01<4:11:07,  2.83s/it]2025-08-23:00:33:43,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6703/12032 [5:59:05<4:37:18,  3.12s/it]2025-08-23:00:33:47,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6704/12032 [5:59:09<4:55:56,  3.33s/it]2025-08-23:00:33:51,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6705/12032 [5:59:11<4:30:16,  3.04s/it]2025-08-23:00:33:53,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6706/12032 [5:59:15<4:40:18,  3.16s/it]2025-08-23:00:33:56,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6707/12032 [5:59:18<4:44:35,  3.21s/it]2025-08-23:00:34:00,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6708/12032 [5:59:22<5:01:16,  3.40s/it]2025-08-23:00:34:04,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6709/12032 [5:59:25<4:51:46,  3.29s/it]2025-08-23:00:34:07,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6710/12032 [5:59:29<5:06:12,  3.45s/it]2025-08-23:00:34:10,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6711/12032 [5:59:31<4:33:12,  3.08s/it]2025-08-23:00:34:13,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6712/12032 [5:59:35<4:52:28,  3.30s/it]2025-08-23:00:34:16,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6713/12032 [5:59:38<5:02:27,  3.41s/it]2025-08-23:00:34:20,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6714/12032 [5:59:42<5:14:11,  3.54s/it]2025-08-23:00:34:24,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6715/12032 [5:59:46<5:12:08,  3.52s/it]2025-08-23:00:34:27,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6716/12032 [5:59:49<5:08:04,  3.48s/it]2025-08-23:00:34:31,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6717/12032 [5:59:53<5:17:41,  3.59s/it]2025-08-23:00:34:35,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6718/12032 [5:59:57<5:24:56,  3.67s/it]2025-08-23:00:34:39,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6719/12032 [6:00:00<5:25:13,  3.67s/it]2025-08-23:00:34:42,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6720/12032 [6:00:04<5:27:38,  3.70s/it]2025-08-23:00:34:46,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6721/12032 [6:00:07<5:16:00,  3.57s/it]2025-08-23:00:34:49,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6722/12032 [6:00:10<5:00:39,  3.40s/it]2025-08-23:00:34:52,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6723/12032 [6:00:14<5:10:57,  3.51s/it]2025-08-23:00:34:56,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6724/12032 [6:00:18<5:14:02,  3.55s/it]2025-08-23:00:35:00,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6725/12032 [6:00:22<5:20:40,  3.63s/it]2025-08-23:00:35:03,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6726/12032 [6:00:25<5:25:20,  3.68s/it]2025-08-23:00:35:07,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6727/12032 [6:00:29<5:28:02,  3.71s/it]2025-08-23:00:35:11,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6728/12032 [6:00:33<5:31:19,  3.75s/it]2025-08-23:00:35:15,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6729/12032 [6:00:37<5:34:35,  3.79s/it]2025-08-23:00:35:19,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6730/12032 [6:00:40<5:23:46,  3.66s/it]2025-08-23:00:35:22,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6731/12032 [6:00:42<4:22:56,  2.98s/it]2025-08-23:00:35:23,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6732/12032 [6:00:45<4:35:58,  3.12s/it]2025-08-23:00:35:27,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6733/12032 [6:00:49<4:48:01,  3.26s/it]2025-08-23:00:35:31,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6734/12032 [6:00:53<5:02:23,  3.42s/it]2025-08-23:00:35:34,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6735/12032 [6:00:56<5:13:17,  3.55s/it]2025-08-23:00:35:38,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6736/12032 [6:01:00<5:19:21,  3.62s/it]2025-08-23:00:35:42,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6737/12032 [6:01:03<4:46:34,  3.25s/it]2025-08-23:00:35:44,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6738/12032 [6:01:05<4:38:31,  3.16s/it]2025-08-23:00:35:47,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6739/12032 [6:01:09<4:57:13,  3.37s/it]2025-08-23:00:35:51,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6740/12032 [6:01:12<4:31:19,  3.08s/it]2025-08-23:00:35:54,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6741/12032 [6:01:14<4:15:08,  2.89s/it]2025-08-23:00:35:56,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6742/12032 [6:01:17<4:08:12,  2.82s/it]2025-08-23:00:35:59,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6743/12032 [6:01:20<4:30:05,  3.06s/it]2025-08-23:00:36:02,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6744/12032 [6:01:24<4:49:43,  3.29s/it]2025-08-23:00:36:06,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6745/12032 [6:01:27<4:27:10,  3.03s/it]2025-08-23:00:36:09,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6746/12032 [6:01:30<4:30:46,  3.07s/it]2025-08-23:00:36:12,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6747/12032 [6:01:34<4:47:33,  3.26s/it]2025-08-23:00:36:15,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6748/12032 [6:01:37<5:01:43,  3.43s/it]2025-08-23:00:36:19,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6749/12032 [6:01:39<4:20:32,  2.96s/it]2025-08-23:00:36:21,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6750/12032 [6:01:43<4:42:56,  3.21s/it]2025-08-23:00:36:25,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6751/12032 [6:01:47<4:58:03,  3.39s/it]2025-08-23:00:36:29,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6752/12032 [6:01:49<4:23:24,  2.99s/it]2025-08-23:00:36:31,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6753/12032 [6:01:51<4:05:19,  2.79s/it]2025-08-23:00:36:33,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6754/12032 [6:01:53<3:50:18,  2.62s/it]2025-08-23:00:36:35,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6755/12032 [6:01:54<3:06:37,  2.12s/it]2025-08-23:00:36:36,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6756/12032 [6:01:57<3:23:43,  2.32s/it]2025-08-23:00:36:39,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6757/12032 [6:02:01<4:02:20,  2.76s/it]2025-08-23:00:36:43,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6758/12032 [6:02:03<3:37:40,  2.48s/it]2025-08-23:00:36:45,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6759/12032 [6:02:04<3:15:21,  2.22s/it]2025-08-23:00:36:46,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6760/12032 [6:02:08<3:57:04,  2.70s/it]2025-08-23:00:36:50,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6761/12032 [6:02:11<3:57:00,  2.70s/it]2025-08-23:00:36:53,282 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6762/12032 [6:02:14<4:04:02,  2.78s/it]2025-08-23:00:36:56,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6763/12032 [6:02:17<4:10:12,  2.85s/it]2025-08-23:00:36:59,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6764/12032 [6:02:20<4:27:42,  3.05s/it]2025-08-23:00:37:02,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6765/12032 [6:02:24<4:46:21,  3.26s/it]2025-08-23:00:37:06,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6766/12032 [6:02:28<4:52:04,  3.33s/it]2025-08-23:00:37:10,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▌    | 6767/12032 [6:02:31<5:04:07,  3.47s/it]2025-08-23:00:37:13,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6768/12032 [6:02:34<4:43:48,  3.23s/it]2025-08-23:00:37:16,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6769/12032 [6:02:38<4:58:48,  3.41s/it]2025-08-23:00:37:20,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6770/12032 [6:02:40<4:25:04,  3.02s/it]2025-08-23:00:37:22,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6771/12032 [6:02:44<4:46:21,  3.27s/it]2025-08-23:00:37:26,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6772/12032 [6:02:48<5:00:50,  3.43s/it]2025-08-23:00:37:30,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6773/12032 [6:02:52<5:10:29,  3.54s/it]2025-08-23:00:37:33,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6774/12032 [6:02:55<5:17:19,  3.62s/it]2025-08-23:00:37:37,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6775/12032 [6:02:59<5:21:21,  3.67s/it]2025-08-23:00:37:41,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6776/12032 [6:03:03<5:21:29,  3.67s/it]2025-08-23:00:37:45,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6777/12032 [6:03:05<4:37:45,  3.17s/it]2025-08-23:00:37:47,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6778/12032 [6:03:08<4:27:40,  3.06s/it]2025-08-23:00:37:49,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6779/12032 [6:03:11<4:47:11,  3.28s/it]2025-08-23:00:37:53,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6780/12032 [6:03:14<4:38:12,  3.18s/it]2025-08-23:00:37:56,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6781/12032 [6:03:16<3:58:14,  2.72s/it]2025-08-23:00:37:58,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6782/12032 [6:03:18<3:36:07,  2.47s/it]2025-08-23:00:38:00,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6783/12032 [6:03:21<3:56:33,  2.70s/it]2025-08-23:00:38:03,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6784/12032 [6:03:25<4:24:20,  3.02s/it]2025-08-23:00:38:07,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6785/12032 [6:03:29<4:46:30,  3.28s/it]2025-08-23:00:38:11,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6786/12032 [6:03:32<4:53:12,  3.35s/it]2025-08-23:00:38:14,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6787/12032 [6:03:36<5:00:44,  3.44s/it]2025-08-23:00:38:18,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6788/12032 [6:03:40<5:09:58,  3.55s/it]2025-08-23:00:38:22,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6789/12032 [6:03:44<5:17:05,  3.63s/it]2025-08-23:00:38:25,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6790/12032 [6:03:47<5:20:57,  3.67s/it]2025-08-23:00:38:29,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6791/12032 [6:03:51<5:14:12,  3.60s/it]2025-08-23:00:38:33,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6792/12032 [6:03:55<5:19:15,  3.66s/it]2025-08-23:00:38:36,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6793/12032 [6:03:58<5:23:29,  3.70s/it]2025-08-23:00:38:40,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6794/12032 [6:04:00<4:36:47,  3.17s/it]2025-08-23:00:38:42,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6795/12032 [6:04:04<4:52:50,  3.36s/it]2025-08-23:00:38:46,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6796/12032 [6:04:07<4:34:33,  3.15s/it]2025-08-23:00:38:49,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6797/12032 [6:04:11<4:52:20,  3.35s/it]2025-08-23:00:38:52,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  56%|█████▋    | 6798/12032 [6:04:14<4:54:59,  3.38s/it]2025-08-23:00:38:56,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6799/12032 [6:04:16<4:17:02,  2.95s/it]2025-08-23:00:38:58,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6800/12032 [6:04:18<3:47:12,  2.61s/it]2025-08-23:00:39:00,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6801/12032 [6:04:22<4:19:06,  2.97s/it]2025-08-23:00:39:03,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6802/12032 [6:04:24<4:16:13,  2.94s/it]2025-08-23:00:39:06,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6803/12032 [6:04:27<4:02:37,  2.78s/it]2025-08-23:00:39:09,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6804/12032 [6:04:31<4:29:23,  3.09s/it]2025-08-23:00:39:13,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6805/12032 [6:04:34<4:33:55,  3.14s/it]2025-08-23:00:39:16,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6806/12032 [6:04:38<4:50:46,  3.34s/it]2025-08-23:00:39:20,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6807/12032 [6:04:40<4:24:09,  3.03s/it]2025-08-23:00:39:22,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6808/12032 [6:04:44<4:44:19,  3.27s/it]2025-08-23:00:39:26,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6809/12032 [6:04:48<4:57:49,  3.42s/it]2025-08-23:00:39:29,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6810/12032 [6:04:51<5:07:24,  3.53s/it]2025-08-23:00:39:33,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6811/12032 [6:04:54<4:49:08,  3.32s/it]2025-08-23:00:39:36,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6812/12032 [6:04:57<4:43:50,  3.26s/it]2025-08-23:00:39:39,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6813/12032 [6:05:01<4:53:56,  3.38s/it]2025-08-23:00:39:43,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6814/12032 [6:05:04<4:37:35,  3.19s/it]2025-08-23:00:39:46,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6815/12032 [6:05:08<4:53:40,  3.38s/it]2025-08-23:00:39:49,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6816/12032 [6:05:11<5:00:54,  3.46s/it]2025-08-23:00:39:53,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6817/12032 [6:05:15<5:08:55,  3.55s/it]2025-08-23:00:39:57,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6818/12032 [6:05:19<5:10:27,  3.57s/it]2025-08-23:00:40:01,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6819/12032 [6:05:22<5:17:19,  3.65s/it]2025-08-23:00:40:04,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6820/12032 [6:05:24<4:29:53,  3.11s/it]2025-08-23:00:40:06,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6821/12032 [6:05:28<4:32:30,  3.14s/it]2025-08-23:00:40:09,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6822/12032 [6:05:31<4:37:48,  3.20s/it]2025-08-23:00:40:13,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6823/12032 [6:05:34<4:36:41,  3.19s/it]2025-08-23:00:40:16,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6824/12032 [6:05:37<4:28:18,  3.09s/it]2025-08-23:00:40:19,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6825/12032 [6:05:40<4:23:56,  3.04s/it]2025-08-23:00:40:22,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6826/12032 [6:05:43<4:38:30,  3.21s/it]2025-08-23:00:40:25,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6827/12032 [6:05:47<4:54:10,  3.39s/it]2025-08-23:00:40:29,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6828/12032 [6:05:49<4:20:11,  3.00s/it]2025-08-23:00:40:31,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6829/12032 [6:05:53<4:42:08,  3.25s/it]2025-08-23:00:40:35,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6830/12032 [6:05:55<3:52:03,  2.68s/it]2025-08-23:00:40:36,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6831/12032 [6:05:58<4:22:06,  3.02s/it]2025-08-23:00:40:40,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6832/12032 [6:06:01<4:23:36,  3.04s/it]2025-08-23:00:40:43,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6833/12032 [6:06:05<4:37:37,  3.20s/it]2025-08-23:00:40:47,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6834/12032 [6:06:09<4:53:30,  3.39s/it]2025-08-23:00:40:51,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6835/12032 [6:06:12<4:40:27,  3.24s/it]2025-08-23:00:40:54,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6836/12032 [6:06:14<4:07:32,  2.86s/it]2025-08-23:00:40:56,037 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6837/12032 [6:06:17<4:25:28,  3.07s/it]2025-08-23:00:40:59,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6838/12032 [6:06:21<4:34:27,  3.17s/it]2025-08-23:00:41:03,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6839/12032 [6:06:21<3:33:20,  2.47s/it]2025-08-23:00:41:03,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6840/12032 [6:06:24<3:30:44,  2.44s/it]2025-08-23:00:41:06,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6841/12032 [6:06:28<4:07:19,  2.86s/it]2025-08-23:00:41:10,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6842/12032 [6:06:30<3:42:28,  2.57s/it]2025-08-23:00:41:11,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6843/12032 [6:06:32<3:27:53,  2.40s/it]2025-08-23:00:41:13,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6844/12032 [6:06:32<2:48:38,  1.95s/it]2025-08-23:00:41:14,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6845/12032 [6:06:33<2:20:50,  1.63s/it]2025-08-23:00:41:15,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6846/12032 [6:06:37<3:20:20,  2.32s/it]2025-08-23:00:41:19,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6847/12032 [6:06:40<3:24:41,  2.37s/it]2025-08-23:00:41:22,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6848/12032 [6:06:42<3:22:19,  2.34s/it]2025-08-23:00:41:24,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6849/12032 [6:06:45<3:47:06,  2.63s/it]2025-08-23:00:41:27,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6850/12032 [6:06:48<3:54:26,  2.71s/it]2025-08-23:00:41:30,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6851/12032 [6:06:52<4:09:02,  2.88s/it]2025-08-23:00:41:33,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6852/12032 [6:06:53<3:23:15,  2.35s/it]2025-08-23:00:41:35,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6853/12032 [6:06:54<2:54:21,  2.02s/it]2025-08-23:00:41:36,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6854/12032 [6:06:55<2:30:57,  1.75s/it]2025-08-23:00:41:37,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6855/12032 [6:06:59<3:25:33,  2.38s/it]2025-08-23:00:41:41,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6856/12032 [6:07:03<4:02:30,  2.81s/it]2025-08-23:00:41:45,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6857/12032 [6:07:07<4:31:28,  3.15s/it]2025-08-23:00:41:48,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6858/12032 [6:07:10<4:30:43,  3.14s/it]2025-08-23:00:41:52,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6859/12032 [6:07:13<4:22:55,  3.05s/it]2025-08-23:00:41:54,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6860/12032 [6:07:15<4:17:14,  2.98s/it]2025-08-23:00:41:57,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6861/12032 [6:07:19<4:20:32,  3.02s/it]2025-08-23:00:42:00,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6862/12032 [6:07:22<4:42:12,  3.28s/it]2025-08-23:00:42:04,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6863/12032 [6:07:26<4:56:06,  3.44s/it]2025-08-23:00:42:08,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6864/12032 [6:07:29<4:48:12,  3.35s/it]2025-08-23:00:42:11,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6865/12032 [6:07:33<4:51:35,  3.39s/it]2025-08-23:00:42:15,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6866/12032 [6:07:37<5:02:17,  3.51s/it]2025-08-23:00:42:18,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6867/12032 [6:07:40<5:05:58,  3.55s/it]2025-08-23:00:42:22,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6868/12032 [6:07:44<5:06:23,  3.56s/it]2025-08-23:00:42:26,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6869/12032 [6:07:48<5:13:38,  3.64s/it]2025-08-23:00:42:30,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6870/12032 [6:07:52<5:18:33,  3.70s/it]2025-08-23:00:42:33,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6871/12032 [6:07:55<5:14:51,  3.66s/it]2025-08-23:00:42:37,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6872/12032 [6:07:59<5:19:08,  3.71s/it]2025-08-23:00:42:41,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6873/12032 [6:08:03<5:21:34,  3.74s/it]2025-08-23:00:42:45,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6874/12032 [6:08:05<4:55:16,  3.43s/it]2025-08-23:00:42:47,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6875/12032 [6:08:08<4:40:10,  3.26s/it]2025-08-23:00:42:50,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6876/12032 [6:08:10<4:08:08,  2.89s/it]2025-08-23:00:42:52,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6877/12032 [6:08:11<3:19:10,  2.32s/it]2025-08-23:00:42:53,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6878/12032 [6:08:15<3:58:19,  2.77s/it]2025-08-23:00:42:57,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6879/12032 [6:08:17<3:27:39,  2.42s/it]2025-08-23:00:42:59,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6880/12032 [6:08:19<3:32:18,  2.47s/it]2025-08-23:00:43:01,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6881/12032 [6:08:23<4:07:07,  2.88s/it]2025-08-23:00:43:05,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6882/12032 [6:08:27<4:30:52,  3.16s/it]2025-08-23:00:43:09,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6883/12032 [6:08:30<4:33:03,  3.18s/it]2025-08-23:00:43:12,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6884/12032 [6:08:34<4:50:28,  3.39s/it]2025-08-23:00:43:16,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6885/12032 [6:08:38<5:02:28,  3.53s/it]2025-08-23:00:43:20,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6886/12032 [6:08:41<4:54:39,  3.44s/it]2025-08-23:00:43:23,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6887/12032 [6:08:44<4:41:49,  3.29s/it]2025-08-23:00:43:26,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6888/12032 [6:08:48<4:55:57,  3.45s/it]2025-08-23:00:43:30,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6889/12032 [6:08:52<5:06:09,  3.57s/it]2025-08-23:00:43:34,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6890/12032 [6:08:55<4:57:13,  3.47s/it]2025-08-23:00:43:37,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6891/12032 [6:08:57<4:24:27,  3.09s/it]2025-08-23:00:43:39,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6892/12032 [6:09:01<4:46:12,  3.34s/it]2025-08-23:00:43:43,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6893/12032 [6:09:05<4:58:30,  3.49s/it]2025-08-23:00:43:47,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6894/12032 [6:09:09<5:07:39,  3.59s/it]2025-08-23:00:43:51,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6895/12032 [6:09:13<5:14:06,  3.67s/it]2025-08-23:00:43:55,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6896/12032 [6:09:16<5:09:31,  3.62s/it]2025-08-23:00:43:58,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6897/12032 [6:09:20<5:15:15,  3.68s/it]2025-08-23:00:44:02,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6898/12032 [6:09:23<4:47:19,  3.36s/it]2025-08-23:00:44:04,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6899/12032 [6:09:26<4:59:21,  3.50s/it]2025-08-23:00:44:08,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6900/12032 [6:09:30<4:59:19,  3.50s/it]2025-08-23:00:44:12,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6901/12032 [6:09:33<4:44:54,  3.33s/it]2025-08-23:00:44:15,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6902/12032 [6:09:37<4:57:46,  3.48s/it]2025-08-23:00:44:19,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6903/12032 [6:09:39<4:38:04,  3.25s/it]2025-08-23:00:44:21,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6904/12032 [6:09:43<4:52:52,  3.43s/it]2025-08-23:00:44:25,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6905/12032 [6:09:47<5:03:23,  3.55s/it]2025-08-23:00:44:29,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6906/12032 [6:09:51<5:11:18,  3.64s/it]2025-08-23:00:44:33,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6907/12032 [6:09:55<5:15:52,  3.70s/it]2025-08-23:00:44:37,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6908/12032 [6:09:58<5:00:19,  3.52s/it]2025-08-23:00:44:40,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6909/12032 [6:10:01<4:59:50,  3.51s/it]2025-08-23:00:44:43,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6910/12032 [6:10:05<5:08:49,  3.62s/it]2025-08-23:00:44:47,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6911/12032 [6:10:09<5:14:39,  3.69s/it]2025-08-23:00:44:51,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6912/12032 [6:10:11<4:24:53,  3.10s/it]2025-08-23:00:44:53,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6913/12032 [6:10:15<4:45:41,  3.35s/it]2025-08-23:00:44:57,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6914/12032 [6:10:18<4:53:25,  3.44s/it]2025-08-23:00:45:00,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6915/12032 [6:10:21<4:38:50,  3.27s/it]2025-08-23:00:45:03,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6916/12032 [6:10:24<4:33:00,  3.20s/it]2025-08-23:00:45:06,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6917/12032 [6:10:28<4:49:41,  3.40s/it]2025-08-23:00:45:10,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  57%|█████▋    | 6918/12032 [6:10:31<4:35:26,  3.23s/it]2025-08-23:00:45:13,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6919/12032 [6:10:33<4:09:53,  2.93s/it]2025-08-23:00:45:15,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6920/12032 [6:10:37<4:19:11,  3.04s/it]2025-08-23:00:45:18,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6921/12032 [6:10:40<4:22:02,  3.08s/it]2025-08-23:00:45:22,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6922/12032 [6:10:44<4:40:47,  3.30s/it]2025-08-23:00:45:25,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6923/12032 [6:10:46<4:15:24,  3.00s/it]2025-08-23:00:45:28,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6924/12032 [6:10:50<4:36:24,  3.25s/it]2025-08-23:00:45:31,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6925/12032 [6:10:53<4:38:18,  3.27s/it]2025-08-23:00:45:35,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6926/12032 [6:10:56<4:37:18,  3.26s/it]2025-08-23:00:45:38,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6927/12032 [6:11:00<4:51:45,  3.43s/it]2025-08-23:00:45:42,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6928/12032 [6:11:03<4:44:55,  3.35s/it]2025-08-23:00:45:45,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6929/12032 [6:11:07<4:56:55,  3.49s/it]2025-08-23:00:45:49,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6930/12032 [6:11:10<4:55:34,  3.48s/it]2025-08-23:00:45:52,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6931/12032 [6:11:14<5:04:29,  3.58s/it]2025-08-23:00:45:56,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6932/12032 [6:11:18<5:10:37,  3.65s/it]2025-08-23:00:46:00,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6933/12032 [6:11:22<5:13:18,  3.69s/it]2025-08-23:00:46:04,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6934/12032 [6:11:23<4:06:09,  2.90s/it]2025-08-23:00:46:05,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6935/12032 [6:11:24<3:32:20,  2.50s/it]2025-08-23:00:46:06,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6936/12032 [6:11:26<3:16:43,  2.32s/it]2025-08-23:00:46:08,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6937/12032 [6:11:30<3:54:48,  2.77s/it]2025-08-23:00:46:12,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6938/12032 [6:11:32<3:25:32,  2.42s/it]2025-08-23:00:46:14,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6939/12032 [6:11:36<4:00:10,  2.83s/it]2025-08-23:00:46:17,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6940/12032 [6:11:38<3:41:46,  2.61s/it]2025-08-23:00:46:20,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6941/12032 [6:11:41<3:49:32,  2.71s/it]2025-08-23:00:46:22,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6942/12032 [6:11:44<4:18:33,  3.05s/it]2025-08-23:00:46:26,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6943/12032 [6:11:48<4:35:32,  3.25s/it]2025-08-23:00:46:30,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6944/12032 [6:11:52<4:49:32,  3.41s/it]2025-08-23:00:46:34,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6945/12032 [6:11:56<4:53:22,  3.46s/it]2025-08-23:00:46:37,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6946/12032 [6:11:59<5:03:43,  3.58s/it]2025-08-23:00:46:41,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6947/12032 [6:12:02<4:31:34,  3.20s/it]2025-08-23:00:46:44,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6948/12032 [6:12:06<4:47:40,  3.39s/it]2025-08-23:00:46:47,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6949/12032 [6:12:08<4:22:01,  3.09s/it]2025-08-23:00:46:50,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6950/12032 [6:12:11<4:17:03,  3.03s/it]2025-08-23:00:46:53,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6951/12032 [6:12:14<4:08:14,  2.93s/it]2025-08-23:00:46:55,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6952/12032 [6:12:17<4:17:58,  3.05s/it]2025-08-23:00:46:59,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6953/12032 [6:12:20<4:28:53,  3.18s/it]2025-08-23:00:47:02,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6954/12032 [6:12:23<4:20:41,  3.08s/it]2025-08-23:00:47:05,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6955/12032 [6:12:26<4:04:15,  2.89s/it]2025-08-23:00:47:07,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6956/12032 [6:12:29<4:13:16,  2.99s/it]2025-08-23:00:47:11,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6957/12032 [6:12:33<4:29:50,  3.19s/it]2025-08-23:00:47:14,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6958/12032 [6:12:36<4:44:55,  3.37s/it]2025-08-23:00:47:18,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6959/12032 [6:12:40<4:56:18,  3.50s/it]2025-08-23:00:47:22,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6960/12032 [6:12:44<5:03:56,  3.60s/it]2025-08-23:00:47:26,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6961/12032 [6:12:48<5:09:19,  3.66s/it]2025-08-23:00:47:30,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6962/12032 [6:12:52<5:13:17,  3.71s/it]2025-08-23:00:47:33,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6963/12032 [6:12:55<5:13:55,  3.72s/it]2025-08-23:00:47:37,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6964/12032 [6:12:59<5:10:16,  3.67s/it]2025-08-23:00:47:41,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6965/12032 [6:13:02<5:07:48,  3.64s/it]2025-08-23:00:47:44,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6966/12032 [6:13:06<5:11:11,  3.69s/it]2025-08-23:00:47:48,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6967/12032 [6:13:09<4:57:14,  3.52s/it]2025-08-23:00:47:51,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6968/12032 [6:13:13<5:04:23,  3.61s/it]2025-08-23:00:47:55,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6969/12032 [6:13:17<5:03:47,  3.60s/it]2025-08-23:00:47:59,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6970/12032 [6:13:20<4:46:31,  3.40s/it]2025-08-23:00:48:02,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6971/12032 [6:13:23<4:49:05,  3.43s/it]2025-08-23:00:48:05,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6972/12032 [6:13:27<4:58:38,  3.54s/it]2025-08-23:00:48:09,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6973/12032 [6:13:31<5:05:39,  3.63s/it]2025-08-23:00:48:13,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6974/12032 [6:13:35<5:10:05,  3.68s/it]2025-08-23:00:48:16,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6975/12032 [6:13:38<5:06:31,  3.64s/it]2025-08-23:00:48:20,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6976/12032 [6:13:42<5:11:25,  3.70s/it]2025-08-23:00:48:24,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6977/12032 [6:13:46<5:14:40,  3.73s/it]2025-08-23:00:48:28,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6978/12032 [6:13:49<4:51:40,  3.46s/it]2025-08-23:00:48:31,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6979/12032 [6:13:52<4:48:02,  3.42s/it]2025-08-23:00:48:34,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6980/12032 [6:13:55<4:40:41,  3.33s/it]2025-08-23:00:48:37,456 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6981/12032 [6:13:57<3:55:28,  2.80s/it]2025-08-23:00:48:39,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6982/12032 [6:14:01<4:21:49,  3.11s/it]2025-08-23:00:48:42,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6983/12032 [6:14:04<4:28:12,  3.19s/it]2025-08-23:00:48:46,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6984/12032 [6:14:07<4:14:34,  3.03s/it]2025-08-23:00:48:48,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6985/12032 [6:14:09<3:50:49,  2.74s/it]2025-08-23:00:48:50,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6986/12032 [6:14:12<4:17:27,  3.06s/it]2025-08-23:00:48:54,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6987/12032 [6:14:16<4:19:40,  3.09s/it]2025-08-23:00:48:57,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6988/12032 [6:14:18<3:57:39,  2.83s/it]2025-08-23:00:49:00,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6989/12032 [6:14:21<4:19:17,  3.09s/it]2025-08-23:00:49:03,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6990/12032 [6:14:25<4:39:29,  3.33s/it]2025-08-23:00:49:07,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6991/12032 [6:14:28<4:11:45,  3.00s/it]2025-08-23:00:49:09,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6992/12032 [6:14:30<4:05:12,  2.92s/it]2025-08-23:00:49:12,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6993/12032 [6:14:34<4:28:04,  3.19s/it]2025-08-23:00:49:16,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6994/12032 [6:14:38<4:43:44,  3.38s/it]2025-08-23:00:49:20,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6995/12032 [6:14:40<4:10:37,  2.99s/it]2025-08-23:00:49:22,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6996/12032 [6:14:44<4:32:22,  3.25s/it]2025-08-23:00:49:26,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6997/12032 [6:14:48<4:47:01,  3.42s/it]2025-08-23:00:49:30,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6998/12032 [6:14:51<4:51:49,  3.48s/it]2025-08-23:00:49:33,663 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 6999/12032 [6:14:54<4:32:39,  3.25s/it]2025-08-23:00:49:36,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7000/12032 [6:14:57<4:20:47,  3.11s/it]2025-08-23:00:49:39,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7001/12032 [6:15:00<4:28:29,  3.20s/it]2025-08-23:00:49:42,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7002/12032 [6:15:04<4:43:59,  3.39s/it]2025-08-23:00:49:46,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7003/12032 [6:15:08<4:49:52,  3.46s/it]2025-08-23:00:49:50,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7004/12032 [6:15:12<4:59:01,  3.57s/it]2025-08-23:00:49:53,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7005/12032 [6:15:15<4:54:34,  3.52s/it]2025-08-23:00:49:57,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7006/12032 [6:15:18<4:38:13,  3.32s/it]2025-08-23:00:50:00,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7007/12032 [6:15:22<4:50:25,  3.47s/it]2025-08-23:00:50:03,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7008/12032 [6:15:24<4:17:01,  3.07s/it]2025-08-23:00:50:06,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7009/12032 [6:15:26<3:49:57,  2.75s/it]2025-08-23:00:50:08,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7010/12032 [6:15:30<4:16:54,  3.07s/it]2025-08-23:00:50:11,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7011/12032 [6:15:32<3:53:09,  2.79s/it]2025-08-23:00:50:14,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7012/12032 [6:15:35<4:18:14,  3.09s/it]2025-08-23:00:50:17,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7013/12032 [6:15:38<4:09:32,  2.98s/it]2025-08-23:00:50:20,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7014/12032 [6:15:42<4:30:52,  3.24s/it]2025-08-23:00:50:24,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7015/12032 [6:15:45<4:26:00,  3.18s/it]2025-08-23:00:50:27,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7016/12032 [6:15:49<4:43:06,  3.39s/it]2025-08-23:00:50:31,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7017/12032 [6:15:52<4:28:09,  3.21s/it]2025-08-23:00:50:34,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7018/12032 [6:15:56<4:43:53,  3.40s/it]2025-08-23:00:50:37,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7019/12032 [6:15:59<4:48:31,  3.45s/it]2025-08-23:00:50:41,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7020/12032 [6:16:03<4:57:43,  3.56s/it]2025-08-23:00:50:45,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7021/12032 [6:16:07<5:05:03,  3.65s/it]2025-08-23:00:50:49,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7022/12032 [6:16:11<5:09:26,  3.71s/it]2025-08-23:00:50:53,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7023/12032 [6:16:14<4:50:19,  3.48s/it]2025-08-23:00:50:55,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7024/12032 [6:16:17<4:58:07,  3.57s/it]2025-08-23:00:50:59,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7025/12032 [6:16:21<4:58:54,  3.58s/it]2025-08-23:00:51:03,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7026/12032 [6:16:22<3:54:05,  2.81s/it]2025-08-23:00:51:04,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7027/12032 [6:16:23<3:13:15,  2.32s/it]2025-08-23:00:51:05,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7028/12032 [6:16:27<3:53:00,  2.79s/it]2025-08-23:00:51:09,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7029/12032 [6:16:30<3:51:00,  2.77s/it]2025-08-23:00:51:12,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7030/12032 [6:16:34<4:18:55,  3.11s/it]2025-08-23:00:51:16,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7031/12032 [6:16:36<3:56:40,  2.84s/it]2025-08-23:00:51:18,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7032/12032 [6:16:39<4:14:09,  3.05s/it]2025-08-23:00:51:21,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7033/12032 [6:16:41<3:39:36,  2.64s/it]2025-08-23:00:51:23,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7034/12032 [6:16:45<4:09:48,  3.00s/it]2025-08-23:00:51:27,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7035/12032 [6:16:49<4:30:40,  3.25s/it]2025-08-23:00:51:31,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7036/12032 [6:16:53<4:44:22,  3.42s/it]2025-08-23:00:51:34,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7037/12032 [6:16:56<4:54:00,  3.53s/it]2025-08-23:00:51:38,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  58%|█████▊    | 7038/12032 [6:17:00<4:56:18,  3.56s/it]2025-08-23:00:51:42,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7039/12032 [6:17:03<4:36:00,  3.32s/it]2025-08-23:00:51:45,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7040/12032 [6:17:07<4:48:05,  3.46s/it]2025-08-23:00:51:48,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7041/12032 [6:17:10<4:57:21,  3.57s/it]2025-08-23:00:51:52,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7042/12032 [6:17:14<5:04:09,  3.66s/it]2025-08-23:00:51:56,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7043/12032 [6:17:17<4:45:21,  3.43s/it]2025-08-23:00:51:59,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7044/12032 [6:17:21<4:55:07,  3.55s/it]2025-08-23:00:52:03,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7045/12032 [6:17:25<5:01:48,  3.63s/it]2025-08-23:00:52:07,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7046/12032 [6:17:29<5:06:42,  3.69s/it]2025-08-23:00:52:10,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7047/12032 [6:17:32<5:09:07,  3.72s/it]2025-08-23:00:52:14,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7048/12032 [6:17:36<5:11:28,  3.75s/it]2025-08-23:00:52:18,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7049/12032 [6:17:40<5:12:34,  3.76s/it]2025-08-23:00:52:22,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7050/12032 [6:17:44<5:13:11,  3.77s/it]2025-08-23:00:52:26,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7051/12032 [6:17:48<5:13:55,  3.78s/it]2025-08-23:00:52:29,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7052/12032 [6:17:51<4:58:22,  3.59s/it]2025-08-23:00:52:33,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7053/12032 [6:17:55<5:03:00,  3.65s/it]2025-08-23:00:52:36,932 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7054/12032 [6:17:58<5:06:55,  3.70s/it]2025-08-23:00:52:40,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7055/12032 [6:18:02<5:09:04,  3.73s/it]2025-08-23:00:52:44,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7056/12032 [6:18:06<5:12:01,  3.76s/it]2025-08-23:00:52:48,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7057/12032 [6:18:10<5:12:24,  3.77s/it]2025-08-23:00:52:52,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7058/12032 [6:18:14<5:13:38,  3.78s/it]2025-08-23:00:52:55,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7059/12032 [6:18:17<5:14:11,  3.79s/it]2025-08-23:00:52:59,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7060/12032 [6:18:21<5:14:39,  3.80s/it]2025-08-23:00:53:03,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7061/12032 [6:18:23<4:29:52,  3.26s/it]2025-08-23:00:53:05,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7062/12032 [6:18:25<3:55:31,  2.84s/it]2025-08-23:00:53:07,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7063/12032 [6:18:29<4:19:24,  3.13s/it]2025-08-23:00:53:11,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7064/12032 [6:18:33<4:35:36,  3.33s/it]2025-08-23:00:53:15,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7065/12032 [6:18:35<4:16:57,  3.10s/it]2025-08-23:00:53:17,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7066/12032 [6:18:39<4:32:26,  3.29s/it]2025-08-23:00:53:21,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7067/12032 [6:18:41<3:48:21,  2.76s/it]2025-08-23:00:53:22,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▊    | 7068/12032 [6:18:44<4:14:15,  3.07s/it]2025-08-23:00:53:26,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7069/12032 [6:18:48<4:29:59,  3.26s/it]2025-08-23:00:53:30,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7070/12032 [6:18:52<4:43:31,  3.43s/it]2025-08-23:00:53:34,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7071/12032 [6:18:56<4:52:47,  3.54s/it]2025-08-23:00:53:38,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7072/12032 [6:18:59<4:59:20,  3.62s/it]2025-08-23:00:53:41,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7073/12032 [6:19:03<5:03:50,  3.68s/it]2025-08-23:00:53:45,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7074/12032 [6:19:07<5:07:06,  3.72s/it]2025-08-23:00:53:49,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7075/12032 [6:19:11<5:09:01,  3.74s/it]2025-08-23:00:53:53,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7076/12032 [6:19:14<4:48:38,  3.49s/it]2025-08-23:00:53:56,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7077/12032 [6:19:16<4:21:08,  3.16s/it]2025-08-23:00:53:58,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7078/12032 [6:19:20<4:37:27,  3.36s/it]2025-08-23:00:54:02,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7079/12032 [6:19:24<4:48:34,  3.50s/it]2025-08-23:00:54:06,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7080/12032 [6:19:28<4:58:00,  3.61s/it]2025-08-23:00:54:10,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7081/12032 [6:19:32<5:03:06,  3.67s/it]2025-08-23:00:54:13,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7082/12032 [6:19:33<4:14:12,  3.08s/it]2025-08-23:00:54:15,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7083/12032 [6:19:37<4:31:37,  3.29s/it]2025-08-23:00:54:19,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7084/12032 [6:19:41<4:46:46,  3.48s/it]2025-08-23:00:54:23,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7085/12032 [6:19:44<4:44:11,  3.45s/it]2025-08-23:00:54:26,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7086/12032 [6:19:46<4:09:15,  3.02s/it]2025-08-23:00:54:28,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7087/12032 [6:19:48<3:42:48,  2.70s/it]2025-08-23:00:54:30,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7088/12032 [6:19:52<4:04:33,  2.97s/it]2025-08-23:00:54:34,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7089/12032 [6:19:56<4:25:44,  3.23s/it]2025-08-23:00:54:38,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7090/12032 [6:20:00<4:40:58,  3.41s/it]2025-08-23:00:54:41,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7091/12032 [6:20:03<4:51:22,  3.54s/it]2025-08-23:00:54:45,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7092/12032 [6:20:06<4:24:14,  3.21s/it]2025-08-23:00:54:48,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7093/12032 [6:20:10<4:39:10,  3.39s/it]2025-08-23:00:54:51,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7094/12032 [6:20:13<4:49:07,  3.51s/it]2025-08-23:00:54:55,794 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7095/12032 [6:20:17<4:56:51,  3.61s/it]2025-08-23:00:54:59,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7096/12032 [6:20:21<5:03:31,  3.69s/it]2025-08-23:00:55:03,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7097/12032 [6:20:24<4:47:31,  3.50s/it]2025-08-23:00:55:06,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7098/12032 [6:20:26<4:10:20,  3.04s/it]2025-08-23:00:55:08,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7099/12032 [6:20:30<4:29:45,  3.28s/it]2025-08-23:00:55:12,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7100/12032 [6:20:33<4:32:51,  3.32s/it]2025-08-23:00:55:15,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7101/12032 [6:20:37<4:38:22,  3.39s/it]2025-08-23:00:55:19,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7102/12032 [6:20:41<4:49:15,  3.52s/it]2025-08-23:00:55:23,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7103/12032 [6:20:44<4:31:43,  3.31s/it]2025-08-23:00:55:25,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7104/12032 [6:20:45<3:34:50,  2.62s/it]2025-08-23:00:55:26,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7105/12032 [6:20:48<4:03:27,  2.96s/it]2025-08-23:00:55:30,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7106/12032 [6:20:51<3:49:48,  2.80s/it]2025-08-23:00:55:33,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7107/12032 [6:20:52<3:04:38,  2.25s/it]2025-08-23:00:55:34,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7108/12032 [6:20:56<3:42:52,  2.72s/it]2025-08-23:00:55:37,932 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7109/12032 [6:20:59<4:09:38,  3.04s/it]2025-08-23:00:55:41,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7110/12032 [6:21:03<4:28:18,  3.27s/it]2025-08-23:00:55:45,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7111/12032 [6:21:07<4:42:41,  3.45s/it]2025-08-23:00:55:49,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7112/12032 [6:21:11<4:51:20,  3.55s/it]2025-08-23:00:55:53,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7113/12032 [6:21:15<4:58:34,  3.64s/it]2025-08-23:00:55:57,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7114/12032 [6:21:19<5:03:28,  3.70s/it]2025-08-23:00:56:00,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7115/12032 [6:21:21<4:39:58,  3.42s/it]2025-08-23:00:56:03,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7116/12032 [6:21:25<4:41:45,  3.44s/it]2025-08-23:00:56:07,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7117/12032 [6:21:29<4:50:55,  3.55s/it]2025-08-23:00:56:10,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7118/12032 [6:21:32<4:57:56,  3.64s/it]2025-08-23:00:56:14,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7119/12032 [6:21:36<4:53:51,  3.59s/it]2025-08-23:00:56:18,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7120/12032 [6:21:40<4:59:49,  3.66s/it]2025-08-23:00:56:22,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7121/12032 [6:21:44<5:03:48,  3.71s/it]2025-08-23:00:56:25,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7122/12032 [6:21:47<4:57:36,  3.64s/it]2025-08-23:00:56:29,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7123/12032 [6:21:50<4:50:37,  3.55s/it]2025-08-23:00:56:32,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7124/12032 [6:21:54<4:57:26,  3.64s/it]2025-08-23:00:56:36,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7125/12032 [6:21:58<5:02:35,  3.70s/it]2025-08-23:00:56:40,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7126/12032 [6:22:00<4:28:12,  3.28s/it]2025-08-23:00:56:42,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7127/12032 [6:22:04<4:28:14,  3.28s/it]2025-08-23:00:56:46,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7128/12032 [6:22:06<4:15:46,  3.13s/it]2025-08-23:00:56:48,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7129/12032 [6:22:10<4:31:38,  3.32s/it]2025-08-23:00:56:52,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7130/12032 [6:22:14<4:44:42,  3.48s/it]2025-08-23:00:56:56,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7131/12032 [6:22:17<4:24:14,  3.24s/it]2025-08-23:00:56:59,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7132/12032 [6:22:18<3:28:22,  2.55s/it]2025-08-23:00:57:00,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7133/12032 [6:22:21<3:39:11,  2.68s/it]2025-08-23:00:57:03,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7134/12032 [6:22:23<3:32:40,  2.61s/it]2025-08-23:00:57:05,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7135/12032 [6:22:27<3:53:38,  2.86s/it]2025-08-23:00:57:08,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7136/12032 [6:22:29<3:44:13,  2.75s/it]2025-08-23:00:57:11,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7137/12032 [6:22:32<3:52:57,  2.86s/it]2025-08-23:00:57:14,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7138/12032 [6:22:36<4:16:14,  3.14s/it]2025-08-23:00:57:18,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7139/12032 [6:22:39<4:05:34,  3.01s/it]2025-08-23:00:57:21,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7140/12032 [6:22:41<3:37:05,  2.66s/it]2025-08-23:00:57:22,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7141/12032 [6:22:44<4:07:20,  3.03s/it]2025-08-23:00:57:26,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7142/12032 [6:22:48<4:12:18,  3.10s/it]2025-08-23:00:57:29,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7143/12032 [6:22:52<4:37:05,  3.40s/it]2025-08-23:00:57:34,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7144/12032 [6:22:55<4:32:09,  3.34s/it]2025-08-23:00:57:37,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7145/12032 [6:22:59<4:40:49,  3.45s/it]2025-08-23:00:57:41,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7146/12032 [6:23:03<4:50:20,  3.57s/it]2025-08-23:00:57:44,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7147/12032 [6:23:06<4:52:03,  3.59s/it]2025-08-23:00:57:48,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7148/12032 [6:23:10<4:56:46,  3.65s/it]2025-08-23:00:57:52,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7149/12032 [6:23:14<5:00:24,  3.69s/it]2025-08-23:00:57:56,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7150/12032 [6:23:17<4:39:21,  3.43s/it]2025-08-23:00:57:58,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7151/12032 [6:23:20<4:49:00,  3.55s/it]2025-08-23:00:58:02,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7152/12032 [6:23:23<4:35:38,  3.39s/it]2025-08-23:00:58:05,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7153/12032 [6:23:25<3:43:30,  2.75s/it]2025-08-23:00:58:06,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7154/12032 [6:23:28<4:09:11,  3.07s/it]2025-08-23:00:58:10,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7155/12032 [6:23:32<4:27:07,  3.29s/it]2025-08-23:00:58:14,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7156/12032 [6:23:36<4:40:01,  3.45s/it]2025-08-23:00:58:18,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7157/12032 [6:23:40<4:50:16,  3.57s/it]2025-08-23:00:58:22,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7158/12032 [6:23:44<4:55:38,  3.64s/it]2025-08-23:00:58:26,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  59%|█████▉    | 7159/12032 [6:23:48<4:59:32,  3.69s/it]2025-08-23:00:58:29,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7160/12032 [6:23:51<4:55:33,  3.64s/it]2025-08-23:00:58:33,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7161/12032 [6:23:54<4:47:43,  3.54s/it]2025-08-23:00:58:36,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7162/12032 [6:23:58<4:55:02,  3.64s/it]2025-08-23:00:58:40,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7163/12032 [6:24:00<4:11:56,  3.10s/it]2025-08-23:00:58:42,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7164/12032 [6:24:03<4:09:22,  3.07s/it]2025-08-23:00:58:45,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7165/12032 [6:24:06<3:57:29,  2.93s/it]2025-08-23:00:58:48,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7166/12032 [6:24:10<4:20:52,  3.22s/it]2025-08-23:00:58:51,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7167/12032 [6:24:13<4:36:50,  3.41s/it]2025-08-23:00:58:55,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7168/12032 [6:24:17<4:47:15,  3.54s/it]2025-08-23:00:58:59,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7169/12032 [6:24:21<4:42:14,  3.48s/it]2025-08-23:00:59:02,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7170/12032 [6:24:24<4:51:22,  3.60s/it]2025-08-23:00:59:06,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7171/12032 [6:24:28<4:56:48,  3.66s/it]2025-08-23:00:59:10,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7172/12032 [6:24:32<5:01:36,  3.72s/it]2025-08-23:00:59:14,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7173/12032 [6:24:36<5:03:43,  3.75s/it]2025-08-23:00:59:18,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7174/12032 [6:24:38<4:30:28,  3.34s/it]2025-08-23:00:59:20,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7175/12032 [6:24:42<4:43:31,  3.50s/it]2025-08-23:00:59:24,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7176/12032 [6:24:46<4:53:43,  3.63s/it]2025-08-23:00:59:28,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7177/12032 [6:24:49<4:37:54,  3.43s/it]2025-08-23:00:59:31,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7178/12032 [6:24:53<4:49:43,  3.58s/it]2025-08-23:00:59:35,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7179/12032 [6:24:57<4:56:29,  3.67s/it]2025-08-23:00:59:39,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7180/12032 [6:25:00<4:50:21,  3.59s/it]2025-08-23:00:59:42,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7181/12032 [6:25:04<4:56:12,  3.66s/it]2025-08-23:00:59:46,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7182/12032 [6:25:06<4:06:02,  3.04s/it]2025-08-23:00:59:48,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7183/12032 [6:25:09<4:05:57,  3.04s/it]2025-08-23:00:59:51,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7184/12032 [6:25:12<4:00:33,  2.98s/it]2025-08-23:00:59:54,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7185/12032 [6:25:13<3:26:12,  2.55s/it]2025-08-23:00:59:55,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7186/12032 [6:25:17<3:58:13,  2.95s/it]2025-08-23:00:59:59,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7187/12032 [6:25:18<3:19:48,  2.47s/it]2025-08-23:01:00:00,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7188/12032 [6:25:22<3:53:01,  2.89s/it]2025-08-23:01:00:04,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7189/12032 [6:25:25<3:54:35,  2.91s/it]2025-08-23:01:00:07,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7190/12032 [6:25:29<4:17:39,  3.19s/it]2025-08-23:01:00:11,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7191/12032 [6:25:31<3:48:12,  2.83s/it]2025-08-23:01:00:13,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7192/12032 [6:25:33<3:20:30,  2.49s/it]2025-08-23:01:00:15,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7193/12032 [6:25:34<2:48:49,  2.09s/it]2025-08-23:01:00:16,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7194/12032 [6:25:36<2:52:43,  2.14s/it]2025-08-23:01:00:18,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7195/12032 [6:25:39<3:05:29,  2.30s/it]2025-08-23:01:00:21,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7196/12032 [6:25:41<2:57:59,  2.21s/it]2025-08-23:01:00:23,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7197/12032 [6:25:45<3:37:43,  2.70s/it]2025-08-23:01:00:27,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7198/12032 [6:25:47<3:32:42,  2.64s/it]2025-08-23:01:00:29,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7199/12032 [6:25:50<3:27:34,  2.58s/it]2025-08-23:01:00:32,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7200/12032 [6:25:51<3:01:09,  2.25s/it]2025-08-23:01:00:33,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7201/12032 [6:25:53<2:59:53,  2.23s/it]2025-08-23:01:00:35,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7202/12032 [6:25:57<3:38:58,  2.72s/it]2025-08-23:01:00:39,551 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7203/12032 [6:26:00<3:44:17,  2.79s/it]2025-08-23:01:00:42,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7204/12032 [6:26:02<3:29:26,  2.60s/it]2025-08-23:01:00:44,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7205/12032 [6:26:06<4:01:10,  3.00s/it]2025-08-23:01:00:48,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7206/12032 [6:26:10<4:21:33,  3.25s/it]2025-08-23:01:00:52,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7207/12032 [6:26:14<4:38:34,  3.46s/it]2025-08-23:01:00:56,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7208/12032 [6:26:17<4:32:35,  3.39s/it]2025-08-23:01:00:59,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7209/12032 [6:26:21<4:45:32,  3.55s/it]2025-08-23:01:01:03,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7210/12032 [6:26:25<4:41:17,  3.50s/it]2025-08-23:01:01:06,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7211/12032 [6:26:28<4:44:58,  3.55s/it]2025-08-23:01:01:10,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7212/12032 [6:26:32<4:54:42,  3.67s/it]2025-08-23:01:01:14,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7213/12032 [6:26:36<5:01:23,  3.75s/it]2025-08-23:01:01:18,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7214/12032 [6:26:40<5:03:08,  3.78s/it]2025-08-23:01:01:22,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7215/12032 [6:26:43<4:43:36,  3.53s/it]2025-08-23:01:01:25,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7216/12032 [6:26:47<4:51:04,  3.63s/it]2025-08-23:01:01:29,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7217/12032 [6:26:51<4:59:57,  3.74s/it]2025-08-23:01:01:33,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7218/12032 [6:26:53<4:15:52,  3.19s/it]2025-08-23:01:01:35,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|█████▉    | 7219/12032 [6:26:57<4:31:35,  3.39s/it]2025-08-23:01:01:38,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7220/12032 [6:27:00<4:42:40,  3.52s/it]2025-08-23:01:01:42,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7221/12032 [6:27:03<4:14:40,  3.18s/it]2025-08-23:01:01:45,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7222/12032 [6:27:07<4:31:29,  3.39s/it]2025-08-23:01:01:48,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7223/12032 [6:27:10<4:42:15,  3.52s/it]2025-08-23:01:01:52,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7224/12032 [6:27:14<4:49:47,  3.62s/it]2025-08-23:01:01:56,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7225/12032 [6:27:18<4:55:03,  3.68s/it]2025-08-23:01:02:00,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7226/12032 [6:27:22<4:52:37,  3.65s/it]2025-08-23:01:02:04,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7227/12032 [6:27:26<4:57:27,  3.71s/it]2025-08-23:01:02:07,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7228/12032 [6:27:29<4:40:34,  3.50s/it]2025-08-23:01:02:10,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7229/12032 [6:27:32<4:48:34,  3.60s/it]2025-08-23:01:02:14,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7230/12032 [6:27:36<4:53:58,  3.67s/it]2025-08-23:01:02:18,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7231/12032 [6:27:40<4:57:38,  3.72s/it]2025-08-23:01:02:22,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7232/12032 [6:27:44<5:00:22,  3.75s/it]2025-08-23:01:02:26,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7233/12032 [6:27:48<5:02:25,  3.78s/it]2025-08-23:01:02:30,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7234/12032 [6:27:52<5:03:05,  3.79s/it]2025-08-23:01:02:33,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7235/12032 [6:27:55<5:04:16,  3.81s/it]2025-08-23:01:02:37,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7236/12032 [6:27:59<4:50:06,  3.63s/it]2025-08-23:01:02:40,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7237/12032 [6:28:02<4:55:07,  3.69s/it]2025-08-23:01:02:44,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7238/12032 [6:28:06<4:58:51,  3.74s/it]2025-08-23:01:02:48,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7239/12032 [6:28:10<5:00:54,  3.77s/it]2025-08-23:01:02:52,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7240/12032 [6:28:14<5:02:42,  3.79s/it]2025-08-23:01:02:56,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7241/12032 [6:28:18<5:04:34,  3.81s/it]2025-08-23:01:03:00,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7242/12032 [6:28:22<5:05:18,  3.82s/it]2025-08-23:01:03:04,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7243/12032 [6:28:26<5:05:21,  3.83s/it]2025-08-23:01:03:07,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7244/12032 [6:28:29<5:05:39,  3.83s/it]2025-08-23:01:03:11,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7245/12032 [6:28:33<5:05:17,  3.83s/it]2025-08-23:01:03:15,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7246/12032 [6:28:37<5:02:30,  3.79s/it]2025-08-23:01:03:19,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7247/12032 [6:28:41<5:04:45,  3.82s/it]2025-08-23:01:03:23,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7248/12032 [6:28:45<5:05:45,  3.83s/it]2025-08-23:01:03:27,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7249/12032 [6:28:48<5:05:16,  3.83s/it]2025-08-23:01:03:30,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7250/12032 [6:28:52<5:05:53,  3.84s/it]2025-08-23:01:03:34,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7251/12032 [6:28:56<5:06:18,  3.84s/it]2025-08-23:01:03:38,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7252/12032 [6:29:00<5:06:31,  3.85s/it]2025-08-23:01:03:42,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7253/12032 [6:29:04<5:05:30,  3.84s/it]2025-08-23:01:03:46,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7254/12032 [6:29:08<5:05:37,  3.84s/it]2025-08-23:01:03:50,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7255/12032 [6:29:10<4:39:29,  3.51s/it]2025-08-23:01:03:52,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7256/12032 [6:29:14<4:46:58,  3.61s/it]2025-08-23:01:03:56,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7257/12032 [6:29:18<4:54:20,  3.70s/it]2025-08-23:01:04:00,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7258/12032 [6:29:22<4:57:25,  3.74s/it]2025-08-23:01:04:04,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7259/12032 [6:29:26<4:59:44,  3.77s/it]2025-08-23:01:04:08,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7260/12032 [6:29:29<4:36:37,  3.48s/it]2025-08-23:01:04:11,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7261/12032 [6:29:32<4:44:37,  3.58s/it]2025-08-23:01:04:14,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7262/12032 [6:29:36<4:51:44,  3.67s/it]2025-08-23:01:04:18,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7263/12032 [6:29:40<4:55:33,  3.72s/it]2025-08-23:01:04:22,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7264/12032 [6:29:44<4:58:10,  3.75s/it]2025-08-23:01:04:26,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7265/12032 [6:29:48<4:56:34,  3.73s/it]2025-08-23:01:04:30,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7266/12032 [6:29:51<4:45:39,  3.60s/it]2025-08-23:01:04:33,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7267/12032 [6:29:54<4:37:14,  3.49s/it]2025-08-23:01:04:36,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7268/12032 [6:29:58<4:46:14,  3.61s/it]2025-08-23:01:04:40,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7269/12032 [6:30:02<4:45:51,  3.60s/it]2025-08-23:01:04:44,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7270/12032 [6:30:04<4:14:07,  3.20s/it]2025-08-23:01:04:46,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7271/12032 [6:30:07<4:21:22,  3.29s/it]2025-08-23:01:04:49,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7272/12032 [6:30:11<4:34:43,  3.46s/it]2025-08-23:01:04:53,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7273/12032 [6:30:15<4:46:56,  3.62s/it]2025-08-23:01:04:57,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7274/12032 [6:30:19<4:52:36,  3.69s/it]2025-08-23:01:05:01,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7275/12032 [6:30:23<4:58:04,  3.76s/it]2025-08-23:01:05:05,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7276/12032 [6:30:27<5:01:14,  3.80s/it]2025-08-23:01:05:09,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7277/12032 [6:30:30<4:47:34,  3.63s/it]2025-08-23:01:05:12,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7278/12032 [6:30:34<4:52:31,  3.69s/it]2025-08-23:01:05:16,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  60%|██████    | 7279/12032 [6:30:38<4:57:25,  3.75s/it]2025-08-23:01:05:20,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7280/12032 [6:30:42<4:58:49,  3.77s/it]2025-08-23:01:05:24,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7281/12032 [6:30:46<5:00:51,  3.80s/it]2025-08-23:01:05:27,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7282/12032 [6:30:47<4:09:27,  3.15s/it]2025-08-23:01:05:29,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7283/12032 [6:30:48<3:18:07,  2.50s/it]2025-08-23:01:05:30,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7284/12032 [6:30:51<3:27:07,  2.62s/it]2025-08-23:01:05:33,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7285/12032 [6:30:54<3:30:45,  2.66s/it]2025-08-23:01:05:36,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7286/12032 [6:30:55<3:00:25,  2.28s/it]2025-08-23:01:05:37,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7287/12032 [6:30:58<3:17:18,  2.49s/it]2025-08-23:01:05:40,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7288/12032 [6:31:00<2:56:36,  2.23s/it]2025-08-23:01:05:42,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7289/12032 [6:31:01<2:18:39,  1.75s/it]2025-08-23:01:05:42,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7290/12032 [6:31:03<2:23:06,  1.81s/it]2025-08-23:01:05:44,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7291/12032 [6:31:04<2:19:24,  1.76s/it]2025-08-23:01:05:46,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7292/12032 [6:31:06<2:21:45,  1.79s/it]2025-08-23:01:05:48,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7293/12032 [6:31:08<2:17:35,  1.74s/it]2025-08-23:01:05:49,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7294/12032 [6:31:11<2:48:59,  2.14s/it]2025-08-23:01:05:53,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7295/12032 [6:31:13<3:02:29,  2.31s/it]2025-08-23:01:05:55,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7296/12032 [6:31:16<2:59:16,  2.27s/it]2025-08-23:01:05:57,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7297/12032 [6:31:18<3:04:19,  2.34s/it]2025-08-23:01:06:00,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7298/12032 [6:31:21<3:17:31,  2.50s/it]2025-08-23:01:06:03,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7299/12032 [6:31:24<3:19:36,  2.53s/it]2025-08-23:01:06:05,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7300/12032 [6:31:26<3:13:44,  2.46s/it]2025-08-23:01:06:08,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7301/12032 [6:31:28<2:59:54,  2.28s/it]2025-08-23:01:06:10,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7302/12032 [6:31:30<3:00:53,  2.29s/it]2025-08-23:01:06:12,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7303/12032 [6:31:34<3:37:19,  2.76s/it]2025-08-23:01:06:16,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7304/12032 [6:31:38<4:03:21,  3.09s/it]2025-08-23:01:06:20,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7305/12032 [6:31:42<4:22:06,  3.33s/it]2025-08-23:01:06:23,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7306/12032 [6:31:45<4:34:11,  3.48s/it]2025-08-23:01:06:27,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7307/12032 [6:31:49<4:42:08,  3.58s/it]2025-08-23:01:06:31,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7308/12032 [6:31:53<4:47:48,  3.66s/it]2025-08-23:01:06:35,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7309/12032 [6:31:57<4:51:13,  3.70s/it]2025-08-23:01:06:39,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7310/12032 [6:32:01<4:54:56,  3.75s/it]2025-08-23:01:06:43,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7311/12032 [6:32:05<4:56:50,  3.77s/it]2025-08-23:01:06:46,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7312/12032 [6:32:08<4:59:05,  3.80s/it]2025-08-23:01:06:50,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7313/12032 [6:32:12<5:00:10,  3.82s/it]2025-08-23:01:06:54,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7314/12032 [6:32:16<5:02:51,  3.85s/it]2025-08-23:01:06:58,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7315/12032 [6:32:20<5:01:59,  3.84s/it]2025-08-23:01:07:02,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7316/12032 [6:32:22<4:20:54,  3.32s/it]2025-08-23:01:07:04,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7317/12032 [6:32:26<4:32:46,  3.47s/it]2025-08-23:01:07:08,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7318/12032 [6:32:30<4:42:42,  3.60s/it]2025-08-23:01:07:12,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7319/12032 [6:32:34<4:48:36,  3.67s/it]2025-08-23:01:07:16,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7320/12032 [6:32:38<4:52:19,  3.72s/it]2025-08-23:01:07:19,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7321/12032 [6:32:41<4:54:26,  3.75s/it]2025-08-23:01:07:23,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7322/12032 [6:32:45<4:42:19,  3.60s/it]2025-08-23:01:07:26,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7323/12032 [6:32:48<4:47:31,  3.66s/it]2025-08-23:01:07:30,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7324/12032 [6:32:52<4:50:43,  3.71s/it]2025-08-23:01:07:34,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7325/12032 [6:32:56<4:53:21,  3.74s/it]2025-08-23:01:07:38,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7326/12032 [6:33:00<4:54:54,  3.76s/it]2025-08-23:01:07:42,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7327/12032 [6:33:04<4:56:26,  3.78s/it]2025-08-23:01:07:46,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7328/12032 [6:33:08<4:57:24,  3.79s/it]2025-08-23:01:07:49,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7329/12032 [6:33:11<4:58:10,  3.80s/it]2025-08-23:01:07:53,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7330/12032 [6:33:12<3:54:38,  2.99s/it]2025-08-23:01:07:54,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7331/12032 [6:33:16<4:13:36,  3.24s/it]2025-08-23:01:07:58,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7332/12032 [6:33:20<4:27:50,  3.42s/it]2025-08-23:01:08:02,481 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7333/12032 [6:33:24<4:36:54,  3.54s/it]2025-08-23:01:08:06,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7334/12032 [6:33:28<4:43:31,  3.62s/it]2025-08-23:01:08:10,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7335/12032 [6:33:32<4:48:43,  3.69s/it]2025-08-23:01:08:13,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7336/12032 [6:33:35<4:51:47,  3.73s/it]2025-08-23:01:08:17,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7337/12032 [6:33:39<4:53:51,  3.76s/it]2025-08-23:01:08:21,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7338/12032 [6:33:43<4:57:17,  3.80s/it]2025-08-23:01:08:25,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7339/12032 [6:33:47<4:57:40,  3.81s/it]2025-08-23:01:08:29,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7340/12032 [6:33:51<4:57:38,  3.81s/it]2025-08-23:01:08:33,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7341/12032 [6:33:55<4:58:05,  3.81s/it]2025-08-23:01:08:36,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7342/12032 [6:33:58<4:58:13,  3.82s/it]2025-08-23:01:08:40,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7343/12032 [6:34:02<4:57:55,  3.81s/it]2025-08-23:01:08:44,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7344/12032 [6:34:06<4:58:04,  3.81s/it]2025-08-23:01:08:48,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7345/12032 [6:34:10<4:57:45,  3.81s/it]2025-08-23:01:08:52,204 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7346/12032 [6:34:14<4:57:05,  3.80s/it]2025-08-23:01:08:55,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7347/12032 [6:34:17<4:56:55,  3.80s/it]2025-08-23:01:08:59,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7348/12032 [6:34:21<4:57:34,  3.81s/it]2025-08-23:01:09:03,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7349/12032 [6:34:25<4:58:07,  3.82s/it]2025-08-23:01:09:07,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7350/12032 [6:34:29<4:59:14,  3.83s/it]2025-08-23:01:09:11,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7351/12032 [6:34:33<4:59:22,  3.84s/it]2025-08-23:01:09:15,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7352/12032 [6:34:37<5:00:37,  3.85s/it]2025-08-23:01:09:19,068 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7353/12032 [6:34:41<4:59:44,  3.84s/it]2025-08-23:01:09:22,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7354/12032 [6:34:44<5:00:31,  3.85s/it]2025-08-23:01:09:26,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7355/12032 [6:34:48<5:02:15,  3.88s/it]2025-08-23:01:09:30,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7356/12032 [6:34:52<5:03:15,  3.89s/it]2025-08-23:01:09:34,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7357/12032 [6:34:56<5:04:39,  3.91s/it]2025-08-23:01:09:38,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7358/12032 [6:35:00<5:04:31,  3.91s/it]2025-08-23:01:09:42,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7359/12032 [6:35:04<5:02:50,  3.89s/it]2025-08-23:01:09:46,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7360/12032 [6:35:08<4:58:39,  3.84s/it]2025-08-23:01:09:50,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7361/12032 [6:35:11<4:57:52,  3.83s/it]2025-08-23:01:09:53,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7362/12032 [6:35:15<4:59:11,  3.84s/it]2025-08-23:01:09:57,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7363/12032 [6:35:19<4:59:22,  3.85s/it]2025-08-23:01:10:01,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7364/12032 [6:35:23<4:58:53,  3.84s/it]2025-08-23:01:10:05,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7365/12032 [6:35:27<4:58:43,  3.84s/it]2025-08-23:01:10:09,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7366/12032 [6:35:30<4:46:36,  3.69s/it]2025-08-23:01:10:12,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7367/12032 [6:35:33<4:30:05,  3.47s/it]2025-08-23:01:10:15,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7368/12032 [6:35:37<4:39:10,  3.59s/it]2025-08-23:01:10:19,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████    | 7369/12032 [6:35:41<4:44:34,  3.66s/it]2025-08-23:01:10:23,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7370/12032 [6:35:45<4:48:39,  3.71s/it]2025-08-23:01:10:27,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7371/12032 [6:35:49<4:51:13,  3.75s/it]2025-08-23:01:10:30,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7372/12032 [6:35:51<4:21:04,  3.36s/it]2025-08-23:01:10:33,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7373/12032 [6:35:55<4:34:30,  3.54s/it]2025-08-23:01:10:37,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7374/12032 [6:35:59<4:41:18,  3.62s/it]2025-08-23:01:10:41,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7375/12032 [6:36:03<4:45:51,  3.68s/it]2025-08-23:01:10:44,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7376/12032 [6:36:06<4:49:00,  3.72s/it]2025-08-23:01:10:48,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7377/12032 [6:36:10<4:50:48,  3.75s/it]2025-08-23:01:10:52,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7378/12032 [6:36:14<4:51:53,  3.76s/it]2025-08-23:01:10:56,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7379/12032 [6:36:18<4:53:28,  3.78s/it]2025-08-23:01:11:00,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7380/12032 [6:36:21<4:45:08,  3.68s/it]2025-08-23:01:11:03,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7381/12032 [6:36:23<3:57:09,  3.06s/it]2025-08-23:01:11:05,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7382/12032 [6:36:27<4:14:36,  3.29s/it]2025-08-23:01:11:09,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7383/12032 [6:36:31<4:26:49,  3.44s/it]2025-08-23:01:11:12,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7384/12032 [6:36:34<4:35:26,  3.56s/it]2025-08-23:01:11:16,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7385/12032 [6:36:38<4:41:18,  3.63s/it]2025-08-23:01:11:20,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7386/12032 [6:36:40<4:00:51,  3.11s/it]2025-08-23:01:11:22,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7387/12032 [6:36:43<4:06:21,  3.18s/it]2025-08-23:01:11:25,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7388/12032 [6:36:47<4:20:10,  3.36s/it]2025-08-23:01:11:29,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7389/12032 [6:36:51<4:23:36,  3.41s/it]2025-08-23:01:11:33,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7390/12032 [6:36:54<4:13:20,  3.27s/it]2025-08-23:01:11:36,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7391/12032 [6:36:57<4:12:40,  3.27s/it]2025-08-23:01:11:39,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7392/12032 [6:37:00<4:03:52,  3.15s/it]2025-08-23:01:11:42,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7393/12032 [6:37:01<3:15:27,  2.53s/it]2025-08-23:01:11:43,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7394/12032 [6:37:03<2:57:20,  2.29s/it]2025-08-23:01:11:44,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7395/12032 [6:37:06<3:17:28,  2.56s/it]2025-08-23:01:11:48,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7396/12032 [6:37:07<2:47:01,  2.16s/it]2025-08-23:01:11:49,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7397/12032 [6:37:10<2:55:50,  2.28s/it]2025-08-23:01:11:51,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7398/12032 [6:37:11<2:35:06,  2.01s/it]2025-08-23:01:11:53,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  61%|██████▏   | 7399/12032 [6:37:15<3:13:34,  2.51s/it]2025-08-23:01:11:56,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7400/12032 [6:37:17<2:59:59,  2.33s/it]2025-08-23:01:11:58,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7401/12032 [6:37:19<2:53:49,  2.25s/it]2025-08-23:01:12:00,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7402/12032 [6:37:22<3:29:38,  2.72s/it]2025-08-23:01:12:04,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7403/12032 [6:37:26<3:55:00,  3.05s/it]2025-08-23:01:12:08,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7404/12032 [6:37:28<3:31:11,  2.74s/it]2025-08-23:01:12:10,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7405/12032 [6:37:30<3:04:22,  2.39s/it]2025-08-23:01:12:12,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7406/12032 [6:37:34<3:36:57,  2.81s/it]2025-08-23:01:12:15,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7407/12032 [6:37:37<3:59:42,  3.11s/it]2025-08-23:01:12:19,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7408/12032 [6:37:41<4:14:57,  3.31s/it]2025-08-23:01:12:23,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7409/12032 [6:37:45<4:26:06,  3.45s/it]2025-08-23:01:12:27,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7410/12032 [6:37:47<3:52:32,  3.02s/it]2025-08-23:01:12:29,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7411/12032 [6:37:51<4:09:45,  3.24s/it]2025-08-23:01:12:33,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7412/12032 [6:37:55<4:22:54,  3.41s/it]2025-08-23:01:12:36,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7413/12032 [6:37:58<4:20:24,  3.38s/it]2025-08-23:01:12:40,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7414/12032 [6:38:02<4:29:50,  3.51s/it]2025-08-23:01:12:44,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7415/12032 [6:38:05<4:36:40,  3.60s/it]2025-08-23:01:12:47,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7416/12032 [6:38:09<4:41:29,  3.66s/it]2025-08-23:01:12:51,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7417/12032 [6:38:13<4:44:46,  3.70s/it]2025-08-23:01:12:55,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7418/12032 [6:38:17<4:46:12,  3.72s/it]2025-08-23:01:12:59,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7419/12032 [6:38:21<4:48:11,  3.75s/it]2025-08-23:01:13:03,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7420/12032 [6:38:24<4:48:43,  3.76s/it]2025-08-23:01:13:06,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7421/12032 [6:38:28<4:49:49,  3.77s/it]2025-08-23:01:13:10,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7422/12032 [6:38:32<4:50:29,  3.78s/it]2025-08-23:01:13:14,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7423/12032 [6:38:36<4:51:13,  3.79s/it]2025-08-23:01:13:18,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7424/12032 [6:38:40<4:53:10,  3.82s/it]2025-08-23:01:13:22,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7425/12032 [6:38:44<4:53:02,  3.82s/it]2025-08-23:01:13:25,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7426/12032 [6:38:47<4:53:54,  3.83s/it]2025-08-23:01:13:29,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7427/12032 [6:38:51<4:54:36,  3.84s/it]2025-08-23:01:13:33,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7428/12032 [6:38:54<4:27:04,  3.48s/it]2025-08-23:01:13:36,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7429/12032 [6:38:58<4:34:30,  3.58s/it]2025-08-23:01:13:40,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7430/12032 [6:39:02<4:39:33,  3.64s/it]2025-08-23:01:13:43,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7431/12032 [6:39:04<4:23:06,  3.43s/it]2025-08-23:01:13:46,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7432/12032 [6:39:08<4:31:30,  3.54s/it]2025-08-23:01:13:50,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7433/12032 [6:39:12<4:34:10,  3.58s/it]2025-08-23:01:13:54,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7434/12032 [6:39:16<4:39:12,  3.64s/it]2025-08-23:01:13:58,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7435/12032 [6:39:20<4:43:15,  3.70s/it]2025-08-23:01:14:01,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7436/12032 [6:39:23<4:44:53,  3.72s/it]2025-08-23:01:14:05,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7437/12032 [6:39:27<4:46:04,  3.74s/it]2025-08-23:01:14:09,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7438/12032 [6:39:31<4:47:25,  3.75s/it]2025-08-23:01:14:13,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7439/12032 [6:39:35<4:47:57,  3.76s/it]2025-08-23:01:14:17,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7440/12032 [6:39:38<4:48:11,  3.77s/it]2025-08-23:01:14:20,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7441/12032 [6:39:42<4:48:32,  3.77s/it]2025-08-23:01:14:24,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7442/12032 [6:39:46<4:49:38,  3.79s/it]2025-08-23:01:14:28,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7443/12032 [6:39:50<4:50:05,  3.79s/it]2025-08-23:01:14:32,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7444/12032 [6:39:53<4:45:33,  3.73s/it]2025-08-23:01:14:35,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7445/12032 [6:39:57<4:47:22,  3.76s/it]2025-08-23:01:14:39,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7446/12032 [6:40:01<4:48:36,  3.78s/it]2025-08-23:01:14:43,437 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7447/12032 [6:40:05<4:49:01,  3.78s/it]2025-08-23:01:14:47,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7448/12032 [6:40:09<4:50:07,  3.80s/it]2025-08-23:01:14:51,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7449/12032 [6:40:13<4:52:10,  3.83s/it]2025-08-23:01:14:54,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7450/12032 [6:40:16<4:53:28,  3.84s/it]2025-08-23:01:14:58,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7451/12032 [6:40:20<4:53:54,  3.85s/it]2025-08-23:01:15:02,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7452/12032 [6:40:24<4:54:50,  3.86s/it]2025-08-23:01:15:06,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7453/12032 [6:40:28<4:56:03,  3.88s/it]2025-08-23:01:15:10,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7454/12032 [6:40:32<4:57:30,  3.90s/it]2025-08-23:01:15:14,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7455/12032 [6:40:36<4:56:40,  3.89s/it]2025-08-23:01:15:18,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7456/12032 [6:40:40<4:56:37,  3.89s/it]2025-08-23:01:15:22,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7457/12032 [6:40:44<4:56:09,  3.88s/it]2025-08-23:01:15:26,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7458/12032 [6:40:48<4:56:36,  3.89s/it]2025-08-23:01:15:29,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7459/12032 [6:40:52<4:56:44,  3.89s/it]2025-08-23:01:15:33,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7460/12032 [6:40:55<4:56:15,  3.89s/it]2025-08-23:01:15:37,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7461/12032 [6:40:59<4:54:31,  3.87s/it]2025-08-23:01:15:41,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7462/12032 [6:41:03<4:53:12,  3.85s/it]2025-08-23:01:15:45,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7463/12032 [6:41:07<4:52:14,  3.84s/it]2025-08-23:01:15:49,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7464/12032 [6:41:11<4:52:52,  3.85s/it]2025-08-23:01:15:53,075 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7465/12032 [6:41:15<4:52:24,  3.84s/it]2025-08-23:01:15:56,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7466/12032 [6:41:18<4:51:18,  3.83s/it]2025-08-23:01:16:00,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7467/12032 [6:41:22<4:50:26,  3.82s/it]2025-08-23:01:16:04,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7468/12032 [6:41:26<4:50:17,  3.82s/it]2025-08-23:01:16:08,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7469/12032 [6:41:30<4:49:50,  3.81s/it]2025-08-23:01:16:12,107 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7470/12032 [6:41:34<4:49:24,  3.81s/it]2025-08-23:01:16:15,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7471/12032 [6:41:36<4:16:58,  3.38s/it]2025-08-23:01:16:18,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7472/12032 [6:41:40<4:26:26,  3.51s/it]2025-08-23:01:16:22,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7473/12032 [6:41:44<4:33:30,  3.60s/it]2025-08-23:01:16:25,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7474/12032 [6:41:46<4:00:08,  3.16s/it]2025-08-23:01:16:28,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7475/12032 [6:41:50<4:14:50,  3.36s/it]2025-08-23:01:16:31,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7476/12032 [6:41:53<4:24:30,  3.48s/it]2025-08-23:01:16:35,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7477/12032 [6:41:57<4:28:21,  3.53s/it]2025-08-23:01:16:39,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7478/12032 [6:42:01<4:33:46,  3.61s/it]2025-08-23:01:16:43,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7479/12032 [6:42:03<4:03:14,  3.21s/it]2025-08-23:01:16:45,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7480/12032 [6:42:07<4:16:03,  3.38s/it]2025-08-23:01:16:49,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7481/12032 [6:42:09<3:41:17,  2.92s/it]2025-08-23:01:16:50,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7482/12032 [6:42:12<3:51:29,  3.05s/it]2025-08-23:01:16:54,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7483/12032 [6:42:15<3:50:44,  3.04s/it]2025-08-23:01:16:57,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7484/12032 [6:42:19<4:07:37,  3.27s/it]2025-08-23:01:17:01,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7485/12032 [6:42:23<4:20:00,  3.43s/it]2025-08-23:01:17:04,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7486/12032 [6:42:24<3:43:21,  2.95s/it]2025-08-23:01:17:06,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7487/12032 [6:42:28<4:03:10,  3.21s/it]2025-08-23:01:17:10,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7488/12032 [6:42:32<4:16:49,  3.39s/it]2025-08-23:01:17:14,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7489/12032 [6:42:36<4:26:34,  3.52s/it]2025-08-23:01:17:18,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7490/12032 [6:42:40<4:32:50,  3.60s/it]2025-08-23:01:17:22,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7491/12032 [6:42:42<3:54:39,  3.10s/it]2025-08-23:01:17:23,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7492/12032 [6:42:45<3:52:05,  3.07s/it]2025-08-23:01:17:26,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7493/12032 [6:42:48<3:54:27,  3.10s/it]2025-08-23:01:17:30,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7494/12032 [6:42:50<3:28:00,  2.75s/it]2025-08-23:01:17:32,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7495/12032 [6:42:54<3:52:02,  3.07s/it]2025-08-23:01:17:35,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7496/12032 [6:42:57<3:54:14,  3.10s/it]2025-08-23:01:17:39,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7497/12032 [6:43:00<3:57:45,  3.15s/it]2025-08-23:01:17:42,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7498/12032 [6:43:03<3:52:42,  3.08s/it]2025-08-23:01:17:45,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7499/12032 [6:43:06<3:43:22,  2.96s/it]2025-08-23:01:17:47,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7500/12032 [6:43:08<3:23:45,  2.70s/it]2025-08-23:01:17:49,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7501/12032 [6:43:09<2:58:18,  2.36s/it]2025-08-23:01:17:51,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7502/12032 [6:43:13<3:31:14,  2.80s/it]2025-08-23:01:17:55,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7503/12032 [6:43:17<3:55:48,  3.12s/it]2025-08-23:01:17:59,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7504/12032 [6:43:18<3:14:42,  2.58s/it]2025-08-23:01:18:00,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7505/12032 [6:43:20<2:57:08,  2.35s/it]2025-08-23:01:18:02,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7506/12032 [6:43:22<2:47:03,  2.21s/it]2025-08-23:01:18:04,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7507/12032 [6:43:26<3:22:51,  2.69s/it]2025-08-23:01:18:08,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7508/12032 [6:43:28<3:14:28,  2.58s/it]2025-08-23:01:18:10,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7509/12032 [6:43:31<3:16:00,  2.60s/it]2025-08-23:01:18:13,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7510/12032 [6:43:33<3:08:31,  2.50s/it]2025-08-23:01:18:15,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7511/12032 [6:43:37<3:37:53,  2.89s/it]2025-08-23:01:18:19,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7512/12032 [6:43:41<4:01:15,  3.20s/it]2025-08-23:01:18:23,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7513/12032 [6:43:43<3:36:18,  2.87s/it]2025-08-23:01:18:25,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7514/12032 [6:43:47<3:57:23,  3.15s/it]2025-08-23:01:18:28,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7515/12032 [6:43:50<4:13:21,  3.37s/it]2025-08-23:01:18:32,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7516/12032 [6:43:54<4:22:50,  3.49s/it]2025-08-23:01:18:36,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7517/12032 [6:43:58<4:30:02,  3.59s/it]2025-08-23:01:18:40,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7518/12032 [6:44:02<4:35:15,  3.66s/it]2025-08-23:01:18:44,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▏   | 7519/12032 [6:44:05<4:20:47,  3.47s/it]2025-08-23:01:18:47,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  62%|██████▎   | 7520/12032 [6:44:09<4:27:48,  3.56s/it]2025-08-23:01:18:51,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7521/12032 [6:44:12<4:32:44,  3.63s/it]2025-08-23:01:18:54,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7522/12032 [6:44:16<4:36:40,  3.68s/it]2025-08-23:01:18:58,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7523/12032 [6:44:20<4:38:52,  3.71s/it]2025-08-23:01:19:02,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7524/12032 [6:44:23<4:13:17,  3.37s/it]2025-08-23:01:19:04,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7525/12032 [6:44:26<4:17:13,  3.42s/it]2025-08-23:01:19:08,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7526/12032 [6:44:30<4:25:38,  3.54s/it]2025-08-23:01:19:12,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7527/12032 [6:44:34<4:31:29,  3.62s/it]2025-08-23:01:19:16,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7528/12032 [6:44:38<4:35:57,  3.68s/it]2025-08-23:01:19:19,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7529/12032 [6:44:40<4:09:05,  3.32s/it]2025-08-23:01:19:22,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7530/12032 [6:44:44<4:21:10,  3.48s/it]2025-08-23:01:19:26,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7531/12032 [6:44:46<3:58:09,  3.17s/it]2025-08-23:01:19:28,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7532/12032 [6:44:50<4:12:01,  3.36s/it]2025-08-23:01:19:32,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7533/12032 [6:44:54<4:22:27,  3.50s/it]2025-08-23:01:19:36,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7534/12032 [6:44:58<4:28:50,  3.59s/it]2025-08-23:01:19:40,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7535/12032 [6:45:02<4:33:30,  3.65s/it]2025-08-23:01:19:43,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7536/12032 [6:45:05<4:37:39,  3.71s/it]2025-08-23:01:19:47,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7537/12032 [6:45:09<4:39:09,  3.73s/it]2025-08-23:01:19:51,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7538/12032 [6:45:13<4:40:51,  3.75s/it]2025-08-23:01:19:55,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7539/12032 [6:45:17<4:42:30,  3.77s/it]2025-08-23:01:19:59,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7540/12032 [6:45:21<4:43:14,  3.78s/it]2025-08-23:01:20:03,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7541/12032 [6:45:24<4:43:45,  3.79s/it]2025-08-23:01:20:06,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7542/12032 [6:45:28<4:43:26,  3.79s/it]2025-08-23:01:20:10,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7543/12032 [6:45:32<4:44:02,  3.80s/it]2025-08-23:01:20:14,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7544/12032 [6:45:36<4:44:10,  3.80s/it]2025-08-23:01:20:18,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7545/12032 [6:45:40<4:44:33,  3.81s/it]2025-08-23:01:20:22,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7546/12032 [6:45:44<4:44:31,  3.81s/it]2025-08-23:01:20:25,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7547/12032 [6:45:47<4:44:26,  3.81s/it]2025-08-23:01:20:29,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7548/12032 [6:45:51<4:44:46,  3.81s/it]2025-08-23:01:20:33,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7549/12032 [6:45:55<4:43:47,  3.80s/it]2025-08-23:01:20:37,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7550/12032 [6:45:59<4:45:03,  3.82s/it]2025-08-23:01:20:41,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7551/12032 [6:46:03<4:45:23,  3.82s/it]2025-08-23:01:20:44,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7552/12032 [6:46:06<4:45:31,  3.82s/it]2025-08-23:01:20:48,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7553/12032 [6:46:09<4:27:58,  3.59s/it]2025-08-23:01:20:51,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7554/12032 [6:46:13<4:33:32,  3.67s/it]2025-08-23:01:20:55,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7555/12032 [6:46:17<4:36:47,  3.71s/it]2025-08-23:01:20:59,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7556/12032 [6:46:21<4:40:24,  3.76s/it]2025-08-23:01:21:03,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7557/12032 [6:46:25<4:41:31,  3.77s/it]2025-08-23:01:21:07,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7558/12032 [6:46:27<4:05:49,  3.30s/it]2025-08-23:01:21:09,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7559/12032 [6:46:31<4:16:38,  3.44s/it]2025-08-23:01:21:13,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7560/12032 [6:46:35<4:25:19,  3.56s/it]2025-08-23:01:21:16,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7561/12032 [6:46:38<4:32:40,  3.66s/it]2025-08-23:01:21:20,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7562/12032 [6:46:42<4:37:02,  3.72s/it]2025-08-23:01:21:24,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7563/12032 [6:46:46<4:39:11,  3.75s/it]2025-08-23:01:21:28,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7564/12032 [6:46:50<4:41:09,  3.78s/it]2025-08-23:01:21:32,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7565/12032 [6:46:53<4:25:43,  3.57s/it]2025-08-23:01:21:35,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7566/12032 [6:46:57<4:30:24,  3.63s/it]2025-08-23:01:21:39,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7567/12032 [6:47:01<4:33:52,  3.68s/it]2025-08-23:01:21:43,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7568/12032 [6:47:04<4:36:29,  3.72s/it]2025-08-23:01:21:46,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7569/12032 [6:47:08<4:39:30,  3.76s/it]2025-08-23:01:21:50,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7570/12032 [6:47:12<4:40:10,  3.77s/it]2025-08-23:01:21:54,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7571/12032 [6:47:16<4:40:54,  3.78s/it]2025-08-23:01:21:58,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7572/12032 [6:47:19<4:18:28,  3.48s/it]2025-08-23:01:22:01,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7573/12032 [6:47:22<4:25:43,  3.58s/it]2025-08-23:01:22:04,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7574/12032 [6:47:26<4:30:13,  3.64s/it]2025-08-23:01:22:08,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7575/12032 [6:47:30<4:35:32,  3.71s/it]2025-08-23:01:22:12,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7576/12032 [6:47:34<4:38:21,  3.75s/it]2025-08-23:01:22:16,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7577/12032 [6:47:38<4:39:13,  3.76s/it]2025-08-23:01:22:20,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7578/12032 [6:47:42<4:39:59,  3.77s/it]2025-08-23:01:22:23,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7579/12032 [6:47:45<4:40:41,  3.78s/it]2025-08-23:01:22:27,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7580/12032 [6:47:48<4:17:51,  3.48s/it]2025-08-23:01:22:30,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7581/12032 [6:47:52<4:25:34,  3.58s/it]2025-08-23:01:22:34,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7582/12032 [6:47:56<4:30:15,  3.64s/it]2025-08-23:01:22:38,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7583/12032 [6:48:00<4:33:34,  3.69s/it]2025-08-23:01:22:41,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7584/12032 [6:48:03<4:35:30,  3.72s/it]2025-08-23:01:22:45,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7585/12032 [6:48:07<4:37:16,  3.74s/it]2025-08-23:01:22:49,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7586/12032 [6:48:11<4:38:34,  3.76s/it]2025-08-23:01:22:53,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7587/12032 [6:48:15<4:39:46,  3.78s/it]2025-08-23:01:22:57,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7588/12032 [6:48:17<3:58:09,  3.22s/it]2025-08-23:01:22:59,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7589/12032 [6:48:19<3:42:38,  3.01s/it]2025-08-23:01:23:01,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7590/12032 [6:48:23<4:00:20,  3.25s/it]2025-08-23:01:23:05,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7591/12032 [6:48:27<4:12:52,  3.42s/it]2025-08-23:01:23:09,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7592/12032 [6:48:31<4:21:41,  3.54s/it]2025-08-23:01:23:12,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7593/12032 [6:48:34<4:27:41,  3.62s/it]2025-08-23:01:23:16,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7594/12032 [6:48:36<3:40:55,  2.99s/it]2025-08-23:01:23:18,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7595/12032 [6:48:40<3:56:10,  3.19s/it]2025-08-23:01:23:21,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7596/12032 [6:48:41<3:21:29,  2.73s/it]2025-08-23:01:23:23,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7597/12032 [6:48:45<3:36:20,  2.93s/it]2025-08-23:01:23:26,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7598/12032 [6:48:47<3:13:59,  2.63s/it]2025-08-23:01:23:28,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7599/12032 [6:48:49<3:10:18,  2.58s/it]2025-08-23:01:23:31,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7600/12032 [6:48:53<3:38:48,  2.96s/it]2025-08-23:01:23:35,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7601/12032 [6:48:56<3:39:27,  2.97s/it]2025-08-23:01:23:38,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7602/12032 [6:48:58<3:24:01,  2.76s/it]2025-08-23:01:23:40,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7603/12032 [6:49:01<3:19:32,  2.70s/it]2025-08-23:01:23:43,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7604/12032 [6:49:04<3:43:10,  3.02s/it]2025-08-23:01:23:46,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7605/12032 [6:49:07<3:35:34,  2.92s/it]2025-08-23:01:23:49,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7606/12032 [6:49:11<3:54:59,  3.19s/it]2025-08-23:01:23:53,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7607/12032 [6:49:13<3:34:16,  2.91s/it]2025-08-23:01:23:55,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7608/12032 [6:49:15<3:17:01,  2.67s/it]2025-08-23:01:23:57,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7609/12032 [6:49:19<3:42:34,  3.02s/it]2025-08-23:01:24:01,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7610/12032 [6:49:21<3:22:41,  2.75s/it]2025-08-23:01:24:03,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7611/12032 [6:49:24<3:17:58,  2.69s/it]2025-08-23:01:24:06,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7612/12032 [6:49:28<3:42:49,  3.02s/it]2025-08-23:01:24:10,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7613/12032 [6:49:31<4:00:06,  3.26s/it]2025-08-23:01:24:13,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7614/12032 [6:49:35<4:12:12,  3.43s/it]2025-08-23:01:24:17,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7615/12032 [6:49:37<3:36:46,  2.94s/it]2025-08-23:01:24:19,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7616/12032 [6:49:40<3:46:12,  3.07s/it]2025-08-23:01:24:22,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7617/12032 [6:49:43<3:32:27,  2.89s/it]2025-08-23:01:24:25,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7618/12032 [6:49:45<3:18:31,  2.70s/it]2025-08-23:01:24:27,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7619/12032 [6:49:49<3:43:16,  3.04s/it]2025-08-23:01:24:31,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7620/12032 [6:49:52<3:47:47,  3.10s/it]2025-08-23:01:24:34,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7621/12032 [6:49:56<4:04:21,  3.32s/it]2025-08-23:01:24:38,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7622/12032 [6:50:00<4:15:19,  3.47s/it]2025-08-23:01:24:42,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7623/12032 [6:50:02<3:40:20,  3.00s/it]2025-08-23:01:24:44,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7624/12032 [6:50:06<3:59:28,  3.26s/it]2025-08-23:01:24:48,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7625/12032 [6:50:08<3:27:32,  2.83s/it]2025-08-23:01:24:49,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7626/12032 [6:50:11<3:50:18,  3.14s/it]2025-08-23:01:24:53,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7627/12032 [6:50:15<4:05:50,  3.35s/it]2025-08-23:01:24:57,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7628/12032 [6:50:19<4:16:32,  3.50s/it]2025-08-23:01:25:01,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7629/12032 [6:50:23<4:24:11,  3.60s/it]2025-08-23:01:25:05,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7630/12032 [6:50:27<4:29:13,  3.67s/it]2025-08-23:01:25:09,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7631/12032 [6:50:31<4:32:47,  3.72s/it]2025-08-23:01:25:12,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7632/12032 [6:50:34<4:34:23,  3.74s/it]2025-08-23:01:25:16,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7633/12032 [6:50:38<4:36:06,  3.77s/it]2025-08-23:01:25:20,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7634/12032 [6:50:41<4:23:00,  3.59s/it]2025-08-23:01:25:23,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7635/12032 [6:50:45<4:28:02,  3.66s/it]2025-08-23:01:25:27,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7636/12032 [6:50:49<4:33:32,  3.73s/it]2025-08-23:01:25:31,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7637/12032 [6:50:53<4:28:46,  3.67s/it]2025-08-23:01:25:34,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7638/12032 [6:50:56<4:32:05,  3.72s/it]2025-08-23:01:25:38,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7639/12032 [6:51:00<4:22:58,  3.59s/it]2025-08-23:01:25:42,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  63%|██████▎   | 7640/12032 [6:51:04<4:27:32,  3.66s/it]2025-08-23:01:25:45,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7641/12032 [6:51:07<4:30:45,  3.70s/it]2025-08-23:01:25:49,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7642/12032 [6:51:10<4:17:59,  3.53s/it]2025-08-23:01:25:52,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7643/12032 [6:51:14<4:24:00,  3.61s/it]2025-08-23:01:25:56,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7644/12032 [6:51:18<4:29:19,  3.68s/it]2025-08-23:01:26:00,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7645/12032 [6:51:22<4:33:53,  3.75s/it]2025-08-23:01:26:04,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7646/12032 [6:51:26<4:35:22,  3.77s/it]2025-08-23:01:26:08,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7647/12032 [6:51:29<4:19:45,  3.55s/it]2025-08-23:01:26:11,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7648/12032 [6:51:33<4:26:00,  3.64s/it]2025-08-23:01:26:15,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7649/12032 [6:51:37<4:30:24,  3.70s/it]2025-08-23:01:26:18,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7650/12032 [6:51:40<4:33:25,  3.74s/it]2025-08-23:01:26:22,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7651/12032 [6:51:44<4:34:57,  3.77s/it]2025-08-23:01:26:26,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7652/12032 [6:51:48<4:35:22,  3.77s/it]2025-08-23:01:26:30,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7653/12032 [6:51:51<4:19:08,  3.55s/it]2025-08-23:01:26:33,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7654/12032 [6:51:55<4:27:31,  3.67s/it]2025-08-23:01:26:37,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7655/12032 [6:51:58<4:09:19,  3.42s/it]2025-08-23:01:26:40,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7656/12032 [6:52:02<4:19:52,  3.56s/it]2025-08-23:01:26:44,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7657/12032 [6:52:06<4:26:10,  3.65s/it]2025-08-23:01:26:47,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7658/12032 [6:52:09<4:31:25,  3.72s/it]2025-08-23:01:26:51,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7659/12032 [6:52:13<4:34:40,  3.77s/it]2025-08-23:01:26:55,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7660/12032 [6:52:17<4:39:04,  3.83s/it]2025-08-23:01:26:59,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7661/12032 [6:52:21<4:40:20,  3.85s/it]2025-08-23:01:27:03,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7662/12032 [6:52:25<4:41:39,  3.87s/it]2025-08-23:01:27:07,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7663/12032 [6:52:29<4:42:03,  3.87s/it]2025-08-23:01:27:11,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7664/12032 [6:52:33<4:42:18,  3.88s/it]2025-08-23:01:27:15,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7665/12032 [6:52:37<4:45:15,  3.92s/it]2025-08-23:01:27:19,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7666/12032 [6:52:41<4:45:18,  3.92s/it]2025-08-23:01:27:23,174 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7667/12032 [6:52:45<4:45:26,  3.92s/it]2025-08-23:01:27:27,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7668/12032 [6:52:49<4:44:15,  3.91s/it]2025-08-23:01:27:30,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7669/12032 [6:52:53<4:45:40,  3.93s/it]2025-08-23:01:27:34,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▎   | 7670/12032 [6:52:55<4:20:46,  3.59s/it]2025-08-23:01:27:37,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7671/12032 [6:52:59<4:25:55,  3.66s/it]2025-08-23:01:27:41,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7672/12032 [6:53:03<4:28:57,  3.70s/it]2025-08-23:01:27:45,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7673/12032 [6:53:07<4:31:32,  3.74s/it]2025-08-23:01:27:49,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7674/12032 [6:53:09<4:01:47,  3.33s/it]2025-08-23:01:27:51,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7675/12032 [6:53:13<4:13:09,  3.49s/it]2025-08-23:01:27:55,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7676/12032 [6:53:17<4:20:27,  3.59s/it]2025-08-23:01:27:59,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7677/12032 [6:53:21<4:25:01,  3.65s/it]2025-08-23:01:28:03,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7678/12032 [6:53:25<4:28:41,  3.70s/it]2025-08-23:01:28:06,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7679/12032 [6:53:28<4:32:43,  3.76s/it]2025-08-23:01:28:10,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7680/12032 [6:53:30<3:54:09,  3.23s/it]2025-08-23:01:28:12,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7681/12032 [6:53:34<4:06:28,  3.40s/it]2025-08-23:01:28:16,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7682/12032 [6:53:38<4:15:19,  3.52s/it]2025-08-23:01:28:20,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7683/12032 [6:53:42<4:21:38,  3.61s/it]2025-08-23:01:28:24,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7684/12032 [6:53:46<4:26:13,  3.67s/it]2025-08-23:01:28:27,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7685/12032 [6:53:49<4:30:00,  3.73s/it]2025-08-23:01:28:31,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7686/12032 [6:53:53<4:31:45,  3.75s/it]2025-08-23:01:28:35,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7687/12032 [6:53:57<4:33:13,  3.77s/it]2025-08-23:01:28:39,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7688/12032 [6:54:01<4:34:10,  3.79s/it]2025-08-23:01:28:43,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7689/12032 [6:54:04<4:22:17,  3.62s/it]2025-08-23:01:28:46,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7690/12032 [6:54:08<4:26:27,  3.68s/it]2025-08-23:01:28:50,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7691/12032 [6:54:12<4:29:09,  3.72s/it]2025-08-23:01:28:54,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7692/12032 [6:54:16<4:31:20,  3.75s/it]2025-08-23:01:28:57,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7693/12032 [6:54:19<4:33:10,  3.78s/it]2025-08-23:01:29:01,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7694/12032 [6:54:23<4:33:21,  3.78s/it]2025-08-23:01:29:05,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7695/12032 [6:54:27<4:34:10,  3.79s/it]2025-08-23:01:29:09,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7696/12032 [6:54:31<4:34:20,  3.80s/it]2025-08-23:01:29:13,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7697/12032 [6:54:35<4:34:59,  3.81s/it]2025-08-23:01:29:17,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7698/12032 [6:54:38<4:21:59,  3.63s/it]2025-08-23:01:29:20,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7699/12032 [6:54:42<4:25:49,  3.68s/it]2025-08-23:01:29:24,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7700/12032 [6:54:45<4:23:50,  3.65s/it]2025-08-23:01:29:27,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7701/12032 [6:54:49<4:23:54,  3.66s/it]2025-08-23:01:29:31,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7702/12032 [6:54:50<3:28:10,  2.88s/it]2025-08-23:01:29:32,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7703/12032 [6:54:54<3:49:46,  3.18s/it]2025-08-23:01:29:36,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7704/12032 [6:54:58<4:04:16,  3.39s/it]2025-08-23:01:29:40,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7705/12032 [6:55:02<4:13:50,  3.52s/it]2025-08-23:01:29:43,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7706/12032 [6:55:05<4:20:32,  3.61s/it]2025-08-23:01:29:47,828 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7707/12032 [6:55:09<4:25:05,  3.68s/it]2025-08-23:01:29:51,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7708/12032 [6:55:13<4:28:10,  3.72s/it]2025-08-23:01:29:55,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7709/12032 [6:55:17<4:30:27,  3.75s/it]2025-08-23:01:29:59,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7710/12032 [6:55:19<3:56:55,  3.29s/it]2025-08-23:01:30:01,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7711/12032 [6:55:22<3:46:00,  3.14s/it]2025-08-23:01:30:04,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7712/12032 [6:55:23<3:01:41,  2.52s/it]2025-08-23:01:30:05,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7713/12032 [6:55:26<3:16:25,  2.73s/it]2025-08-23:01:30:08,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7714/12032 [6:55:30<3:40:15,  3.06s/it]2025-08-23:01:30:12,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7715/12032 [6:55:32<3:14:02,  2.70s/it]2025-08-23:01:30:14,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7716/12032 [6:55:34<3:00:11,  2.50s/it]2025-08-23:01:30:16,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7717/12032 [6:55:36<2:45:50,  2.31s/it]2025-08-23:01:30:18,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7718/12032 [6:55:37<2:30:18,  2.09s/it]2025-08-23:01:30:19,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7719/12032 [6:55:41<2:53:10,  2.41s/it]2025-08-23:01:30:22,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7720/12032 [6:55:44<3:23:56,  2.84s/it]2025-08-23:01:30:26,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7721/12032 [6:55:48<3:45:18,  3.14s/it]2025-08-23:01:30:30,587 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7722/12032 [6:55:51<3:30:20,  2.93s/it]2025-08-23:01:30:33,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7723/12032 [6:55:53<3:15:16,  2.72s/it]2025-08-23:01:30:35,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7724/12032 [6:55:56<3:12:27,  2.68s/it]2025-08-23:01:30:37,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7725/12032 [6:56:00<3:43:20,  3.11s/it]2025-08-23:01:30:41,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7726/12032 [6:56:02<3:26:31,  2.88s/it]2025-08-23:01:30:44,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7727/12032 [6:56:06<3:46:32,  3.16s/it]2025-08-23:01:30:48,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7728/12032 [6:56:09<3:48:46,  3.19s/it]2025-08-23:01:30:51,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7729/12032 [6:56:11<3:12:29,  2.68s/it]2025-08-23:01:30:52,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7730/12032 [6:56:13<3:06:08,  2.60s/it]2025-08-23:01:30:55,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7731/12032 [6:56:17<3:32:10,  2.96s/it]2025-08-23:01:30:59,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7732/12032 [6:56:19<3:10:58,  2.66s/it]2025-08-23:01:31:01,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7733/12032 [6:56:22<3:17:20,  2.75s/it]2025-08-23:01:31:04,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7734/12032 [6:56:23<2:52:48,  2.41s/it]2025-08-23:01:31:05,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7735/12032 [6:56:26<2:52:51,  2.41s/it]2025-08-23:01:31:08,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7736/12032 [6:56:28<2:45:29,  2.31s/it]2025-08-23:01:31:10,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7737/12032 [6:56:30<2:40:05,  2.24s/it]2025-08-23:01:31:12,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7738/12032 [6:56:31<2:22:44,  1.99s/it]2025-08-23:01:31:13,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7739/12032 [6:56:32<2:03:46,  1.73s/it]2025-08-23:01:31:14,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7740/12032 [6:56:36<2:44:04,  2.29s/it]2025-08-23:01:31:18,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7741/12032 [6:56:40<3:16:46,  2.75s/it]2025-08-23:01:31:22,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7742/12032 [6:56:44<3:40:44,  3.09s/it]2025-08-23:01:31:26,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7743/12032 [6:56:47<3:55:41,  3.30s/it]2025-08-23:01:31:29,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7744/12032 [6:56:51<4:07:24,  3.46s/it]2025-08-23:01:31:33,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7745/12032 [6:56:55<4:11:01,  3.51s/it]2025-08-23:01:31:37,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7746/12032 [6:56:59<4:18:08,  3.61s/it]2025-08-23:01:31:41,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7747/12032 [6:57:03<4:23:43,  3.69s/it]2025-08-23:01:31:45,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7748/12032 [6:57:07<4:28:07,  3.76s/it]2025-08-23:01:31:48,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7749/12032 [6:57:09<4:04:57,  3.43s/it]2025-08-23:01:31:51,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7750/12032 [6:57:12<3:55:49,  3.30s/it]2025-08-23:01:31:54,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7751/12032 [6:57:16<3:55:11,  3.30s/it]2025-08-23:01:31:57,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7752/12032 [6:57:19<4:06:32,  3.46s/it]2025-08-23:01:32:01,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7753/12032 [6:57:23<4:15:04,  3.58s/it]2025-08-23:01:32:05,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7754/12032 [6:57:27<4:10:30,  3.51s/it]2025-08-23:01:32:08,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7755/12032 [6:57:30<4:16:11,  3.59s/it]2025-08-23:01:32:12,717 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7756/12032 [6:57:34<4:20:42,  3.66s/it]2025-08-23:01:32:16,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7757/12032 [6:57:37<4:11:07,  3.52s/it]2025-08-23:01:32:19,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7758/12032 [6:57:41<4:18:16,  3.63s/it]2025-08-23:01:32:23,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7759/12032 [6:57:44<4:00:16,  3.37s/it]2025-08-23:01:32:26,385 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  64%|██████▍   | 7760/12032 [6:57:48<4:09:35,  3.51s/it]2025-08-23:01:32:30,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7761/12032 [6:57:52<4:17:29,  3.62s/it]2025-08-23:01:32:34,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7762/12032 [6:57:56<4:22:45,  3.69s/it]2025-08-23:01:32:37,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7763/12032 [6:57:58<4:03:54,  3.43s/it]2025-08-23:01:32:40,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7764/12032 [6:58:02<4:12:24,  3.55s/it]2025-08-23:01:32:44,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7765/12032 [6:58:06<4:10:14,  3.52s/it]2025-08-23:01:32:48,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7766/12032 [6:58:09<4:16:13,  3.60s/it]2025-08-23:01:32:51,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7767/12032 [6:58:13<4:21:46,  3.68s/it]2025-08-23:01:32:55,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7768/12032 [6:58:17<4:26:46,  3.75s/it]2025-08-23:01:32:59,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7769/12032 [6:58:21<4:30:34,  3.81s/it]2025-08-23:01:33:03,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7770/12032 [6:58:25<4:31:47,  3.83s/it]2025-08-23:01:33:07,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7771/12032 [6:58:29<4:31:24,  3.82s/it]2025-08-23:01:33:11,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7772/12032 [6:58:33<4:31:02,  3.82s/it]2025-08-23:01:33:15,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7773/12032 [6:58:37<4:30:42,  3.81s/it]2025-08-23:01:33:18,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7774/12032 [6:58:40<4:30:43,  3.81s/it]2025-08-23:01:33:22,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7775/12032 [6:58:44<4:31:53,  3.83s/it]2025-08-23:01:33:26,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7776/12032 [6:58:48<4:31:46,  3.83s/it]2025-08-23:01:33:30,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7777/12032 [6:58:52<4:31:36,  3.83s/it]2025-08-23:01:33:34,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7778/12032 [6:58:56<4:33:13,  3.85s/it]2025-08-23:01:33:38,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7779/12032 [6:59:00<4:33:34,  3.86s/it]2025-08-23:01:33:41,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7780/12032 [6:59:04<4:34:50,  3.88s/it]2025-08-23:01:33:45,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7781/12032 [6:59:07<4:35:14,  3.88s/it]2025-08-23:01:33:49,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7782/12032 [6:59:11<4:35:08,  3.88s/it]2025-08-23:01:33:53,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7783/12032 [6:59:15<4:34:55,  3.88s/it]2025-08-23:01:33:57,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7784/12032 [6:59:19<4:35:15,  3.89s/it]2025-08-23:01:34:01,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7785/12032 [6:59:23<4:34:00,  3.87s/it]2025-08-23:01:34:05,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7786/12032 [6:59:27<4:34:05,  3.87s/it]2025-08-23:01:34:09,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7787/12032 [6:59:31<4:32:08,  3.85s/it]2025-08-23:01:34:12,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7788/12032 [6:59:34<4:31:55,  3.84s/it]2025-08-23:01:34:16,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7789/12032 [6:59:38<4:32:16,  3.85s/it]2025-08-23:01:34:20,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7790/12032 [6:59:42<4:31:47,  3.84s/it]2025-08-23:01:34:24,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7791/12032 [6:59:46<4:30:56,  3.83s/it]2025-08-23:01:34:28,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7792/12032 [6:59:50<4:30:11,  3.82s/it]2025-08-23:01:34:32,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7793/12032 [6:59:54<4:29:43,  3.82s/it]2025-08-23:01:34:35,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7794/12032 [6:59:58<4:34:41,  3.89s/it]2025-08-23:01:34:39,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7795/12032 [7:00:01<4:33:08,  3.87s/it]2025-08-23:01:34:43,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7796/12032 [7:00:05<4:30:52,  3.84s/it]2025-08-23:01:34:47,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7797/12032 [7:00:09<4:29:57,  3.82s/it]2025-08-23:01:34:51,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7798/12032 [7:00:13<4:28:44,  3.81s/it]2025-08-23:01:34:55,107 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7799/12032 [7:00:17<4:28:54,  3.81s/it]2025-08-23:01:34:58,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7800/12032 [7:00:20<4:29:57,  3.83s/it]2025-08-23:01:35:02,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7801/12032 [7:00:24<4:29:28,  3.82s/it]2025-08-23:01:35:06,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7802/12032 [7:00:28<4:29:07,  3.82s/it]2025-08-23:01:35:10,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7803/12032 [7:00:32<4:28:48,  3.81s/it]2025-08-23:01:35:14,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7804/12032 [7:00:34<3:53:13,  3.31s/it]2025-08-23:01:35:16,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7805/12032 [7:00:37<3:56:52,  3.36s/it]2025-08-23:01:35:19,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7806/12032 [7:00:41<3:54:36,  3.33s/it]2025-08-23:01:35:23,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7807/12032 [7:00:42<3:17:43,  2.81s/it]2025-08-23:01:35:24,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7808/12032 [7:00:45<3:08:58,  2.68s/it]2025-08-23:01:35:27,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7809/12032 [7:00:47<3:03:00,  2.60s/it]2025-08-23:01:35:29,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7810/12032 [7:00:51<3:28:59,  2.97s/it]2025-08-23:01:35:33,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7811/12032 [7:00:54<3:26:59,  2.94s/it]2025-08-23:01:35:36,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7812/12032 [7:00:57<3:31:04,  3.00s/it]2025-08-23:01:35:39,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7813/12032 [7:00:59<3:10:31,  2.71s/it]2025-08-23:01:35:41,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7814/12032 [7:01:03<3:33:35,  3.04s/it]2025-08-23:01:35:45,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7815/12032 [7:01:07<3:49:52,  3.27s/it]2025-08-23:01:35:48,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7816/12032 [7:01:10<4:00:37,  3.42s/it]2025-08-23:01:35:52,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7817/12032 [7:01:13<3:45:17,  3.21s/it]2025-08-23:01:35:55,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7818/12032 [7:01:14<3:06:01,  2.65s/it]2025-08-23:01:35:56,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7819/12032 [7:01:17<3:02:32,  2.60s/it]2025-08-23:01:35:59,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▍   | 7820/12032 [7:01:21<3:29:00,  2.98s/it]2025-08-23:01:36:03,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7821/12032 [7:01:24<3:30:46,  3.00s/it]2025-08-23:01:36:06,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7822/12032 [7:01:28<3:47:54,  3.25s/it]2025-08-23:01:36:10,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7823/12032 [7:01:30<3:34:05,  3.05s/it]2025-08-23:01:36:12,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7824/12032 [7:01:33<3:25:19,  2.93s/it]2025-08-23:01:36:15,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7825/12032 [7:01:37<3:45:24,  3.21s/it]2025-08-23:01:36:19,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7826/12032 [7:01:41<3:57:42,  3.39s/it]2025-08-23:01:36:22,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7827/12032 [7:01:44<3:51:17,  3.30s/it]2025-08-23:01:36:26,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7828/12032 [7:01:48<4:03:30,  3.48s/it]2025-08-23:01:36:29,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7829/12032 [7:01:51<3:52:11,  3.31s/it]2025-08-23:01:36:32,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7830/12032 [7:01:52<3:10:15,  2.72s/it]2025-08-23:01:36:34,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7831/12032 [7:01:56<3:34:21,  3.06s/it]2025-08-23:01:36:38,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7832/12032 [7:01:58<3:24:38,  2.92s/it]2025-08-23:01:36:40,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7833/12032 [7:02:01<3:13:35,  2.77s/it]2025-08-23:01:36:43,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7834/12032 [7:02:02<2:45:19,  2.36s/it]2025-08-23:01:36:44,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7835/12032 [7:02:05<2:50:29,  2.44s/it]2025-08-23:01:36:47,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7836/12032 [7:02:09<3:19:35,  2.85s/it]2025-08-23:01:36:50,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7837/12032 [7:02:12<3:34:43,  3.07s/it]2025-08-23:01:36:54,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7838/12032 [7:02:15<3:22:16,  2.89s/it]2025-08-23:01:36:56,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7839/12032 [7:02:18<3:40:47,  3.16s/it]2025-08-23:01:37:00,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7840/12032 [7:02:22<3:41:50,  3.18s/it]2025-08-23:01:37:03,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7841/12032 [7:02:25<3:54:28,  3.36s/it]2025-08-23:01:37:07,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7842/12032 [7:02:29<4:03:53,  3.49s/it]2025-08-23:01:37:11,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7843/12032 [7:02:33<4:10:40,  3.59s/it]2025-08-23:01:37:15,363 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7844/12032 [7:02:37<4:14:53,  3.65s/it]2025-08-23:01:37:19,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7845/12032 [7:02:41<4:17:47,  3.69s/it]2025-08-23:01:37:22,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7846/12032 [7:02:44<4:19:41,  3.72s/it]2025-08-23:01:37:26,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7847/12032 [7:02:47<3:48:17,  3.27s/it]2025-08-23:01:37:28,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7848/12032 [7:02:50<3:59:56,  3.44s/it]2025-08-23:01:37:32,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7849/12032 [7:02:54<4:07:16,  3.55s/it]2025-08-23:01:37:36,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7850/12032 [7:02:58<4:05:42,  3.53s/it]2025-08-23:01:37:40,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7851/12032 [7:03:01<3:51:19,  3.32s/it]2025-08-23:01:37:42,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7852/12032 [7:03:03<3:33:45,  3.07s/it]2025-08-23:01:37:45,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7853/12032 [7:03:07<3:49:08,  3.29s/it]2025-08-23:01:37:49,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7854/12032 [7:03:11<4:00:29,  3.45s/it]2025-08-23:01:37:53,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7855/12032 [7:03:14<4:07:32,  3.56s/it]2025-08-23:01:37:56,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7856/12032 [7:03:18<4:07:44,  3.56s/it]2025-08-23:01:38:00,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7857/12032 [7:03:22<4:12:09,  3.62s/it]2025-08-23:01:38:04,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7858/12032 [7:03:24<3:42:56,  3.20s/it]2025-08-23:01:38:06,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7859/12032 [7:03:26<3:21:44,  2.90s/it]2025-08-23:01:38:08,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7860/12032 [7:03:30<3:39:51,  3.16s/it]2025-08-23:01:38:12,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7861/12032 [7:03:34<3:53:27,  3.36s/it]2025-08-23:01:38:16,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7862/12032 [7:03:38<4:02:28,  3.49s/it]2025-08-23:01:38:19,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7863/12032 [7:03:41<4:09:08,  3.59s/it]2025-08-23:01:38:23,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7864/12032 [7:03:45<4:13:35,  3.65s/it]2025-08-23:01:38:27,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7865/12032 [7:03:49<4:17:05,  3.70s/it]2025-08-23:01:38:31,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7866/12032 [7:03:53<4:20:55,  3.76s/it]2025-08-23:01:38:35,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7867/12032 [7:03:57<4:22:32,  3.78s/it]2025-08-23:01:38:39,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7868/12032 [7:04:01<4:22:59,  3.79s/it]2025-08-23:01:38:42,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7869/12032 [7:04:03<4:02:22,  3.49s/it]2025-08-23:01:38:45,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7870/12032 [7:04:07<4:09:06,  3.59s/it]2025-08-23:01:38:49,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7871/12032 [7:04:11<4:14:17,  3.67s/it]2025-08-23:01:38:53,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7872/12032 [7:04:15<4:17:08,  3.71s/it]2025-08-23:01:38:57,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7873/12032 [7:04:19<4:18:51,  3.73s/it]2025-08-23:01:39:01,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7874/12032 [7:04:22<4:20:33,  3.76s/it]2025-08-23:01:39:04,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7875/12032 [7:04:26<4:21:19,  3.77s/it]2025-08-23:01:39:08,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7876/12032 [7:04:30<4:22:28,  3.79s/it]2025-08-23:01:39:12,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7877/12032 [7:04:34<4:17:11,  3.71s/it]2025-08-23:01:39:15,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7878/12032 [7:04:37<4:18:35,  3.74s/it]2025-08-23:01:39:19,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7879/12032 [7:04:41<4:19:51,  3.75s/it]2025-08-23:01:39:23,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  65%|██████▌   | 7880/12032 [7:04:45<4:20:44,  3.77s/it]2025-08-23:01:39:27,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7881/12032 [7:04:49<4:22:17,  3.79s/it]2025-08-23:01:39:31,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7882/12032 [7:04:52<4:11:03,  3.63s/it]2025-08-23:01:39:34,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7883/12032 [7:04:56<4:14:29,  3.68s/it]2025-08-23:01:39:38,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7884/12032 [7:05:00<4:16:29,  3.71s/it]2025-08-23:01:39:42,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7885/12032 [7:05:03<4:07:59,  3.59s/it]2025-08-23:01:39:45,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7886/12032 [7:05:07<4:12:46,  3.66s/it]2025-08-23:01:39:49,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7887/12032 [7:05:11<4:15:58,  3.71s/it]2025-08-23:01:39:52,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7888/12032 [7:05:14<4:17:50,  3.73s/it]2025-08-23:01:39:56,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7889/12032 [7:05:18<4:19:42,  3.76s/it]2025-08-23:01:40:00,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7890/12032 [7:05:22<4:20:06,  3.77s/it]2025-08-23:01:40:04,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7891/12032 [7:05:26<4:21:04,  3.78s/it]2025-08-23:01:40:08,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7892/12032 [7:05:30<4:21:45,  3.79s/it]2025-08-23:01:40:12,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7893/12032 [7:05:33<4:21:37,  3.79s/it]2025-08-23:01:40:15,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7894/12032 [7:05:37<4:22:00,  3.80s/it]2025-08-23:01:40:19,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7895/12032 [7:05:41<4:21:27,  3.79s/it]2025-08-23:01:40:23,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7896/12032 [7:05:45<4:22:19,  3.81s/it]2025-08-23:01:40:27,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7897/12032 [7:05:49<4:22:35,  3.81s/it]2025-08-23:01:40:31,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7898/12032 [7:05:53<4:22:01,  3.80s/it]2025-08-23:01:40:34,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7899/12032 [7:05:56<4:22:23,  3.81s/it]2025-08-23:01:40:38,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7900/12032 [7:06:00<4:22:05,  3.81s/it]2025-08-23:01:40:42,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7901/12032 [7:06:04<4:21:56,  3.80s/it]2025-08-23:01:40:46,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7902/12032 [7:06:08<4:21:57,  3.81s/it]2025-08-23:01:40:50,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7903/12032 [7:06:12<4:21:26,  3.80s/it]2025-08-23:01:40:53,871 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7904/12032 [7:06:15<4:21:30,  3.80s/it]2025-08-23:01:40:57,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7905/12032 [7:06:19<4:21:08,  3.80s/it]2025-08-23:01:41:01,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7906/12032 [7:06:22<4:04:49,  3.56s/it]2025-08-23:01:41:04,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7907/12032 [7:06:25<3:47:50,  3.31s/it]2025-08-23:01:41:07,211 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7908/12032 [7:06:28<3:53:57,  3.40s/it]2025-08-23:01:41:10,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7909/12032 [7:06:32<4:00:44,  3.50s/it]2025-08-23:01:41:14,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7910/12032 [7:06:34<3:35:22,  3.14s/it]2025-08-23:01:41:16,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7911/12032 [7:06:37<3:27:49,  3.03s/it]2025-08-23:01:41:19,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7912/12032 [7:06:41<3:44:09,  3.26s/it]2025-08-23:01:41:23,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7913/12032 [7:06:45<3:56:11,  3.44s/it]2025-08-23:01:41:27,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7914/12032 [7:06:49<4:04:59,  3.57s/it]2025-08-23:01:41:31,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7915/12032 [7:06:53<4:10:38,  3.65s/it]2025-08-23:01:41:34,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7916/12032 [7:06:56<4:13:59,  3.70s/it]2025-08-23:01:41:38,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7917/12032 [7:06:58<3:37:06,  3.17s/it]2025-08-23:01:41:40,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7918/12032 [7:07:02<3:47:14,  3.31s/it]2025-08-23:01:41:44,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7919/12032 [7:07:06<3:57:25,  3.46s/it]2025-08-23:01:41:48,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7920/12032 [7:07:09<3:44:38,  3.28s/it]2025-08-23:01:41:51,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7921/12032 [7:07:11<3:18:12,  2.89s/it]2025-08-23:01:41:53,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7922/12032 [7:07:13<2:57:22,  2.59s/it]2025-08-23:01:41:54,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7923/12032 [7:07:14<2:36:02,  2.28s/it]2025-08-23:01:41:56,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7924/12032 [7:07:16<2:30:30,  2.20s/it]2025-08-23:01:41:58,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7925/12032 [7:07:20<3:02:48,  2.67s/it]2025-08-23:01:42:02,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7926/12032 [7:07:22<2:47:14,  2.44s/it]2025-08-23:01:42:04,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7927/12032 [7:07:25<3:03:33,  2.68s/it]2025-08-23:01:42:07,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7928/12032 [7:07:27<2:54:39,  2.55s/it]2025-08-23:01:42:09,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7929/12032 [7:07:31<3:21:51,  2.95s/it]2025-08-23:01:42:13,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7930/12032 [7:07:33<2:53:52,  2.54s/it]2025-08-23:01:42:15,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7931/12032 [7:07:37<3:20:41,  2.94s/it]2025-08-23:01:42:18,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7932/12032 [7:07:38<2:50:47,  2.50s/it]2025-08-23:01:42:20,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7933/12032 [7:07:41<3:01:21,  2.65s/it]2025-08-23:01:42:23,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7934/12032 [7:07:45<3:26:37,  3.03s/it]2025-08-23:01:42:27,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7935/12032 [7:07:48<3:16:11,  2.87s/it]2025-08-23:01:42:29,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7936/12032 [7:07:51<3:35:16,  3.15s/it]2025-08-23:01:42:33,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7937/12032 [7:07:54<3:16:04,  2.87s/it]2025-08-23:01:42:35,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7938/12032 [7:07:57<3:34:59,  3.15s/it]2025-08-23:01:42:39,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7939/12032 [7:08:00<3:17:39,  2.90s/it]2025-08-23:01:42:42,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7940/12032 [7:08:04<3:37:04,  3.18s/it]2025-08-23:01:42:45,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7941/12032 [7:08:07<3:33:51,  3.14s/it]2025-08-23:01:42:48,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7942/12032 [7:08:10<3:44:38,  3.30s/it]2025-08-23:01:42:52,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7943/12032 [7:08:13<3:35:31,  3.16s/it]2025-08-23:01:42:55,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7944/12032 [7:08:17<3:49:14,  3.36s/it]2025-08-23:01:42:59,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7945/12032 [7:08:21<3:58:58,  3.51s/it]2025-08-23:01:43:03,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7946/12032 [7:08:25<4:09:22,  3.66s/it]2025-08-23:01:43:07,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7947/12032 [7:08:29<4:12:45,  3.71s/it]2025-08-23:01:43:10,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7948/12032 [7:08:32<4:15:05,  3.75s/it]2025-08-23:01:43:14,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7949/12032 [7:08:36<4:16:40,  3.77s/it]2025-08-23:01:43:18,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7950/12032 [7:08:40<4:18:17,  3.80s/it]2025-08-23:01:43:22,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7951/12032 [7:08:42<3:39:20,  3.22s/it]2025-08-23:01:43:24,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7952/12032 [7:08:46<3:51:19,  3.40s/it]2025-08-23:01:43:28,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7953/12032 [7:08:50<4:00:15,  3.53s/it]2025-08-23:01:43:32,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7954/12032 [7:08:54<4:06:25,  3.63s/it]2025-08-23:01:43:35,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7955/12032 [7:08:57<3:53:32,  3.44s/it]2025-08-23:01:43:38,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7956/12032 [7:09:00<4:01:56,  3.56s/it]2025-08-23:01:43:42,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7957/12032 [7:09:03<3:44:38,  3.31s/it]2025-08-23:01:43:45,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7958/12032 [7:09:07<3:55:50,  3.47s/it]2025-08-23:01:43:49,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7959/12032 [7:09:11<4:02:33,  3.57s/it]2025-08-23:01:43:53,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7960/12032 [7:09:14<4:05:11,  3.61s/it]2025-08-23:01:43:56,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7961/12032 [7:09:18<4:09:12,  3.67s/it]2025-08-23:01:44:00,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7962/12032 [7:09:22<4:12:48,  3.73s/it]2025-08-23:01:44:04,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7963/12032 [7:09:26<4:14:58,  3.76s/it]2025-08-23:01:44:08,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7964/12032 [7:09:29<4:04:12,  3.60s/it]2025-08-23:01:44:11,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7965/12032 [7:09:32<3:48:54,  3.38s/it]2025-08-23:01:44:14,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7966/12032 [7:09:34<3:15:01,  2.88s/it]2025-08-23:01:44:16,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7967/12032 [7:09:36<3:04:51,  2.73s/it]2025-08-23:01:44:18,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7968/12032 [7:09:40<3:27:14,  3.06s/it]2025-08-23:01:44:22,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7969/12032 [7:09:44<3:43:43,  3.30s/it]2025-08-23:01:44:26,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7970/12032 [7:09:48<3:54:32,  3.46s/it]2025-08-23:01:44:30,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▌   | 7971/12032 [7:09:52<4:03:14,  3.59s/it]2025-08-23:01:44:33,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7972/12032 [7:09:55<4:05:34,  3.63s/it]2025-08-23:01:44:37,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7973/12032 [7:09:59<4:10:01,  3.70s/it]2025-08-23:01:44:41,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7974/12032 [7:10:03<4:13:06,  3.74s/it]2025-08-23:01:44:45,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7975/12032 [7:10:07<4:14:51,  3.77s/it]2025-08-23:01:44:49,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7976/12032 [7:10:11<4:15:50,  3.78s/it]2025-08-23:01:44:52,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7977/12032 [7:10:15<4:19:21,  3.84s/it]2025-08-23:01:44:56,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7978/12032 [7:10:18<4:19:13,  3.84s/it]2025-08-23:01:45:00,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7979/12032 [7:10:22<4:19:06,  3.84s/it]2025-08-23:01:45:04,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7980/12032 [7:10:26<4:18:40,  3.83s/it]2025-08-23:01:45:08,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7981/12032 [7:10:30<4:18:37,  3.83s/it]2025-08-23:01:45:12,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7982/12032 [7:10:34<4:20:03,  3.85s/it]2025-08-23:01:45:16,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7983/12032 [7:10:37<4:14:21,  3.77s/it]2025-08-23:01:45:19,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7984/12032 [7:10:41<4:15:18,  3.78s/it]2025-08-23:01:45:23,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7985/12032 [7:10:45<4:17:38,  3.82s/it]2025-08-23:01:45:27,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7986/12032 [7:10:49<4:17:38,  3.82s/it]2025-08-23:01:45:31,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7987/12032 [7:10:53<4:17:25,  3.82s/it]2025-08-23:01:45:35,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7988/12032 [7:10:57<4:17:09,  3.82s/it]2025-08-23:01:45:38,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7989/12032 [7:11:00<4:17:23,  3.82s/it]2025-08-23:01:45:42,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7990/12032 [7:11:04<4:18:08,  3.83s/it]2025-08-23:01:45:46,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7991/12032 [7:11:08<4:17:53,  3.83s/it]2025-08-23:01:45:50,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7992/12032 [7:11:12<4:17:19,  3.82s/it]2025-08-23:01:45:54,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7993/12032 [7:11:16<4:16:16,  3.81s/it]2025-08-23:01:45:57,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7994/12032 [7:11:19<4:16:20,  3.81s/it]2025-08-23:01:46:01,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7995/12032 [7:11:23<4:16:25,  3.81s/it]2025-08-23:01:46:05,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7996/12032 [7:11:27<4:17:42,  3.83s/it]2025-08-23:01:46:09,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7997/12032 [7:11:31<4:19:31,  3.86s/it]2025-08-23:01:46:13,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7998/12032 [7:11:35<4:18:29,  3.84s/it]2025-08-23:01:46:17,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 7999/12032 [7:11:39<4:19:32,  3.86s/it]2025-08-23:01:46:21,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 8000/12032 [7:11:43<4:20:53,  3.88s/it]2025-08-23:01:46:25,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  66%|██████▋   | 8001/12032 [7:11:47<4:20:04,  3.87s/it]2025-08-23:01:46:28,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8002/12032 [7:11:50<4:18:58,  3.86s/it]2025-08-23:01:46:32,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8003/12032 [7:11:54<4:18:34,  3.85s/it]2025-08-23:01:46:36,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8004/12032 [7:11:58<4:18:11,  3.85s/it]2025-08-23:01:46:40,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8005/12032 [7:12:02<4:17:35,  3.84s/it]2025-08-23:01:46:44,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8006/12032 [7:12:06<4:18:36,  3.85s/it]2025-08-23:01:46:48,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8007/12032 [7:12:10<4:17:21,  3.84s/it]2025-08-23:01:46:51,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8008/12032 [7:12:14<4:20:53,  3.89s/it]2025-08-23:01:46:55,923 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8009/12032 [7:12:17<4:18:58,  3.86s/it]2025-08-23:01:46:59,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8010/12032 [7:12:21<4:17:36,  3.84s/it]2025-08-23:01:47:03,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8011/12032 [7:12:25<4:17:02,  3.84s/it]2025-08-23:01:47:07,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8012/12032 [7:12:29<4:17:10,  3.84s/it]2025-08-23:01:47:11,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8013/12032 [7:12:32<4:09:08,  3.72s/it]2025-08-23:01:47:14,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8014/12032 [7:12:35<3:42:41,  3.33s/it]2025-08-23:01:47:17,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8015/12032 [7:12:39<3:52:30,  3.47s/it]2025-08-23:01:47:20,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8016/12032 [7:12:42<3:59:26,  3.58s/it]2025-08-23:01:47:24,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8017/12032 [7:12:45<3:41:31,  3.31s/it]2025-08-23:01:47:27,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8018/12032 [7:12:48<3:30:16,  3.14s/it]2025-08-23:01:47:30,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8019/12032 [7:12:52<3:44:15,  3.35s/it]2025-08-23:01:47:33,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8020/12032 [7:12:54<3:32:57,  3.18s/it]2025-08-23:01:47:36,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8021/12032 [7:12:57<3:31:09,  3.16s/it]2025-08-23:01:47:39,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8022/12032 [7:13:01<3:44:46,  3.36s/it]2025-08-23:01:47:43,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8023/12032 [7:13:03<3:13:34,  2.90s/it]2025-08-23:01:47:45,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8024/12032 [7:13:05<2:46:07,  2.49s/it]2025-08-23:01:47:47,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8025/12032 [7:13:09<3:13:05,  2.89s/it]2025-08-23:01:47:50,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8026/12032 [7:13:12<3:31:16,  3.16s/it]2025-08-23:01:47:54,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8027/12032 [7:13:16<3:43:51,  3.35s/it]2025-08-23:01:47:58,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8028/12032 [7:13:18<3:21:10,  3.01s/it]2025-08-23:01:48:00,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8029/12032 [7:13:21<3:18:12,  2.97s/it]2025-08-23:01:48:03,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8030/12032 [7:13:24<3:11:29,  2.87s/it]2025-08-23:01:48:06,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8031/12032 [7:13:28<3:30:39,  3.16s/it]2025-08-23:01:48:10,015 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8032/12032 [7:13:30<3:05:15,  2.78s/it]2025-08-23:01:48:11,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8033/12032 [7:13:32<3:00:27,  2.71s/it]2025-08-23:01:48:14,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8034/12032 [7:13:34<2:48:37,  2.53s/it]2025-08-23:01:48:16,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8035/12032 [7:13:37<2:53:18,  2.60s/it]2025-08-23:01:48:19,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8036/12032 [7:13:39<2:38:58,  2.39s/it]2025-08-23:01:48:21,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8037/12032 [7:13:41<2:37:41,  2.37s/it]2025-08-23:01:48:23,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8038/12032 [7:13:45<3:05:54,  2.79s/it]2025-08-23:01:48:27,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8039/12032 [7:13:49<3:20:19,  3.01s/it]2025-08-23:01:48:30,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8040/12032 [7:13:51<3:04:19,  2.77s/it]2025-08-23:01:48:33,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8041/12032 [7:13:52<2:39:14,  2.39s/it]2025-08-23:01:48:34,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8042/12032 [7:13:54<2:32:08,  2.29s/it]2025-08-23:01:48:36,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8043/12032 [7:13:56<2:27:12,  2.21s/it]2025-08-23:01:48:38,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8044/12032 [7:14:00<3:00:19,  2.71s/it]2025-08-23:01:48:42,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8045/12032 [7:14:04<3:21:55,  3.04s/it]2025-08-23:01:48:46,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8046/12032 [7:14:08<3:35:08,  3.24s/it]2025-08-23:01:48:50,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8047/12032 [7:14:11<3:45:47,  3.40s/it]2025-08-23:01:48:53,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8048/12032 [7:14:14<3:34:36,  3.23s/it]2025-08-23:01:48:56,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8049/12032 [7:14:18<3:46:24,  3.41s/it]2025-08-23:01:49:00,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8050/12032 [7:14:22<3:54:20,  3.53s/it]2025-08-23:01:49:04,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8051/12032 [7:14:26<4:00:31,  3.63s/it]2025-08-23:01:49:08,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8052/12032 [7:14:30<4:04:28,  3.69s/it]2025-08-23:01:49:11,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8053/12032 [7:14:32<3:43:34,  3.37s/it]2025-08-23:01:49:14,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8054/12032 [7:14:36<3:51:02,  3.48s/it]2025-08-23:01:49:18,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8055/12032 [7:14:39<3:48:03,  3.44s/it]2025-08-23:01:49:21,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8056/12032 [7:14:41<3:20:59,  3.03s/it]2025-08-23:01:49:23,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8057/12032 [7:14:45<3:36:36,  3.27s/it]2025-08-23:01:49:27,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8058/12032 [7:14:48<3:31:17,  3.19s/it]2025-08-23:01:49:30,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8059/12032 [7:14:52<3:43:29,  3.38s/it]2025-08-23:01:49:34,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8060/12032 [7:14:56<3:52:16,  3.51s/it]2025-08-23:01:49:38,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8061/12032 [7:15:00<3:58:57,  3.61s/it]2025-08-23:01:49:42,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8062/12032 [7:15:03<3:52:56,  3.52s/it]2025-08-23:01:49:45,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8063/12032 [7:15:07<3:58:16,  3.60s/it]2025-08-23:01:49:49,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8064/12032 [7:15:11<4:02:45,  3.67s/it]2025-08-23:01:49:53,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8065/12032 [7:15:14<4:05:59,  3.72s/it]2025-08-23:01:49:56,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8066/12032 [7:15:17<3:45:16,  3.41s/it]2025-08-23:01:49:59,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8067/12032 [7:15:21<3:54:03,  3.54s/it]2025-08-23:01:50:03,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8068/12032 [7:15:24<3:38:30,  3.31s/it]2025-08-23:01:50:06,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8069/12032 [7:15:28<3:49:04,  3.47s/it]2025-08-23:01:50:09,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8070/12032 [7:15:32<3:57:17,  3.59s/it]2025-08-23:01:50:13,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8071/12032 [7:15:35<4:02:19,  3.67s/it]2025-08-23:01:50:17,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8072/12032 [7:15:39<4:06:10,  3.73s/it]2025-08-23:01:50:21,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8073/12032 [7:15:43<4:07:36,  3.75s/it]2025-08-23:01:50:25,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8074/12032 [7:15:47<4:08:24,  3.77s/it]2025-08-23:01:50:29,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8075/12032 [7:15:51<4:09:27,  3.78s/it]2025-08-23:01:50:33,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8076/12032 [7:15:55<4:11:08,  3.81s/it]2025-08-23:01:50:36,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8077/12032 [7:15:58<4:07:43,  3.76s/it]2025-08-23:01:50:40,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8078/12032 [7:16:02<4:09:00,  3.78s/it]2025-08-23:01:50:44,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8079/12032 [7:16:06<4:09:57,  3.79s/it]2025-08-23:01:50:48,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8080/12032 [7:16:10<4:10:05,  3.80s/it]2025-08-23:01:50:51,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8081/12032 [7:16:13<4:10:58,  3.81s/it]2025-08-23:01:50:55,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8082/12032 [7:16:17<4:11:48,  3.82s/it]2025-08-23:01:50:59,676 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8083/12032 [7:16:21<4:11:50,  3.83s/it]2025-08-23:01:51:03,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8084/12032 [7:16:25<4:12:00,  3.83s/it]2025-08-23:01:51:07,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8085/12032 [7:16:29<4:12:06,  3.83s/it]2025-08-23:01:51:11,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8086/12032 [7:16:33<4:11:53,  3.83s/it]2025-08-23:01:51:15,007 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8087/12032 [7:16:37<4:13:25,  3.85s/it]2025-08-23:01:51:18,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8088/12032 [7:16:40<4:12:59,  3.85s/it]2025-08-23:01:51:22,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8089/12032 [7:16:44<4:10:18,  3.81s/it]2025-08-23:01:51:26,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8090/12032 [7:16:46<3:37:36,  3.31s/it]2025-08-23:01:51:28,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8091/12032 [7:16:50<3:47:50,  3.47s/it]2025-08-23:01:51:32,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8092/12032 [7:16:54<3:55:23,  3.58s/it]2025-08-23:01:51:36,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8093/12032 [7:16:58<4:00:38,  3.67s/it]2025-08-23:01:51:40,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8094/12032 [7:17:02<4:03:21,  3.71s/it]2025-08-23:01:51:43,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8095/12032 [7:17:05<4:05:45,  3.75s/it]2025-08-23:01:51:47,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8096/12032 [7:17:09<4:07:42,  3.78s/it]2025-08-23:01:51:51,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8097/12032 [7:17:13<4:10:32,  3.82s/it]2025-08-23:01:51:55,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8098/12032 [7:17:17<4:10:25,  3.82s/it]2025-08-23:01:51:59,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8099/12032 [7:17:21<4:10:27,  3.82s/it]2025-08-23:01:52:03,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8100/12032 [7:17:23<3:40:16,  3.36s/it]2025-08-23:01:52:05,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8101/12032 [7:17:27<3:49:19,  3.50s/it]2025-08-23:01:52:09,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8102/12032 [7:17:31<3:55:44,  3.60s/it]2025-08-23:01:52:13,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8103/12032 [7:17:35<3:59:36,  3.66s/it]2025-08-23:01:52:16,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8104/12032 [7:17:38<4:02:51,  3.71s/it]2025-08-23:01:52:20,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8105/12032 [7:17:42<4:06:52,  3.77s/it]2025-08-23:01:52:24,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8106/12032 [7:17:46<4:08:05,  3.79s/it]2025-08-23:01:52:28,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8107/12032 [7:17:50<4:09:01,  3.81s/it]2025-08-23:01:52:32,385 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8108/12032 [7:17:54<4:09:05,  3.81s/it]2025-08-23:01:52:36,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8109/12032 [7:17:58<4:09:44,  3.82s/it]2025-08-23:01:52:40,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8110/12032 [7:18:02<4:10:13,  3.83s/it]2025-08-23:01:52:43,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8111/12032 [7:18:05<4:09:52,  3.82s/it]2025-08-23:01:52:47,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8112/12032 [7:18:09<4:09:53,  3.82s/it]2025-08-23:01:52:51,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8113/12032 [7:18:13<4:10:20,  3.83s/it]2025-08-23:01:52:55,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8114/12032 [7:18:17<4:10:01,  3.83s/it]2025-08-23:01:52:59,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8115/12032 [7:18:21<4:09:55,  3.83s/it]2025-08-23:01:53:03,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8116/12032 [7:18:24<4:09:16,  3.82s/it]2025-08-23:01:53:06,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8117/12032 [7:18:28<4:08:55,  3.81s/it]2025-08-23:01:53:10,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8118/12032 [7:18:32<4:08:35,  3.81s/it]2025-08-23:01:53:14,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8119/12032 [7:18:36<4:08:59,  3.82s/it]2025-08-23:01:53:18,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8120/12032 [7:18:39<3:48:33,  3.51s/it]2025-08-23:01:53:21,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  67%|██████▋   | 8121/12032 [7:18:43<3:56:28,  3.63s/it]2025-08-23:01:53:24,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8122/12032 [7:18:46<3:59:49,  3.68s/it]2025-08-23:01:53:28,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8123/12032 [7:18:48<3:27:42,  3.19s/it]2025-08-23:01:53:30,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8124/12032 [7:18:52<3:40:35,  3.39s/it]2025-08-23:01:53:34,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8125/12032 [7:18:55<3:25:40,  3.16s/it]2025-08-23:01:53:37,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8126/12032 [7:18:59<3:38:40,  3.36s/it]2025-08-23:01:53:41,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8127/12032 [7:19:02<3:38:43,  3.36s/it]2025-08-23:01:53:44,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8128/12032 [7:19:06<3:48:00,  3.50s/it]2025-08-23:01:53:48,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8129/12032 [7:19:10<3:54:37,  3.61s/it]2025-08-23:01:53:52,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8130/12032 [7:19:12<3:33:56,  3.29s/it]2025-08-23:01:53:54,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8131/12032 [7:19:16<3:44:10,  3.45s/it]2025-08-23:01:53:58,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8132/12032 [7:19:20<3:51:40,  3.56s/it]2025-08-23:01:54:02,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8133/12032 [7:19:24<3:57:24,  3.65s/it]2025-08-23:01:54:06,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8134/12032 [7:19:26<3:32:16,  3.27s/it]2025-08-23:01:54:08,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8135/12032 [7:19:28<3:10:36,  2.93s/it]2025-08-23:01:54:10,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8136/12032 [7:19:32<3:14:52,  3.00s/it]2025-08-23:01:54:13,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8137/12032 [7:19:35<3:15:11,  3.01s/it]2025-08-23:01:54:16,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8138/12032 [7:19:38<3:31:51,  3.26s/it]2025-08-23:01:54:20,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8139/12032 [7:19:40<3:04:55,  2.85s/it]2025-08-23:01:54:22,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8140/12032 [7:19:44<3:24:16,  3.15s/it]2025-08-23:01:54:26,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8141/12032 [7:19:48<3:37:05,  3.35s/it]2025-08-23:01:54:30,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8142/12032 [7:19:52<3:45:49,  3.48s/it]2025-08-23:01:54:34,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8143/12032 [7:19:56<3:53:11,  3.60s/it]2025-08-23:01:54:37,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8144/12032 [7:20:00<3:59:02,  3.69s/it]2025-08-23:01:54:41,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8145/12032 [7:20:02<3:43:11,  3.45s/it]2025-08-23:01:54:44,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8146/12032 [7:20:06<3:51:17,  3.57s/it]2025-08-23:01:54:48,634 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8147/12032 [7:20:09<3:41:28,  3.42s/it]2025-08-23:01:54:51,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8148/12032 [7:20:13<3:49:23,  3.54s/it]2025-08-23:01:54:55,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8149/12032 [7:20:17<3:54:57,  3.63s/it]2025-08-23:01:54:59,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8150/12032 [7:20:21<3:58:07,  3.68s/it]2025-08-23:01:55:03,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8151/12032 [7:20:22<3:14:39,  3.01s/it]2025-08-23:01:55:04,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8152/12032 [7:20:26<3:21:35,  3.12s/it]2025-08-23:01:55:07,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8153/12032 [7:20:28<3:14:55,  3.02s/it]2025-08-23:01:55:10,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8154/12032 [7:20:32<3:19:59,  3.09s/it]2025-08-23:01:55:14,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8155/12032 [7:20:33<2:47:37,  2.59s/it]2025-08-23:01:55:15,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8156/12032 [7:20:37<3:03:23,  2.84s/it]2025-08-23:01:55:18,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8157/12032 [7:20:38<2:44:03,  2.54s/it]2025-08-23:01:55:20,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8158/12032 [7:20:42<3:10:54,  2.96s/it]2025-08-23:01:55:24,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8159/12032 [7:20:46<3:27:23,  3.21s/it]2025-08-23:01:55:28,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8160/12032 [7:20:48<2:54:33,  2.70s/it]2025-08-23:01:55:29,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8161/12032 [7:20:49<2:30:18,  2.33s/it]2025-08-23:01:55:31,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8162/12032 [7:20:53<2:59:16,  2.78s/it]2025-08-23:01:55:35,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8163/12032 [7:20:57<3:19:11,  3.09s/it]2025-08-23:01:55:39,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8164/12032 [7:21:00<3:16:19,  3.05s/it]2025-08-23:01:55:42,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8165/12032 [7:21:02<2:57:44,  2.76s/it]2025-08-23:01:55:44,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8166/12032 [7:21:06<3:17:56,  3.07s/it]2025-08-23:01:55:47,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8167/12032 [7:21:08<3:03:23,  2.85s/it]2025-08-23:01:55:50,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8168/12032 [7:21:09<2:38:29,  2.46s/it]2025-08-23:01:55:51,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8169/12032 [7:21:12<2:32:42,  2.37s/it]2025-08-23:01:55:53,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8170/12032 [7:21:14<2:26:11,  2.27s/it]2025-08-23:01:55:55,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8171/12032 [7:21:17<2:56:27,  2.74s/it]2025-08-23:01:55:59,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8172/12032 [7:21:19<2:23:37,  2.23s/it]2025-08-23:01:56:00,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8173/12032 [7:21:21<2:33:17,  2.38s/it]2025-08-23:01:56:03,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8174/12032 [7:21:24<2:46:40,  2.59s/it]2025-08-23:01:56:06,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8175/12032 [7:21:27<2:53:48,  2.70s/it]2025-08-23:01:56:09,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8176/12032 [7:21:31<3:15:23,  3.04s/it]2025-08-23:01:56:13,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8177/12032 [7:21:35<3:29:54,  3.27s/it]2025-08-23:01:56:17,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8178/12032 [7:21:38<3:20:27,  3.12s/it]2025-08-23:01:56:20,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8179/12032 [7:21:42<3:34:32,  3.34s/it]2025-08-23:01:56:23,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8180/12032 [7:21:45<3:44:19,  3.49s/it]2025-08-23:01:56:27,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8181/12032 [7:21:49<3:50:37,  3.59s/it]2025-08-23:01:56:31,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8182/12032 [7:21:53<3:54:59,  3.66s/it]2025-08-23:01:56:35,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8183/12032 [7:21:57<3:57:52,  3.71s/it]2025-08-23:01:56:39,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8184/12032 [7:22:01<4:00:46,  3.75s/it]2025-08-23:01:56:43,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8185/12032 [7:22:05<4:02:40,  3.78s/it]2025-08-23:01:56:46,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8186/12032 [7:22:08<4:03:23,  3.80s/it]2025-08-23:01:56:50,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8187/12032 [7:22:12<4:04:58,  3.82s/it]2025-08-23:01:56:54,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8188/12032 [7:22:16<4:04:35,  3.82s/it]2025-08-23:01:56:58,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8189/12032 [7:22:20<4:05:17,  3.83s/it]2025-08-23:01:57:02,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8190/12032 [7:22:23<3:54:08,  3.66s/it]2025-08-23:01:57:05,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8191/12032 [7:22:27<3:57:03,  3.70s/it]2025-08-23:01:57:09,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8192/12032 [7:22:31<3:59:33,  3.74s/it]2025-08-23:01:57:13,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8193/12032 [7:22:35<4:00:44,  3.76s/it]2025-08-23:01:57:17,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8194/12032 [7:22:39<4:02:19,  3.79s/it]2025-08-23:01:57:20,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8195/12032 [7:22:42<4:03:58,  3.82s/it]2025-08-23:01:57:24,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8196/12032 [7:22:46<4:08:59,  3.89s/it]2025-08-23:01:57:28,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8197/12032 [7:22:50<4:09:41,  3.91s/it]2025-08-23:01:57:32,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8198/12032 [7:22:54<4:07:43,  3.88s/it]2025-08-23:01:57:36,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8199/12032 [7:22:58<4:06:15,  3.85s/it]2025-08-23:01:57:40,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8200/12032 [7:23:02<4:05:53,  3.85s/it]2025-08-23:01:57:44,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8201/12032 [7:23:06<4:04:37,  3.83s/it]2025-08-23:01:57:47,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8202/12032 [7:23:09<4:04:12,  3.83s/it]2025-08-23:01:57:51,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8203/12032 [7:23:13<4:03:55,  3.82s/it]2025-08-23:01:57:55,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8204/12032 [7:23:17<4:04:06,  3.83s/it]2025-08-23:01:57:59,456 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8205/12032 [7:23:21<4:04:25,  3.83s/it]2025-08-23:01:58:03,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8206/12032 [7:23:25<4:04:32,  3.84s/it]2025-08-23:01:58:07,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8207/12032 [7:23:29<4:03:27,  3.82s/it]2025-08-23:01:58:10,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8208/12032 [7:23:32<4:02:34,  3.81s/it]2025-08-23:01:58:14,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8209/12032 [7:23:36<4:02:40,  3.81s/it]2025-08-23:01:58:18,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8210/12032 [7:23:40<4:09:11,  3.91s/it]2025-08-23:01:58:22,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8211/12032 [7:23:44<4:08:52,  3.91s/it]2025-08-23:01:58:26,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8212/12032 [7:23:48<4:08:09,  3.90s/it]2025-08-23:01:58:30,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8213/12032 [7:23:52<4:05:59,  3.86s/it]2025-08-23:01:58:34,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8214/12032 [7:23:56<4:05:12,  3.85s/it]2025-08-23:01:58:38,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8215/12032 [7:24:00<4:04:18,  3.84s/it]2025-08-23:01:58:41,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8216/12032 [7:24:03<4:03:25,  3.83s/it]2025-08-23:01:58:45,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8217/12032 [7:24:07<4:02:55,  3.82s/it]2025-08-23:01:58:49,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8218/12032 [7:24:11<4:02:15,  3.81s/it]2025-08-23:01:58:53,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8219/12032 [7:24:15<4:02:02,  3.81s/it]2025-08-23:01:58:57,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8220/12032 [7:24:19<4:01:45,  3.81s/it]2025-08-23:01:59:00,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8221/12032 [7:24:22<4:01:12,  3.80s/it]2025-08-23:01:59:04,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8222/12032 [7:24:26<4:01:22,  3.80s/it]2025-08-23:01:59:08,446 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8223/12032 [7:24:30<4:01:08,  3.80s/it]2025-08-23:01:59:12,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8224/12032 [7:24:34<4:01:06,  3.80s/it]2025-08-23:01:59:16,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8225/12032 [7:24:37<4:01:00,  3.80s/it]2025-08-23:01:59:19,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8226/12032 [7:24:39<3:14:54,  3.07s/it]2025-08-23:01:59:21,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8227/12032 [7:24:43<3:28:18,  3.28s/it]2025-08-23:01:59:24,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8228/12032 [7:24:46<3:38:09,  3.44s/it]2025-08-23:01:59:28,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8229/12032 [7:24:50<3:45:20,  3.56s/it]2025-08-23:01:59:32,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8230/12032 [7:24:54<3:50:05,  3.63s/it]2025-08-23:01:59:36,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8231/12032 [7:24:56<3:24:10,  3.22s/it]2025-08-23:01:59:38,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8232/12032 [7:25:00<3:35:46,  3.41s/it]2025-08-23:01:59:42,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8233/12032 [7:25:04<3:43:03,  3.52s/it]2025-08-23:01:59:46,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8234/12032 [7:25:08<3:49:38,  3.63s/it]2025-08-23:01:59:50,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8235/12032 [7:25:12<3:54:16,  3.70s/it]2025-08-23:01:59:54,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8236/12032 [7:25:16<3:57:43,  3.76s/it]2025-08-23:01:59:57,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8237/12032 [7:25:20<4:03:04,  3.84s/it]2025-08-23:02:00:02,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8238/12032 [7:25:24<4:06:56,  3.91s/it]2025-08-23:02:00:06,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8239/12032 [7:25:28<4:10:29,  3.96s/it]2025-08-23:02:00:10,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8240/12032 [7:25:32<4:12:06,  3.99s/it]2025-08-23:02:00:14,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  68%|██████▊   | 8241/12032 [7:25:36<4:13:27,  4.01s/it]2025-08-23:02:00:18,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8242/12032 [7:25:40<4:13:21,  4.01s/it]2025-08-23:02:00:22,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8243/12032 [7:25:44<4:15:02,  4.04s/it]2025-08-23:02:00:26,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8244/12032 [7:25:48<4:15:45,  4.05s/it]2025-08-23:02:00:30,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8245/12032 [7:25:52<4:16:35,  4.07s/it]2025-08-23:02:00:34,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8246/12032 [7:25:56<4:15:55,  4.06s/it]2025-08-23:02:00:38,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8247/12032 [7:26:00<4:16:04,  4.06s/it]2025-08-23:02:00:42,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8248/12032 [7:26:04<4:11:24,  3.99s/it]2025-08-23:02:00:46,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8249/12032 [7:26:07<3:54:46,  3.72s/it]2025-08-23:02:00:49,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8250/12032 [7:26:09<3:10:49,  3.03s/it]2025-08-23:02:00:50,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8251/12032 [7:26:11<2:59:17,  2.85s/it]2025-08-23:02:00:53,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8252/12032 [7:26:15<3:17:27,  3.13s/it]2025-08-23:02:00:57,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8253/12032 [7:26:17<3:04:36,  2.93s/it]2025-08-23:02:00:59,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8254/12032 [7:26:19<2:40:43,  2.55s/it]2025-08-23:02:01:01,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8255/12032 [7:26:22<2:52:09,  2.73s/it]2025-08-23:02:01:04,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8256/12032 [7:26:25<2:46:56,  2.65s/it]2025-08-23:02:01:06,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8257/12032 [7:26:28<3:08:45,  3.00s/it]2025-08-23:02:01:10,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8258/12032 [7:26:30<2:39:13,  2.53s/it]2025-08-23:02:01:12,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8259/12032 [7:26:33<2:45:52,  2.64s/it]2025-08-23:02:01:15,102 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8260/12032 [7:26:34<2:24:00,  2.29s/it]2025-08-23:02:01:16,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8261/12032 [7:26:37<2:27:47,  2.35s/it]2025-08-23:02:01:19,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8262/12032 [7:26:39<2:27:38,  2.35s/it]2025-08-23:02:01:21,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8263/12032 [7:26:41<2:24:12,  2.30s/it]2025-08-23:02:01:23,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8264/12032 [7:26:45<2:52:47,  2.75s/it]2025-08-23:02:01:27,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8265/12032 [7:26:47<2:35:16,  2.47s/it]2025-08-23:02:01:29,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8266/12032 [7:26:50<2:43:48,  2.61s/it]2025-08-23:02:01:32,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8267/12032 [7:26:54<3:07:07,  2.98s/it]2025-08-23:02:01:36,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8268/12032 [7:26:57<3:09:10,  3.02s/it]2025-08-23:02:01:39,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8269/12032 [7:27:00<3:11:38,  3.06s/it]2025-08-23:02:01:42,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8270/12032 [7:27:02<2:50:14,  2.72s/it]2025-08-23:02:01:44,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▊   | 8271/12032 [7:27:03<2:29:41,  2.39s/it]2025-08-23:02:01:45,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8272/12032 [7:27:06<2:23:30,  2.29s/it]2025-08-23:02:01:47,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8273/12032 [7:27:07<2:09:44,  2.07s/it]2025-08-23:02:01:49,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8274/12032 [7:27:10<2:23:36,  2.29s/it]2025-08-23:02:01:52,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8275/12032 [7:27:14<2:52:35,  2.76s/it]2025-08-23:02:01:56,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8276/12032 [7:27:18<3:13:45,  3.10s/it]2025-08-23:02:01:59,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8277/12032 [7:27:21<3:27:37,  3.32s/it]2025-08-23:02:02:03,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8278/12032 [7:27:25<3:37:40,  3.48s/it]2025-08-23:02:02:07,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8279/12032 [7:27:29<3:43:37,  3.58s/it]2025-08-23:02:02:11,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8280/12032 [7:27:33<3:48:26,  3.65s/it]2025-08-23:02:02:15,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8281/12032 [7:27:37<3:52:10,  3.71s/it]2025-08-23:02:02:19,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8282/12032 [7:27:41<3:55:17,  3.76s/it]2025-08-23:02:02:23,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8283/12032 [7:27:44<3:55:32,  3.77s/it]2025-08-23:02:02:26,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8284/12032 [7:27:48<3:55:59,  3.78s/it]2025-08-23:02:02:30,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8285/12032 [7:27:52<3:56:26,  3.79s/it]2025-08-23:02:02:34,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8286/12032 [7:27:55<3:34:53,  3.44s/it]2025-08-23:02:02:37,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8287/12032 [7:27:59<3:41:36,  3.55s/it]2025-08-23:02:02:40,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8288/12032 [7:28:02<3:45:53,  3.62s/it]2025-08-23:02:02:44,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8289/12032 [7:28:04<3:16:43,  3.15s/it]2025-08-23:02:02:46,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8290/12032 [7:28:07<3:13:11,  3.10s/it]2025-08-23:02:02:49,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8291/12032 [7:28:10<3:12:51,  3.09s/it]2025-08-23:02:02:52,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8292/12032 [7:28:14<3:25:49,  3.30s/it]2025-08-23:02:02:56,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8293/12032 [7:28:18<3:39:44,  3.53s/it]2025-08-23:02:03:00,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8294/12032 [7:28:22<3:38:07,  3.50s/it]2025-08-23:02:03:04,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8295/12032 [7:28:26<3:48:38,  3.67s/it]2025-08-23:02:03:08,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8296/12032 [7:28:30<3:55:26,  3.78s/it]2025-08-23:02:03:12,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8297/12032 [7:28:34<4:02:10,  3.89s/it]2025-08-23:02:03:16,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8298/12032 [7:28:38<4:03:47,  3.92s/it]2025-08-23:02:03:20,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8299/12032 [7:28:42<4:07:45,  3.98s/it]2025-08-23:02:03:24,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8300/12032 [7:28:46<4:08:10,  3.99s/it]2025-08-23:02:03:28,397 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8301/12032 [7:28:50<4:09:12,  4.01s/it]2025-08-23:02:03:32,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8302/12032 [7:28:54<4:05:17,  3.95s/it]2025-08-23:02:03:36,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8303/12032 [7:28:58<4:02:37,  3.90s/it]2025-08-23:02:03:40,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8304/12032 [7:29:01<4:00:11,  3.87s/it]2025-08-23:02:03:43,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8305/12032 [7:29:05<3:58:46,  3.84s/it]2025-08-23:02:03:47,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8306/12032 [7:29:09<3:58:06,  3.83s/it]2025-08-23:02:03:51,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8307/12032 [7:29:13<3:57:54,  3.83s/it]2025-08-23:02:03:55,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8308/12032 [7:29:17<3:57:01,  3.82s/it]2025-08-23:02:03:59,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8309/12032 [7:29:21<3:57:13,  3.82s/it]2025-08-23:02:04:02,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8310/12032 [7:29:24<3:56:47,  3.82s/it]2025-08-23:02:04:06,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8311/12032 [7:29:28<3:57:40,  3.83s/it]2025-08-23:02:04:10,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8312/12032 [7:29:32<3:57:13,  3.83s/it]2025-08-23:02:04:14,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8313/12032 [7:29:36<3:57:04,  3.82s/it]2025-08-23:02:04:18,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8314/12032 [7:29:40<3:58:23,  3.85s/it]2025-08-23:02:04:22,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8315/12032 [7:29:44<3:57:48,  3.84s/it]2025-08-23:02:04:25,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8316/12032 [7:29:47<3:56:30,  3.82s/it]2025-08-23:02:04:29,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8317/12032 [7:29:51<3:56:23,  3.82s/it]2025-08-23:02:04:33,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8318/12032 [7:29:55<3:56:20,  3.82s/it]2025-08-23:02:04:37,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8319/12032 [7:29:59<3:56:22,  3.82s/it]2025-08-23:02:04:41,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8320/12032 [7:30:03<3:55:56,  3.81s/it]2025-08-23:02:04:44,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8321/12032 [7:30:06<3:55:33,  3.81s/it]2025-08-23:02:04:48,731 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8322/12032 [7:30:10<3:55:43,  3.81s/it]2025-08-23:02:04:52,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8323/12032 [7:30:14<3:55:07,  3.80s/it]2025-08-23:02:04:56,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8324/12032 [7:30:18<3:54:31,  3.79s/it]2025-08-23:02:05:00,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8325/12032 [7:30:21<3:45:38,  3.65s/it]2025-08-23:02:05:03,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8326/12032 [7:30:25<3:48:24,  3.70s/it]2025-08-23:02:05:07,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8327/12032 [7:30:29<3:49:45,  3.72s/it]2025-08-23:02:05:11,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8328/12032 [7:30:32<3:50:34,  3.74s/it]2025-08-23:02:05:14,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8329/12032 [7:30:36<3:52:53,  3.77s/it]2025-08-23:02:05:18,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8330/12032 [7:30:39<3:36:13,  3.50s/it]2025-08-23:02:05:21,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8331/12032 [7:30:43<3:42:22,  3.61s/it]2025-08-23:02:05:25,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8332/12032 [7:30:47<3:45:54,  3.66s/it]2025-08-23:02:05:29,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8333/12032 [7:30:51<3:48:14,  3.70s/it]2025-08-23:02:05:32,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8334/12032 [7:30:54<3:50:32,  3.74s/it]2025-08-23:02:05:36,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8335/12032 [7:30:57<3:26:03,  3.34s/it]2025-08-23:02:05:39,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8336/12032 [7:31:01<3:35:11,  3.49s/it]2025-08-23:02:05:43,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8337/12032 [7:31:05<3:41:11,  3.59s/it]2025-08-23:02:05:46,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8338/12032 [7:31:08<3:45:11,  3.66s/it]2025-08-23:02:05:50,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8339/12032 [7:31:12<3:47:52,  3.70s/it]2025-08-23:02:05:54,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8340/12032 [7:31:16<3:45:28,  3.66s/it]2025-08-23:02:05:58,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8341/12032 [7:31:19<3:37:27,  3.53s/it]2025-08-23:02:06:01,288 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8342/12032 [7:31:22<3:24:00,  3.32s/it]2025-08-23:02:06:04,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8343/12032 [7:31:26<3:33:06,  3.47s/it]2025-08-23:02:06:07,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8344/12032 [7:31:29<3:33:18,  3.47s/it]2025-08-23:02:06:11,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8345/12032 [7:31:33<3:41:37,  3.61s/it]2025-08-23:02:06:15,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8346/12032 [7:31:36<3:30:47,  3.43s/it]2025-08-23:02:06:18,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8347/12032 [7:31:40<3:37:47,  3.55s/it]2025-08-23:02:06:22,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8348/12032 [7:31:43<3:34:33,  3.49s/it]2025-08-23:02:06:25,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8349/12032 [7:31:47<3:40:13,  3.59s/it]2025-08-23:02:06:29,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8350/12032 [7:31:49<3:12:26,  3.14s/it]2025-08-23:02:06:31,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8351/12032 [7:31:53<3:25:59,  3.36s/it]2025-08-23:02:06:35,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8352/12032 [7:31:57<3:35:06,  3.51s/it]2025-08-23:02:06:39,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8353/12032 [7:32:01<3:40:13,  3.59s/it]2025-08-23:02:06:42,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8354/12032 [7:32:04<3:43:23,  3.64s/it]2025-08-23:02:06:46,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8355/12032 [7:32:08<3:46:53,  3.70s/it]2025-08-23:02:06:50,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8356/12032 [7:32:11<3:21:25,  3.29s/it]2025-08-23:02:06:52,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8357/12032 [7:32:12<2:47:52,  2.74s/it]2025-08-23:02:06:54,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8358/12032 [7:32:14<2:41:40,  2.64s/it]2025-08-23:02:06:56,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8359/12032 [7:32:17<2:34:04,  2.52s/it]2025-08-23:02:06:58,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8360/12032 [7:32:20<2:58:08,  2.91s/it]2025-08-23:02:07:02,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8361/12032 [7:32:22<2:39:04,  2.60s/it]2025-08-23:02:07:04,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  69%|██████▉   | 8362/12032 [7:32:25<2:37:09,  2.57s/it]2025-08-23:02:07:07,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8363/12032 [7:32:27<2:36:15,  2.56s/it]2025-08-23:02:07:09,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8364/12032 [7:32:30<2:45:08,  2.70s/it]2025-08-23:02:07:12,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8365/12032 [7:32:33<2:42:29,  2.66s/it]2025-08-23:02:07:15,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8366/12032 [7:32:36<2:58:07,  2.92s/it]2025-08-23:02:07:18,797 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8367/12032 [7:32:39<2:49:10,  2.77s/it]2025-08-23:02:07:21,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8368/12032 [7:32:42<2:49:07,  2.77s/it]2025-08-23:02:07:23,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8369/12032 [7:32:44<2:49:33,  2.78s/it]2025-08-23:02:07:26,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8370/12032 [7:32:48<3:08:30,  3.09s/it]2025-08-23:02:07:30,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8371/12032 [7:32:52<3:14:26,  3.19s/it]2025-08-23:02:07:34,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8372/12032 [7:32:54<3:03:07,  3.00s/it]2025-08-23:02:07:36,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8373/12032 [7:32:56<2:36:15,  2.56s/it]2025-08-23:02:07:38,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8374/12032 [7:32:57<2:07:50,  2.10s/it]2025-08-23:02:07:39,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8375/12032 [7:32:59<2:17:03,  2.25s/it]2025-08-23:02:07:41,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8376/12032 [7:33:03<2:45:08,  2.71s/it]2025-08-23:02:07:45,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8377/12032 [7:33:05<2:33:47,  2.52s/it]2025-08-23:02:07:47,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8378/12032 [7:33:08<2:36:53,  2.58s/it]2025-08-23:02:07:50,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8379/12032 [7:33:10<2:25:14,  2.39s/it]2025-08-23:02:07:52,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8380/12032 [7:33:12<2:22:33,  2.34s/it]2025-08-23:02:07:54,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8381/12032 [7:33:15<2:27:12,  2.42s/it]2025-08-23:02:07:57,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8382/12032 [7:33:18<2:46:58,  2.74s/it]2025-08-23:02:08:00,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8383/12032 [7:33:22<3:07:21,  3.08s/it]2025-08-23:02:08:04,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8384/12032 [7:33:26<3:20:26,  3.30s/it]2025-08-23:02:08:08,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8385/12032 [7:33:30<3:29:06,  3.44s/it]2025-08-23:02:08:12,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8386/12032 [7:33:33<3:35:03,  3.54s/it]2025-08-23:02:08:15,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8387/12032 [7:33:37<3:39:29,  3.61s/it]2025-08-23:02:08:19,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8388/12032 [7:33:41<3:43:37,  3.68s/it]2025-08-23:02:08:23,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8389/12032 [7:33:44<3:23:09,  3.35s/it]2025-08-23:02:08:26,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8390/12032 [7:33:47<3:27:03,  3.41s/it]2025-08-23:02:08:29,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8391/12032 [7:33:51<3:33:42,  3.52s/it]2025-08-23:02:08:33,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8392/12032 [7:33:55<3:38:36,  3.60s/it]2025-08-23:02:08:37,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8393/12032 [7:33:59<3:42:11,  3.66s/it]2025-08-23:02:08:40,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8394/12032 [7:34:02<3:44:55,  3.71s/it]2025-08-23:02:08:44,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8395/12032 [7:34:06<3:48:05,  3.76s/it]2025-08-23:02:08:48,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8396/12032 [7:34:10<3:49:08,  3.78s/it]2025-08-23:02:08:52,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8397/12032 [7:34:14<3:49:58,  3.80s/it]2025-08-23:02:08:56,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8398/12032 [7:34:18<3:50:39,  3.81s/it]2025-08-23:02:09:00,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8399/12032 [7:34:22<3:51:36,  3.83s/it]2025-08-23:02:09:04,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8400/12032 [7:34:25<3:51:26,  3.82s/it]2025-08-23:02:09:07,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8401/12032 [7:34:29<3:51:21,  3.82s/it]2025-08-23:02:09:11,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8402/12032 [7:34:32<3:28:09,  3.44s/it]2025-08-23:02:09:14,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8403/12032 [7:34:36<3:34:45,  3.55s/it]2025-08-23:02:09:18,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8404/12032 [7:34:40<3:42:24,  3.68s/it]2025-08-23:02:09:21,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8405/12032 [7:34:43<3:45:13,  3.73s/it]2025-08-23:02:09:25,815 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8406/12032 [7:34:47<3:48:39,  3.78s/it]2025-08-23:02:09:29,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8407/12032 [7:34:51<3:49:07,  3.79s/it]2025-08-23:02:09:33,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8408/12032 [7:34:55<3:51:16,  3.83s/it]2025-08-23:02:09:37,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8409/12032 [7:34:59<3:51:36,  3.84s/it]2025-08-23:02:09:41,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8410/12032 [7:35:03<3:52:53,  3.86s/it]2025-08-23:02:09:45,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8411/12032 [7:35:07<3:52:06,  3.85s/it]2025-08-23:02:09:49,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8412/12032 [7:35:11<3:53:03,  3.86s/it]2025-08-23:02:09:52,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8413/12032 [7:35:14<3:52:16,  3.85s/it]2025-08-23:02:09:56,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8414/12032 [7:35:18<3:52:21,  3.85s/it]2025-08-23:02:10:00,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8415/12032 [7:35:22<3:52:00,  3.85s/it]2025-08-23:02:10:04,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8416/12032 [7:35:25<3:28:34,  3.46s/it]2025-08-23:02:10:07,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8417/12032 [7:35:29<3:35:29,  3.58s/it]2025-08-23:02:10:10,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8418/12032 [7:35:32<3:40:02,  3.65s/it]2025-08-23:02:10:14,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8419/12032 [7:35:34<3:02:34,  3.03s/it]2025-08-23:02:10:16,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8420/12032 [7:35:38<3:15:51,  3.25s/it]2025-08-23:02:10:20,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8421/12032 [7:35:42<3:28:09,  3.46s/it]2025-08-23:02:10:23,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|██████▉   | 8422/12032 [7:35:45<3:34:21,  3.56s/it]2025-08-23:02:10:27,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8423/12032 [7:35:49<3:38:51,  3.64s/it]2025-08-23:02:10:31,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8424/12032 [7:35:53<3:41:56,  3.69s/it]2025-08-23:02:10:35,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8425/12032 [7:35:57<3:43:47,  3.72s/it]2025-08-23:02:10:39,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8426/12032 [7:36:01<3:45:14,  3.75s/it]2025-08-23:02:10:43,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8427/12032 [7:36:04<3:45:51,  3.76s/it]2025-08-23:02:10:46,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8428/12032 [7:36:08<3:47:03,  3.78s/it]2025-08-23:02:10:50,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8429/12032 [7:36:12<3:48:05,  3.80s/it]2025-08-23:02:10:54,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8430/12032 [7:36:16<3:48:20,  3.80s/it]2025-08-23:02:10:58,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8431/12032 [7:36:20<3:48:34,  3.81s/it]2025-08-23:02:11:02,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8432/12032 [7:36:24<3:48:42,  3.81s/it]2025-08-23:02:11:05,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8433/12032 [7:36:27<3:49:07,  3.82s/it]2025-08-23:02:11:09,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8434/12032 [7:36:31<3:50:03,  3.84s/it]2025-08-23:02:11:13,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8435/12032 [7:36:35<3:49:35,  3.83s/it]2025-08-23:02:11:17,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8436/12032 [7:36:39<3:48:57,  3.82s/it]2025-08-23:02:11:21,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8437/12032 [7:36:43<3:49:12,  3.83s/it]2025-08-23:02:11:25,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8438/12032 [7:36:47<3:49:08,  3.83s/it]2025-08-23:02:11:28,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8439/12032 [7:36:50<3:34:54,  3.59s/it]2025-08-23:02:11:31,960 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8440/12032 [7:36:54<3:40:25,  3.68s/it]2025-08-23:02:11:35,859 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8441/12032 [7:36:56<3:19:36,  3.34s/it]2025-08-23:02:11:38,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8442/12032 [7:37:00<3:26:03,  3.44s/it]2025-08-23:02:11:42,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8443/12032 [7:37:04<3:33:59,  3.58s/it]2025-08-23:02:11:45,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8444/12032 [7:37:08<3:40:02,  3.68s/it]2025-08-23:02:11:49,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8445/12032 [7:37:10<3:26:06,  3.45s/it]2025-08-23:02:11:52,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8446/12032 [7:37:14<3:36:15,  3.62s/it]2025-08-23:02:11:56,814 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8447/12032 [7:37:18<3:40:15,  3.69s/it]2025-08-23:02:12:00,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8448/12032 [7:37:22<3:42:53,  3.73s/it]2025-08-23:02:12:04,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8449/12032 [7:37:24<3:08:11,  3.15s/it]2025-08-23:02:12:06,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8450/12032 [7:37:27<3:12:41,  3.23s/it]2025-08-23:02:12:09,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8451/12032 [7:37:31<3:12:58,  3.23s/it]2025-08-23:02:12:12,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8452/12032 [7:37:34<3:24:05,  3.42s/it]2025-08-23:02:12:16,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8453/12032 [7:37:38<3:30:57,  3.54s/it]2025-08-23:02:12:20,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8454/12032 [7:37:40<2:51:56,  2.88s/it]2025-08-23:02:12:21,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8455/12032 [7:37:41<2:30:58,  2.53s/it]2025-08-23:02:12:23,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8456/12032 [7:37:44<2:33:41,  2.58s/it]2025-08-23:02:12:26,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8457/12032 [7:37:45<2:13:03,  2.23s/it]2025-08-23:02:12:27,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8458/12032 [7:37:49<2:32:51,  2.57s/it]2025-08-23:02:12:31,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8459/12032 [7:37:50<2:14:17,  2.26s/it]2025-08-23:02:12:32,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8460/12032 [7:37:54<2:42:22,  2.73s/it]2025-08-23:02:12:36,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8461/12032 [7:37:58<3:01:50,  3.06s/it]2025-08-23:02:12:40,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8462/12032 [7:38:00<2:42:58,  2.74s/it]2025-08-23:02:12:42,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8463/12032 [7:38:01<2:18:13,  2.32s/it]2025-08-23:02:12:43,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8464/12032 [7:38:05<2:44:50,  2.77s/it]2025-08-23:02:12:47,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8465/12032 [7:38:07<2:21:06,  2.37s/it]2025-08-23:02:12:48,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8466/12032 [7:38:10<2:36:45,  2.64s/it]2025-08-23:02:12:52,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8467/12032 [7:38:14<2:57:14,  2.98s/it]2025-08-23:02:12:55,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8468/12032 [7:38:17<3:09:22,  3.19s/it]2025-08-23:02:12:59,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8469/12032 [7:38:20<2:59:16,  3.02s/it]2025-08-23:02:13:02,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8470/12032 [7:38:24<3:13:22,  3.26s/it]2025-08-23:02:13:06,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8471/12032 [7:38:26<2:52:53,  2.91s/it]2025-08-23:02:13:08,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8472/12032 [7:38:28<2:39:42,  2.69s/it]2025-08-23:02:13:10,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8473/12032 [7:38:32<3:00:21,  3.04s/it]2025-08-23:02:13:14,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8474/12032 [7:38:33<2:28:26,  2.50s/it]2025-08-23:02:13:15,472 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8475/12032 [7:38:37<2:51:10,  2.89s/it]2025-08-23:02:13:19,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8476/12032 [7:38:40<2:47:57,  2.83s/it]2025-08-23:02:13:21,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8477/12032 [7:38:43<3:05:25,  3.13s/it]2025-08-23:02:13:25,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8478/12032 [7:38:47<3:17:34,  3.34s/it]2025-08-23:02:13:29,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8479/12032 [7:38:51<3:25:55,  3.48s/it]2025-08-23:02:13:33,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8480/12032 [7:38:55<3:31:39,  3.58s/it]2025-08-23:02:13:37,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8481/12032 [7:38:59<3:35:48,  3.65s/it]2025-08-23:02:13:41,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  70%|███████   | 8482/12032 [7:39:02<3:24:52,  3.46s/it]2025-08-23:02:13:44,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8483/12032 [7:39:06<3:32:41,  3.60s/it]2025-08-23:02:13:47,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8484/12032 [7:39:08<3:11:11,  3.23s/it]2025-08-23:02:13:50,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8485/12032 [7:39:12<3:23:05,  3.44s/it]2025-08-23:02:13:54,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8486/12032 [7:39:14<2:53:20,  2.93s/it]2025-08-23:02:13:56,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8487/12032 [7:39:18<3:10:06,  3.22s/it]2025-08-23:02:13:59,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8488/12032 [7:39:21<3:20:41,  3.40s/it]2025-08-23:02:14:03,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8489/12032 [7:39:25<3:27:39,  3.52s/it]2025-08-23:02:14:07,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8490/12032 [7:39:29<3:32:22,  3.60s/it]2025-08-23:02:14:11,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8491/12032 [7:39:33<3:36:36,  3.67s/it]2025-08-23:02:14:15,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8492/12032 [7:39:37<3:38:39,  3.71s/it]2025-08-23:02:14:18,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8493/12032 [7:39:40<3:39:44,  3.73s/it]2025-08-23:02:14:22,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8494/12032 [7:39:44<3:42:26,  3.77s/it]2025-08-23:02:14:26,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8495/12032 [7:39:48<3:43:31,  3.79s/it]2025-08-23:02:14:30,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8496/12032 [7:39:52<3:44:45,  3.81s/it]2025-08-23:02:14:34,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8497/12032 [7:39:55<3:37:01,  3.68s/it]2025-08-23:02:14:37,664 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8498/12032 [7:39:59<3:39:15,  3.72s/it]2025-08-23:02:14:41,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8499/12032 [7:40:03<3:40:33,  3.75s/it]2025-08-23:02:14:45,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8500/12032 [7:40:07<3:41:26,  3.76s/it]2025-08-23:02:14:49,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8501/12032 [7:40:11<3:42:01,  3.77s/it]2025-08-23:02:14:52,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8502/12032 [7:40:14<3:42:48,  3.79s/it]2025-08-23:02:14:56,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8503/12032 [7:40:18<3:37:10,  3.69s/it]2025-08-23:02:15:00,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8504/12032 [7:40:22<3:39:09,  3.73s/it]2025-08-23:02:15:03,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8505/12032 [7:40:25<3:41:03,  3.76s/it]2025-08-23:02:15:07,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8506/12032 [7:40:29<3:41:44,  3.77s/it]2025-08-23:02:15:11,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8507/12032 [7:40:33<3:42:39,  3.79s/it]2025-08-23:02:15:15,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8508/12032 [7:40:37<3:43:08,  3.80s/it]2025-08-23:02:15:19,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8509/12032 [7:40:41<3:43:20,  3.80s/it]2025-08-23:02:15:23,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8510/12032 [7:40:43<3:11:07,  3.26s/it]2025-08-23:02:15:25,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8511/12032 [7:40:46<3:08:19,  3.21s/it]2025-08-23:02:15:28,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8512/12032 [7:40:49<2:59:45,  3.06s/it]2025-08-23:02:15:30,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8513/12032 [7:40:50<2:29:07,  2.54s/it]2025-08-23:02:15:32,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8514/12032 [7:40:54<2:48:46,  2.88s/it]2025-08-23:02:15:35,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8515/12032 [7:40:56<2:39:34,  2.72s/it]2025-08-23:02:15:38,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8516/12032 [7:40:57<2:08:21,  2.19s/it]2025-08-23:02:15:39,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8517/12032 [7:40:58<1:50:27,  1.89s/it]2025-08-23:02:15:40,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8518/12032 [7:41:01<2:12:30,  2.26s/it]2025-08-23:02:15:43,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8519/12032 [7:41:04<2:16:10,  2.33s/it]2025-08-23:02:15:45,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8520/12032 [7:41:07<2:42:01,  2.77s/it]2025-08-23:02:15:49,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8521/12032 [7:41:09<2:19:43,  2.39s/it]2025-08-23:02:15:51,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8522/12032 [7:41:11<2:12:00,  2.26s/it]2025-08-23:02:15:53,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8523/12032 [7:41:12<1:54:49,  1.96s/it]2025-08-23:02:15:54,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8524/12032 [7:41:16<2:26:53,  2.51s/it]2025-08-23:02:15:58,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8525/12032 [7:41:19<2:36:44,  2.68s/it]2025-08-23:02:16:01,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8526/12032 [7:41:22<2:38:15,  2.71s/it]2025-08-23:02:16:04,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8527/12032 [7:41:26<2:56:54,  3.03s/it]2025-08-23:02:16:07,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8528/12032 [7:41:27<2:35:36,  2.66s/it]2025-08-23:02:16:09,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8529/12032 [7:41:30<2:38:06,  2.71s/it]2025-08-23:02:16:12,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8530/12032 [7:41:34<2:49:18,  2.90s/it]2025-08-23:02:16:15,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8531/12032 [7:41:37<3:00:24,  3.09s/it]2025-08-23:02:16:19,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8532/12032 [7:41:41<3:12:36,  3.30s/it]2025-08-23:02:16:23,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8533/12032 [7:41:43<2:43:24,  2.80s/it]2025-08-23:02:16:24,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8534/12032 [7:41:45<2:43:07,  2.80s/it]2025-08-23:02:16:27,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8535/12032 [7:41:46<2:13:38,  2.29s/it]2025-08-23:02:16:28,759 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8536/12032 [7:41:47<1:48:04,  1.85s/it]2025-08-23:02:16:29,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8537/12032 [7:41:50<1:57:08,  2.01s/it]2025-08-23:02:16:31,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8538/12032 [7:41:51<1:38:08,  1.69s/it]2025-08-23:02:16:32,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8539/12032 [7:41:53<1:43:46,  1.78s/it]2025-08-23:02:16:34,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8540/12032 [7:41:54<1:29:58,  1.55s/it]2025-08-23:02:16:35,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8541/12032 [7:41:55<1:22:12,  1.41s/it]2025-08-23:02:16:36,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8542/12032 [7:41:56<1:14:51,  1.29s/it]2025-08-23:02:16:37,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8543/12032 [7:41:57<1:15:37,  1.30s/it]2025-08-23:02:16:39,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8544/12032 [7:41:58<1:06:45,  1.15s/it]2025-08-23:02:16:40,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8545/12032 [7:42:01<1:41:29,  1.75s/it]2025-08-23:02:16:43,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8546/12032 [7:42:03<1:50:38,  1.90s/it]2025-08-23:02:16:45,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8547/12032 [7:42:05<1:41:25,  1.75s/it]2025-08-23:02:16:46,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8548/12032 [7:42:07<1:57:27,  2.02s/it]2025-08-23:02:16:49,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8549/12032 [7:42:10<2:05:00,  2.15s/it]2025-08-23:02:16:52,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8550/12032 [7:42:11<1:47:11,  1.85s/it]2025-08-23:02:16:53,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8551/12032 [7:42:14<2:04:14,  2.14s/it]2025-08-23:02:16:55,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8552/12032 [7:42:17<2:23:11,  2.47s/it]2025-08-23:02:16:59,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8553/12032 [7:42:21<2:47:02,  2.88s/it]2025-08-23:02:17:03,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8554/12032 [7:42:21<2:04:40,  2.15s/it]2025-08-23:02:17:03,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8555/12032 [7:42:22<1:38:38,  1.70s/it]2025-08-23:02:17:04,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8556/12032 [7:42:23<1:23:53,  1.45s/it]2025-08-23:02:17:05,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8557/12032 [7:42:24<1:24:57,  1.47s/it]2025-08-23:02:17:06,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8558/12032 [7:42:26<1:27:32,  1.51s/it]2025-08-23:02:17:08,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8559/12032 [7:42:27<1:22:51,  1.43s/it]2025-08-23:02:17:09,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8560/12032 [7:42:31<2:03:37,  2.14s/it]2025-08-23:02:17:13,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8561/12032 [7:42:34<2:25:40,  2.52s/it]2025-08-23:02:17:16,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8562/12032 [7:42:38<2:47:23,  2.89s/it]2025-08-23:02:17:20,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8563/12032 [7:42:39<2:08:28,  2.22s/it]2025-08-23:02:17:21,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8564/12032 [7:42:42<2:35:01,  2.68s/it]2025-08-23:02:17:24,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8565/12032 [7:42:43<2:00:42,  2.09s/it]2025-08-23:02:17:25,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8566/12032 [7:42:45<2:04:02,  2.15s/it]2025-08-23:02:17:27,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8567/12032 [7:42:46<1:41:18,  1.75s/it]2025-08-23:02:17:28,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8568/12032 [7:42:50<2:16:55,  2.37s/it]2025-08-23:02:17:32,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8569/12032 [7:42:53<2:31:17,  2.62s/it]2025-08-23:02:17:35,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8570/12032 [7:42:54<2:04:39,  2.16s/it]2025-08-23:02:17:36,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8571/12032 [7:42:56<2:00:40,  2.09s/it]2025-08-23:02:17:38,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████   | 8572/12032 [7:43:00<2:28:20,  2.57s/it]2025-08-23:02:17:42,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8573/12032 [7:43:03<2:43:17,  2.83s/it]2025-08-23:02:17:45,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8574/12032 [7:43:07<2:59:39,  3.12s/it]2025-08-23:02:17:49,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8575/12032 [7:43:11<3:11:57,  3.33s/it]2025-08-23:02:17:53,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8576/12032 [7:43:15<3:20:05,  3.47s/it]2025-08-23:02:17:57,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8577/12032 [7:43:18<3:17:21,  3.43s/it]2025-08-23:02:18:00,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8578/12032 [7:43:21<3:12:32,  3.34s/it]2025-08-23:02:18:03,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8579/12032 [7:43:25<3:18:39,  3.45s/it]2025-08-23:02:18:07,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8580/12032 [7:43:29<3:24:52,  3.56s/it]2025-08-23:02:18:11,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8581/12032 [7:43:30<2:43:26,  2.84s/it]2025-08-23:02:18:12,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8582/12032 [7:43:34<2:59:35,  3.12s/it]2025-08-23:02:18:16,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8583/12032 [7:43:36<2:50:51,  2.97s/it]2025-08-23:02:18:18,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8584/12032 [7:43:37<2:18:38,  2.41s/it]2025-08-23:02:18:19,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8585/12032 [7:43:41<2:41:46,  2.82s/it]2025-08-23:02:18:23,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8586/12032 [7:43:43<2:18:09,  2.41s/it]2025-08-23:02:18:25,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8587/12032 [7:43:44<1:57:40,  2.05s/it]2025-08-23:02:18:26,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8588/12032 [7:43:45<1:47:10,  1.87s/it]2025-08-23:02:18:27,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8589/12032 [7:43:49<2:10:16,  2.27s/it]2025-08-23:02:18:30,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8590/12032 [7:43:50<1:47:08,  1.87s/it]2025-08-23:02:18:31,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8591/12032 [7:43:51<1:39:53,  1.74s/it]2025-08-23:02:18:33,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8592/12032 [7:43:55<2:16:02,  2.37s/it]2025-08-23:02:18:37,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8593/12032 [7:43:56<1:58:12,  2.06s/it]2025-08-23:02:18:38,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8594/12032 [7:44:00<2:27:36,  2.58s/it]2025-08-23:02:18:42,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8595/12032 [7:44:02<2:10:38,  2.28s/it]2025-08-23:02:18:43,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8596/12032 [7:44:03<1:57:36,  2.05s/it]2025-08-23:02:18:45,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8597/12032 [7:44:06<2:06:26,  2.21s/it]2025-08-23:02:18:47,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8598/12032 [7:44:09<2:34:34,  2.70s/it]2025-08-23:02:18:51,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8599/12032 [7:44:13<2:52:59,  3.02s/it]2025-08-23:02:18:55,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8600/12032 [7:44:16<2:46:48,  2.92s/it]2025-08-23:02:18:58,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8601/12032 [7:44:18<2:31:22,  2.65s/it]2025-08-23:02:19:00,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  71%|███████▏  | 8602/12032 [7:44:21<2:40:29,  2.81s/it]2025-08-23:02:19:03,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8603/12032 [7:44:25<2:57:48,  3.11s/it]2025-08-23:02:19:07,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8604/12032 [7:44:27<2:38:16,  2.77s/it]2025-08-23:02:19:09,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8605/12032 [7:44:28<2:06:34,  2.22s/it]2025-08-23:02:19:10,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8606/12032 [7:44:30<2:01:52,  2.13s/it]2025-08-23:02:19:12,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8607/12032 [7:44:31<1:42:42,  1.80s/it]2025-08-23:02:19:13,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8608/12032 [7:44:33<1:51:08,  1.95s/it]2025-08-23:02:19:15,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8609/12032 [7:44:34<1:39:05,  1.74s/it]2025-08-23:02:19:16,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8610/12032 [7:44:37<1:52:52,  1.98s/it]2025-08-23:02:19:19,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8611/12032 [7:44:38<1:38:52,  1.73s/it]2025-08-23:02:19:20,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8612/12032 [7:44:39<1:30:49,  1.59s/it]2025-08-23:02:19:21,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8613/12032 [7:44:40<1:19:37,  1.40s/it]2025-08-23:02:19:22,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8614/12032 [7:44:42<1:27:18,  1.53s/it]2025-08-23:02:19:24,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8615/12032 [7:44:43<1:18:08,  1.37s/it]2025-08-23:02:19:25,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8616/12032 [7:44:45<1:19:34,  1.40s/it]2025-08-23:02:19:26,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8617/12032 [7:44:45<1:09:35,  1.22s/it]2025-08-23:02:19:27,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8618/12032 [7:44:49<1:45:56,  1.86s/it]2025-08-23:02:19:31,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8619/12032 [7:44:50<1:33:18,  1.64s/it]2025-08-23:02:19:32,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8620/12032 [7:44:51<1:22:56,  1.46s/it]2025-08-23:02:19:33,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8621/12032 [7:44:55<2:02:40,  2.16s/it]2025-08-23:02:19:36,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8622/12032 [7:44:56<1:49:05,  1.92s/it]2025-08-23:02:19:38,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8623/12032 [7:45:00<2:21:28,  2.49s/it]2025-08-23:02:19:42,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8624/12032 [7:45:03<2:28:50,  2.62s/it]2025-08-23:02:19:45,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8625/12032 [7:45:03<1:54:34,  2.02s/it]2025-08-23:02:19:45,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8626/12032 [7:45:04<1:33:17,  1.64s/it]2025-08-23:02:19:46,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8627/12032 [7:45:05<1:21:04,  1.43s/it]2025-08-23:02:19:47,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8628/12032 [7:45:08<1:53:00,  1.99s/it]2025-08-23:02:19:50,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8629/12032 [7:45:09<1:33:18,  1.65s/it]2025-08-23:02:19:51,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8630/12032 [7:45:10<1:25:04,  1.50s/it]2025-08-23:02:19:52,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8631/12032 [7:45:12<1:32:30,  1.63s/it]2025-08-23:02:19:54,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8632/12032 [7:45:16<2:09:05,  2.28s/it]2025-08-23:02:19:58,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8633/12032 [7:45:20<2:34:35,  2.73s/it]2025-08-23:02:20:02,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8634/12032 [7:45:23<2:46:21,  2.94s/it]2025-08-23:02:20:05,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8635/12032 [7:45:26<2:42:10,  2.86s/it]2025-08-23:02:20:08,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8636/12032 [7:45:27<2:13:05,  2.35s/it]2025-08-23:02:20:09,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8637/12032 [7:45:30<2:25:35,  2.57s/it]2025-08-23:02:20:12,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8638/12032 [7:45:34<2:45:40,  2.93s/it]2025-08-23:02:20:16,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8639/12032 [7:45:35<2:14:48,  2.38s/it]2025-08-23:02:20:17,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8640/12032 [7:45:36<1:51:16,  1.97s/it]2025-08-23:02:20:18,439 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8641/12032 [7:45:39<2:07:05,  2.25s/it]2025-08-23:02:20:21,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8642/12032 [7:45:42<2:16:56,  2.42s/it]2025-08-23:02:20:24,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8643/12032 [7:45:43<1:51:35,  1.98s/it]2025-08-23:02:20:25,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8644/12032 [7:45:46<2:05:34,  2.22s/it]2025-08-23:02:20:27,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8645/12032 [7:45:49<2:33:13,  2.71s/it]2025-08-23:02:20:31,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8646/12032 [7:45:53<2:51:04,  3.03s/it]2025-08-23:02:20:35,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8647/12032 [7:45:56<2:42:23,  2.88s/it]2025-08-23:02:20:38,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8648/12032 [7:45:57<2:19:06,  2.47s/it]2025-08-23:02:20:39,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8649/12032 [7:45:59<2:03:15,  2.19s/it]2025-08-23:02:20:41,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8650/12032 [7:46:00<1:51:49,  1.98s/it]2025-08-23:02:20:42,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8651/12032 [7:46:04<2:21:47,  2.52s/it]2025-08-23:02:20:46,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8652/12032 [7:46:06<2:16:30,  2.42s/it]2025-08-23:02:20:48,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8653/12032 [7:46:08<2:03:07,  2.19s/it]2025-08-23:02:20:50,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8654/12032 [7:46:11<2:17:55,  2.45s/it]2025-08-23:02:20:53,271 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8655/12032 [7:46:12<1:55:06,  2.05s/it]2025-08-23:02:20:54,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8656/12032 [7:46:13<1:34:25,  1.68s/it]2025-08-23:02:20:55,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8657/12032 [7:46:17<2:09:40,  2.31s/it]2025-08-23:02:20:58,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8658/12032 [7:46:19<2:17:43,  2.45s/it]2025-08-23:02:21:01,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8659/12032 [7:46:21<2:04:43,  2.22s/it]2025-08-23:02:21:03,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8660/12032 [7:46:22<1:50:41,  1.97s/it]2025-08-23:02:21:04,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8661/12032 [7:46:24<1:47:13,  1.91s/it]2025-08-23:02:21:06,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8662/12032 [7:46:28<2:17:30,  2.45s/it]2025-08-23:02:21:10,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8663/12032 [7:46:31<2:26:48,  2.61s/it]2025-08-23:02:21:13,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8664/12032 [7:46:33<2:18:39,  2.47s/it]2025-08-23:02:21:15,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8665/12032 [7:46:35<2:07:48,  2.28s/it]2025-08-23:02:21:17,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8666/12032 [7:46:37<2:01:11,  2.16s/it]2025-08-23:02:21:19,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8667/12032 [7:46:40<2:25:38,  2.60s/it]2025-08-23:02:21:22,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8668/12032 [7:46:44<2:46:30,  2.97s/it]2025-08-23:02:21:26,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8669/12032 [7:46:48<3:01:19,  3.24s/it]2025-08-23:02:21:30,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8670/12032 [7:46:49<2:27:48,  2.64s/it]2025-08-23:02:21:31,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8671/12032 [7:46:53<2:46:35,  2.97s/it]2025-08-23:02:21:35,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8672/12032 [7:46:57<2:59:52,  3.21s/it]2025-08-23:02:21:39,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8673/12032 [7:47:00<2:56:52,  3.16s/it]2025-08-23:02:21:42,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8674/12032 [7:47:01<2:16:43,  2.44s/it]2025-08-23:02:21:43,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8675/12032 [7:47:04<2:30:25,  2.69s/it]2025-08-23:02:21:46,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8676/12032 [7:47:05<1:58:20,  2.12s/it]2025-08-23:02:21:47,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8677/12032 [7:47:07<1:57:18,  2.10s/it]2025-08-23:02:21:49,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8678/12032 [7:47:08<1:47:32,  1.92s/it]2025-08-23:02:21:50,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8679/12032 [7:47:09<1:34:19,  1.69s/it]2025-08-23:02:21:51,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8680/12032 [7:47:10<1:19:49,  1.43s/it]2025-08-23:02:21:52,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8681/12032 [7:47:11<1:14:31,  1.33s/it]2025-08-23:02:21:53,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8682/12032 [7:47:12<1:05:18,  1.17s/it]2025-08-23:02:21:54,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8683/12032 [7:47:13<58:37,  1.05s/it]  2025-08-23:02:21:55,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8684/12032 [7:47:14<58:07,  1.04s/it]2025-08-23:02:21:56,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8685/12032 [7:47:15<52:24,  1.06it/s]2025-08-23:02:21:56,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8686/12032 [7:47:16<53:19,  1.05it/s]2025-08-23:02:21:57,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8687/12032 [7:47:19<1:41:38,  1.82s/it]2025-08-23:02:22:01,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8688/12032 [7:47:20<1:25:32,  1.53s/it]2025-08-23:02:22:02,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8689/12032 [7:47:24<2:02:57,  2.21s/it]2025-08-23:02:22:06,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8690/12032 [7:47:27<2:14:44,  2.42s/it]2025-08-23:02:22:09,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8691/12032 [7:47:28<1:44:21,  1.87s/it]2025-08-23:02:22:09,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8692/12032 [7:47:30<1:45:04,  1.89s/it]2025-08-23:02:22:11,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8693/12032 [7:47:31<1:39:57,  1.80s/it]2025-08-23:02:22:13,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8694/12032 [7:47:35<2:13:06,  2.39s/it]2025-08-23:02:22:17,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8695/12032 [7:47:39<2:36:39,  2.82s/it]2025-08-23:02:22:21,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8696/12032 [7:47:40<2:12:56,  2.39s/it]2025-08-23:02:22:22,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8697/12032 [7:47:44<2:35:49,  2.80s/it]2025-08-23:02:22:26,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8698/12032 [7:47:45<2:08:41,  2.32s/it]2025-08-23:02:22:27,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8699/12032 [7:47:46<1:45:25,  1.90s/it]2025-08-23:02:22:28,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8700/12032 [7:47:47<1:27:59,  1.58s/it]2025-08-23:02:22:29,204 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8701/12032 [7:47:50<1:54:28,  2.06s/it]2025-08-23:02:22:32,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8702/12032 [7:47:54<2:22:58,  2.58s/it]2025-08-23:02:22:36,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8703/12032 [7:47:56<2:17:46,  2.48s/it]2025-08-23:02:22:38,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8704/12032 [7:47:57<1:48:14,  1.95s/it]2025-08-23:02:22:39,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8705/12032 [7:48:00<2:08:44,  2.32s/it]2025-08-23:02:22:42,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8706/12032 [7:48:03<2:12:57,  2.40s/it]2025-08-23:02:22:44,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8707/12032 [7:48:04<1:48:58,  1.97s/it]2025-08-23:02:22:45,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8708/12032 [7:48:06<1:53:37,  2.05s/it]2025-08-23:02:22:48,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8709/12032 [7:48:07<1:48:23,  1.96s/it]2025-08-23:02:22:49,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8710/12032 [7:48:11<2:12:46,  2.40s/it]2025-08-23:02:22:53,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8711/12032 [7:48:15<2:36:45,  2.83s/it]2025-08-23:02:22:57,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8712/12032 [7:48:18<2:39:05,  2.88s/it]2025-08-23:02:23:00,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8713/12032 [7:48:20<2:27:58,  2.68s/it]2025-08-23:02:23:02,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8714/12032 [7:48:24<2:45:46,  3.00s/it]2025-08-23:02:23:06,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8715/12032 [7:48:26<2:39:28,  2.88s/it]2025-08-23:02:23:08,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8716/12032 [7:48:30<2:54:20,  3.15s/it]2025-08-23:02:23:12,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8717/12032 [7:48:34<3:05:34,  3.36s/it]2025-08-23:02:23:16,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8718/12032 [7:48:36<2:48:00,  3.04s/it]2025-08-23:02:23:18,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8719/12032 [7:48:40<2:59:57,  3.26s/it]2025-08-23:02:23:22,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8720/12032 [7:48:43<2:51:28,  3.11s/it]2025-08-23:02:23:25,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8721/12032 [7:48:46<2:48:52,  3.06s/it]2025-08-23:02:23:28,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8722/12032 [7:48:48<2:36:50,  2.84s/it]2025-08-23:02:23:30,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  72%|███████▏  | 8723/12032 [7:48:52<2:51:52,  3.12s/it]2025-08-23:02:23:34,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8724/12032 [7:48:56<3:02:32,  3.31s/it]2025-08-23:02:23:37,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8725/12032 [7:48:57<2:29:15,  2.71s/it]2025-08-23:02:23:39,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8726/12032 [7:49:00<2:35:05,  2.81s/it]2025-08-23:02:23:42,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8727/12032 [7:49:01<2:06:40,  2.30s/it]2025-08-23:02:23:43,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8728/12032 [7:49:04<2:11:25,  2.39s/it]2025-08-23:02:23:45,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8729/12032 [7:49:05<1:49:08,  1.98s/it]2025-08-23:02:23:47,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8730/12032 [7:49:08<2:15:25,  2.46s/it]2025-08-23:02:23:50,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8731/12032 [7:49:10<2:03:50,  2.25s/it]2025-08-23:02:23:52,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8732/12032 [7:49:11<1:40:24,  1.83s/it]2025-08-23:02:23:53,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8733/12032 [7:49:13<1:46:13,  1.93s/it]2025-08-23:02:23:55,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8734/12032 [7:49:14<1:31:45,  1.67s/it]2025-08-23:02:23:56,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8735/12032 [7:49:18<2:06:35,  2.30s/it]2025-08-23:02:24:00,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8736/12032 [7:49:19<1:45:43,  1.92s/it]2025-08-23:02:24:01,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8737/12032 [7:49:21<1:47:56,  1.97s/it]2025-08-23:02:24:03,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8738/12032 [7:49:22<1:31:16,  1.66s/it]2025-08-23:02:24:04,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8739/12032 [7:49:23<1:16:34,  1.40s/it]2025-08-23:02:24:05,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8740/12032 [7:49:26<1:49:15,  1.99s/it]2025-08-23:02:24:08,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8741/12032 [7:49:29<2:00:48,  2.20s/it]2025-08-23:02:24:11,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8742/12032 [7:49:30<1:40:15,  1.83s/it]2025-08-23:02:24:12,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8743/12032 [7:49:33<2:03:12,  2.25s/it]2025-08-23:02:24:15,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8744/12032 [7:49:36<2:18:53,  2.53s/it]2025-08-23:02:24:18,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8745/12032 [7:49:39<2:28:37,  2.71s/it]2025-08-23:02:24:21,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8746/12032 [7:49:42<2:21:16,  2.58s/it]2025-08-23:02:24:23,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8747/12032 [7:49:44<2:23:57,  2.63s/it]2025-08-23:02:24:26,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8748/12032 [7:49:46<2:06:52,  2.32s/it]2025-08-23:02:24:28,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8749/12032 [7:49:47<1:45:56,  1.94s/it]2025-08-23:02:24:29,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8750/12032 [7:49:48<1:30:20,  1.65s/it]2025-08-23:02:24:30,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8751/12032 [7:49:49<1:23:58,  1.54s/it]2025-08-23:02:24:31,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8752/12032 [7:49:50<1:12:42,  1.33s/it]2025-08-23:02:24:32,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8753/12032 [7:49:51<1:08:29,  1.25s/it]2025-08-23:02:24:33,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8754/12032 [7:49:55<1:49:45,  2.01s/it]2025-08-23:02:24:37,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8755/12032 [7:49:59<2:19:16,  2.55s/it]2025-08-23:02:24:41,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8756/12032 [7:50:00<1:57:13,  2.15s/it]2025-08-23:02:24:42,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8757/12032 [7:50:01<1:45:20,  1.93s/it]2025-08-23:02:24:43,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8758/12032 [7:50:03<1:39:04,  1.82s/it]2025-08-23:02:24:45,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8759/12032 [7:50:04<1:23:41,  1.53s/it]2025-08-23:02:24:46,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8760/12032 [7:50:04<1:08:35,  1.26s/it]2025-08-23:02:24:46,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8761/12032 [7:50:05<1:05:52,  1.21s/it]2025-08-23:02:24:47,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8762/12032 [7:50:07<1:03:35,  1.17s/it]2025-08-23:02:24:48,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8763/12032 [7:50:10<1:46:11,  1.95s/it]2025-08-23:02:24:52,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8764/12032 [7:50:12<1:36:29,  1.77s/it]2025-08-23:02:24:53,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8765/12032 [7:50:13<1:25:41,  1.57s/it]2025-08-23:02:24:55,107 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8766/12032 [7:50:14<1:18:29,  1.44s/it]2025-08-23:02:24:56,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8767/12032 [7:50:15<1:05:27,  1.20s/it]2025-08-23:02:24:56,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8768/12032 [7:50:18<1:48:17,  1.99s/it]2025-08-23:02:25:00,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8769/12032 [7:50:20<1:47:48,  1.98s/it]2025-08-23:02:25:02,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8770/12032 [7:50:23<1:57:10,  2.16s/it]2025-08-23:02:25:05,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8771/12032 [7:50:24<1:35:37,  1.76s/it]2025-08-23:02:25:06,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8772/12032 [7:50:28<2:09:08,  2.38s/it]2025-08-23:02:25:09,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8773/12032 [7:50:28<1:43:42,  1.91s/it]2025-08-23:02:25:10,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8774/12032 [7:50:32<2:13:22,  2.46s/it]2025-08-23:02:25:14,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8775/12032 [7:50:35<2:20:12,  2.58s/it]2025-08-23:02:25:17,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8776/12032 [7:50:38<2:34:59,  2.86s/it]2025-08-23:02:25:20,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8777/12032 [7:50:40<2:05:22,  2.31s/it]2025-08-23:02:25:21,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8778/12032 [7:50:43<2:29:25,  2.76s/it]2025-08-23:02:25:25,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8779/12032 [7:50:44<1:53:25,  2.09s/it]2025-08-23:02:25:26,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8780/12032 [7:50:45<1:43:40,  1.91s/it]2025-08-23:02:25:27,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8781/12032 [7:50:49<2:14:53,  2.49s/it]2025-08-23:02:25:31,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8782/12032 [7:50:50<1:53:28,  2.10s/it]2025-08-23:02:25:32,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8783/12032 [7:50:53<2:08:21,  2.37s/it]2025-08-23:02:25:35,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8784/12032 [7:50:54<1:40:24,  1.85s/it]2025-08-23:02:25:36,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8785/12032 [7:50:55<1:26:34,  1.60s/it]2025-08-23:02:25:37,363 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8786/12032 [7:50:56<1:16:45,  1.42s/it]2025-08-23:02:25:38,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8787/12032 [7:50:58<1:32:15,  1.71s/it]2025-08-23:02:25:40,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8788/12032 [7:50:59<1:15:23,  1.39s/it]2025-08-23:02:25:41,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8789/12032 [7:51:02<1:47:23,  1.99s/it]2025-08-23:02:25:44,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8790/12032 [7:51:03<1:27:57,  1.63s/it]2025-08-23:02:25:45,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8791/12032 [7:51:07<2:02:29,  2.27s/it]2025-08-23:02:25:49,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8792/12032 [7:51:11<2:28:14,  2.75s/it]2025-08-23:02:25:53,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8793/12032 [7:51:12<1:57:39,  2.18s/it]2025-08-23:02:25:54,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8794/12032 [7:51:16<2:25:31,  2.70s/it]2025-08-23:02:25:57,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8795/12032 [7:51:17<2:00:05,  2.23s/it]2025-08-23:02:25:59,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8796/12032 [7:51:18<1:43:03,  1.91s/it]2025-08-23:02:26:00,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8797/12032 [7:51:20<1:40:17,  1.86s/it]2025-08-23:02:26:01,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8798/12032 [7:51:23<2:03:33,  2.29s/it]2025-08-23:02:26:05,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8799/12032 [7:51:27<2:27:53,  2.74s/it]2025-08-23:02:26:09,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8800/12032 [7:51:31<2:46:10,  3.09s/it]2025-08-23:02:26:12,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8801/12032 [7:51:34<2:57:51,  3.30s/it]2025-08-23:02:26:16,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8802/12032 [7:51:38<3:06:36,  3.47s/it]2025-08-23:02:26:20,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8803/12032 [7:51:41<2:56:10,  3.27s/it]2025-08-23:02:26:23,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8804/12032 [7:51:45<3:06:13,  3.46s/it]2025-08-23:02:26:27,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8805/12032 [7:51:49<3:11:16,  3.56s/it]2025-08-23:02:26:31,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8806/12032 [7:51:52<3:10:52,  3.55s/it]2025-08-23:02:26:34,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8807/12032 [7:51:54<2:34:35,  2.88s/it]2025-08-23:02:26:35,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8808/12032 [7:51:56<2:25:12,  2.70s/it]2025-08-23:02:26:38,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8809/12032 [7:51:59<2:37:14,  2.93s/it]2025-08-23:02:26:41,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8810/12032 [7:52:00<2:02:09,  2.27s/it]2025-08-23:02:26:42,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8811/12032 [7:52:04<2:27:03,  2.74s/it]2025-08-23:02:26:46,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8812/12032 [7:52:08<2:44:21,  3.06s/it]2025-08-23:02:26:50,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8813/12032 [7:52:09<2:08:56,  2.40s/it]2025-08-23:02:26:50,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8814/12032 [7:52:12<2:31:04,  2.82s/it]2025-08-23:02:26:54,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8815/12032 [7:52:14<2:10:37,  2.44s/it]2025-08-23:02:26:56,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8816/12032 [7:52:16<2:06:41,  2.36s/it]2025-08-23:02:26:58,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8817/12032 [7:52:20<2:29:26,  2.79s/it]2025-08-23:02:27:02,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8818/12032 [7:52:24<2:45:38,  3.09s/it]2025-08-23:02:27:06,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8819/12032 [7:52:27<2:46:03,  3.10s/it]2025-08-23:02:27:09,202 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8820/12032 [7:52:30<2:50:52,  3.19s/it]2025-08-23:02:27:12,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8821/12032 [7:52:34<3:00:34,  3.37s/it]2025-08-23:02:27:16,406 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8822/12032 [7:52:37<2:51:59,  3.21s/it]2025-08-23:02:27:19,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8823/12032 [7:52:40<2:46:30,  3.11s/it]2025-08-23:02:27:22,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8824/12032 [7:52:41<2:15:28,  2.53s/it]2025-08-23:02:27:23,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8825/12032 [7:52:42<1:53:02,  2.11s/it]2025-08-23:02:27:24,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8826/12032 [7:52:43<1:31:29,  1.71s/it]2025-08-23:02:27:25,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8827/12032 [7:52:44<1:21:39,  1.53s/it]2025-08-23:02:27:26,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8828/12032 [7:52:45<1:13:32,  1.38s/it]2025-08-23:02:27:27,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8829/12032 [7:52:46<1:04:39,  1.21s/it]2025-08-23:02:27:28,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8830/12032 [7:52:49<1:42:12,  1.92s/it]2025-08-23:02:27:31,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8831/12032 [7:52:50<1:23:06,  1.56s/it]2025-08-23:02:27:32,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8832/12032 [7:52:51<1:14:09,  1.39s/it]2025-08-23:02:27:33,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8833/12032 [7:52:52<1:08:49,  1.29s/it]2025-08-23:02:27:34,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8834/12032 [7:52:53<1:02:27,  1.17s/it]2025-08-23:02:27:35,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8835/12032 [7:52:54<53:53,  1.01s/it]  2025-08-23:02:27:36,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8836/12032 [7:52:54<47:02,  1.13it/s]2025-08-23:02:27:36,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8837/12032 [7:52:55<40:36,  1.31it/s]2025-08-23:02:27:37,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8838/12032 [7:52:55<40:10,  1.32it/s]2025-08-23:02:27:37,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8839/12032 [7:52:57<46:20,  1.15it/s]2025-08-23:02:27:38,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8840/12032 [7:52:59<1:02:12,  1.17s/it]2025-08-23:02:27:40,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8841/12032 [7:52:59<58:34,  1.10s/it]  2025-08-23:02:27:41,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8842/12032 [7:53:01<1:07:20,  1.27s/it]2025-08-23:02:27:43,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  73%|███████▎  | 8843/12032 [7:53:02<58:18,  1.10s/it]  2025-08-23:02:27:44,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8844/12032 [7:53:04<1:15:29,  1.42s/it]2025-08-23:02:27:46,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8845/12032 [7:53:05<1:07:03,  1.26s/it]2025-08-23:02:27:47,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8846/12032 [7:53:06<1:00:37,  1.14s/it]2025-08-23:02:27:48,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8847/12032 [7:53:06<51:55,  1.02it/s]  2025-08-23:02:27:48,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8848/12032 [7:53:07<48:52,  1.09it/s]2025-08-23:02:27:49,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8849/12032 [7:53:08<45:34,  1.16it/s]2025-08-23:02:27:50,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8850/12032 [7:53:12<1:32:23,  1.74s/it]2025-08-23:02:27:53,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8851/12032 [7:53:13<1:28:18,  1.67s/it]2025-08-23:02:27:55,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8852/12032 [7:53:14<1:10:20,  1.33s/it]2025-08-23:02:27:55,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8853/12032 [7:53:16<1:32:34,  1.75s/it]2025-08-23:02:27:58,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8854/12032 [7:53:17<1:13:04,  1.38s/it]2025-08-23:02:27:59,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8855/12032 [7:53:20<1:44:09,  1.97s/it]2025-08-23:02:28:02,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8856/12032 [7:53:24<2:14:07,  2.53s/it]2025-08-23:02:28:06,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8857/12032 [7:53:28<2:34:05,  2.91s/it]2025-08-23:02:28:10,234 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8858/12032 [7:53:31<2:41:53,  3.06s/it]2025-08-23:02:28:13,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8859/12032 [7:53:35<2:53:02,  3.27s/it]2025-08-23:02:28:17,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8860/12032 [7:53:39<3:00:46,  3.42s/it]2025-08-23:02:28:21,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8861/12032 [7:53:40<2:32:21,  2.88s/it]2025-08-23:02:28:22,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8862/12032 [7:53:44<2:40:43,  3.04s/it]2025-08-23:02:28:26,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8863/12032 [7:53:45<2:16:41,  2.59s/it]2025-08-23:02:28:27,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8864/12032 [7:53:49<2:35:29,  2.94s/it]2025-08-23:02:28:31,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8865/12032 [7:53:53<2:45:01,  3.13s/it]2025-08-23:02:28:35,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8866/12032 [7:53:55<2:24:23,  2.74s/it]2025-08-23:02:28:36,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8867/12032 [7:53:56<2:08:22,  2.43s/it]2025-08-23:02:28:38,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8868/12032 [7:53:59<2:18:46,  2.63s/it]2025-08-23:02:28:41,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8869/12032 [7:54:02<2:11:51,  2.50s/it]2025-08-23:02:28:43,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8870/12032 [7:54:04<2:06:51,  2.41s/it]2025-08-23:02:28:46,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8871/12032 [7:54:07<2:26:41,  2.78s/it]2025-08-23:02:28:49,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8872/12032 [7:54:11<2:42:55,  3.09s/it]2025-08-23:02:28:53,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▎  | 8873/12032 [7:54:12<2:09:09,  2.45s/it]2025-08-23:02:28:54,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8874/12032 [7:54:14<1:59:43,  2.27s/it]2025-08-23:02:28:56,400 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8875/12032 [7:54:15<1:36:49,  1.84s/it]2025-08-23:02:28:57,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8876/12032 [7:54:17<1:43:29,  1.97s/it]2025-08-23:02:28:59,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8877/12032 [7:54:20<1:54:34,  2.18s/it]2025-08-23:02:29:02,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8878/12032 [7:54:21<1:34:13,  1.79s/it]2025-08-23:02:29:03,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8879/12032 [7:54:24<2:05:34,  2.39s/it]2025-08-23:02:29:06,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8880/12032 [7:54:27<2:01:56,  2.32s/it]2025-08-23:02:29:08,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8881/12032 [7:54:30<2:11:14,  2.50s/it]2025-08-23:02:29:11,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8882/12032 [7:54:31<1:47:55,  2.06s/it]2025-08-23:02:29:12,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8883/12032 [7:54:32<1:31:11,  1.74s/it]2025-08-23:02:29:13,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8884/12032 [7:54:33<1:28:22,  1.68s/it]2025-08-23:02:29:15,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8885/12032 [7:54:37<2:01:37,  2.32s/it]2025-08-23:02:29:19,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8886/12032 [7:54:40<2:11:51,  2.51s/it]2025-08-23:02:29:22,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8887/12032 [7:54:44<2:31:26,  2.89s/it]2025-08-23:02:29:26,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8888/12032 [7:54:45<2:01:54,  2.33s/it]2025-08-23:02:29:27,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8889/12032 [7:54:47<1:59:18,  2.28s/it]2025-08-23:02:29:29,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8890/12032 [7:54:51<2:23:49,  2.75s/it]2025-08-23:02:29:33,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8891/12032 [7:54:53<2:22:53,  2.73s/it]2025-08-23:02:29:35,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8892/12032 [7:54:55<2:12:28,  2.53s/it]2025-08-23:02:29:37,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8893/12032 [7:54:57<1:53:55,  2.18s/it]2025-08-23:02:29:39,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8894/12032 [7:54:58<1:32:44,  1.77s/it]2025-08-23:02:29:39,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8895/12032 [7:54:59<1:29:53,  1.72s/it]2025-08-23:02:29:41,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8896/12032 [7:55:00<1:20:24,  1.54s/it]2025-08-23:02:29:42,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8897/12032 [7:55:03<1:43:19,  1.98s/it]2025-08-23:02:29:45,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8898/12032 [7:55:04<1:26:55,  1.66s/it]2025-08-23:02:29:46,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8899/12032 [7:55:05<1:09:19,  1.33s/it]2025-08-23:02:29:47,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8900/12032 [7:55:07<1:27:53,  1.68s/it]2025-08-23:02:29:49,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8901/12032 [7:55:09<1:35:02,  1.82s/it]2025-08-23:02:29:51,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8902/12032 [7:55:13<1:57:27,  2.25s/it]2025-08-23:02:29:55,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8903/12032 [7:55:14<1:36:34,  1.85s/it]2025-08-23:02:29:56,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8904/12032 [7:55:16<1:42:42,  1.97s/it]2025-08-23:02:29:58,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8905/12032 [7:55:17<1:25:36,  1.64s/it]2025-08-23:02:29:59,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8906/12032 [7:55:21<1:59:23,  2.29s/it]2025-08-23:02:30:02,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8907/12032 [7:55:24<2:22:36,  2.74s/it]2025-08-23:02:30:06,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8908/12032 [7:55:27<2:13:07,  2.56s/it]2025-08-23:02:30:08,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8909/12032 [7:55:28<1:59:26,  2.29s/it]2025-08-23:02:30:10,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8910/12032 [7:55:29<1:35:32,  1.84s/it]2025-08-23:02:30:11,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8911/12032 [7:55:33<2:06:00,  2.42s/it]2025-08-23:02:30:15,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8912/12032 [7:55:33<1:38:38,  1.90s/it]2025-08-23:02:30:15,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8913/12032 [7:55:36<1:53:58,  2.19s/it]2025-08-23:02:30:18,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8914/12032 [7:55:39<1:59:43,  2.30s/it]2025-08-23:02:30:21,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8915/12032 [7:55:41<1:50:22,  2.12s/it]2025-08-23:02:30:22,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8916/12032 [7:55:42<1:43:21,  1.99s/it]2025-08-23:02:30:24,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8917/12032 [7:55:46<2:11:07,  2.53s/it]2025-08-23:02:30:28,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8918/12032 [7:55:50<2:27:21,  2.84s/it]2025-08-23:02:30:31,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8919/12032 [7:55:53<2:41:36,  3.11s/it]2025-08-23:02:30:35,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8920/12032 [7:55:57<2:51:19,  3.30s/it]2025-08-23:02:30:39,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8921/12032 [7:56:01<2:53:32,  3.35s/it]2025-08-23:02:30:42,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8922/12032 [7:56:02<2:21:17,  2.73s/it]2025-08-23:02:30:44,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8923/12032 [7:56:03<2:02:58,  2.37s/it]2025-08-23:02:30:45,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8924/12032 [7:56:06<2:10:38,  2.52s/it]2025-08-23:02:30:48,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8925/12032 [7:56:09<2:18:50,  2.68s/it]2025-08-23:02:30:51,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8926/12032 [7:56:11<2:04:31,  2.41s/it]2025-08-23:02:30:53,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8927/12032 [7:56:15<2:26:38,  2.83s/it]2025-08-23:02:30:57,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8928/12032 [7:56:19<2:41:53,  3.13s/it]2025-08-23:02:31:01,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8929/12032 [7:56:22<2:51:32,  3.32s/it]2025-08-23:02:31:04,797 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8930/12032 [7:56:24<2:17:35,  2.66s/it]2025-08-23:02:31:05,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8931/12032 [7:56:24<1:49:11,  2.11s/it]2025-08-23:02:31:06,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8932/12032 [7:56:28<2:16:18,  2.64s/it]2025-08-23:02:31:10,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8933/12032 [7:56:32<2:32:32,  2.95s/it]2025-08-23:02:31:14,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8934/12032 [7:56:36<2:45:06,  3.20s/it]2025-08-23:02:31:18,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8935/12032 [7:56:40<2:53:53,  3.37s/it]2025-08-23:02:31:21,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8936/12032 [7:56:43<2:58:24,  3.46s/it]2025-08-23:02:31:25,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8937/12032 [7:56:47<3:02:13,  3.53s/it]2025-08-23:02:31:29,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8938/12032 [7:56:50<2:53:58,  3.37s/it]2025-08-23:02:31:32,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8939/12032 [7:56:51<2:14:23,  2.61s/it]2025-08-23:02:31:33,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8940/12032 [7:56:55<2:32:55,  2.97s/it]2025-08-23:02:31:36,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8941/12032 [7:56:55<2:01:24,  2.36s/it]2025-08-23:02:31:37,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8942/12032 [7:56:58<2:10:03,  2.53s/it]2025-08-23:02:31:40,703 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8943/12032 [7:57:00<1:52:10,  2.18s/it]2025-08-23:02:31:42,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8944/12032 [7:57:01<1:38:11,  1.91s/it]2025-08-23:02:31:43,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8945/12032 [7:57:02<1:19:29,  1.54s/it]2025-08-23:02:31:44,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8946/12032 [7:57:04<1:37:03,  1.89s/it]2025-08-23:02:31:46,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8947/12032 [7:57:08<2:06:47,  2.47s/it]2025-08-23:02:31:50,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8948/12032 [7:57:11<2:13:20,  2.59s/it]2025-08-23:02:31:53,443 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8949/12032 [7:57:13<1:56:08,  2.26s/it]2025-08-23:02:31:54,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8950/12032 [7:57:16<2:19:28,  2.72s/it]2025-08-23:02:31:58,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8951/12032 [7:57:19<2:17:56,  2.69s/it]2025-08-23:02:32:01,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8952/12032 [7:57:22<2:27:20,  2.87s/it]2025-08-23:02:32:04,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8953/12032 [7:57:26<2:32:54,  2.98s/it]2025-08-23:02:32:07,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8954/12032 [7:57:29<2:38:29,  3.09s/it]2025-08-23:02:32:11,200 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8955/12032 [7:57:33<2:48:41,  3.29s/it]2025-08-23:02:32:14,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8956/12032 [7:57:36<2:55:42,  3.43s/it]2025-08-23:02:32:18,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8957/12032 [7:57:39<2:40:22,  3.13s/it]2025-08-23:02:32:21,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8958/12032 [7:57:41<2:25:36,  2.84s/it]2025-08-23:02:32:23,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8959/12032 [7:57:45<2:38:38,  3.10s/it]2025-08-23:02:32:27,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8960/12032 [7:57:48<2:48:54,  3.30s/it]2025-08-23:02:32:30,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8961/12032 [7:57:50<2:20:07,  2.74s/it]2025-08-23:02:32:32,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8962/12032 [7:57:52<2:06:35,  2.47s/it]2025-08-23:02:32:34,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  74%|███████▍  | 8963/12032 [7:57:53<1:43:53,  2.03s/it]2025-08-23:02:32:35,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8964/12032 [7:57:54<1:25:48,  1.68s/it]2025-08-23:02:32:35,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8965/12032 [7:57:55<1:18:15,  1.53s/it]2025-08-23:02:32:37,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8966/12032 [7:57:59<1:53:00,  2.21s/it]2025-08-23:02:32:40,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8967/12032 [7:58:00<1:35:06,  1.86s/it]2025-08-23:02:32:41,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8968/12032 [7:58:02<1:48:34,  2.13s/it]2025-08-23:02:32:44,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8969/12032 [7:58:04<1:40:31,  1.97s/it]2025-08-23:02:32:46,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8970/12032 [7:58:06<1:45:36,  2.07s/it]2025-08-23:02:32:48,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8971/12032 [7:58:09<1:54:55,  2.25s/it]2025-08-23:02:32:51,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8972/12032 [7:58:10<1:39:08,  1.94s/it]2025-08-23:02:32:52,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8973/12032 [7:58:12<1:37:38,  1.92s/it]2025-08-23:02:32:54,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8974/12032 [7:58:13<1:16:32,  1.50s/it]2025-08-23:02:32:54,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8975/12032 [7:58:14<1:20:07,  1.57s/it]2025-08-23:02:32:56,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8976/12032 [7:58:15<1:08:53,  1.35s/it]2025-08-23:02:32:57,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8977/12032 [7:58:16<1:04:41,  1.27s/it]2025-08-23:02:32:58,539 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8978/12032 [7:58:17<59:01,  1.16s/it]  2025-08-23:02:32:59,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8979/12032 [7:58:18<52:27,  1.03s/it]2025-08-23:02:33:00,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8980/12032 [7:58:20<1:02:43,  1.23s/it]2025-08-23:02:33:01,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8981/12032 [7:58:21<1:01:43,  1.21s/it]2025-08-23:02:33:03,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8982/12032 [7:58:22<1:00:09,  1.18s/it]2025-08-23:02:33:04,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8983/12032 [7:58:22<51:10,  1.01s/it]  2025-08-23:02:33:04,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8984/12032 [7:58:25<1:14:09,  1.46s/it]2025-08-23:02:33:07,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8985/12032 [7:58:28<1:39:24,  1.96s/it]2025-08-23:02:33:10,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8986/12032 [7:58:30<1:45:43,  2.08s/it]2025-08-23:02:33:12,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8987/12032 [7:58:31<1:30:17,  1.78s/it]2025-08-23:02:33:13,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8988/12032 [7:58:35<1:56:23,  2.29s/it]2025-08-23:02:33:17,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48382 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8989/12032 [7:58:36<1:40:55,  1.99s/it]2025-08-23:02:33:18,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8990/12032 [7:58:37<1:26:14,  1.70s/it]2025-08-23:02:33:19,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8991/12032 [7:58:41<1:58:22,  2.34s/it]2025-08-23:02:33:23,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8992/12032 [7:58:45<2:18:10,  2.73s/it]2025-08-23:02:33:27,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8993/12032 [7:58:45<1:43:22,  2.04s/it]2025-08-23:02:33:27,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8994/12032 [7:58:48<1:54:07,  2.25s/it]2025-08-23:02:33:30,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8995/12032 [7:58:48<1:27:49,  1.74s/it]2025-08-23:02:33:30,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8996/12032 [7:58:51<1:34:28,  1.87s/it]2025-08-23:02:33:32,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8997/12032 [7:58:51<1:17:09,  1.53s/it]2025-08-23:02:33:33,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8998/12032 [7:58:52<1:04:04,  1.27s/it]2025-08-23:02:33:34,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 8999/12032 [7:58:53<55:30,  1.10s/it]  2025-08-23:02:33:35,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9000/12032 [7:58:54<53:33,  1.06s/it]2025-08-23:02:33:36,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9001/12032 [7:58:57<1:34:36,  1.87s/it]2025-08-23:02:33:39,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9002/12032 [7:59:00<1:46:43,  2.11s/it]2025-08-23:02:33:42,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9003/12032 [7:59:04<2:11:39,  2.61s/it]2025-08-23:02:33:46,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9004/12032 [7:59:07<2:25:48,  2.89s/it]2025-08-23:02:33:49,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9005/12032 [7:59:11<2:39:26,  3.16s/it]2025-08-23:02:33:53,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9006/12032 [7:59:15<2:48:12,  3.34s/it]2025-08-23:02:33:57,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9007/12032 [7:59:19<2:55:10,  3.47s/it]2025-08-23:02:34:01,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9008/12032 [7:59:23<2:59:37,  3.56s/it]2025-08-23:02:34:04,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9009/12032 [7:59:26<3:02:48,  3.63s/it]2025-08-23:02:34:08,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9010/12032 [7:59:30<3:05:24,  3.68s/it]2025-08-23:02:34:12,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9011/12032 [7:59:31<2:24:56,  2.88s/it]2025-08-23:02:34:13,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9012/12032 [7:59:35<2:39:11,  3.16s/it]2025-08-23:02:34:17,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9013/12032 [7:59:38<2:39:51,  3.18s/it]2025-08-23:02:34:20,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9014/12032 [7:59:40<2:22:32,  2.83s/it]2025-08-23:02:34:22,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9015/12032 [7:59:44<2:36:55,  3.12s/it]2025-08-23:02:34:26,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9016/12032 [7:59:48<2:46:41,  3.32s/it]2025-08-23:02:34:30,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9017/12032 [7:59:49<2:17:56,  2.75s/it]2025-08-23:02:34:31,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9018/12032 [7:59:52<2:15:17,  2.69s/it]2025-08-23:02:34:34,117 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9019/12032 [7:59:55<2:17:10,  2.73s/it]2025-08-23:02:34:36,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9020/12032 [7:59:57<2:13:44,  2.66s/it]2025-08-23:02:34:39,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9021/12032 [8:00:00<2:23:42,  2.86s/it]2025-08-23:02:34:42,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9022/12032 [8:00:01<1:54:03,  2.27s/it]2025-08-23:02:34:43,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▍  | 9023/12032 [8:00:05<2:16:22,  2.72s/it]2025-08-23:02:34:47,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9024/12032 [8:00:07<2:04:27,  2.48s/it]2025-08-23:02:34:49,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9025/12032 [8:00:10<2:19:22,  2.78s/it]2025-08-23:02:34:52,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9026/12032 [8:00:14<2:34:44,  3.09s/it]2025-08-23:02:34:56,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9027/12032 [8:00:16<2:09:15,  2.58s/it]2025-08-23:02:34:58,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9028/12032 [8:00:18<2:06:22,  2.52s/it]2025-08-23:02:35:00,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9029/12032 [8:00:20<1:52:05,  2.24s/it]2025-08-23:02:35:02,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9030/12032 [8:00:21<1:44:47,  2.09s/it]2025-08-23:02:35:03,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9031/12032 [8:00:23<1:37:18,  1.95s/it]2025-08-23:02:35:05,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9032/12032 [8:00:26<1:54:27,  2.29s/it]2025-08-23:02:35:08,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9033/12032 [8:00:27<1:36:44,  1.94s/it]2025-08-23:02:35:09,563 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9034/12032 [8:00:31<2:03:11,  2.47s/it]2025-08-23:02:35:13,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9035/12032 [8:00:32<1:38:49,  1.98s/it]2025-08-23:02:35:14,107 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9036/12032 [8:00:35<2:00:53,  2.42s/it]2025-08-23:02:35:17,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9037/12032 [8:00:39<2:18:29,  2.77s/it]2025-08-23:02:35:21,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9038/12032 [8:00:43<2:33:28,  3.08s/it]2025-08-23:02:35:24,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9039/12032 [8:00:46<2:36:00,  3.13s/it]2025-08-23:02:35:28,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9040/12032 [8:00:49<2:41:03,  3.23s/it]2025-08-23:02:35:31,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9041/12032 [8:00:51<2:18:09,  2.77s/it]2025-08-23:02:35:33,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9042/12032 [8:00:55<2:33:32,  3.08s/it]2025-08-23:02:35:37,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9043/12032 [8:00:59<2:44:10,  3.30s/it]2025-08-23:02:35:40,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9044/12032 [8:01:00<2:17:33,  2.76s/it]2025-08-23:02:35:42,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9045/12032 [8:01:01<1:48:37,  2.18s/it]2025-08-23:02:35:43,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9046/12032 [8:01:02<1:26:29,  1.74s/it]2025-08-23:02:35:44,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9047/12032 [8:01:03<1:16:24,  1.54s/it]2025-08-23:02:35:45,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9048/12032 [8:01:04<1:06:31,  1.34s/it]2025-08-23:02:35:45,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9049/12032 [8:01:05<1:02:37,  1.26s/it]2025-08-23:02:35:47,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9050/12032 [8:01:06<56:12,  1.13s/it]  2025-08-23:02:35:47,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9051/12032 [8:01:06<49:48,  1.00s/it]2025-08-23:02:35:48,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9052/12032 [8:01:07<53:52,  1.08s/it]2025-08-23:02:35:49,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9053/12032 [8:01:11<1:34:09,  1.90s/it]2025-08-23:02:35:53,622 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9054/12032 [8:01:12<1:19:40,  1.61s/it]2025-08-23:02:35:54,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9055/12032 [8:01:16<1:48:35,  2.19s/it]2025-08-23:02:35:58,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9056/12032 [8:01:16<1:23:59,  1.69s/it]2025-08-23:02:35:58,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9057/12032 [8:01:20<1:53:08,  2.28s/it]2025-08-23:02:36:02,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9058/12032 [8:01:22<1:54:02,  2.30s/it]2025-08-23:02:36:04,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9059/12032 [8:01:25<2:04:03,  2.50s/it]2025-08-23:02:36:07,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9060/12032 [8:01:26<1:35:58,  1.94s/it]2025-08-23:02:36:08,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9061/12032 [8:01:28<1:35:56,  1.94s/it]2025-08-23:02:36:10,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9062/12032 [8:01:29<1:18:06,  1.58s/it]2025-08-23:02:36:10,906 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9063/12032 [8:01:30<1:11:36,  1.45s/it]2025-08-23:02:36:12,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9064/12032 [8:01:30<1:00:19,  1.22s/it]2025-08-23:02:36:12,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9065/12032 [8:01:31<52:40,  1.07s/it]  2025-08-23:02:36:13,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9066/12032 [8:01:32<51:11,  1.04s/it]2025-08-23:02:36:14,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9067/12032 [8:01:36<1:32:53,  1.88s/it]2025-08-23:02:36:18,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9068/12032 [8:01:37<1:19:53,  1.62s/it]2025-08-23:02:36:19,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9069/12032 [8:01:40<1:45:51,  2.14s/it]2025-08-23:02:36:22,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9070/12032 [8:01:43<2:00:49,  2.45s/it]2025-08-23:02:36:25,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9071/12032 [8:01:44<1:37:54,  1.98s/it]2025-08-23:02:36:26,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9072/12032 [8:01:46<1:35:30,  1.94s/it]2025-08-23:02:36:28,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9073/12032 [8:01:49<1:43:49,  2.11s/it]2025-08-23:02:36:31,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9074/12032 [8:01:51<1:44:50,  2.13s/it]2025-08-23:02:36:33,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9075/12032 [8:01:55<2:10:24,  2.65s/it]2025-08-23:02:36:37,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9076/12032 [8:01:58<2:19:35,  2.83s/it]2025-08-23:02:36:40,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9077/12032 [8:02:00<2:07:11,  2.58s/it]2025-08-23:02:36:42,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9078/12032 [8:02:04<2:26:05,  2.97s/it]2025-08-23:02:36:46,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9079/12032 [8:02:06<2:19:35,  2.84s/it]2025-08-23:02:36:48,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9080/12032 [8:02:09<2:20:58,  2.87s/it]2025-08-23:02:36:51,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9081/12032 [8:02:13<2:35:35,  3.16s/it]2025-08-23:02:36:55,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9082/12032 [8:02:17<2:45:04,  3.36s/it]2025-08-23:02:36:59,317 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9083/12032 [8:02:20<2:45:56,  3.38s/it]2025-08-23:02:37:02,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  75%|███████▌  | 9084/12032 [8:02:24<2:48:41,  3.43s/it]2025-08-23:02:37:06,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9085/12032 [8:02:28<2:55:19,  3.57s/it]2025-08-23:02:37:10,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9086/12032 [8:02:31<2:47:16,  3.41s/it]2025-08-23:02:37:13,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9087/12032 [8:02:32<2:13:41,  2.72s/it]2025-08-23:02:37:14,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9088/12032 [8:02:35<2:19:25,  2.84s/it]2025-08-23:02:37:17,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9089/12032 [8:02:36<1:52:43,  2.30s/it]2025-08-23:02:37:18,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9090/12032 [8:02:37<1:34:33,  1.93s/it]2025-08-23:02:37:19,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9091/12032 [8:02:41<1:57:11,  2.39s/it]2025-08-23:02:37:23,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9092/12032 [8:02:42<1:35:49,  1.96s/it]2025-08-23:02:37:23,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9093/12032 [8:02:44<1:37:20,  1.99s/it]2025-08-23:02:37:26,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9094/12032 [8:02:45<1:27:39,  1.79s/it]2025-08-23:02:37:27,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9095/12032 [8:02:49<1:57:00,  2.39s/it]2025-08-23:02:37:31,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9096/12032 [8:02:52<2:05:03,  2.56s/it]2025-08-23:02:37:34,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9097/12032 [8:02:56<2:22:53,  2.92s/it]2025-08-23:02:37:37,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9098/12032 [8:02:56<1:53:04,  2.31s/it]2025-08-23:02:37:38,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9099/12032 [8:02:58<1:45:36,  2.16s/it]2025-08-23:02:37:40,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9100/12032 [8:03:01<1:52:13,  2.30s/it]2025-08-23:02:37:43,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9101/12032 [8:03:04<2:02:14,  2.50s/it]2025-08-23:02:37:46,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9102/12032 [8:03:06<2:02:00,  2.50s/it]2025-08-23:02:37:48,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9103/12032 [8:03:08<1:52:12,  2.30s/it]2025-08-23:02:37:50,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9104/12032 [8:03:11<2:01:35,  2.49s/it]2025-08-23:02:37:53,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9105/12032 [8:03:13<1:59:48,  2.46s/it]2025-08-23:02:37:55,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9106/12032 [8:03:16<2:06:07,  2.59s/it]2025-08-23:02:37:58,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9107/12032 [8:03:18<1:46:38,  2.19s/it]2025-08-23:02:37:59,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9108/12032 [8:03:20<1:43:20,  2.12s/it]2025-08-23:02:38:01,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9109/12032 [8:03:23<2:06:29,  2.60s/it]2025-08-23:02:38:05,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9110/12032 [8:03:25<1:50:52,  2.28s/it]2025-08-23:02:38:07,149 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9111/12032 [8:03:27<1:52:17,  2.31s/it]2025-08-23:02:38:09,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9112/12032 [8:03:31<2:15:10,  2.78s/it]2025-08-23:02:38:13,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9113/12032 [8:03:35<2:30:21,  3.09s/it]2025-08-23:02:38:17,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9114/12032 [8:03:36<2:08:18,  2.64s/it]2025-08-23:02:38:18,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9115/12032 [8:03:38<1:47:09,  2.20s/it]2025-08-23:02:38:19,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9116/12032 [8:03:41<2:02:25,  2.52s/it]2025-08-23:02:38:23,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9117/12032 [8:03:42<1:42:13,  2.10s/it]2025-08-23:02:38:24,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9118/12032 [8:03:43<1:22:20,  1.70s/it]2025-08-23:02:38:25,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9119/12032 [8:03:44<1:10:33,  1.45s/it]2025-08-23:02:38:26,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9120/12032 [8:03:45<1:06:37,  1.37s/it]2025-08-23:02:38:27,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9121/12032 [8:03:46<1:00:43,  1.25s/it]2025-08-23:02:38:28,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9122/12032 [8:03:47<1:03:13,  1.30s/it]2025-08-23:02:38:29,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9123/12032 [8:03:48<1:00:03,  1.24s/it]2025-08-23:02:38:30,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9124/12032 [8:03:49<55:32,  1.15s/it]  2025-08-23:02:38:31,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9125/12032 [8:03:50<55:13,  1.14s/it]2025-08-23:02:38:32,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9126/12032 [8:03:51<52:29,  1.08s/it]2025-08-23:02:38:33,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9127/12032 [8:03:52<50:47,  1.05s/it]2025-08-23:02:38:34,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9128/12032 [8:03:53<51:44,  1.07s/it]2025-08-23:02:38:35,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9129/12032 [8:03:57<1:26:19,  1.78s/it]2025-08-23:02:38:39,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9130/12032 [8:03:58<1:20:14,  1.66s/it]2025-08-23:02:38:40,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9131/12032 [8:04:00<1:14:48,  1.55s/it]2025-08-23:02:38:41,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9132/12032 [8:04:01<1:09:26,  1.44s/it]2025-08-23:02:38:43,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9133/12032 [8:04:02<1:10:34,  1.46s/it]2025-08-23:02:38:44,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9134/12032 [8:04:03<1:01:21,  1.27s/it]2025-08-23:02:38:45,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9135/12032 [8:04:07<1:38:29,  2.04s/it]2025-08-23:02:38:49,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9136/12032 [8:04:09<1:33:58,  1.95s/it]2025-08-23:02:38:50,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9137/12032 [8:04:11<1:37:57,  2.03s/it]2025-08-23:02:38:53,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9138/12032 [8:04:12<1:30:41,  1.88s/it]2025-08-23:02:38:54,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9139/12032 [8:04:14<1:31:04,  1.89s/it]2025-08-23:02:38:56,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9140/12032 [8:04:15<1:17:05,  1.60s/it]2025-08-23:02:38:57,556 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9141/12032 [8:04:17<1:26:55,  1.80s/it]2025-08-23:02:38:59,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9142/12032 [8:04:19<1:15:50,  1.57s/it]2025-08-23:02:39:00,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9143/12032 [8:04:19<1:06:33,  1.38s/it]2025-08-23:02:39:01,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9144/12032 [8:04:23<1:41:21,  2.11s/it]2025-08-23:02:39:05,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9145/12032 [8:04:24<1:21:40,  1.70s/it]2025-08-23:02:39:06,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9146/12032 [8:04:27<1:41:30,  2.11s/it]2025-08-23:02:39:09,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9147/12032 [8:04:28<1:21:37,  1.70s/it]2025-08-23:02:39:10,157 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9148/12032 [8:04:31<1:48:41,  2.26s/it]2025-08-23:02:39:13,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9149/12032 [8:04:34<1:49:54,  2.29s/it]2025-08-23:02:39:16,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9150/12032 [8:04:38<2:11:18,  2.73s/it]2025-08-23:02:39:19,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9151/12032 [8:04:40<2:07:32,  2.66s/it]2025-08-23:02:39:22,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9152/12032 [8:04:43<2:09:39,  2.70s/it]2025-08-23:02:39:25,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9153/12032 [8:04:44<1:44:49,  2.18s/it]2025-08-23:02:39:26,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9154/12032 [8:04:45<1:25:59,  1.79s/it]2025-08-23:02:39:26,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9155/12032 [8:04:48<1:54:51,  2.40s/it]2025-08-23:02:39:30,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9156/12032 [8:04:52<2:15:03,  2.82s/it]2025-08-23:02:39:34,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9157/12032 [8:04:55<2:08:12,  2.68s/it]2025-08-23:02:39:36,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9158/12032 [8:04:57<2:08:24,  2.68s/it]2025-08-23:02:39:39,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9159/12032 [8:05:01<2:24:29,  3.02s/it]2025-08-23:02:39:43,442 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9160/12032 [8:05:05<2:36:13,  3.26s/it]2025-08-23:02:39:47,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9161/12032 [8:05:07<2:25:20,  3.04s/it]2025-08-23:02:39:49,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9162/12032 [8:05:11<2:27:37,  3.09s/it]2025-08-23:02:39:52,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9163/12032 [8:05:14<2:35:10,  3.25s/it]2025-08-23:02:39:56,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9164/12032 [8:05:15<1:58:00,  2.47s/it]2025-08-23:02:39:57,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9165/12032 [8:05:16<1:34:33,  1.98s/it]2025-08-23:02:39:58,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9166/12032 [8:05:18<1:37:29,  2.04s/it]2025-08-23:02:40:00,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9167/12032 [8:05:19<1:20:46,  1.69s/it]2025-08-23:02:40:01,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9168/12032 [8:05:23<1:51:34,  2.34s/it]2025-08-23:02:40:05,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9169/12032 [8:05:24<1:32:10,  1.93s/it]2025-08-23:02:40:05,989 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9170/12032 [8:05:25<1:24:14,  1.77s/it]2025-08-23:02:40:07,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9171/12032 [8:05:28<1:42:56,  2.16s/it]2025-08-23:02:40:10,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9172/12032 [8:05:30<1:35:58,  2.01s/it]2025-08-23:02:40:12,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9173/12032 [8:05:31<1:19:33,  1.67s/it]2025-08-23:02:40:12,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▌  | 9174/12032 [8:05:33<1:35:20,  2.00s/it]2025-08-23:02:40:15,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9175/12032 [8:05:35<1:23:59,  1.76s/it]2025-08-23:02:40:16,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9176/12032 [8:05:36<1:15:25,  1.58s/it]2025-08-23:02:40:18,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9177/12032 [8:05:37<1:13:31,  1.55s/it]2025-08-23:02:40:19,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9178/12032 [8:05:39<1:13:41,  1.55s/it]2025-08-23:02:40:21,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9179/12032 [8:05:42<1:31:57,  1.93s/it]2025-08-23:02:40:23,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9180/12032 [8:05:44<1:31:35,  1.93s/it]2025-08-23:02:40:25,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9181/12032 [8:05:47<1:55:04,  2.42s/it]2025-08-23:02:40:29,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9182/12032 [8:05:51<2:14:46,  2.84s/it]2025-08-23:02:40:33,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9183/12032 [8:05:54<2:23:05,  3.01s/it]2025-08-23:02:40:36,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9184/12032 [8:05:55<1:51:05,  2.34s/it]2025-08-23:02:40:37,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9185/12032 [8:05:56<1:31:40,  1.93s/it]2025-08-23:02:40:38,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9186/12032 [8:06:00<1:59:03,  2.51s/it]2025-08-23:02:40:42,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9187/12032 [8:06:03<2:09:04,  2.72s/it]2025-08-23:02:40:45,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9188/12032 [8:06:04<1:41:13,  2.14s/it]2025-08-23:02:40:46,291 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9189/12032 [8:06:08<2:04:38,  2.63s/it]2025-08-23:02:40:50,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9190/12032 [8:06:08<1:37:32,  2.06s/it]2025-08-23:02:40:50,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9191/12032 [8:06:11<1:43:37,  2.19s/it]2025-08-23:02:40:53,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9192/12032 [8:06:14<1:59:29,  2.52s/it]2025-08-23:02:40:56,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9193/12032 [8:06:16<1:42:42,  2.17s/it]2025-08-23:02:40:57,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9194/12032 [8:06:17<1:29:32,  1.89s/it]2025-08-23:02:40:59,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9195/12032 [8:06:21<1:56:56,  2.47s/it]2025-08-23:02:41:03,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9196/12032 [8:06:22<1:39:30,  2.11s/it]2025-08-23:02:41:04,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9197/12032 [8:06:23<1:21:48,  1.73s/it]2025-08-23:02:41:05,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9198/12032 [8:06:23<1:05:22,  1.38s/it]2025-08-23:02:41:05,697 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9199/12032 [8:06:24<55:21,  1.17s/it]  2025-08-23:02:41:06,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9200/12032 [8:06:25<47:25,  1.00s/it]2025-08-23:02:41:06,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9201/12032 [8:06:26<48:17,  1.02s/it]2025-08-23:02:41:08,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9202/12032 [8:06:28<1:11:24,  1.51s/it]2025-08-23:02:41:10,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9203/12032 [8:06:30<1:09:23,  1.47s/it]2025-08-23:02:41:12,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  76%|███████▋  | 9204/12032 [8:06:30<57:03,  1.21s/it]  2025-08-23:02:41:12,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9205/12032 [8:06:31<53:01,  1.13s/it]2025-08-23:02:41:13,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9206/12032 [8:06:35<1:25:27,  1.81s/it]2025-08-23:02:41:17,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9207/12032 [8:06:36<1:11:47,  1.52s/it]2025-08-23:02:41:17,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9208/12032 [8:06:39<1:41:24,  2.15s/it]2025-08-23:02:41:21,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9209/12032 [8:06:43<2:02:04,  2.59s/it]2025-08-23:02:41:25,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9210/12032 [8:06:46<2:11:47,  2.80s/it]2025-08-23:02:41:28,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9211/12032 [8:06:48<1:55:04,  2.45s/it]2025-08-23:02:41:30,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9212/12032 [8:06:52<2:14:23,  2.86s/it]2025-08-23:02:41:33,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9213/12032 [8:06:53<1:57:25,  2.50s/it]2025-08-23:02:41:35,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9214/12032 [8:06:54<1:35:23,  2.03s/it]2025-08-23:02:41:36,458 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9215/12032 [8:06:56<1:32:27,  1.97s/it]2025-08-23:02:41:38,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9216/12032 [8:06:57<1:17:05,  1.64s/it]2025-08-23:02:41:39,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9217/12032 [8:06:59<1:27:38,  1.87s/it]2025-08-23:02:41:41,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9218/12032 [8:07:03<1:55:22,  2.46s/it]2025-08-23:02:41:45,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9219/12032 [8:07:06<1:59:31,  2.55s/it]2025-08-23:02:41:48,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9220/12032 [8:07:09<2:13:44,  2.85s/it]2025-08-23:02:41:51,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9221/12032 [8:07:10<1:47:59,  2.31s/it]2025-08-23:02:41:52,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9222/12032 [8:07:14<2:08:50,  2.75s/it]2025-08-23:02:41:56,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9223/12032 [8:07:17<2:07:23,  2.72s/it]2025-08-23:02:41:59,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9224/12032 [8:07:19<2:05:35,  2.68s/it]2025-08-23:02:42:01,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9225/12032 [8:07:23<2:20:55,  3.01s/it]2025-08-23:02:42:05,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9226/12032 [8:07:24<1:56:24,  2.49s/it]2025-08-23:02:42:06,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9227/12032 [8:07:26<1:35:57,  2.05s/it]2025-08-23:02:42:07,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9228/12032 [8:07:26<1:19:23,  1.70s/it]2025-08-23:02:42:08,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9229/12032 [8:07:27<1:03:03,  1.35s/it]2025-08-23:02:42:09,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9230/12032 [8:07:30<1:21:07,  1.74s/it]2025-08-23:02:42:11,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9231/12032 [8:07:31<1:13:31,  1.58s/it]2025-08-23:02:42:13,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9232/12032 [8:07:35<1:44:45,  2.24s/it]2025-08-23:02:42:16,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9233/12032 [8:07:36<1:34:51,  2.03s/it]2025-08-23:02:42:18,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9234/12032 [8:07:38<1:27:47,  1.88s/it]2025-08-23:02:42:19,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9235/12032 [8:07:39<1:14:48,  1.60s/it]2025-08-23:02:42:20,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9236/12032 [8:07:42<1:35:40,  2.05s/it]2025-08-23:02:42:24,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9237/12032 [8:07:44<1:32:32,  1.99s/it]2025-08-23:02:42:25,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9238/12032 [8:07:47<1:48:05,  2.32s/it]2025-08-23:02:42:28,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9239/12032 [8:07:50<2:08:54,  2.77s/it]2025-08-23:02:42:32,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9240/12032 [8:07:53<2:09:09,  2.78s/it]2025-08-23:02:42:35,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9241/12032 [8:07:54<1:44:02,  2.24s/it]2025-08-23:02:42:36,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9242/12032 [8:07:55<1:28:39,  1.91s/it]2025-08-23:02:42:37,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9243/12032 [8:07:57<1:31:21,  1.97s/it]2025-08-23:02:42:39,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9244/12032 [8:07:58<1:13:59,  1.59s/it]2025-08-23:02:42:40,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9245/12032 [8:08:02<1:44:51,  2.26s/it]2025-08-23:02:42:44,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57956 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9246/12032 [8:08:03<1:33:02,  2.00s/it]2025-08-23:02:42:45,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9247/12032 [8:08:04<1:18:10,  1.68s/it]2025-08-23:02:42:46,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9248/12032 [8:08:06<1:14:45,  1.61s/it]2025-08-23:02:42:48,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9249/12032 [8:08:06<1:01:10,  1.32s/it]2025-08-23:02:42:48,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9250/12032 [8:08:10<1:36:08,  2.07s/it]2025-08-23:02:42:52,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9251/12032 [8:08:11<1:20:44,  1.74s/it]2025-08-23:02:42:53,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9252/12032 [8:08:12<1:08:30,  1.48s/it]2025-08-23:02:42:54,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9253/12032 [8:08:13<1:03:05,  1.36s/it]2025-08-23:02:42:55,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9254/12032 [8:08:17<1:37:27,  2.10s/it]2025-08-23:02:42:59,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9255/12032 [8:08:18<1:23:18,  1.80s/it]2025-08-23:02:43:00,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9256/12032 [8:08:20<1:27:19,  1.89s/it]2025-08-23:02:43:02,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9257/12032 [8:08:21<1:14:46,  1.62s/it]2025-08-23:02:43:03,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9258/12032 [8:08:25<1:44:38,  2.26s/it]2025-08-23:02:43:07,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9259/12032 [8:08:26<1:26:09,  1.86s/it]2025-08-23:02:43:08,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9260/12032 [8:08:30<1:52:31,  2.44s/it]2025-08-23:02:43:11,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9261/12032 [8:08:34<2:12:06,  2.86s/it]2025-08-23:02:43:15,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9262/12032 [8:08:35<1:50:01,  2.38s/it]2025-08-23:02:43:17,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9263/12032 [8:08:36<1:29:28,  1.94s/it]2025-08-23:02:43:18,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9264/12032 [8:08:37<1:15:28,  1.64s/it]2025-08-23:02:43:18,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9265/12032 [8:08:38<1:12:19,  1.57s/it]2025-08-23:02:43:20,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9266/12032 [8:08:39<1:04:11,  1.39s/it]2025-08-23:02:43:21,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9267/12032 [8:08:40<57:15,  1.24s/it]  2025-08-23:02:43:22,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9268/12032 [8:08:41<50:11,  1.09s/it]2025-08-23:02:43:22,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9269/12032 [8:08:41<44:36,  1.03it/s]2025-08-23:02:43:23,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9270/12032 [8:08:45<1:23:26,  1.81s/it]2025-08-23:02:43:27,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9271/12032 [8:08:49<1:50:39,  2.40s/it]2025-08-23:02:43:31,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9272/12032 [8:08:52<2:02:12,  2.66s/it]2025-08-23:02:43:34,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9273/12032 [8:08:56<2:17:54,  3.00s/it]2025-08-23:02:43:38,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9274/12032 [8:08:57<1:52:27,  2.45s/it]2025-08-23:02:43:39,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9275/12032 [8:09:00<1:59:09,  2.59s/it]2025-08-23:02:43:42,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9276/12032 [8:09:04<2:15:43,  2.95s/it]2025-08-23:02:43:46,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9277/12032 [8:09:07<2:24:28,  3.15s/it]2025-08-23:02:43:49,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9278/12032 [8:09:11<2:33:14,  3.34s/it]2025-08-23:02:43:53,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9279/12032 [8:09:13<2:14:24,  2.93s/it]2025-08-23:02:43:55,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9280/12032 [8:09:17<2:26:37,  3.20s/it]2025-08-23:02:43:59,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9281/12032 [8:09:21<2:35:25,  3.39s/it]2025-08-23:02:44:03,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9282/12032 [8:09:24<2:28:44,  3.25s/it]2025-08-23:02:44:06,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9283/12032 [8:09:26<2:08:59,  2.82s/it]2025-08-23:02:44:07,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9284/12032 [8:09:29<2:22:11,  3.10s/it]2025-08-23:02:44:11,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9285/12032 [8:09:33<2:30:37,  3.29s/it]2025-08-23:02:44:15,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9286/12032 [8:09:37<2:37:55,  3.45s/it]2025-08-23:02:44:19,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9287/12032 [8:09:39<2:19:07,  3.04s/it]2025-08-23:02:44:21,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9288/12032 [8:09:42<2:16:35,  2.99s/it]2025-08-23:02:44:24,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9289/12032 [8:09:45<2:25:01,  3.17s/it]2025-08-23:02:44:27,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9290/12032 [8:09:46<1:52:16,  2.46s/it]2025-08-23:02:44:28,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9291/12032 [8:09:48<1:41:03,  2.21s/it]2025-08-23:02:44:30,201 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9292/12032 [8:09:51<1:56:23,  2.55s/it]2025-08-23:02:44:33,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9293/12032 [8:09:53<1:47:26,  2.35s/it]2025-08-23:02:44:35,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9294/12032 [8:09:57<2:04:30,  2.73s/it]2025-08-23:02:44:39,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9295/12032 [8:09:59<2:02:18,  2.68s/it]2025-08-23:02:44:41,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9296/12032 [8:10:01<1:45:56,  2.32s/it]2025-08-23:02:44:43,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9297/12032 [8:10:05<2:06:23,  2.77s/it]2025-08-23:02:44:46,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9298/12032 [8:10:07<2:08:20,  2.82s/it]2025-08-23:02:44:49,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9299/12032 [8:10:10<1:58:13,  2.60s/it]2025-08-23:02:44:51,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9300/12032 [8:10:11<1:35:40,  2.10s/it]2025-08-23:02:44:52,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9301/12032 [8:10:13<1:47:19,  2.36s/it]2025-08-23:02:44:55,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9302/12032 [8:10:17<2:07:32,  2.80s/it]2025-08-23:02:44:59,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9303/12032 [8:10:21<2:21:28,  3.11s/it]2025-08-23:02:45:03,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9304/12032 [8:10:25<2:30:52,  3.32s/it]2025-08-23:02:45:07,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9305/12032 [8:10:29<2:37:37,  3.47s/it]2025-08-23:02:45:11,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9306/12032 [8:10:33<2:42:23,  3.57s/it]2025-08-23:02:45:14,932 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9307/12032 [8:10:34<2:06:28,  2.78s/it]2025-08-23:02:45:15,875 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9308/12032 [8:10:35<1:43:56,  2.29s/it]2025-08-23:02:45:17,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9309/12032 [8:10:39<2:05:03,  2.76s/it]2025-08-23:02:45:20,852 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9310/12032 [8:10:40<1:42:28,  2.26s/it]2025-08-23:02:45:21,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9311/12032 [8:10:41<1:25:25,  1.88s/it]2025-08-23:02:45:22,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9312/12032 [8:10:42<1:15:37,  1.67s/it]2025-08-23:02:45:24,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9313/12032 [8:10:44<1:19:04,  1.74s/it]2025-08-23:02:45:26,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9314/12032 [8:10:45<1:09:22,  1.53s/it]2025-08-23:02:45:27,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9315/12032 [8:10:46<1:04:19,  1.42s/it]2025-08-23:02:45:28,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9316/12032 [8:10:47<1:01:45,  1.36s/it]2025-08-23:02:45:29,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9317/12032 [8:10:48<51:44,  1.14s/it]  2025-08-23:02:45:30,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9318/12032 [8:10:49<47:45,  1.06s/it]2025-08-23:02:45:30,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9319/12032 [8:10:50<45:27,  1.01s/it]2025-08-23:02:45:31,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9320/12032 [8:10:51<45:58,  1.02s/it]2025-08-23:02:45:32,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9321/12032 [8:10:53<1:06:22,  1.47s/it]2025-08-23:02:45:35,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9322/12032 [8:10:54<1:02:17,  1.38s/it]2025-08-23:02:45:36,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9323/12032 [8:10:58<1:35:28,  2.11s/it]2025-08-23:02:45:40,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  77%|███████▋  | 9324/12032 [8:10:59<1:13:45,  1.63s/it]2025-08-23:02:45:40,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9325/12032 [8:11:02<1:42:48,  2.28s/it]2025-08-23:02:45:44,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9326/12032 [8:11:04<1:29:15,  1.98s/it]2025-08-23:02:45:45,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9327/12032 [8:11:06<1:33:44,  2.08s/it]2025-08-23:02:45:48,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9328/12032 [8:11:08<1:37:40,  2.17s/it]2025-08-23:02:45:50,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9329/12032 [8:11:09<1:18:04,  1.73s/it]2025-08-23:02:45:51,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9330/12032 [8:11:10<1:04:29,  1.43s/it]2025-08-23:02:45:52,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9331/12032 [8:11:10<52:57,  1.18s/it]  2025-08-23:02:45:52,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9332/12032 [8:11:11<47:36,  1.06s/it]2025-08-23:02:45:53,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9333/12032 [8:11:14<1:11:50,  1.60s/it]2025-08-23:02:45:56,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9334/12032 [8:11:15<1:08:25,  1.52s/it]2025-08-23:02:45:57,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9335/12032 [8:11:16<1:02:45,  1.40s/it]2025-08-23:02:45:58,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9336/12032 [8:11:18<1:10:52,  1.58s/it]2025-08-23:02:46:00,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9337/12032 [8:11:19<1:01:58,  1.38s/it]2025-08-23:02:46:01,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9338/12032 [8:11:20<57:06,  1.27s/it]  2025-08-23:02:46:02,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9339/12032 [8:11:21<46:00,  1.02s/it]2025-08-23:02:46:03,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9340/12032 [8:11:22<53:26,  1.19s/it]2025-08-23:02:46:04,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9341/12032 [8:11:24<57:51,  1.29s/it]2025-08-23:02:46:06,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9342/12032 [8:11:28<1:32:03,  2.05s/it]2025-08-23:02:46:10,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9343/12032 [8:11:32<1:55:21,  2.57s/it]2025-08-23:02:46:13,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9344/12032 [8:11:35<2:11:42,  2.94s/it]2025-08-23:02:46:17,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9345/12032 [8:11:39<2:23:33,  3.21s/it]2025-08-23:02:46:21,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9346/12032 [8:11:43<2:31:16,  3.38s/it]2025-08-23:02:46:25,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9347/12032 [8:11:44<2:05:27,  2.80s/it]2025-08-23:02:46:26,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9348/12032 [8:11:48<2:09:50,  2.90s/it]2025-08-23:02:46:29,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9349/12032 [8:11:51<2:17:08,  3.07s/it]2025-08-23:02:46:33,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9350/12032 [8:11:55<2:26:43,  3.28s/it]2025-08-23:02:46:37,132 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9351/12032 [8:11:59<2:33:35,  3.44s/it]2025-08-23:02:46:40,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9352/12032 [8:12:02<2:39:12,  3.56s/it]2025-08-23:02:46:44,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9353/12032 [8:12:06<2:42:10,  3.63s/it]2025-08-23:02:46:48,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9354/12032 [8:12:10<2:43:51,  3.67s/it]2025-08-23:02:46:52,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9355/12032 [8:12:12<2:21:39,  3.17s/it]2025-08-23:02:46:54,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9356/12032 [8:12:15<2:22:50,  3.20s/it]2025-08-23:02:46:57,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9357/12032 [8:12:19<2:30:27,  3.37s/it]2025-08-23:02:47:01,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9358/12032 [8:12:21<2:16:59,  3.07s/it]2025-08-23:02:47:03,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9359/12032 [8:12:25<2:19:46,  3.14s/it]2025-08-23:02:47:07,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9360/12032 [8:12:28<2:24:05,  3.24s/it]2025-08-23:02:47:10,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9361/12032 [8:12:32<2:31:21,  3.40s/it]2025-08-23:02:47:14,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9362/12032 [8:12:33<1:56:11,  2.61s/it]2025-08-23:02:47:15,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9363/12032 [8:12:34<1:42:58,  2.31s/it]2025-08-23:02:47:16,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9364/12032 [8:12:37<1:48:26,  2.44s/it]2025-08-23:02:47:19,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9365/12032 [8:12:39<1:42:25,  2.30s/it]2025-08-23:02:47:21,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9366/12032 [8:12:42<1:52:13,  2.53s/it]2025-08-23:02:47:24,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9367/12032 [8:12:43<1:29:24,  2.01s/it]2025-08-23:02:47:25,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9368/12032 [8:12:46<1:47:28,  2.42s/it]2025-08-23:02:47:28,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9369/12032 [8:12:47<1:26:13,  1.94s/it]2025-08-23:02:47:29,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9370/12032 [8:12:50<1:42:55,  2.32s/it]2025-08-23:02:47:32,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9371/12032 [8:12:53<1:44:28,  2.36s/it]2025-08-23:02:47:35,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9372/12032 [8:12:57<2:03:29,  2.79s/it]2025-08-23:02:47:38,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9373/12032 [8:12:57<1:36:58,  2.19s/it]2025-08-23:02:47:39,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9374/12032 [8:13:01<1:57:24,  2.65s/it]2025-08-23:02:47:43,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9375/12032 [8:13:02<1:33:32,  2.11s/it]2025-08-23:02:47:44,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9376/12032 [8:13:03<1:24:48,  1.92s/it]2025-08-23:02:47:45,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9377/12032 [8:13:07<1:49:09,  2.47s/it]2025-08-23:02:47:49,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9378/12032 [8:13:11<2:06:14,  2.85s/it]2025-08-23:02:47:53,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9379/12032 [8:13:15<2:16:42,  3.09s/it]2025-08-23:02:47:56,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9380/12032 [8:13:18<2:26:11,  3.31s/it]2025-08-23:02:48:00,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9381/12032 [8:13:19<1:55:03,  2.60s/it]2025-08-23:02:48:01,678 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9382/12032 [8:13:21<1:38:38,  2.23s/it]2025-08-23:02:48:03,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9383/12032 [8:13:22<1:21:58,  1.86s/it]2025-08-23:02:48:04,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9384/12032 [8:13:25<1:41:33,  2.30s/it]2025-08-23:02:48:07,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9385/12032 [8:13:26<1:22:49,  1.88s/it]2025-08-23:02:48:08,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9386/12032 [8:13:28<1:25:08,  1.93s/it]2025-08-23:02:48:10,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9387/12032 [8:13:29<1:18:45,  1.79s/it]2025-08-23:02:48:11,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9388/12032 [8:13:30<1:04:22,  1.46s/it]2025-08-23:02:48:12,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9389/12032 [8:13:32<1:10:18,  1.60s/it]2025-08-23:02:48:14,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9390/12032 [8:13:33<59:57,  1.36s/it]  2025-08-23:02:48:15,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9391/12032 [8:13:34<53:13,  1.21s/it]2025-08-23:02:48:16,037 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9392/12032 [8:13:35<49:10,  1.12s/it]2025-08-23:02:48:16,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9393/12032 [8:13:35<45:04,  1.02s/it]2025-08-23:02:48:17,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9394/12032 [8:13:37<51:44,  1.18s/it]2025-08-23:02:48:19,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9395/12032 [8:13:38<48:09,  1.10s/it]2025-08-23:02:48:20,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9396/12032 [8:13:39<45:15,  1.03s/it]2025-08-23:02:48:21,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9397/12032 [8:13:39<41:12,  1.07it/s]2025-08-23:02:48:21,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9398/12032 [8:13:41<48:15,  1.10s/it]2025-08-23:02:48:23,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9399/12032 [8:13:43<1:03:39,  1.45s/it]2025-08-23:02:48:25,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9400/12032 [8:13:44<57:43,  1.32s/it]  2025-08-23:02:48:26,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9401/12032 [8:13:45<48:38,  1.11s/it]2025-08-23:02:48:27,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9402/12032 [8:13:46<51:51,  1.18s/it]2025-08-23:02:48:28,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9403/12032 [8:13:47<45:03,  1.03s/it]2025-08-23:02:48:29,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9404/12032 [8:13:49<1:04:25,  1.47s/it]2025-08-23:02:48:31,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9405/12032 [8:13:50<59:04,  1.35s/it]  2025-08-23:02:48:32,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9406/12032 [8:13:51<50:09,  1.15s/it]2025-08-23:02:48:33,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9407/12032 [8:13:52<48:10,  1.10s/it]2025-08-23:02:48:34,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9408/12032 [8:13:53<49:14,  1.13s/it]2025-08-23:02:48:35,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36532 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9409/12032 [8:13:54<45:02,  1.03s/it]2025-08-23:02:48:36,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9410/12032 [8:13:55<44:05,  1.01s/it]2025-08-23:02:48:37,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9411/12032 [8:13:56<48:45,  1.12s/it]2025-08-23:02:48:38,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9412/12032 [8:13:57<41:42,  1.05it/s]2025-08-23:02:48:39,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9413/12032 [8:13:58<44:37,  1.02s/it]2025-08-23:02:48:40,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9414/12032 [8:13:59<44:37,  1.02s/it]2025-08-23:02:48:41,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9415/12032 [8:14:01<54:35,  1.25s/it]2025-08-23:02:48:43,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9416/12032 [8:14:02<45:17,  1.04s/it]2025-08-23:02:48:43,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9417/12032 [8:14:03<47:47,  1.10s/it]2025-08-23:02:48:45,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9418/12032 [8:14:07<1:23:48,  1.92s/it]2025-08-23:02:48:48,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9419/12032 [8:14:10<1:48:14,  2.49s/it]2025-08-23:02:48:52,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9420/12032 [8:14:14<2:05:25,  2.88s/it]2025-08-23:02:48:56,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9421/12032 [8:14:18<2:18:48,  3.19s/it]2025-08-23:02:49:00,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9422/12032 [8:14:21<2:12:23,  3.04s/it]2025-08-23:02:49:03,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9423/12032 [8:14:22<1:43:14,  2.37s/it]2025-08-23:02:49:03,958 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9424/12032 [8:14:25<1:51:18,  2.56s/it]2025-08-23:02:49:06,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9425/12032 [8:14:28<2:06:59,  2.92s/it]2025-08-23:02:49:10,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9426/12032 [8:14:31<1:59:42,  2.76s/it]2025-08-23:02:49:13,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9427/12032 [8:14:35<2:12:52,  3.06s/it]2025-08-23:02:49:16,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9428/12032 [8:14:38<2:22:32,  3.28s/it]2025-08-23:02:49:20,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9429/12032 [8:14:42<2:30:34,  3.47s/it]2025-08-23:02:49:24,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9430/12032 [8:14:43<1:56:33,  2.69s/it]2025-08-23:02:49:25,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9431/12032 [8:14:45<1:51:23,  2.57s/it]2025-08-23:02:49:27,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9432/12032 [8:14:48<1:57:58,  2.72s/it]2025-08-23:02:49:30,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9433/12032 [8:14:49<1:33:19,  2.15s/it]2025-08-23:02:49:31,636 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9434/12032 [8:14:50<1:15:44,  1.75s/it]2025-08-23:02:49:32,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9435/12032 [8:14:54<1:39:43,  2.30s/it]2025-08-23:02:49:36,037 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9436/12032 [8:14:57<1:58:54,  2.75s/it]2025-08-23:02:49:39,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9437/12032 [8:15:01<2:12:22,  3.06s/it]2025-08-23:02:49:43,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9438/12032 [8:15:05<2:21:21,  3.27s/it]2025-08-23:02:49:47,369 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9439/12032 [8:15:09<2:27:26,  3.41s/it]2025-08-23:02:49:51,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9440/12032 [8:15:10<2:02:45,  2.84s/it]2025-08-23:02:49:52,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9441/12032 [8:15:13<2:01:00,  2.80s/it]2025-08-23:02:49:55,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9442/12032 [8:15:15<1:53:20,  2.63s/it]2025-08-23:02:49:57,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9443/12032 [8:15:19<2:08:31,  2.98s/it]2025-08-23:02:50:01,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9444/12032 [8:15:21<2:01:24,  2.81s/it]2025-08-23:02:50:03,781 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  78%|███████▊  | 9445/12032 [8:15:23<1:50:42,  2.57s/it]2025-08-23:02:50:05,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9446/12032 [8:15:27<2:07:30,  2.96s/it]2025-08-23:02:50:09,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9447/12032 [8:15:31<2:17:41,  3.20s/it]2025-08-23:02:50:13,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9448/12032 [8:15:35<2:25:48,  3.39s/it]2025-08-23:02:50:17,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9449/12032 [8:15:36<1:56:15,  2.70s/it]2025-08-23:02:50:18,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9450/12032 [8:15:38<1:53:48,  2.64s/it]2025-08-23:02:50:20,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9451/12032 [8:15:39<1:31:43,  2.13s/it]2025-08-23:02:50:21,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9452/12032 [8:15:42<1:40:48,  2.34s/it]2025-08-23:02:50:24,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9453/12032 [8:15:43<1:20:07,  1.86s/it]2025-08-23:02:50:25,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9454/12032 [8:15:47<1:45:50,  2.46s/it]2025-08-23:02:50:29,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9455/12032 [8:15:48<1:32:24,  2.15s/it]2025-08-23:02:50:30,642 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9456/12032 [8:15:51<1:36:47,  2.25s/it]2025-08-23:02:50:33,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9457/12032 [8:15:52<1:16:57,  1.79s/it]2025-08-23:02:50:33,854 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9458/12032 [8:15:52<1:03:47,  1.49s/it]2025-08-23:02:50:34,626 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9459/12032 [8:15:54<1:09:18,  1.62s/it]2025-08-23:02:50:36,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9460/12032 [8:15:55<56:08,  1.31s/it]  2025-08-23:02:50:37,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9461/12032 [8:15:58<1:24:40,  1.98s/it]2025-08-23:02:50:40,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9462/12032 [8:15:59<1:12:03,  1.68s/it]2025-08-23:02:50:41,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9463/12032 [8:16:01<1:10:10,  1.64s/it]2025-08-23:02:50:43,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9464/12032 [8:16:02<1:01:01,  1.43s/it]2025-08-23:02:50:44,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9465/12032 [8:16:06<1:32:07,  2.15s/it]2025-08-23:02:50:47,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9466/12032 [8:16:06<1:13:25,  1.72s/it]2025-08-23:02:50:48,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9467/12032 [8:16:07<59:21,  1.39s/it]  2025-08-23:02:50:49,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9468/12032 [8:16:08<54:41,  1.28s/it]2025-08-23:02:50:50,330 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9469/12032 [8:16:10<1:02:45,  1.47s/it]2025-08-23:02:50:52,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9470/12032 [8:16:11<52:35,  1.23s/it]  2025-08-23:02:50:52,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9471/12032 [8:16:12<56:01,  1.31s/it]2025-08-23:02:50:54,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9472/12032 [8:16:13<57:13,  1.34s/it]2025-08-23:02:50:55,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9473/12032 [8:16:18<1:31:47,  2.15s/it]2025-08-23:02:50:59,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9474/12032 [8:16:22<1:56:11,  2.73s/it]2025-08-23:02:51:03,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▊  | 9475/12032 [8:16:26<2:14:40,  3.16s/it]2025-08-23:02:51:08,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9476/12032 [8:16:30<2:25:06,  3.41s/it]2025-08-23:02:51:12,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9477/12032 [8:16:34<2:31:30,  3.56s/it]2025-08-23:02:51:16,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9478/12032 [8:16:38<2:37:07,  3.69s/it]2025-08-23:02:51:20,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9479/12032 [8:16:41<2:33:56,  3.62s/it]2025-08-23:02:51:23,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9480/12032 [8:16:45<2:35:57,  3.67s/it]2025-08-23:02:51:27,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9481/12032 [8:16:46<2:04:50,  2.94s/it]2025-08-23:02:51:28,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9482/12032 [8:16:50<2:15:38,  3.19s/it]2025-08-23:02:51:32,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9483/12032 [8:16:52<1:57:18,  2.76s/it]2025-08-23:02:51:34,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9484/12032 [8:16:55<2:10:34,  3.07s/it]2025-08-23:02:51:37,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9485/12032 [8:16:59<2:20:13,  3.30s/it]2025-08-23:02:51:41,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9486/12032 [8:17:00<1:48:41,  2.56s/it]2025-08-23:02:51:42,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9487/12032 [8:17:02<1:37:32,  2.30s/it]2025-08-23:02:51:44,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9488/12032 [8:17:05<1:46:45,  2.52s/it]2025-08-23:02:51:47,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9489/12032 [8:17:06<1:29:06,  2.10s/it]2025-08-23:02:51:48,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9490/12032 [8:17:07<1:11:07,  1.68s/it]2025-08-23:02:51:49,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9491/12032 [8:17:10<1:33:39,  2.21s/it]2025-08-23:02:51:52,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9492/12032 [8:17:11<1:17:03,  1.82s/it]2025-08-23:02:51:53,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9493/12032 [8:17:15<1:42:21,  2.42s/it]2025-08-23:02:51:57,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9494/12032 [8:17:17<1:33:28,  2.21s/it]2025-08-23:02:51:58,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9495/12032 [8:17:18<1:20:45,  1.91s/it]2025-08-23:02:52:00,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9496/12032 [8:17:19<1:12:25,  1.71s/it]2025-08-23:02:52:01,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9497/12032 [8:17:23<1:38:31,  2.33s/it]2025-08-23:02:52:05,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9498/12032 [8:17:24<1:21:49,  1.94s/it]2025-08-23:02:52:06,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9499/12032 [8:17:28<1:45:22,  2.50s/it]2025-08-23:02:52:09,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9500/12032 [8:17:29<1:25:51,  2.03s/it]2025-08-23:02:52:10,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9501/12032 [8:17:32<1:43:47,  2.46s/it]2025-08-23:02:52:14,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9502/12032 [8:17:33<1:23:42,  1.99s/it]2025-08-23:02:52:15,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9503/12032 [8:17:34<1:17:52,  1.85s/it]2025-08-23:02:52:16,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9504/12032 [8:17:35<1:00:43,  1.44s/it]2025-08-23:02:52:17,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9505/12032 [8:17:37<1:09:25,  1.65s/it]2025-08-23:02:52:19,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9506/12032 [8:17:40<1:23:59,  2.00s/it]2025-08-23:02:52:22,222 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9507/12032 [8:17:41<1:13:45,  1.75s/it]2025-08-23:02:52:23,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9508/12032 [8:17:42<59:42,  1.42s/it]  2025-08-23:02:52:24,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9509/12032 [8:17:43<52:50,  1.26s/it]2025-08-23:02:52:24,927 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9510/12032 [8:17:44<48:33,  1.16s/it]2025-08-23:02:52:25,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9511/12032 [8:17:45<48:21,  1.15s/it]2025-08-23:02:52:26,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9512/12032 [8:17:46<49:52,  1.19s/it]2025-08-23:02:52:28,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9513/12032 [8:17:47<49:46,  1.19s/it]2025-08-23:02:52:29,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9514/12032 [8:17:48<45:02,  1.07s/it]2025-08-23:02:52:30,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9515/12032 [8:17:49<48:44,  1.16s/it]2025-08-23:02:52:31,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9516/12032 [8:17:53<1:21:51,  1.95s/it]2025-08-23:02:52:35,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9517/12032 [8:17:57<1:45:46,  2.52s/it]2025-08-23:02:52:39,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9518/12032 [8:18:01<2:01:27,  2.90s/it]2025-08-23:02:52:43,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9519/12032 [8:18:04<2:12:16,  3.16s/it]2025-08-23:02:52:46,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9520/12032 [8:18:08<2:20:11,  3.35s/it]2025-08-23:02:52:50,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9521/12032 [8:18:12<2:25:04,  3.47s/it]2025-08-23:02:52:54,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9522/12032 [8:18:15<2:15:07,  3.23s/it]2025-08-23:02:52:57,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9523/12032 [8:18:18<2:21:51,  3.39s/it]2025-08-23:02:53:00,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9524/12032 [8:18:22<2:26:37,  3.51s/it]2025-08-23:02:53:04,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9525/12032 [8:18:26<2:30:58,  3.61s/it]2025-08-23:02:53:08,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9526/12032 [8:18:27<1:59:12,  2.85s/it]2025-08-23:02:53:09,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9527/12032 [8:18:30<2:00:09,  2.88s/it]2025-08-23:02:53:12,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9528/12032 [8:18:32<1:42:49,  2.46s/it]2025-08-23:02:53:13,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9529/12032 [8:18:33<1:32:03,  2.21s/it]2025-08-23:02:53:15,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9530/12032 [8:18:37<1:51:14,  2.67s/it]2025-08-23:02:53:19,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9531/12032 [8:18:38<1:28:27,  2.12s/it]2025-08-23:02:53:20,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9532/12032 [8:18:42<1:49:50,  2.64s/it]2025-08-23:02:53:23,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9533/12032 [8:18:44<1:48:23,  2.60s/it]2025-08-23:02:53:26,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9534/12032 [8:18:47<1:54:06,  2.74s/it]2025-08-23:02:53:29,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9535/12032 [8:18:48<1:28:22,  2.12s/it]2025-08-23:02:53:30,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9536/12032 [8:18:49<1:16:23,  1.84s/it]2025-08-23:02:53:31,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9537/12032 [8:18:50<1:02:55,  1.51s/it]2025-08-23:02:53:32,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9538/12032 [8:18:50<52:12,  1.26s/it]  2025-08-23:02:53:32,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9539/12032 [8:18:51<48:51,  1.18s/it]2025-08-23:02:53:33,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9540/12032 [8:18:53<48:58,  1.18s/it]2025-08-23:02:53:35,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9541/12032 [8:18:56<1:21:11,  1.96s/it]2025-08-23:02:53:38,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9542/12032 [8:18:58<1:21:16,  1.96s/it]2025-08-23:02:53:40,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9543/12032 [8:19:00<1:22:42,  1.99s/it]2025-08-23:02:53:42,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9544/12032 [8:19:04<1:46:13,  2.56s/it]2025-08-23:02:53:46,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9545/12032 [8:19:06<1:31:08,  2.20s/it]2025-08-23:02:53:48,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9546/12032 [8:19:08<1:31:54,  2.22s/it]2025-08-23:02:53:50,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9547/12032 [8:19:11<1:46:28,  2.57s/it]2025-08-23:02:53:53,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9548/12032 [8:19:12<1:27:09,  2.11s/it]2025-08-23:02:53:54,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9549/12032 [8:19:14<1:16:42,  1.85s/it]2025-08-23:02:53:56,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9550/12032 [8:19:15<1:06:51,  1.62s/it]2025-08-23:02:53:57,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9551/12032 [8:19:17<1:20:50,  1.96s/it]2025-08-23:02:53:59,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9552/12032 [8:19:19<1:13:07,  1.77s/it]2025-08-23:02:54:01,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9553/12032 [8:19:20<1:02:32,  1.51s/it]2025-08-23:02:54:02,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9554/12032 [8:19:23<1:28:12,  2.14s/it]2025-08-23:02:54:05,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9555/12032 [8:19:27<1:48:24,  2.63s/it]2025-08-23:02:54:09,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9556/12032 [8:19:29<1:33:46,  2.27s/it]2025-08-23:02:54:10,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9557/12032 [8:19:32<1:52:46,  2.73s/it]2025-08-23:02:54:14,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9558/12032 [8:19:34<1:38:24,  2.39s/it]2025-08-23:02:54:16,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9559/12032 [8:19:37<1:44:30,  2.54s/it]2025-08-23:02:54:19,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9560/12032 [8:19:41<1:59:46,  2.91s/it]2025-08-23:02:54:22,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9561/12032 [8:19:42<1:43:13,  2.51s/it]2025-08-23:02:54:24,482 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9562/12032 [8:19:46<1:58:43,  2.88s/it]2025-08-23:02:54:28,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9563/12032 [8:19:50<2:10:32,  3.17s/it]2025-08-23:02:54:32,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9564/12032 [8:19:51<1:45:18,  2.56s/it]2025-08-23:02:54:33,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  79%|███████▉  | 9565/12032 [8:19:52<1:32:23,  2.25s/it]2025-08-23:02:54:34,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9566/12032 [8:19:56<1:50:52,  2.70s/it]2025-08-23:02:54:38,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9567/12032 [8:20:00<2:04:06,  3.02s/it]2025-08-23:02:54:42,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9568/12032 [8:20:04<2:13:00,  3.24s/it]2025-08-23:02:54:46,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9569/12032 [8:20:07<2:19:37,  3.40s/it]2025-08-23:02:54:49,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9570/12032 [8:20:10<2:03:17,  3.00s/it]2025-08-23:02:54:51,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9571/12032 [8:20:10<1:33:44,  2.29s/it]2025-08-23:02:54:52,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9572/12032 [8:20:12<1:23:10,  2.03s/it]2025-08-23:02:54:53,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9573/12032 [8:20:15<1:43:56,  2.54s/it]2025-08-23:02:54:57,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9574/12032 [8:20:17<1:29:34,  2.19s/it]2025-08-23:02:54:58,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9575/12032 [8:20:20<1:43:38,  2.53s/it]2025-08-23:02:55:02,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9576/12032 [8:20:21<1:27:49,  2.15s/it]2025-08-23:02:55:03,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9577/12032 [8:20:22<1:12:57,  1.78s/it]2025-08-23:02:55:04,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9578/12032 [8:20:26<1:34:35,  2.31s/it]2025-08-23:02:55:08,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9579/12032 [8:20:28<1:30:19,  2.21s/it]2025-08-23:02:55:10,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9580/12032 [8:20:28<1:11:26,  1.75s/it]2025-08-23:02:55:10,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9581/12032 [8:20:29<57:34,  1.41s/it]  2025-08-23:02:55:11,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9582/12032 [8:20:30<55:50,  1.37s/it]2025-08-23:02:55:12,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9583/12032 [8:20:31<47:58,  1.18s/it]2025-08-23:02:55:13,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9584/12032 [8:20:32<46:06,  1.13s/it]2025-08-23:02:55:14,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9585/12032 [8:20:33<41:12,  1.01s/it]2025-08-23:02:55:15,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9586/12032 [8:20:34<39:28,  1.03it/s]2025-08-23:02:55:15,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9587/12032 [8:20:34<38:01,  1.07it/s]2025-08-23:02:55:16,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9588/12032 [8:20:36<40:53,  1.00s/it]2025-08-23:02:55:17,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9589/12032 [8:20:37<40:08,  1.01it/s]2025-08-23:02:55:18,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9590/12032 [8:20:38<42:41,  1.05s/it]2025-08-23:02:55:20,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9591/12032 [8:20:39<47:54,  1.18s/it]2025-08-23:02:55:21,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9592/12032 [8:20:42<1:07:31,  1.66s/it]2025-08-23:02:55:24,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9593/12032 [8:20:43<1:05:01,  1.60s/it]2025-08-23:02:55:25,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9594/12032 [8:20:44<57:33,  1.42s/it]  2025-08-23:02:55:26,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9595/12032 [8:20:48<1:27:11,  2.15s/it]2025-08-23:02:55:30,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9596/12032 [8:20:50<1:21:02,  2.00s/it]2025-08-23:02:55:32,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9597/12032 [8:20:54<1:41:46,  2.51s/it]2025-08-23:02:55:36,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9598/12032 [8:20:55<1:30:34,  2.23s/it]2025-08-23:02:55:37,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9599/12032 [8:20:56<1:15:06,  1.85s/it]2025-08-23:02:55:38,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9600/12032 [8:20:57<1:03:54,  1.58s/it]2025-08-23:02:55:39,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9601/12032 [8:20:58<59:15,  1.46s/it]  2025-08-23:02:55:40,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9602/12032 [8:20:59<54:04,  1.34s/it]2025-08-23:02:55:41,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9603/12032 [8:21:00<47:30,  1.17s/it]2025-08-23:02:55:42,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9604/12032 [8:21:04<1:20:09,  1.98s/it]2025-08-23:02:55:46,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9605/12032 [8:21:08<1:42:50,  2.54s/it]2025-08-23:02:55:50,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9606/12032 [8:21:10<1:32:14,  2.28s/it]2025-08-23:02:55:51,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9607/12032 [8:21:13<1:49:32,  2.71s/it]2025-08-23:02:55:55,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9608/12032 [8:21:17<2:03:36,  3.06s/it]2025-08-23:02:55:59,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9609/12032 [8:21:20<2:01:48,  3.02s/it]2025-08-23:02:56:02,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9610/12032 [8:21:23<2:00:54,  3.00s/it]2025-08-23:02:56:05,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9611/12032 [8:21:27<2:10:34,  3.24s/it]2025-08-23:02:56:09,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9612/12032 [8:21:31<2:17:16,  3.40s/it]2025-08-23:02:56:12,965 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9613/12032 [8:21:34<2:22:13,  3.53s/it]2025-08-23:02:56:16,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9614/12032 [8:21:38<2:26:10,  3.63s/it]2025-08-23:02:56:20,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9615/12032 [8:21:42<2:27:56,  3.67s/it]2025-08-23:02:56:24,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9616/12032 [8:21:46<2:28:41,  3.69s/it]2025-08-23:02:56:28,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9617/12032 [8:21:49<2:25:52,  3.62s/it]2025-08-23:02:56:31,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9618/12032 [8:21:53<2:28:38,  3.69s/it]2025-08-23:02:56:35,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9619/12032 [8:21:55<2:07:56,  3.18s/it]2025-08-23:02:56:37,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9620/12032 [8:21:58<2:01:39,  3.03s/it]2025-08-23:02:56:40,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9621/12032 [8:22:01<1:58:57,  2.96s/it]2025-08-23:02:56:42,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9622/12032 [8:22:04<2:08:38,  3.20s/it]2025-08-23:02:56:46,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9623/12032 [8:22:05<1:39:12,  2.47s/it]2025-08-23:02:56:47,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9624/12032 [8:22:09<1:54:40,  2.86s/it]2025-08-23:02:56:51,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|███████▉  | 9625/12032 [8:22:10<1:29:39,  2.24s/it]2025-08-23:02:56:52,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9626/12032 [8:22:12<1:36:33,  2.41s/it]2025-08-23:02:56:54,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9627/12032 [8:22:15<1:32:30,  2.31s/it]2025-08-23:02:56:56,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9628/12032 [8:22:15<1:14:03,  1.85s/it]2025-08-23:02:56:57,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9629/12032 [8:22:17<1:08:10,  1.70s/it]2025-08-23:02:56:59,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9630/12032 [8:22:18<1:02:10,  1.55s/it]2025-08-23:02:57:00,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9631/12032 [8:22:19<53:52,  1.35s/it]  2025-08-23:02:57:01,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9632/12032 [8:22:19<45:35,  1.14s/it]2025-08-23:02:57:01,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9633/12032 [8:22:23<1:17:21,  1.93s/it]2025-08-23:02:57:05,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9634/12032 [8:22:24<1:02:34,  1.57s/it]2025-08-23:02:57:06,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9635/12032 [8:22:25<51:42,  1.29s/it]  2025-08-23:02:57:06,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9636/12032 [8:22:27<59:43,  1.50s/it]2025-08-23:02:57:08,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9637/12032 [8:22:28<59:09,  1.48s/it]2025-08-23:02:57:10,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9638/12032 [8:22:32<1:27:10,  2.18s/it]2025-08-23:02:57:14,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9639/12032 [8:22:36<1:46:35,  2.67s/it]2025-08-23:02:57:17,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9640/12032 [8:22:39<1:59:35,  3.00s/it]2025-08-23:02:57:21,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9641/12032 [8:22:41<1:40:10,  2.51s/it]2025-08-23:02:57:23,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9642/12032 [8:22:45<1:55:17,  2.89s/it]2025-08-23:02:57:26,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9643/12032 [8:22:48<2:05:48,  3.16s/it]2025-08-23:02:57:30,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9644/12032 [8:22:52<2:13:39,  3.36s/it]2025-08-23:02:57:34,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9645/12032 [8:22:56<2:18:49,  3.49s/it]2025-08-23:02:57:38,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9646/12032 [8:23:00<2:22:31,  3.58s/it]2025-08-23:02:57:42,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9647/12032 [8:23:04<2:25:18,  3.66s/it]2025-08-23:02:57:45,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9648/12032 [8:23:07<2:24:11,  3.63s/it]2025-08-23:02:57:49,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9649/12032 [8:23:11<2:26:13,  3.68s/it]2025-08-23:02:57:53,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9650/12032 [8:23:15<2:27:38,  3.72s/it]2025-08-23:02:57:57,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9651/12032 [8:23:17<2:08:28,  3.24s/it]2025-08-23:02:57:59,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9652/12032 [8:23:19<2:00:12,  3.03s/it]2025-08-23:02:58:01,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9653/12032 [8:23:23<2:08:57,  3.25s/it]2025-08-23:02:58:05,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9654/12032 [8:23:25<1:57:15,  2.96s/it]2025-08-23:02:58:07,800 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9655/12032 [8:23:29<2:07:22,  3.22s/it]2025-08-23:02:58:11,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9656/12032 [8:23:30<1:37:50,  2.47s/it]2025-08-23:02:58:12,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9657/12032 [8:23:34<1:53:26,  2.87s/it]2025-08-23:02:58:16,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9658/12032 [8:23:35<1:31:25,  2.31s/it]2025-08-23:02:58:17,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9659/12032 [8:23:38<1:43:49,  2.63s/it]2025-08-23:02:58:20,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9660/12032 [8:23:41<1:51:00,  2.81s/it]2025-08-23:02:58:23,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9661/12032 [8:23:45<2:02:40,  3.10s/it]2025-08-23:02:58:27,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9662/12032 [8:23:48<1:53:30,  2.87s/it]2025-08-23:02:58:29,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9663/12032 [8:23:48<1:26:22,  2.19s/it]2025-08-23:02:58:30,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9664/12032 [8:23:49<1:07:53,  1.72s/it]2025-08-23:02:58:31,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9665/12032 [8:23:49<56:06,  1.42s/it]  2025-08-23:02:58:31,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9666/12032 [8:23:53<1:22:15,  2.09s/it]2025-08-23:02:58:35,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9667/12032 [8:23:57<1:41:55,  2.59s/it]2025-08-23:02:58:39,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9668/12032 [8:24:00<1:51:53,  2.84s/it]2025-08-23:02:58:42,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9669/12032 [8:24:02<1:33:26,  2.37s/it]2025-08-23:02:58:43,921 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9670/12032 [8:24:05<1:40:51,  2.56s/it]2025-08-23:02:58:46,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9671/12032 [8:24:06<1:24:17,  2.14s/it]2025-08-23:02:58:48,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9672/12032 [8:24:08<1:20:54,  2.06s/it]2025-08-23:02:58:49,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9673/12032 [8:24:09<1:17:26,  1.97s/it]2025-08-23:02:58:51,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9674/12032 [8:24:11<1:10:40,  1.80s/it]2025-08-23:02:58:53,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9675/12032 [8:24:12<1:02:54,  1.60s/it]2025-08-23:02:58:54,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9676/12032 [8:24:16<1:28:45,  2.26s/it]2025-08-23:02:58:58,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9677/12032 [8:24:17<1:14:42,  1.90s/it]2025-08-23:02:58:59,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9678/12032 [8:24:18<1:06:47,  1.70s/it]2025-08-23:02:59:00,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9679/12032 [8:24:19<56:16,  1.43s/it]  2025-08-23:02:59:01,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9680/12032 [8:24:20<49:31,  1.26s/it]2025-08-23:02:59:02,029 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9681/12032 [8:24:22<56:53,  1.45s/it]2025-08-23:02:59:03,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9682/12032 [8:24:23<57:23,  1.47s/it]2025-08-23:02:59:05,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9683/12032 [8:24:24<45:58,  1.17s/it]2025-08-23:02:59:05,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9684/12032 [8:24:27<1:07:36,  1.73s/it]2025-08-23:02:59:08,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  80%|████████  | 9685/12032 [8:24:27<55:41,  1.42s/it]  2025-08-23:02:59:09,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9686/12032 [8:24:29<1:01:28,  1.57s/it]2025-08-23:02:59:11,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9687/12032 [8:24:32<1:17:27,  1.98s/it]2025-08-23:02:59:14,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9688/12032 [8:24:36<1:38:28,  2.52s/it]2025-08-23:02:59:18,279 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9689/12032 [8:24:40<1:53:29,  2.91s/it]2025-08-23:02:59:22,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9690/12032 [8:24:42<1:43:35,  2.65s/it]2025-08-23:02:59:24,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9691/12032 [8:24:46<1:56:43,  2.99s/it]2025-08-23:02:59:27,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9692/12032 [8:24:49<2:05:38,  3.22s/it]2025-08-23:02:59:31,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9693/12032 [8:24:53<2:12:21,  3.40s/it]2025-08-23:02:59:35,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9694/12032 [8:24:57<2:18:17,  3.55s/it]2025-08-23:02:59:39,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9695/12032 [8:24:59<2:01:09,  3.11s/it]2025-08-23:02:59:41,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9696/12032 [8:25:02<2:02:19,  3.14s/it]2025-08-23:02:59:44,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9697/12032 [8:25:04<1:42:37,  2.64s/it]2025-08-23:02:59:46,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9698/12032 [8:25:08<1:56:23,  2.99s/it]2025-08-23:02:59:49,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9699/12032 [8:25:09<1:33:22,  2.40s/it]2025-08-23:02:59:51,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9700/12032 [8:25:10<1:19:13,  2.04s/it]2025-08-23:02:59:52,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9701/12032 [8:25:14<1:39:56,  2.57s/it]2025-08-23:02:59:56,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9702/12032 [8:25:17<1:53:05,  2.91s/it]2025-08-23:02:59:59,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9703/12032 [8:25:21<2:03:58,  3.19s/it]2025-08-23:03:00:03,567 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9704/12032 [8:25:24<1:59:17,  3.07s/it]2025-08-23:03:00:06,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9705/12032 [8:25:26<1:46:34,  2.75s/it]2025-08-23:03:00:08,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9706/12032 [8:25:27<1:31:42,  2.37s/it]2025-08-23:03:00:09,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9707/12032 [8:25:31<1:46:51,  2.76s/it]2025-08-23:03:00:13,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9708/12032 [8:25:32<1:27:21,  2.26s/it]2025-08-23:03:00:14,579 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9709/12032 [8:25:33<1:09:37,  1.80s/it]2025-08-23:03:00:15,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9710/12032 [8:25:34<55:44,  1.44s/it]  2025-08-23:03:00:15,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9711/12032 [8:25:35<1:00:22,  1.56s/it]2025-08-23:03:00:17,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9712/12032 [8:25:39<1:23:43,  2.17s/it]2025-08-23:03:00:21,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9713/12032 [8:25:40<1:09:51,  1.81s/it]2025-08-23:03:00:22,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9714/12032 [8:25:44<1:32:38,  2.40s/it]2025-08-23:03:00:26,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9715/12032 [8:25:45<1:24:16,  2.18s/it]2025-08-23:03:00:27,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9716/12032 [8:25:49<1:43:01,  2.67s/it]2025-08-23:03:00:31,566 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9717/12032 [8:25:51<1:38:11,  2.55s/it]2025-08-23:03:00:33,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9718/12032 [8:25:52<1:19:24,  2.06s/it]2025-08-23:03:00:34,746 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9719/12032 [8:25:53<1:05:16,  1.69s/it]2025-08-23:03:00:35,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9720/12032 [8:25:55<1:07:55,  1.76s/it]2025-08-23:03:00:37,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9721/12032 [8:25:56<57:02,  1.48s/it]  2025-08-23:03:00:38,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9722/12032 [8:26:00<1:25:04,  2.21s/it]2025-08-23:03:00:42,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9723/12032 [8:26:01<1:09:08,  1.80s/it]2025-08-23:03:00:43,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9724/12032 [8:26:02<1:08:06,  1.77s/it]2025-08-23:03:00:44,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9725/12032 [8:26:04<1:05:20,  1.70s/it]2025-08-23:03:00:46,321 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9726/12032 [8:26:07<1:17:29,  2.02s/it]2025-08-23:03:00:49,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9727/12032 [8:26:07<1:01:30,  1.60s/it]2025-08-23:03:00:49,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9728/12032 [8:26:08<51:36,  1.34s/it]  2025-08-23:03:00:50,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9729/12032 [8:26:09<47:22,  1.23s/it]2025-08-23:03:00:51,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9730/12032 [8:26:13<1:18:00,  2.03s/it]2025-08-23:03:00:55,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9731/12032 [8:26:14<1:01:36,  1.61s/it]2025-08-23:03:00:55,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9732/12032 [8:26:17<1:26:32,  2.26s/it]2025-08-23:03:00:59,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9733/12032 [8:26:21<1:44:09,  2.72s/it]2025-08-23:03:01:03,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9734/12032 [8:26:25<1:56:20,  3.04s/it]2025-08-23:03:01:07,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9735/12032 [8:26:29<2:04:43,  3.26s/it]2025-08-23:03:01:11,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9736/12032 [8:26:33<2:10:52,  3.42s/it]2025-08-23:03:01:14,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9737/12032 [8:26:36<2:15:05,  3.53s/it]2025-08-23:03:01:18,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9738/12032 [8:26:40<2:18:02,  3.61s/it]2025-08-23:03:01:22,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9739/12032 [8:26:44<2:20:00,  3.66s/it]2025-08-23:03:01:26,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9740/12032 [8:26:45<1:53:11,  2.96s/it]2025-08-23:03:01:27,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9741/12032 [8:26:49<2:02:27,  3.21s/it]2025-08-23:03:01:31,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9742/12032 [8:26:52<2:01:57,  3.20s/it]2025-08-23:03:01:34,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9743/12032 [8:26:53<1:40:06,  2.62s/it]2025-08-23:03:01:35,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9744/12032 [8:26:55<1:22:27,  2.16s/it]2025-08-23:03:01:36,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9745/12032 [8:26:58<1:41:07,  2.65s/it]2025-08-23:03:01:40,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9746/12032 [8:26:59<1:23:46,  2.20s/it]2025-08-23:03:01:41,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9747/12032 [8:27:02<1:27:38,  2.30s/it]2025-08-23:03:01:44,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9748/12032 [8:27:05<1:40:59,  2.65s/it]2025-08-23:03:01:47,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9749/12032 [8:27:07<1:26:45,  2.28s/it]2025-08-23:03:01:49,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9750/12032 [8:27:11<1:43:40,  2.73s/it]2025-08-23:03:01:53,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9751/12032 [8:27:13<1:34:46,  2.49s/it]2025-08-23:03:01:54,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9752/12032 [8:27:13<1:13:17,  1.93s/it]2025-08-23:03:01:55,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9753/12032 [8:27:17<1:34:17,  2.48s/it]2025-08-23:03:01:59,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9754/12032 [8:27:18<1:15:04,  1.98s/it]2025-08-23:03:02:00,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9755/12032 [8:27:22<1:35:38,  2.52s/it]2025-08-23:03:02:03,935 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9756/12032 [8:27:24<1:29:37,  2.36s/it]2025-08-23:03:02:05,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9757/12032 [8:27:27<1:37:36,  2.57s/it]2025-08-23:03:02:08,998 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9758/12032 [8:27:30<1:51:22,  2.94s/it]2025-08-23:03:02:12,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9759/12032 [8:27:34<2:00:56,  3.19s/it]2025-08-23:03:02:16,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9760/12032 [8:27:38<2:07:19,  3.36s/it]2025-08-23:03:02:20,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9761/12032 [8:27:40<1:49:27,  2.89s/it]2025-08-23:03:02:22,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9762/12032 [8:27:41<1:25:09,  2.25s/it]2025-08-23:03:02:22,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9763/12032 [8:27:44<1:38:35,  2.61s/it]2025-08-23:03:02:26,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9764/12032 [8:27:46<1:28:28,  2.34s/it]2025-08-23:03:02:28,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9765/12032 [8:27:47<1:20:10,  2.12s/it]2025-08-23:03:02:29,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9766/12032 [8:27:48<1:06:04,  1.75s/it]2025-08-23:03:02:30,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9767/12032 [8:27:49<57:13,  1.52s/it]  2025-08-23:03:02:31,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9768/12032 [8:27:53<1:22:27,  2.19s/it]2025-08-23:03:02:35,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9769/12032 [8:27:54<1:05:56,  1.75s/it]2025-08-23:03:02:35,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9770/12032 [8:27:56<1:18:09,  2.07s/it]2025-08-23:03:02:38,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9771/12032 [8:28:00<1:37:25,  2.59s/it]2025-08-23:03:02:42,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9772/12032 [8:28:03<1:36:36,  2.56s/it]2025-08-23:03:02:45,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9773/12032 [8:28:07<1:50:04,  2.92s/it]2025-08-23:03:02:48,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9774/12032 [8:28:10<1:55:06,  3.06s/it]2025-08-23:03:02:52,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████  | 9775/12032 [8:28:14<2:02:58,  3.27s/it]2025-08-23:03:02:56,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9776/12032 [8:28:17<2:08:30,  3.42s/it]2025-08-23:03:02:59,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9777/12032 [8:28:21<2:10:21,  3.47s/it]2025-08-23:03:03:03,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9778/12032 [8:28:25<2:14:30,  3.58s/it]2025-08-23:03:03:07,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9779/12032 [8:28:29<2:17:49,  3.67s/it]2025-08-23:03:03:11,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9780/12032 [8:28:32<2:18:49,  3.70s/it]2025-08-23:03:03:14,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9781/12032 [8:28:33<1:47:45,  2.87s/it]2025-08-23:03:03:15,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9782/12032 [8:28:35<1:30:02,  2.40s/it]2025-08-23:03:03:17,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9783/12032 [8:28:39<1:45:17,  2.81s/it]2025-08-23:03:03:20,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9784/12032 [8:28:41<1:39:08,  2.65s/it]2025-08-23:03:03:23,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9785/12032 [8:28:45<1:51:40,  2.98s/it]2025-08-23:03:03:26,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9786/12032 [8:28:45<1:28:16,  2.36s/it]2025-08-23:03:03:27,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9787/12032 [8:28:49<1:44:47,  2.80s/it]2025-08-23:03:03:31,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9788/12032 [8:28:51<1:28:19,  2.36s/it]2025-08-23:03:03:32,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9789/12032 [8:28:52<1:12:21,  1.94s/it]2025-08-23:03:03:33,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9790/12032 [8:28:52<57:51,  1.55s/it]  2025-08-23:03:03:34,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9791/12032 [8:28:53<48:00,  1.29s/it]2025-08-23:03:03:35,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9792/12032 [8:28:53<39:28,  1.06s/it]2025-08-23:03:03:35,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9793/12032 [8:28:55<46:37,  1.25s/it]2025-08-23:03:03:37,431 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9794/12032 [8:28:57<53:36,  1.44s/it]2025-08-23:03:03:39,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9795/12032 [8:28:58<51:30,  1.38s/it]2025-08-23:03:03:40,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9796/12032 [8:29:00<55:18,  1.48s/it]2025-08-23:03:03:42,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9797/12032 [8:29:01<50:12,  1.35s/it]2025-08-23:03:03:43,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9798/12032 [8:29:02<51:44,  1.39s/it]2025-08-23:03:03:44,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9799/12032 [8:29:04<52:36,  1.41s/it]2025-08-23:03:03:46,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9800/12032 [8:29:06<54:39,  1.47s/it]2025-08-23:03:03:47,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9801/12032 [8:29:07<57:17,  1.54s/it]2025-08-23:03:03:49,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9802/12032 [8:29:08<53:02,  1.43s/it]2025-08-23:03:03:50,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9803/12032 [8:29:11<1:01:12,  1.65s/it]2025-08-23:03:03:52,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9804/12032 [8:29:12<58:15,  1.57s/it]  2025-08-23:03:03:54,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9805/12032 [8:29:13<51:56,  1.40s/it]2025-08-23:03:03:55,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  81%|████████▏ | 9806/12032 [8:29:14<46:40,  1.26s/it]2025-08-23:03:03:56,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9807/12032 [8:29:15<44:08,  1.19s/it]2025-08-23:03:03:57,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9808/12032 [8:29:16<48:02,  1.30s/it]2025-08-23:03:03:58,791 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9809/12032 [8:29:18<47:41,  1.29s/it]2025-08-23:03:04:00,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9810/12032 [8:29:19<46:36,  1.26s/it]2025-08-23:03:04:01,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9811/12032 [8:29:20<45:03,  1.22s/it]2025-08-23:03:04:02,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9812/12032 [8:29:21<42:48,  1.16s/it]2025-08-23:03:04:03,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9813/12032 [8:29:25<1:12:57,  1.97s/it]2025-08-23:03:04:07,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9814/12032 [8:29:29<1:33:22,  2.53s/it]2025-08-23:03:04:11,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9815/12032 [8:29:33<1:47:17,  2.90s/it]2025-08-23:03:04:14,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9816/12032 [8:29:36<1:57:04,  3.17s/it]2025-08-23:03:04:18,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9817/12032 [8:29:38<1:38:49,  2.68s/it]2025-08-23:03:04:20,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9818/12032 [8:29:39<1:18:24,  2.12s/it]2025-08-23:03:04:21,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9819/12032 [8:29:41<1:20:37,  2.19s/it]2025-08-23:03:04:23,348 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9820/12032 [8:29:42<1:04:42,  1.76s/it]2025-08-23:03:04:24,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9821/12032 [8:29:43<56:09,  1.52s/it]  2025-08-23:03:04:25,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9822/12032 [8:29:43<46:44,  1.27s/it]2025-08-23:03:04:25,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9823/12032 [8:29:45<49:38,  1.35s/it]2025-08-23:03:04:27,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9824/12032 [8:29:46<48:59,  1.33s/it]2025-08-23:03:04:28,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9825/12032 [8:29:48<53:59,  1.47s/it]2025-08-23:03:04:30,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9826/12032 [8:29:52<1:16:49,  2.09s/it]2025-08-23:03:04:33,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9827/12032 [8:29:55<1:36:29,  2.63s/it]2025-08-23:03:04:37,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9828/12032 [8:29:58<1:31:39,  2.50s/it]2025-08-23:03:04:39,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9829/12032 [8:29:59<1:18:04,  2.13s/it]2025-08-23:03:04:41,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9830/12032 [8:30:00<1:09:38,  1.90s/it]2025-08-23:03:04:42,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9831/12032 [8:30:01<1:00:34,  1.65s/it]2025-08-23:03:04:43,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9832/12032 [8:30:02<49:43,  1.36s/it]  2025-08-23:03:04:44,349 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9833/12032 [8:30:03<44:37,  1.22s/it]2025-08-23:03:04:45,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9834/12032 [8:30:04<37:58,  1.04s/it]2025-08-23:03:04:45,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9835/12032 [8:30:05<39:18,  1.07s/it]2025-08-23:03:04:47,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9836/12032 [8:30:06<40:06,  1.10s/it]2025-08-23:03:04:48,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9837/12032 [8:30:07<38:34,  1.05s/it]2025-08-23:03:04:49,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9838/12032 [8:30:08<39:28,  1.08s/it]2025-08-23:03:04:50,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9839/12032 [8:30:09<37:38,  1.03s/it]2025-08-23:03:04:51,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9840/12032 [8:30:13<1:08:09,  1.87s/it]2025-08-23:03:04:54,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9841/12032 [8:30:16<1:28:57,  2.44s/it]2025-08-23:03:04:58,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9842/12032 [8:30:20<1:43:36,  2.84s/it]2025-08-23:03:05:02,535 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9843/12032 [8:30:24<1:54:04,  3.13s/it]2025-08-23:03:05:06,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9844/12032 [8:30:28<2:01:32,  3.33s/it]2025-08-23:03:05:10,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9845/12032 [8:30:32<2:06:39,  3.48s/it]2025-08-23:03:05:13,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9846/12032 [8:30:33<1:46:36,  2.93s/it]2025-08-23:03:05:15,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9847/12032 [8:30:35<1:38:37,  2.71s/it]2025-08-23:03:05:17,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9848/12032 [8:30:39<1:50:26,  3.03s/it]2025-08-23:03:05:21,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9849/12032 [8:30:43<1:58:46,  3.26s/it]2025-08-23:03:05:25,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9850/12032 [8:30:47<2:04:57,  3.44s/it]2025-08-23:03:05:29,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9851/12032 [8:30:48<1:38:50,  2.72s/it]2025-08-23:03:05:30,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9852/12032 [8:30:51<1:40:09,  2.76s/it]2025-08-23:03:05:33,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9853/12032 [8:30:52<1:25:35,  2.36s/it]2025-08-23:03:05:34,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9854/12032 [8:30:55<1:33:17,  2.57s/it]2025-08-23:03:05:37,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9855/12032 [8:30:56<1:13:09,  2.02s/it]2025-08-23:03:05:38,339 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9856/12032 [8:30:58<1:10:17,  1.94s/it]2025-08-23:03:05:40,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9857/12032 [8:30:58<57:16,  1.58s/it]  2025-08-23:03:05:40,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9858/12032 [8:30:59<50:48,  1.40s/it]2025-08-23:03:05:41,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9859/12032 [8:31:00<42:15,  1.17s/it]2025-08-23:03:05:42,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9860/12032 [8:31:01<41:56,  1.16s/it]2025-08-23:03:05:43,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9861/12032 [8:31:02<40:03,  1.11s/it]2025-08-23:03:05:44,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9862/12032 [8:31:03<41:11,  1.14s/it]2025-08-23:03:05:45,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9863/12032 [8:31:05<44:53,  1.24s/it]2025-08-23:03:05:47,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9864/12032 [8:31:06<43:33,  1.21s/it]2025-08-23:03:05:48,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9865/12032 [8:31:10<1:11:39,  1.98s/it]2025-08-23:03:05:52,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9866/12032 [8:31:11<1:02:58,  1.74s/it]2025-08-23:03:05:53,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9867/12032 [8:31:12<55:42,  1.54s/it]  2025-08-23:03:05:54,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9868/12032 [8:31:15<1:08:42,  1.91s/it]2025-08-23:03:05:57,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9869/12032 [8:31:16<56:08,  1.56s/it]  2025-08-23:03:05:57,941 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9870/12032 [8:31:16<48:58,  1.36s/it]2025-08-23:03:05:58,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9871/12032 [8:31:17<42:29,  1.18s/it]2025-08-23:03:05:59,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9872/12032 [8:31:21<1:11:14,  1.98s/it]2025-08-23:03:06:03,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9873/12032 [8:31:24<1:21:59,  2.28s/it]2025-08-23:03:06:06,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9874/12032 [8:31:28<1:38:43,  2.75s/it]2025-08-23:03:06:10,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9875/12032 [8:31:30<1:27:55,  2.45s/it]2025-08-23:03:06:12,003 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9876/12032 [8:31:33<1:42:09,  2.84s/it]2025-08-23:03:06:15,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9877/12032 [8:31:37<1:47:00,  2.98s/it]2025-08-23:03:06:19,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9878/12032 [8:31:41<1:56:34,  3.25s/it]2025-08-23:03:06:22,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9879/12032 [8:31:44<2:02:31,  3.41s/it]2025-08-23:03:06:26,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9880/12032 [8:31:46<1:47:49,  3.01s/it]2025-08-23:03:06:28,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9881/12032 [8:31:48<1:26:50,  2.42s/it]2025-08-23:03:06:29,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9882/12032 [8:31:51<1:42:22,  2.86s/it]2025-08-23:03:06:33,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9883/12032 [8:31:52<1:21:45,  2.28s/it]2025-08-23:03:06:34,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9884/12032 [8:31:54<1:13:15,  2.05s/it]2025-08-23:03:06:36,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9885/12032 [8:31:57<1:25:38,  2.39s/it]2025-08-23:03:06:39,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9886/12032 [8:31:58<1:13:34,  2.06s/it]2025-08-23:03:06:40,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9887/12032 [8:31:59<58:46,  1.64s/it]  2025-08-23:03:06:41,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9888/12032 [8:32:00<54:50,  1.53s/it]2025-08-23:03:06:42,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9889/12032 [8:32:04<1:18:43,  2.20s/it]2025-08-23:03:06:46,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9890/12032 [8:32:08<1:35:19,  2.67s/it]2025-08-23:03:06:50,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9891/12032 [8:32:08<1:14:03,  2.08s/it]2025-08-23:03:06:50,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9892/12032 [8:32:09<1:02:25,  1.75s/it]2025-08-23:03:06:51,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9893/12032 [8:32:11<59:49,  1.68s/it]  2025-08-23:03:06:53,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9894/12032 [8:32:12<52:31,  1.47s/it]2025-08-23:03:06:54,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9895/12032 [8:32:13<44:37,  1.25s/it]2025-08-23:03:06:55,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9896/12032 [8:32:14<41:49,  1.17s/it]2025-08-23:03:06:56,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9897/12032 [8:32:15<41:39,  1.17s/it]2025-08-23:03:06:57,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9898/12032 [8:32:17<49:35,  1.39s/it]2025-08-23:03:06:59,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9899/12032 [8:32:19<1:03:34,  1.79s/it]2025-08-23:03:07:01,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9900/12032 [8:32:21<1:01:25,  1.73s/it]2025-08-23:03:07:03,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9901/12032 [8:32:24<1:11:22,  2.01s/it]2025-08-23:03:07:06,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9902/12032 [8:32:28<1:30:19,  2.54s/it]2025-08-23:03:07:09,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9903/12032 [8:32:29<1:21:54,  2.31s/it]2025-08-23:03:07:11,633 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9904/12032 [8:32:30<1:06:36,  1.88s/it]2025-08-23:03:07:12,508 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9905/12032 [8:32:33<1:18:56,  2.23s/it]2025-08-23:03:07:15,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9906/12032 [8:32:34<1:01:20,  1.73s/it]2025-08-23:03:07:16,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9907/12032 [8:32:38<1:23:31,  2.36s/it]2025-08-23:03:07:19,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9908/12032 [8:32:38<1:06:48,  1.89s/it]2025-08-23:03:07:20,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9909/12032 [8:32:41<1:16:53,  2.17s/it]2025-08-23:03:07:23,574 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9910/12032 [8:32:45<1:34:03,  2.66s/it]2025-08-23:03:07:27,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9911/12032 [8:32:49<1:45:41,  2.99s/it]2025-08-23:03:07:31,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9912/12032 [8:32:53<1:54:03,  3.23s/it]2025-08-23:03:07:34,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9913/12032 [8:32:56<1:59:37,  3.39s/it]2025-08-23:03:07:38,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9914/12032 [8:32:57<1:29:34,  2.54s/it]2025-08-23:03:07:39,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9915/12032 [8:33:01<1:42:28,  2.90s/it]2025-08-23:03:07:42,986 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9916/12032 [8:33:04<1:51:40,  3.17s/it]2025-08-23:03:07:46,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9917/12032 [8:33:07<1:40:20,  2.85s/it]2025-08-23:03:07:48,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9918/12032 [8:33:08<1:24:21,  2.39s/it]2025-08-23:03:07:50,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9919/12032 [8:33:12<1:39:02,  2.81s/it]2025-08-23:03:07:53,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9920/12032 [8:33:13<1:24:31,  2.40s/it]2025-08-23:03:07:55,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9921/12032 [8:33:15<1:14:18,  2.11s/it]2025-08-23:03:07:56,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9922/12032 [8:33:18<1:32:42,  2.64s/it]2025-08-23:03:08:00,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9923/12032 [8:33:22<1:44:43,  2.98s/it]2025-08-23:03:08:04,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9924/12032 [8:33:23<1:19:07,  2.25s/it]2025-08-23:03:08:05,065 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9925/12032 [8:33:24<1:06:35,  1.90s/it]2025-08-23:03:08:06,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  82%|████████▏ | 9926/12032 [8:33:28<1:26:18,  2.46s/it]2025-08-23:03:08:09,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9927/12032 [8:33:31<1:39:57,  2.85s/it]2025-08-23:03:08:13,663 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9928/12032 [8:33:35<1:50:19,  3.15s/it]2025-08-23:03:08:17,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9929/12032 [8:33:37<1:38:35,  2.81s/it]2025-08-23:03:08:19,537 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9930/12032 [8:33:41<1:45:12,  3.00s/it]2025-08-23:03:08:22,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9931/12032 [8:33:42<1:32:26,  2.64s/it]2025-08-23:03:08:24,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9932/12032 [8:33:45<1:36:18,  2.75s/it]2025-08-23:03:08:27,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9933/12032 [8:33:47<1:27:20,  2.50s/it]2025-08-23:03:08:29,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9934/12032 [8:33:48<1:09:59,  2.00s/it]2025-08-23:03:08:30,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9935/12032 [8:33:49<1:00:17,  1.72s/it]2025-08-23:03:08:31,617 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9936/12032 [8:33:51<1:04:01,  1.83s/it]2025-08-23:03:08:33,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9937/12032 [8:33:52<53:08,  1.52s/it]  2025-08-23:03:08:34,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9938/12032 [8:33:53<50:07,  1.44s/it]2025-08-23:03:08:35,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9939/12032 [8:33:54<43:39,  1.25s/it]2025-08-23:03:08:36,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9940/12032 [8:33:56<47:09,  1.35s/it]2025-08-23:03:08:38,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9941/12032 [8:33:58<54:04,  1.55s/it]2025-08-23:03:08:40,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9942/12032 [8:34:02<1:17:26,  2.22s/it]2025-08-23:03:08:43,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9943/12032 [8:34:05<1:34:14,  2.71s/it]2025-08-23:03:08:47,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9944/12032 [8:34:09<1:45:43,  3.04s/it]2025-08-23:03:08:51,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9945/12032 [8:34:13<1:54:38,  3.30s/it]2025-08-23:03:08:55,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9946/12032 [8:34:15<1:36:00,  2.76s/it]2025-08-23:03:08:57,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9947/12032 [8:34:18<1:46:43,  3.07s/it]2025-08-23:03:09:00,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9948/12032 [8:34:21<1:43:27,  2.98s/it]2025-08-23:03:09:03,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9949/12032 [8:34:24<1:38:16,  2.83s/it]2025-08-23:03:09:06,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9950/12032 [8:34:28<1:49:19,  3.15s/it]2025-08-23:03:09:09,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9951/12032 [8:34:31<1:56:18,  3.35s/it]2025-08-23:03:09:13,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9952/12032 [8:34:35<2:01:18,  3.50s/it]2025-08-23:03:09:17,613 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9953/12032 [8:34:39<2:04:23,  3.59s/it]2025-08-23:03:09:21,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9954/12032 [8:34:43<2:06:16,  3.65s/it]2025-08-23:03:09:25,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9955/12032 [8:34:47<2:07:42,  3.69s/it]2025-08-23:03:09:28,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9956/12032 [8:34:49<1:55:55,  3.35s/it]2025-08-23:03:09:31,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9957/12032 [8:34:53<2:00:11,  3.48s/it]2025-08-23:03:09:35,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9958/12032 [8:34:57<2:03:11,  3.56s/it]2025-08-23:03:09:39,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9959/12032 [8:35:01<2:05:17,  3.63s/it]2025-08-23:03:09:42,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9960/12032 [8:35:04<2:06:56,  3.68s/it]2025-08-23:03:09:46,643 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9961/12032 [8:35:08<2:03:42,  3.58s/it]2025-08-23:03:09:50,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9962/12032 [8:35:12<2:06:35,  3.67s/it]2025-08-23:03:09:53,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9963/12032 [8:35:15<2:08:00,  3.71s/it]2025-08-23:03:09:57,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9964/12032 [8:35:17<1:47:02,  3.11s/it]2025-08-23:03:09:59,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9965/12032 [8:35:21<1:54:39,  3.33s/it]2025-08-23:03:10:03,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9966/12032 [8:35:25<2:00:06,  3.49s/it]2025-08-23:03:10:07,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9967/12032 [8:35:29<2:04:07,  3.61s/it]2025-08-23:03:10:10,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9968/12032 [8:35:32<2:05:55,  3.66s/it]2025-08-23:03:10:14,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9969/12032 [8:35:36<2:02:28,  3.56s/it]2025-08-23:03:10:18,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9970/12032 [8:35:40<2:04:50,  3.63s/it]2025-08-23:03:10:21,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9971/12032 [8:35:43<2:06:22,  3.68s/it]2025-08-23:03:10:25,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9972/12032 [8:35:47<2:07:30,  3.71s/it]2025-08-23:03:10:29,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9973/12032 [8:35:50<1:54:34,  3.34s/it]2025-08-23:03:10:31,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9974/12032 [8:35:52<1:42:46,  3.00s/it]2025-08-23:03:10:34,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9975/12032 [8:35:56<1:50:48,  3.23s/it]2025-08-23:03:10:37,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9976/12032 [8:35:59<1:56:34,  3.40s/it]2025-08-23:03:10:41,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9977/12032 [8:36:03<2:00:45,  3.53s/it]2025-08-23:03:10:45,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9978/12032 [8:36:07<2:03:17,  3.60s/it]2025-08-23:03:10:49,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9979/12032 [8:36:11<2:05:16,  3.66s/it]2025-08-23:03:10:53,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9980/12032 [8:36:15<2:06:30,  3.70s/it]2025-08-23:03:10:56,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9981/12032 [8:36:18<2:07:33,  3.73s/it]2025-08-23:03:11:00,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9982/12032 [8:36:22<2:08:12,  3.75s/it]2025-08-23:03:11:04,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9983/12032 [8:36:26<2:08:14,  3.76s/it]2025-08-23:03:11:08,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9984/12032 [8:36:30<2:08:26,  3.76s/it]2025-08-23:03:11:12,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9985/12032 [8:36:33<2:08:31,  3.77s/it]2025-08-23:03:11:15,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9986/12032 [8:36:36<1:55:01,  3.37s/it]2025-08-23:03:11:18,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9987/12032 [8:36:39<1:51:51,  3.28s/it]2025-08-23:03:11:21,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9988/12032 [8:36:43<1:56:52,  3.43s/it]2025-08-23:03:11:25,125 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9989/12032 [8:36:47<2:00:21,  3.53s/it]2025-08-23:03:11:28,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9990/12032 [8:36:50<2:02:51,  3.61s/it]2025-08-23:03:11:32,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9991/12032 [8:36:54<2:04:35,  3.66s/it]2025-08-23:03:11:36,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9992/12032 [8:36:58<2:05:41,  3.70s/it]2025-08-23:03:11:40,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9993/12032 [8:37:01<2:03:23,  3.63s/it]2025-08-23:03:11:43,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9994/12032 [8:37:05<2:04:50,  3.68s/it]2025-08-23:03:11:47,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9995/12032 [8:37:09<2:05:59,  3.71s/it]2025-08-23:03:11:51,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9996/12032 [8:37:10<1:43:43,  3.06s/it]2025-08-23:03:11:52,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9997/12032 [8:37:14<1:51:27,  3.29s/it]2025-08-23:03:11:56,653 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9998/12032 [8:37:18<1:56:38,  3.44s/it]2025-08-23:03:12:00,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 9999/12032 [8:37:21<1:51:48,  3.30s/it]2025-08-23:03:12:03,425 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10000/12032 [8:37:25<1:56:40,  3.44s/it]2025-08-23:03:12:07,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10001/12032 [8:37:27<1:48:03,  3.19s/it]2025-08-23:03:12:09,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10002/12032 [8:37:28<1:25:37,  2.53s/it]2025-08-23:03:12:10,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10003/12032 [8:37:30<1:13:23,  2.17s/it]2025-08-23:03:12:12,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10004/12032 [8:37:34<1:29:32,  2.65s/it]2025-08-23:03:12:15,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10005/12032 [8:37:37<1:40:19,  2.97s/it]2025-08-23:03:12:19,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10006/12032 [8:37:38<1:18:37,  2.33s/it]2025-08-23:03:12:20,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10007/12032 [8:37:39<1:02:47,  1.86s/it]2025-08-23:03:12:21,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10008/12032 [8:37:40<57:05,  1.69s/it]  2025-08-23:03:12:22,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10009/12032 [8:37:43<1:08:09,  2.02s/it]2025-08-23:03:12:25,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10010/12032 [8:37:45<1:07:48,  2.01s/it]2025-08-23:03:12:27,292 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10011/12032 [8:37:47<1:04:22,  1.91s/it]2025-08-23:03:12:28,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10012/12032 [8:37:48<57:06,  1.70s/it]  2025-08-23:03:12:30,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10013/12032 [8:37:49<49:22,  1.47s/it]2025-08-23:03:12:31,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10014/12032 [8:37:50<48:27,  1.44s/it]2025-08-23:03:12:32,474 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10015/12032 [8:37:51<45:46,  1.36s/it]2025-08-23:03:12:33,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10016/12032 [8:37:52<38:34,  1.15s/it]2025-08-23:03:12:34,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10017/12032 [8:37:53<34:56,  1.04s/it]2025-08-23:03:12:35,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10018/12032 [8:37:54<36:18,  1.08s/it]2025-08-23:03:12:36,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10019/12032 [8:37:58<1:03:42,  1.90s/it]2025-08-23:03:12:40,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10020/12032 [8:38:01<1:22:16,  2.45s/it]2025-08-23:03:12:43,822 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10021/12032 [8:38:05<1:36:24,  2.88s/it]2025-08-23:03:12:47,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10022/12032 [8:38:09<1:46:16,  3.17s/it]2025-08-23:03:12:51,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45100 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10023/12032 [8:38:13<1:53:03,  3.38s/it]2025-08-23:03:12:55,401 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10024/12032 [8:38:17<1:57:18,  3.51s/it]2025-08-23:03:12:59,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45122 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10025/12032 [8:38:21<2:00:48,  3.61s/it]2025-08-23:03:13:03,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10026/12032 [8:38:25<2:02:52,  3.68s/it]2025-08-23:03:13:06,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10027/12032 [8:38:29<2:05:41,  3.76s/it]2025-08-23:03:13:10,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10028/12032 [8:38:32<2:06:10,  3.78s/it]2025-08-23:03:13:14,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10029/12032 [8:38:36<2:06:10,  3.78s/it]2025-08-23:03:13:18,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10030/12032 [8:38:40<2:06:36,  3.79s/it]2025-08-23:03:13:22,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10031/12032 [8:38:44<2:06:24,  3.79s/it]2025-08-23:03:13:26,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10032/12032 [8:38:48<2:06:31,  3.80s/it]2025-08-23:03:13:29,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10033/12032 [8:38:51<2:06:38,  3.80s/it]2025-08-23:03:13:33,683 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10034/12032 [8:38:55<2:06:28,  3.80s/it]2025-08-23:03:13:37,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10035/12032 [8:38:59<2:06:06,  3.79s/it]2025-08-23:03:13:41,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10036/12032 [8:39:03<2:05:53,  3.78s/it]2025-08-23:03:13:45,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10037/12032 [8:39:06<2:06:00,  3.79s/it]2025-08-23:03:13:48,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10038/12032 [8:39:10<2:06:16,  3.80s/it]2025-08-23:03:13:52,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10039/12032 [8:39:14<2:06:02,  3.79s/it]2025-08-23:03:13:56,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10040/12032 [8:39:18<2:05:51,  3.79s/it]2025-08-23:03:14:00,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10041/12032 [8:39:22<2:05:35,  3.78s/it]2025-08-23:03:14:03,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10042/12032 [8:39:26<2:06:30,  3.81s/it]2025-08-23:03:14:07,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10043/12032 [8:39:29<2:06:56,  3.83s/it]2025-08-23:03:14:11,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10044/12032 [8:39:33<2:06:57,  3.83s/it]2025-08-23:03:14:15,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10045/12032 [8:39:37<2:06:31,  3.82s/it]2025-08-23:03:14:19,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  83%|████████▎ | 10046/12032 [8:39:41<2:05:59,  3.81s/it]2025-08-23:03:14:23,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10047/12032 [8:39:45<2:06:38,  3.83s/it]2025-08-23:03:14:27,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10048/12032 [8:39:48<2:06:11,  3.82s/it]2025-08-23:03:14:30,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10049/12032 [8:39:52<2:05:53,  3.81s/it]2025-08-23:03:14:34,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10050/12032 [8:39:56<2:05:31,  3.80s/it]2025-08-23:03:14:38,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10051/12032 [8:40:00<2:05:18,  3.80s/it]2025-08-23:03:14:42,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10052/12032 [8:40:04<2:05:14,  3.80s/it]2025-08-23:03:14:45,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10053/12032 [8:40:07<2:05:10,  3.80s/it]2025-08-23:03:14:49,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10054/12032 [8:40:11<2:05:17,  3.80s/it]2025-08-23:03:14:53,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10055/12032 [8:40:15<2:04:50,  3.79s/it]2025-08-23:03:14:57,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10056/12032 [8:40:17<1:48:31,  3.30s/it]2025-08-23:03:14:59,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10057/12032 [8:40:21<1:53:19,  3.44s/it]2025-08-23:03:15:03,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10058/12032 [8:40:22<1:34:14,  2.86s/it]2025-08-23:03:15:04,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10059/12032 [8:40:24<1:18:14,  2.38s/it]2025-08-23:03:15:06,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10060/12032 [8:40:27<1:31:54,  2.80s/it]2025-08-23:03:15:09,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10061/12032 [8:40:31<1:42:30,  3.12s/it]2025-08-23:03:15:13,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10062/12032 [8:40:35<1:48:30,  3.30s/it]2025-08-23:03:15:17,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10063/12032 [8:40:39<1:53:02,  3.44s/it]2025-08-23:03:15:21,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10064/12032 [8:40:43<1:56:20,  3.55s/it]2025-08-23:03:15:24,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10065/12032 [8:40:46<1:58:56,  3.63s/it]2025-08-23:03:15:28,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10066/12032 [8:40:50<2:00:30,  3.68s/it]2025-08-23:03:15:32,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10067/12032 [8:40:54<2:01:13,  3.70s/it]2025-08-23:03:15:36,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10068/12032 [8:40:58<2:01:48,  3.72s/it]2025-08-23:03:15:40,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10069/12032 [8:41:02<2:02:20,  3.74s/it]2025-08-23:03:15:43,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10070/12032 [8:41:05<2:02:46,  3.75s/it]2025-08-23:03:15:47,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10071/12032 [8:41:09<2:02:56,  3.76s/it]2025-08-23:03:15:51,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10072/12032 [8:41:13<2:02:49,  3.76s/it]2025-08-23:03:15:55,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10073/12032 [8:41:17<2:02:59,  3.77s/it]2025-08-23:03:15:58,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10074/12032 [8:41:20<2:03:04,  3.77s/it]2025-08-23:03:16:02,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10075/12032 [8:41:24<1:58:11,  3.62s/it]2025-08-23:03:16:06,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▎ | 10076/12032 [8:41:26<1:48:58,  3.34s/it]2025-08-23:03:16:08,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10077/12032 [8:41:30<1:53:40,  3.49s/it]2025-08-23:03:16:12,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10078/12032 [8:41:34<1:56:22,  3.57s/it]2025-08-23:03:16:16,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49038 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10079/12032 [8:41:38<1:58:04,  3.63s/it]2025-08-23:03:16:20,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10080/12032 [8:41:42<1:59:25,  3.67s/it]2025-08-23:03:16:23,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10081/12032 [8:41:45<2:00:53,  3.72s/it]2025-08-23:03:16:27,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10082/12032 [8:41:49<2:01:35,  3.74s/it]2025-08-23:03:16:31,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10083/12032 [8:41:53<2:01:42,  3.75s/it]2025-08-23:03:16:35,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10084/12032 [8:41:54<1:39:18,  3.06s/it]2025-08-23:03:16:36,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10085/12032 [8:41:56<1:28:36,  2.73s/it]2025-08-23:03:16:38,647 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10086/12032 [8:42:00<1:38:42,  3.04s/it]2025-08-23:03:16:42,419 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10087/12032 [8:42:04<1:46:17,  3.28s/it]2025-08-23:03:16:46,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10088/12032 [8:42:08<1:50:59,  3.43s/it]2025-08-23:03:16:50,016 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10089/12032 [8:42:11<1:54:17,  3.53s/it]2025-08-23:03:16:53,788 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10090/12032 [8:42:15<1:56:28,  3.60s/it]2025-08-23:03:16:57,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10091/12032 [8:42:19<1:57:59,  3.65s/it]2025-08-23:03:17:01,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10092/12032 [8:42:23<1:59:21,  3.69s/it]2025-08-23:03:17:05,103 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10093/12032 [8:42:25<1:46:56,  3.31s/it]2025-08-23:03:17:07,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10094/12032 [8:42:27<1:30:53,  2.81s/it]2025-08-23:03:17:09,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10095/12032 [8:42:29<1:20:17,  2.49s/it]2025-08-23:03:17:10,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10096/12032 [8:42:32<1:32:27,  2.87s/it]2025-08-23:03:17:14,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10097/12032 [8:42:36<1:41:48,  3.16s/it]2025-08-23:03:17:18,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10098/12032 [8:42:40<1:48:10,  3.36s/it]2025-08-23:03:17:22,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10099/12032 [8:42:41<1:27:03,  2.70s/it]2025-08-23:03:17:23,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10100/12032 [8:42:44<1:26:50,  2.70s/it]2025-08-23:03:17:26,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10101/12032 [8:42:45<1:11:04,  2.21s/it]2025-08-23:03:17:27,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10102/12032 [8:42:49<1:26:25,  2.69s/it]2025-08-23:03:17:31,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10103/12032 [8:42:52<1:37:00,  3.02s/it]2025-08-23:03:17:34,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10104/12032 [8:42:56<1:44:28,  3.25s/it]2025-08-23:03:17:38,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10105/12032 [8:42:57<1:24:42,  2.64s/it]2025-08-23:03:17:39,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10106/12032 [8:42:58<1:07:21,  2.10s/it]2025-08-23:03:17:40,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10107/12032 [8:42:59<52:13,  1.63s/it]  2025-08-23:03:17:41,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10108/12032 [8:43:00<45:52,  1.43s/it]2025-08-23:03:17:42,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10109/12032 [8:43:02<49:23,  1.54s/it]2025-08-23:03:17:43,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10110/12032 [8:43:04<58:59,  1.84s/it]2025-08-23:03:17:46,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10111/12032 [8:43:06<59:35,  1.86s/it]2025-08-23:03:17:48,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10112/12032 [8:43:07<51:14,  1.60s/it]2025-08-23:03:17:49,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10113/12032 [8:43:11<1:12:24,  2.26s/it]2025-08-23:03:17:53,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10114/12032 [8:43:15<1:26:53,  2.72s/it]2025-08-23:03:17:57,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10115/12032 [8:43:18<1:37:33,  3.05s/it]2025-08-23:03:18:00,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10116/12032 [8:43:22<1:44:59,  3.29s/it]2025-08-23:03:18:04,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10117/12032 [8:43:26<1:49:47,  3.44s/it]2025-08-23:03:18:08,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10118/12032 [8:43:30<1:53:32,  3.56s/it]2025-08-23:03:18:12,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10119/12032 [8:43:34<1:55:20,  3.62s/it]2025-08-23:03:18:16,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10120/12032 [8:43:37<1:56:40,  3.66s/it]2025-08-23:03:18:19,825 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10121/12032 [8:43:41<1:59:06,  3.74s/it]2025-08-23:03:18:23,747 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10122/12032 [8:43:45<1:59:32,  3.76s/it]2025-08-23:03:18:27,540 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10123/12032 [8:43:49<2:00:07,  3.78s/it]2025-08-23:03:18:31,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10124/12032 [8:43:53<2:00:22,  3.79s/it]2025-08-23:03:18:35,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10125/12032 [8:43:57<2:00:25,  3.79s/it]2025-08-23:03:18:38,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10126/12032 [8:44:00<2:00:30,  3.79s/it]2025-08-23:03:18:42,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10127/12032 [8:44:04<2:00:45,  3.80s/it]2025-08-23:03:18:46,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10128/12032 [8:44:08<2:01:19,  3.82s/it]2025-08-23:03:18:50,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10129/12032 [8:44:12<2:01:18,  3.82s/it]2025-08-23:03:18:54,296 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10130/12032 [8:44:16<2:01:26,  3.83s/it]2025-08-23:03:18:58,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10131/12032 [8:44:20<2:01:21,  3.83s/it]2025-08-23:03:19:01,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10132/12032 [8:44:23<2:01:34,  3.84s/it]2025-08-23:03:19:05,831 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10133/12032 [8:44:27<2:01:30,  3.84s/it]2025-08-23:03:19:09,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10134/12032 [8:44:31<2:01:17,  3.83s/it]2025-08-23:03:19:13,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10135/12032 [8:44:35<2:01:01,  3.83s/it]2025-08-23:03:19:17,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10136/12032 [8:44:39<2:00:49,  3.82s/it]2025-08-23:03:19:21,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10137/12032 [8:44:43<2:00:09,  3.80s/it]2025-08-23:03:19:24,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10138/12032 [8:44:46<2:00:19,  3.81s/it]2025-08-23:03:19:28,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10139/12032 [8:44:50<2:01:33,  3.85s/it]2025-08-23:03:19:32,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10140/12032 [8:44:54<2:01:05,  3.84s/it]2025-08-23:03:19:36,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10141/12032 [8:44:58<2:01:34,  3.86s/it]2025-08-23:03:19:40,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39950 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10142/12032 [8:45:02<2:00:51,  3.84s/it]2025-08-23:03:19:44,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10143/12032 [8:45:05<1:58:07,  3.75s/it]2025-08-23:03:19:47,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10144/12032 [8:45:09<1:58:29,  3.77s/it]2025-08-23:03:19:51,506 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10145/12032 [8:45:11<1:39:19,  3.16s/it]2025-08-23:03:19:53,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10146/12032 [8:45:14<1:41:17,  3.22s/it]2025-08-23:03:19:56,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10147/12032 [8:45:16<1:23:58,  2.67s/it]2025-08-23:03:19:58,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10148/12032 [8:45:17<1:10:51,  2.26s/it]2025-08-23:03:19:59,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10149/12032 [8:45:19<1:06:13,  2.11s/it]2025-08-23:03:20:01,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10150/12032 [8:45:23<1:21:57,  2.61s/it]2025-08-23:03:20:04,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10151/12032 [8:45:25<1:16:27,  2.44s/it]2025-08-23:03:20:06,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10152/12032 [8:45:28<1:28:56,  2.84s/it]2025-08-23:03:20:10,654 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59052 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10153/12032 [8:45:31<1:24:48,  2.71s/it]2025-08-23:03:20:13,057 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10154/12032 [8:45:34<1:33:37,  2.99s/it]2025-08-23:03:20:16,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10155/12032 [8:45:38<1:40:58,  3.23s/it]2025-08-23:03:20:20,488 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10156/12032 [8:45:42<1:46:34,  3.41s/it]2025-08-23:03:20:24,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10157/12032 [8:45:46<1:51:54,  3.58s/it]2025-08-23:03:20:28,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10158/12032 [8:45:50<1:54:38,  3.67s/it]2025-08-23:03:20:32,182 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10159/12032 [8:45:54<1:56:47,  3.74s/it]2025-08-23:03:20:36,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10160/12032 [8:45:58<1:57:17,  3.76s/it]2025-08-23:03:20:39,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10161/12032 [8:46:01<1:57:51,  3.78s/it]2025-08-23:03:20:43,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10162/12032 [8:46:05<1:57:32,  3.77s/it]2025-08-23:03:20:47,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10163/12032 [8:46:09<1:57:49,  3.78s/it]2025-08-23:03:20:51,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10164/12032 [8:46:13<1:57:40,  3.78s/it]2025-08-23:03:20:55,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10165/12032 [8:46:17<1:58:06,  3.80s/it]2025-08-23:03:20:58,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10166/12032 [8:46:20<1:58:06,  3.80s/it]2025-08-23:03:21:02,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  84%|████████▍ | 10167/12032 [8:46:24<1:57:52,  3.79s/it]2025-08-23:03:21:06,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10168/12032 [8:46:28<1:57:45,  3.79s/it]2025-08-23:03:21:10,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10169/12032 [8:46:32<1:57:51,  3.80s/it]2025-08-23:03:21:14,060 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52076 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10170/12032 [8:46:36<1:58:08,  3.81s/it]2025-08-23:03:21:17,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10171/12032 [8:46:39<1:57:41,  3.79s/it]2025-08-23:03:21:21,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10172/12032 [8:46:43<1:57:47,  3.80s/it]2025-08-23:03:21:25,471 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10173/12032 [8:46:47<1:57:40,  3.80s/it]2025-08-23:03:21:29,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10174/12032 [8:46:51<1:57:51,  3.81s/it]2025-08-23:03:21:33,090 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10175/12032 [8:46:55<1:57:33,  3.80s/it]2025-08-23:03:21:36,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10176/12032 [8:46:58<1:57:25,  3.80s/it]2025-08-23:03:21:40,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10177/12032 [8:47:02<1:57:05,  3.79s/it]2025-08-23:03:21:44,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10178/12032 [8:47:06<1:57:00,  3.79s/it]2025-08-23:03:21:48,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10179/12032 [8:47:08<1:41:21,  3.28s/it]2025-08-23:03:21:50,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10180/12032 [8:47:12<1:46:06,  3.44s/it]2025-08-23:03:21:54,117 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10181/12032 [8:47:15<1:46:31,  3.45s/it]2025-08-23:03:21:57,606 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10182/12032 [8:47:19<1:49:39,  3.56s/it]2025-08-23:03:22:01,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10183/12032 [8:47:23<1:51:45,  3.63s/it]2025-08-23:03:22:05,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10184/12032 [8:47:24<1:31:07,  2.96s/it]2025-08-23:03:22:06,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10185/12032 [8:47:28<1:40:36,  3.27s/it]2025-08-23:03:22:10,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10186/12032 [8:47:32<1:46:54,  3.47s/it]2025-08-23:03:22:14,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10187/12032 [8:47:36<1:50:49,  3.60s/it]2025-08-23:03:22:18,447 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10188/12032 [8:47:40<1:52:28,  3.66s/it]2025-08-23:03:22:22,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10189/12032 [8:47:44<1:53:34,  3.70s/it]2025-08-23:03:22:26,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10190/12032 [8:47:47<1:54:15,  3.72s/it]2025-08-23:03:22:29,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10191/12032 [8:47:51<1:54:44,  3.74s/it]2025-08-23:03:22:33,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10192/12032 [8:47:55<1:56:40,  3.80s/it]2025-08-23:03:22:37,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10193/12032 [8:47:58<1:49:14,  3.56s/it]2025-08-23:03:22:40,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36734 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10194/12032 [8:48:02<1:51:42,  3.65s/it]2025-08-23:03:22:44,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10195/12032 [8:48:06<1:53:20,  3.70s/it]2025-08-23:03:22:48,212 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10196/12032 [8:48:08<1:34:17,  3.08s/it]2025-08-23:03:22:49,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10197/12032 [8:48:09<1:20:46,  2.64s/it]2025-08-23:03:22:51,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10198/12032 [8:48:13<1:28:38,  2.90s/it]2025-08-23:03:22:54,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10199/12032 [8:48:15<1:24:38,  2.77s/it]2025-08-23:03:22:57,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10200/12032 [8:48:19<1:34:44,  3.10s/it]2025-08-23:03:23:01,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10201/12032 [8:48:23<1:41:35,  3.33s/it]2025-08-23:03:23:05,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10202/12032 [8:48:27<1:47:09,  3.51s/it]2025-08-23:03:23:09,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10203/12032 [8:48:28<1:24:41,  2.78s/it]2025-08-23:03:23:10,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10204/12032 [8:48:28<1:05:15,  2.14s/it]2025-08-23:03:23:10,829 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10205/12032 [8:48:32<1:15:41,  2.49s/it]2025-08-23:03:23:14,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59488 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10206/12032 [8:48:33<1:03:44,  2.09s/it]2025-08-23:03:23:15,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10207/12032 [8:48:34<55:24,  1.82s/it]  2025-08-23:03:23:16,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10208/12032 [8:48:37<1:03:53,  2.10s/it]2025-08-23:03:23:19,239 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10209/12032 [8:48:38<54:15,  1.79s/it]  2025-08-23:03:23:20,287 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10210/12032 [8:48:41<1:01:51,  2.04s/it]2025-08-23:03:23:22,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10211/12032 [8:48:41<51:03,  1.68s/it]  2025-08-23:03:23:23,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10212/12032 [8:48:43<53:57,  1.78s/it]2025-08-23:03:23:25,771 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10213/12032 [8:48:45<55:20,  1.83s/it]2025-08-23:03:23:27,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10214/12032 [8:48:47<51:43,  1.71s/it]2025-08-23:03:23:29,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10215/12032 [8:48:48<48:18,  1.60s/it]2025-08-23:03:23:30,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10216/12032 [8:48:49<42:27,  1.40s/it]2025-08-23:03:23:31,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10217/12032 [8:48:53<1:04:04,  2.12s/it]2025-08-23:03:23:35,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10218/12032 [8:48:57<1:18:51,  2.61s/it]2025-08-23:03:23:38,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10219/12032 [8:49:00<1:29:29,  2.96s/it]2025-08-23:03:23:42,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60982 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10220/12032 [8:49:04<1:36:52,  3.21s/it]2025-08-23:03:23:46,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10221/12032 [8:49:08<1:42:37,  3.40s/it]2025-08-23:03:23:50,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10222/12032 [8:49:12<1:45:58,  3.51s/it]2025-08-23:03:23:54,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10223/12032 [8:49:16<1:48:20,  3.59s/it]2025-08-23:03:23:57,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10224/12032 [8:49:19<1:49:59,  3.65s/it]2025-08-23:03:24:01,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10225/12032 [8:49:22<1:44:01,  3.45s/it]2025-08-23:03:24:04,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10226/12032 [8:49:26<1:47:25,  3.57s/it]2025-08-23:03:24:08,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▍ | 10227/12032 [8:49:30<1:49:15,  3.63s/it]2025-08-23:03:24:12,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10228/12032 [8:49:34<1:50:15,  3.67s/it]2025-08-23:03:24:16,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10229/12032 [8:49:38<1:51:25,  3.71s/it]2025-08-23:03:24:19,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10230/12032 [8:49:41<1:51:56,  3.73s/it]2025-08-23:03:24:23,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10231/12032 [8:49:45<1:53:20,  3.78s/it]2025-08-23:03:24:27,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10232/12032 [8:49:49<1:53:55,  3.80s/it]2025-08-23:03:24:31,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10233/12032 [8:49:53<1:53:28,  3.78s/it]2025-08-23:03:24:35,148 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10234/12032 [8:49:57<1:53:16,  3.78s/it]2025-08-23:03:24:38,917 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10235/12032 [8:50:00<1:52:56,  3.77s/it]2025-08-23:03:24:42,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10236/12032 [8:50:04<1:53:44,  3.80s/it]2025-08-23:03:24:46,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10237/12032 [8:50:08<1:53:58,  3.81s/it]2025-08-23:03:24:50,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10238/12032 [8:50:12<1:54:22,  3.83s/it]2025-08-23:03:24:54,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10239/12032 [8:50:16<1:54:19,  3.83s/it]2025-08-23:03:24:58,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10240/12032 [8:50:20<1:54:04,  3.82s/it]2025-08-23:03:25:01,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10241/12032 [8:50:23<1:46:48,  3.58s/it]2025-08-23:03:25:04,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10242/12032 [8:50:26<1:49:04,  3.66s/it]2025-08-23:03:25:08,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10243/12032 [8:50:30<1:50:34,  3.71s/it]2025-08-23:03:25:12,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10244/12032 [8:50:34<1:51:08,  3.73s/it]2025-08-23:03:25:16,322 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37594 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10245/12032 [8:50:38<1:51:28,  3.74s/it]2025-08-23:03:25:20,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10246/12032 [8:50:42<1:52:01,  3.76s/it]2025-08-23:03:25:23,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48768 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10247/12032 [8:50:43<1:28:09,  2.96s/it]2025-08-23:03:25:25,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10248/12032 [8:50:44<1:17:38,  2.61s/it]2025-08-23:03:25:26,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10249/12032 [8:50:48<1:27:47,  2.95s/it]2025-08-23:03:25:30,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10250/12032 [8:50:50<1:13:29,  2.47s/it]2025-08-23:03:25:31,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10251/12032 [8:50:53<1:18:37,  2.65s/it]2025-08-23:03:25:34,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10252/12032 [8:50:56<1:21:34,  2.75s/it]2025-08-23:03:25:37,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10253/12032 [8:50:59<1:30:51,  3.06s/it]2025-08-23:03:25:41,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10254/12032 [8:51:00<1:12:56,  2.46s/it]2025-08-23:03:25:42,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10255/12032 [8:51:02<1:02:27,  2.11s/it]2025-08-23:03:25:44,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10256/12032 [8:51:03<52:00,  1.76s/it]  2025-08-23:03:25:45,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10257/12032 [8:51:06<1:09:17,  2.34s/it]2025-08-23:03:25:48,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10258/12032 [8:51:08<58:43,  1.99s/it]  2025-08-23:03:25:49,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10259/12032 [8:51:11<1:14:29,  2.52s/it]2025-08-23:03:25:53,651 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10260/12032 [8:51:15<1:26:25,  2.93s/it]2025-08-23:03:25:57,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10261/12032 [8:51:19<1:34:21,  3.20s/it]2025-08-23:03:26:01,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10262/12032 [8:51:22<1:28:07,  2.99s/it]2025-08-23:03:26:03,850 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10263/12032 [8:51:23<1:16:57,  2.61s/it]2025-08-23:03:26:05,580 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10264/12032 [8:51:27<1:27:18,  2.96s/it]2025-08-23:03:26:09,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10265/12032 [8:51:31<1:34:26,  3.21s/it]2025-08-23:03:26:13,143 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10266/12032 [8:51:35<1:39:18,  3.37s/it]2025-08-23:03:26:16,907 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10267/12032 [8:51:38<1:43:36,  3.52s/it]2025-08-23:03:26:20,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10268/12032 [8:51:42<1:46:18,  3.62s/it]2025-08-23:03:26:24,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10269/12032 [8:51:46<1:48:03,  3.68s/it]2025-08-23:03:26:28,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10270/12032 [8:51:50<1:49:01,  3.71s/it]2025-08-23:03:26:32,224 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10271/12032 [8:51:53<1:40:07,  3.41s/it]2025-08-23:03:26:34,933 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10272/12032 [8:51:56<1:43:14,  3.52s/it]2025-08-23:03:26:38,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10273/12032 [8:52:00<1:45:58,  3.61s/it]2025-08-23:03:26:42,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10274/12032 [8:52:04<1:47:58,  3.69s/it]2025-08-23:03:26:46,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10275/12032 [8:52:07<1:43:30,  3.53s/it]2025-08-23:03:26:49,575 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10276/12032 [8:52:11<1:45:29,  3.60s/it]2025-08-23:03:26:53,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10277/12032 [8:52:15<1:47:48,  3.69s/it]2025-08-23:03:26:57,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10278/12032 [8:52:17<1:30:14,  3.09s/it]2025-08-23:03:26:58,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10279/12032 [8:52:20<1:36:28,  3.30s/it]2025-08-23:03:27:02,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10280/12032 [8:52:24<1:40:24,  3.44s/it]2025-08-23:03:27:06,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10281/12032 [8:52:27<1:34:38,  3.24s/it]2025-08-23:03:27:09,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10282/12032 [8:52:31<1:39:48,  3.42s/it]2025-08-23:03:27:13,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10283/12032 [8:52:35<1:42:58,  3.53s/it]2025-08-23:03:27:16,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10284/12032 [8:52:38<1:45:26,  3.62s/it]2025-08-23:03:27:20,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10285/12032 [8:52:42<1:46:46,  3.67s/it]2025-08-23:03:27:24,486 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10286/12032 [8:52:46<1:48:06,  3.71s/it]2025-08-23:03:27:28,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  85%|████████▌ | 10287/12032 [8:52:50<1:49:01,  3.75s/it]2025-08-23:03:27:32,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10288/12032 [8:52:54<1:49:34,  3.77s/it]2025-08-23:03:27:35,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10289/12032 [8:52:57<1:50:03,  3.79s/it]2025-08-23:03:27:39,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10290/12032 [8:53:00<1:41:34,  3.50s/it]2025-08-23:03:27:42,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10291/12032 [8:53:04<1:44:13,  3.59s/it]2025-08-23:03:27:46,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10292/12032 [8:53:08<1:45:57,  3.65s/it]2025-08-23:03:27:50,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10293/12032 [8:53:12<1:47:01,  3.69s/it]2025-08-23:03:27:54,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10294/12032 [8:53:15<1:47:53,  3.72s/it]2025-08-23:03:27:57,804 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10295/12032 [8:53:19<1:48:25,  3.75s/it]2025-08-23:03:28:01,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10296/12032 [8:53:23<1:49:07,  3.77s/it]2025-08-23:03:28:05,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10297/12032 [8:53:27<1:47:28,  3.72s/it]2025-08-23:03:28:09,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51092 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10298/12032 [8:53:30<1:48:03,  3.74s/it]2025-08-23:03:28:12,811 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10299/12032 [8:53:34<1:48:23,  3.75s/it]2025-08-23:03:28:16,596 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10300/12032 [8:53:38<1:48:37,  3.76s/it]2025-08-23:03:28:20,382 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10301/12032 [8:53:40<1:36:44,  3.35s/it]2025-08-23:03:28:22,780 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10302/12032 [8:53:44<1:41:04,  3.51s/it]2025-08-23:03:28:26,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10303/12032 [8:53:48<1:40:29,  3.49s/it]2025-08-23:03:28:30,085 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10304/12032 [8:53:52<1:43:31,  3.59s/it]2025-08-23:03:28:33,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49184 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10305/12032 [8:53:55<1:45:08,  3.65s/it]2025-08-23:03:28:37,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10306/12032 [8:53:59<1:46:36,  3.71s/it]2025-08-23:03:28:41,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10307/12032 [8:54:01<1:27:49,  3.05s/it]2025-08-23:03:28:43,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53786 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10308/12032 [8:54:05<1:34:32,  3.29s/it]2025-08-23:03:28:46,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10309/12032 [8:54:08<1:31:16,  3.18s/it]2025-08-23:03:28:49,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10310/12032 [8:54:10<1:27:08,  3.04s/it]2025-08-23:03:28:52,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10311/12032 [8:54:14<1:33:49,  3.27s/it]2025-08-23:03:28:56,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10312/12032 [8:54:16<1:24:29,  2.95s/it]2025-08-23:03:28:58,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10313/12032 [8:54:19<1:26:01,  3.00s/it]2025-08-23:03:29:01,689 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10314/12032 [8:54:22<1:21:32,  2.85s/it]2025-08-23:03:29:04,175 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10315/12032 [8:54:25<1:21:26,  2.85s/it]2025-08-23:03:29:07,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10316/12032 [8:54:28<1:29:28,  3.13s/it]2025-08-23:03:29:10,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10317/12032 [8:54:30<1:11:45,  2.51s/it]2025-08-23:03:29:11,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10318/12032 [8:54:31<1:05:10,  2.28s/it]2025-08-23:03:29:13,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10319/12032 [8:54:32<54:56,  1.92s/it]  2025-08-23:03:29:14,713 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10320/12032 [8:54:34<52:35,  1.84s/it]2025-08-23:03:29:16,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10321/12032 [8:54:35<47:49,  1.68s/it]2025-08-23:03:29:17,655 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10322/12032 [8:54:37<44:30,  1.56s/it]2025-08-23:03:29:18,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10323/12032 [8:54:37<36:42,  1.29s/it]2025-08-23:03:29:19,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10324/12032 [8:54:38<32:49,  1.15s/it]2025-08-23:03:29:20,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10325/12032 [8:54:40<36:25,  1.28s/it]2025-08-23:03:29:22,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10326/12032 [8:54:41<38:39,  1.36s/it]2025-08-23:03:29:23,557 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10327/12032 [8:54:42<36:44,  1.29s/it]2025-08-23:03:29:24,695 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10328/12032 [8:54:44<37:25,  1.32s/it]2025-08-23:03:29:26,071 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10329/12032 [8:54:46<43:04,  1.52s/it]2025-08-23:03:29:28,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10330/12032 [8:54:49<1:02:19,  2.20s/it]2025-08-23:03:29:31,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10331/12032 [8:54:53<1:16:17,  2.69s/it]2025-08-23:03:29:35,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10332/12032 [8:54:57<1:25:33,  3.02s/it]2025-08-23:03:29:39,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10333/12032 [8:55:01<1:31:56,  3.25s/it]2025-08-23:03:29:43,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10334/12032 [8:55:05<1:36:49,  3.42s/it]2025-08-23:03:29:47,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10335/12032 [8:55:09<1:39:53,  3.53s/it]2025-08-23:03:29:50,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10336/12032 [8:55:12<1:42:44,  3.63s/it]2025-08-23:03:29:54,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10337/12032 [8:55:16<1:45:05,  3.72s/it]2025-08-23:03:29:58,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10338/12032 [8:55:19<1:38:36,  3.49s/it]2025-08-23:03:30:01,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45228 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10339/12032 [8:55:23<1:41:13,  3.59s/it]2025-08-23:03:30:05,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10340/12032 [8:55:27<1:42:47,  3.65s/it]2025-08-23:03:30:09,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10341/12032 [8:55:31<1:44:11,  3.70s/it]2025-08-23:03:30:13,024 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58816 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10342/12032 [8:55:35<1:45:37,  3.75s/it]2025-08-23:03:30:16,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10343/12032 [8:55:38<1:46:00,  3.77s/it]2025-08-23:03:30:20,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10344/12032 [8:55:42<1:46:23,  3.78s/it]2025-08-23:03:30:24,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10345/12032 [8:55:46<1:46:34,  3.79s/it]2025-08-23:03:30:28,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10346/12032 [8:55:50<1:46:53,  3.80s/it]2025-08-23:03:30:32,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10347/12032 [8:55:54<1:46:51,  3.80s/it]2025-08-23:03:30:35,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48692 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10348/12032 [8:55:57<1:46:39,  3.80s/it]2025-08-23:03:30:39,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10349/12032 [8:56:01<1:45:26,  3.76s/it]2025-08-23:03:30:43,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10350/12032 [8:56:05<1:45:44,  3.77s/it]2025-08-23:03:30:47,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10351/12032 [8:56:09<1:45:57,  3.78s/it]2025-08-23:03:30:51,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51110 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10352/12032 [8:56:13<1:46:10,  3.79s/it]2025-08-23:03:30:54,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10353/12032 [8:56:16<1:46:20,  3.80s/it]2025-08-23:03:30:58,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10354/12032 [8:56:20<1:46:41,  3.81s/it]2025-08-23:03:31:02,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10355/12032 [8:56:24<1:46:31,  3.81s/it]2025-08-23:03:31:06,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10356/12032 [8:56:28<1:46:17,  3.80s/it]2025-08-23:03:31:10,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10357/12032 [8:56:32<1:46:08,  3.80s/it]2025-08-23:03:31:13,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10358/12032 [8:56:35<1:45:58,  3.80s/it]2025-08-23:03:31:17,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34954 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10359/12032 [8:56:39<1:46:10,  3.81s/it]2025-08-23:03:31:21,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10360/12032 [8:56:43<1:45:56,  3.80s/it]2025-08-23:03:31:25,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10361/12032 [8:56:47<1:45:45,  3.80s/it]2025-08-23:03:31:29,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10362/12032 [8:56:51<1:45:39,  3.80s/it]2025-08-23:03:31:32,890 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10363/12032 [8:56:54<1:45:38,  3.80s/it]2025-08-23:03:31:36,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10364/12032 [8:56:58<1:45:43,  3.80s/it]2025-08-23:03:31:40,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10365/12032 [8:57:02<1:46:04,  3.82s/it]2025-08-23:03:31:44,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33520 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10366/12032 [8:57:06<1:45:52,  3.81s/it]2025-08-23:03:31:48,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10367/12032 [8:57:10<1:45:38,  3.81s/it]2025-08-23:03:31:51,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10368/12032 [8:57:12<1:30:52,  3.28s/it]2025-08-23:03:31:53,995 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10369/12032 [8:57:13<1:13:16,  2.64s/it]2025-08-23:03:31:55,161 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10370/12032 [8:57:17<1:23:18,  3.01s/it]2025-08-23:03:31:59,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10371/12032 [8:57:18<1:11:56,  2.60s/it]2025-08-23:03:32:00,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10372/12032 [8:57:20<1:08:13,  2.47s/it]2025-08-23:03:32:02,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10373/12032 [8:57:24<1:19:25,  2.87s/it]2025-08-23:03:32:06,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10374/12032 [8:57:28<1:26:34,  3.13s/it]2025-08-23:03:32:10,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10375/12032 [8:57:29<1:08:36,  2.48s/it]2025-08-23:03:32:11,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10376/12032 [8:57:33<1:19:54,  2.90s/it]2025-08-23:03:32:15,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▌ | 10377/12032 [8:57:37<1:28:01,  3.19s/it]2025-08-23:03:32:19,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10378/12032 [8:57:41<1:33:05,  3.38s/it]2025-08-23:03:32:22,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10379/12032 [8:57:44<1:36:25,  3.50s/it]2025-08-23:03:32:26,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10380/12032 [8:57:48<1:38:56,  3.59s/it]2025-08-23:03:32:30,496 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46696 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10381/12032 [8:57:52<1:41:01,  3.67s/it]2025-08-23:03:32:34,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10382/12032 [8:57:56<1:43:18,  3.76s/it]2025-08-23:03:32:38,304 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10383/12032 [8:58:00<1:44:07,  3.79s/it]2025-08-23:03:32:42,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10384/12032 [8:58:04<1:45:00,  3.82s/it]2025-08-23:03:32:46,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10385/12032 [8:58:08<1:44:34,  3.81s/it]2025-08-23:03:32:49,849 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10386/12032 [8:58:11<1:45:09,  3.83s/it]2025-08-23:03:32:53,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10387/12032 [8:58:15<1:45:00,  3.83s/it]2025-08-23:03:32:57,560 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10388/12032 [8:58:19<1:44:31,  3.81s/it]2025-08-23:03:33:01,340 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10389/12032 [8:58:23<1:44:27,  3.81s/it]2025-08-23:03:33:05,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10390/12032 [8:58:27<1:44:43,  3.83s/it]2025-08-23:03:33:09,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40866 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10391/12032 [8:58:30<1:44:14,  3.81s/it]2025-08-23:03:33:12,784 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10392/12032 [8:58:34<1:44:09,  3.81s/it]2025-08-23:03:33:16,594 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10393/12032 [8:58:38<1:43:35,  3.79s/it]2025-08-23:03:33:20,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10394/12032 [8:58:42<1:43:29,  3.79s/it]2025-08-23:03:33:24,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10395/12032 [8:58:44<1:30:32,  3.32s/it]2025-08-23:03:33:26,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10396/12032 [8:58:48<1:34:17,  3.46s/it]2025-08-23:03:33:30,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38688 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10397/12032 [8:58:52<1:36:59,  3.56s/it]2025-08-23:03:33:33,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10398/12032 [8:58:55<1:38:50,  3.63s/it]2025-08-23:03:33:37,720 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10399/12032 [8:58:59<1:41:17,  3.72s/it]2025-08-23:03:33:41,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10400/12032 [8:59:03<1:42:15,  3.76s/it]2025-08-23:03:33:45,504 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35146 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10401/12032 [8:59:07<1:42:51,  3.78s/it]2025-08-23:03:33:49,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10402/12032 [8:59:11<1:43:21,  3.80s/it]2025-08-23:03:33:53,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10403/12032 [8:59:15<1:46:45,  3.93s/it]2025-08-23:03:33:57,427 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10404/12032 [8:59:19<1:46:48,  3.94s/it]2025-08-23:03:34:01,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10405/12032 [8:59:23<1:45:20,  3.88s/it]2025-08-23:03:34:05,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10406/12032 [8:59:27<1:44:57,  3.87s/it]2025-08-23:03:34:08,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  86%|████████▋ | 10407/12032 [8:59:30<1:44:03,  3.84s/it]2025-08-23:03:34:12,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10408/12032 [8:59:33<1:32:12,  3.41s/it]2025-08-23:03:34:15,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10409/12032 [8:59:36<1:33:34,  3.46s/it]2025-08-23:03:34:18,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10410/12032 [8:59:40<1:36:40,  3.58s/it]2025-08-23:03:34:22,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10411/12032 [8:59:44<1:38:20,  3.64s/it]2025-08-23:03:34:26,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37570 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10412/12032 [8:59:48<1:39:18,  3.68s/it]2025-08-23:03:34:30,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10413/12032 [8:59:51<1:36:43,  3.58s/it]2025-08-23:03:34:33,498 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10414/12032 [8:59:55<1:38:41,  3.66s/it]2025-08-23:03:34:37,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10415/12032 [8:59:57<1:26:46,  3.22s/it]2025-08-23:03:34:39,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10416/12032 [9:00:01<1:31:17,  3.39s/it]2025-08-23:03:34:43,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10417/12032 [9:00:05<1:34:23,  3.51s/it]2025-08-23:03:34:47,092 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10418/12032 [9:00:09<1:37:09,  3.61s/it]2025-08-23:03:34:50,949 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10419/12032 [9:00:12<1:38:50,  3.68s/it]2025-08-23:03:34:54,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38008 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10420/12032 [9:00:16<1:39:43,  3.71s/it]2025-08-23:03:34:58,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10421/12032 [9:00:20<1:40:46,  3.75s/it]2025-08-23:03:35:02,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10422/12032 [9:00:24<1:41:36,  3.79s/it]2025-08-23:03:35:06,285 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10423/12032 [9:00:27<1:32:12,  3.44s/it]2025-08-23:03:35:08,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10424/12032 [9:00:29<1:22:18,  3.07s/it]2025-08-23:03:35:11,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10425/12032 [9:00:30<1:05:38,  2.45s/it]2025-08-23:03:35:12,127 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10426/12032 [9:00:34<1:16:27,  2.86s/it]2025-08-23:03:35:15,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10427/12032 [9:00:36<1:12:31,  2.71s/it]2025-08-23:03:35:18,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10428/12032 [9:00:40<1:20:59,  3.03s/it]2025-08-23:03:35:22,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10429/12032 [9:00:43<1:20:28,  3.01s/it]2025-08-23:03:35:25,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10430/12032 [9:00:44<1:09:31,  2.60s/it]2025-08-23:03:35:26,698 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10431/12032 [9:00:48<1:19:52,  2.99s/it]2025-08-23:03:35:30,600 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10432/12032 [9:00:50<1:07:59,  2.55s/it]2025-08-23:03:35:32,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10433/12032 [9:00:54<1:18:12,  2.93s/it]2025-08-23:03:35:35,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10434/12032 [9:00:56<1:15:58,  2.85s/it]2025-08-23:03:35:38,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10435/12032 [9:00:59<1:11:14,  2.68s/it]2025-08-23:03:35:40,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10436/12032 [9:01:00<1:00:55,  2.29s/it]2025-08-23:03:35:42,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10437/12032 [9:01:03<1:03:56,  2.41s/it]2025-08-23:03:35:44,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10438/12032 [9:01:04<53:00,  2.00s/it]  2025-08-23:03:35:45,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10439/12032 [9:01:05<46:33,  1.75s/it]2025-08-23:03:35:47,165 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10440/12032 [9:01:06<45:01,  1.70s/it]2025-08-23:03:35:48,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10441/12032 [9:01:08<41:48,  1.58s/it]2025-08-23:03:35:50,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10442/12032 [9:01:11<58:08,  2.19s/it]2025-08-23:03:35:53,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10443/12032 [9:01:13<57:03,  2.15s/it]2025-08-23:03:35:55,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45970 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10444/12032 [9:01:16<58:04,  2.19s/it]2025-08-23:03:35:58,010 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10445/12032 [9:01:19<1:10:37,  2.67s/it]2025-08-23:03:36:01,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10446/12032 [9:01:23<1:20:11,  3.03s/it]2025-08-23:03:36:05,672 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10447/12032 [9:01:27<1:26:19,  3.27s/it]2025-08-23:03:36:09,487 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10448/12032 [9:01:31<1:30:17,  3.42s/it]2025-08-23:03:36:13,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10449/12032 [9:01:35<1:32:59,  3.52s/it]2025-08-23:03:36:17,030 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10450/12032 [9:01:38<1:34:52,  3.60s/it]2025-08-23:03:36:20,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10451/12032 [9:01:42<1:36:35,  3.67s/it]2025-08-23:03:36:24,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10452/12032 [9:01:46<1:37:30,  3.70s/it]2025-08-23:03:36:28,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10453/12032 [9:01:50<1:38:29,  3.74s/it]2025-08-23:03:36:32,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10454/12032 [9:01:54<1:38:53,  3.76s/it]2025-08-23:03:36:36,050 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10455/12032 [9:01:57<1:38:54,  3.76s/it]2025-08-23:03:36:39,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10456/12032 [9:02:01<1:39:03,  3.77s/it]2025-08-23:03:36:43,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10457/12032 [9:02:05<1:35:43,  3.65s/it]2025-08-23:03:36:46,966 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10458/12032 [9:02:08<1:36:33,  3.68s/it]2025-08-23:03:36:50,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10459/12032 [9:02:12<1:38:36,  3.76s/it]2025-08-23:03:36:54,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10460/12032 [9:02:16<1:38:38,  3.76s/it]2025-08-23:03:36:58,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10461/12032 [9:02:20<1:38:49,  3.77s/it]2025-08-23:03:37:02,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10462/12032 [9:02:24<1:38:56,  3.78s/it]2025-08-23:03:37:06,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49752 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10463/12032 [9:02:27<1:38:51,  3.78s/it]2025-08-23:03:37:09,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49766 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10464/12032 [9:02:31<1:38:46,  3.78s/it]2025-08-23:03:37:13,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10465/12032 [9:02:35<1:40:10,  3.84s/it]2025-08-23:03:37:17,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10466/12032 [9:02:39<1:39:43,  3.82s/it]2025-08-23:03:37:21,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10467/12032 [9:02:43<1:39:15,  3.81s/it]2025-08-23:03:37:25,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10468/12032 [9:02:46<1:37:20,  3.73s/it]2025-08-23:03:37:28,690 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10469/12032 [9:02:50<1:37:50,  3.76s/it]2025-08-23:03:37:32,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10470/12032 [9:02:54<1:37:53,  3.76s/it]2025-08-23:03:37:36,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10471/12032 [9:02:58<1:39:08,  3.81s/it]2025-08-23:03:37:40,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10472/12032 [9:03:02<1:38:37,  3.79s/it]2025-08-23:03:37:43,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10473/12032 [9:03:05<1:38:46,  3.80s/it]2025-08-23:03:37:47,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10474/12032 [9:03:09<1:38:32,  3.79s/it]2025-08-23:03:37:51,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10475/12032 [9:03:13<1:38:16,  3.79s/it]2025-08-23:03:37:55,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10476/12032 [9:03:17<1:38:45,  3.81s/it]2025-08-23:03:37:59,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10477/12032 [9:03:18<1:14:47,  2.89s/it]2025-08-23:03:37:59,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10478/12032 [9:03:20<1:13:09,  2.82s/it]2025-08-23:03:38:02,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10479/12032 [9:03:21<58:54,  2.28s/it]  2025-08-23:03:38:03,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10480/12032 [9:03:25<1:10:29,  2.72s/it]2025-08-23:03:38:07,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10481/12032 [9:03:29<1:18:40,  3.04s/it]2025-08-23:03:38:11,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10482/12032 [9:03:33<1:24:15,  3.26s/it]2025-08-23:03:38:14,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10483/12032 [9:03:36<1:28:30,  3.43s/it]2025-08-23:03:38:18,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10484/12032 [9:03:40<1:31:11,  3.53s/it]2025-08-23:03:38:22,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10485/12032 [9:03:44<1:32:56,  3.60s/it]2025-08-23:03:38:26,283 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10486/12032 [9:03:48<1:34:20,  3.66s/it]2025-08-23:03:38:30,077 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10487/12032 [9:03:52<1:35:07,  3.69s/it]2025-08-23:03:38:33,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10488/12032 [9:03:55<1:35:39,  3.72s/it]2025-08-23:03:38:37,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10489/12032 [9:03:59<1:36:06,  3.74s/it]2025-08-23:03:38:41,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10490/12032 [9:04:03<1:36:03,  3.74s/it]2025-08-23:03:38:45,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10491/12032 [9:04:05<1:24:37,  3.30s/it]2025-08-23:03:38:47,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10492/12032 [9:04:09<1:28:24,  3.44s/it]2025-08-23:03:38:51,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10493/12032 [9:04:13<1:31:09,  3.55s/it]2025-08-23:03:38:55,006 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10494/12032 [9:04:14<1:13:24,  2.86s/it]2025-08-23:03:38:56,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10495/12032 [9:04:18<1:20:34,  3.15s/it]2025-08-23:03:39:00,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10496/12032 [9:04:22<1:26:07,  3.36s/it]2025-08-23:03:39:03,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10497/12032 [9:04:25<1:29:24,  3.49s/it]2025-08-23:03:39:07,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10498/12032 [9:04:29<1:31:50,  3.59s/it]2025-08-23:03:39:11,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10499/12032 [9:04:33<1:33:27,  3.66s/it]2025-08-23:03:39:15,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10500/12032 [9:04:37<1:34:28,  3.70s/it]2025-08-23:03:39:19,164 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10501/12032 [9:04:41<1:35:09,  3.73s/it]2025-08-23:03:39:22,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10502/12032 [9:04:44<1:35:29,  3.74s/it]2025-08-23:03:39:26,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10503/12032 [9:04:48<1:35:35,  3.75s/it]2025-08-23:03:39:30,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10504/12032 [9:04:52<1:36:00,  3.77s/it]2025-08-23:03:39:34,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10505/12032 [9:04:56<1:36:17,  3.78s/it]2025-08-23:03:39:38,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10506/12032 [9:05:00<1:36:15,  3.78s/it]2025-08-23:03:39:41,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10507/12032 [9:05:03<1:36:17,  3.79s/it]2025-08-23:03:39:45,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38924 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10508/12032 [9:05:07<1:36:19,  3.79s/it]2025-08-23:03:39:49,526 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10509/12032 [9:05:11<1:37:03,  3.82s/it]2025-08-23:03:39:53,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10510/12032 [9:05:15<1:36:47,  3.82s/it]2025-08-23:03:39:57,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10511/12032 [9:05:19<1:36:33,  3.81s/it]2025-08-23:03:40:01,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10512/12032 [9:05:22<1:36:23,  3.81s/it]2025-08-23:03:40:04,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10513/12032 [9:05:26<1:36:05,  3.80s/it]2025-08-23:03:40:08,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10514/12032 [9:05:30<1:36:17,  3.81s/it]2025-08-23:03:40:12,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10515/12032 [9:05:34<1:36:02,  3.80s/it]2025-08-23:03:40:16,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10516/12032 [9:05:38<1:35:56,  3.80s/it]2025-08-23:03:40:19,988 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10517/12032 [9:05:41<1:35:55,  3.80s/it]2025-08-23:03:40:23,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10518/12032 [9:05:45<1:35:48,  3.80s/it]2025-08-23:03:40:27,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10519/12032 [9:05:49<1:35:48,  3.80s/it]2025-08-23:03:40:31,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10520/12032 [9:05:53<1:35:49,  3.80s/it]2025-08-23:03:40:35,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10521/12032 [9:05:54<1:18:07,  3.10s/it]2025-08-23:03:40:36,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10522/12032 [9:05:58<1:22:39,  3.28s/it]2025-08-23:03:40:40,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10523/12032 [9:06:02<1:26:19,  3.43s/it]2025-08-23:03:40:44,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10524/12032 [9:06:05<1:25:26,  3.40s/it]2025-08-23:03:40:47,477 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10525/12032 [9:06:09<1:28:17,  3.52s/it]2025-08-23:03:40:51,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10526/12032 [9:06:10<1:11:11,  2.84s/it]2025-08-23:03:40:52,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  87%|████████▋ | 10527/12032 [9:06:12<1:02:56,  2.51s/it]2025-08-23:03:40:54,260 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10528/12032 [9:06:15<1:03:44,  2.54s/it]2025-08-23:03:40:56,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10529/12032 [9:06:16<53:44,  2.15s/it]  2025-08-23:03:40:58,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10530/12032 [9:06:17<44:41,  1.79s/it]2025-08-23:03:40:59,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10531/12032 [9:06:21<1:00:12,  2.41s/it]2025-08-23:03:41:02,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10532/12032 [9:06:23<1:03:37,  2.54s/it]2025-08-23:03:41:05,768 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10533/12032 [9:06:27<1:13:21,  2.94s/it]2025-08-23:03:41:09,616 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10534/12032 [9:06:31<1:19:53,  3.20s/it]2025-08-23:03:41:13,432 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10535/12032 [9:06:35<1:24:33,  3.39s/it]2025-08-23:03:41:17,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10536/12032 [9:06:39<1:27:40,  3.52s/it]2025-08-23:03:41:21,076 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10537/12032 [9:06:43<1:29:43,  3.60s/it]2025-08-23:03:41:24,874 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10538/12032 [9:06:46<1:31:22,  3.67s/it]2025-08-23:03:41:28,705 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10539/12032 [9:06:50<1:32:26,  3.71s/it]2025-08-23:03:41:32,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10540/12032 [9:06:54<1:33:04,  3.74s/it]2025-08-23:03:41:36,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60598 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10541/12032 [9:06:58<1:34:08,  3.79s/it]2025-08-23:03:41:40,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10542/12032 [9:07:02<1:35:06,  3.83s/it]2025-08-23:03:41:44,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10543/12032 [9:07:06<1:34:41,  3.82s/it]2025-08-23:03:41:47,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10544/12032 [9:07:09<1:34:22,  3.81s/it]2025-08-23:03:41:51,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10545/12032 [9:07:13<1:34:17,  3.80s/it]2025-08-23:03:41:55,522 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10546/12032 [9:07:15<1:21:20,  3.28s/it]2025-08-23:03:41:57,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10547/12032 [9:07:19<1:25:14,  3.44s/it]2025-08-23:03:42:01,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10548/12032 [9:07:23<1:28:07,  3.56s/it]2025-08-23:03:42:05,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10549/12032 [9:07:27<1:29:55,  3.64s/it]2025-08-23:03:42:09,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10550/12032 [9:07:31<1:31:04,  3.69s/it]2025-08-23:03:42:12,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10551/12032 [9:07:34<1:31:53,  3.72s/it]2025-08-23:03:42:16,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10552/12032 [9:07:38<1:32:32,  3.75s/it]2025-08-23:03:42:20,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10553/12032 [9:07:42<1:33:08,  3.78s/it]2025-08-23:03:42:24,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10554/12032 [9:07:43<1:15:50,  3.08s/it]2025-08-23:03:42:25,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10555/12032 [9:07:47<1:21:01,  3.29s/it]2025-08-23:03:42:29,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10556/12032 [9:07:51<1:24:55,  3.45s/it]2025-08-23:03:42:33,393 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10557/12032 [9:07:55<1:27:22,  3.55s/it]2025-08-23:03:42:37,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10558/12032 [9:07:59<1:29:18,  3.64s/it]2025-08-23:03:42:41,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10559/12032 [9:08:02<1:30:21,  3.68s/it]2025-08-23:03:42:44,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10560/12032 [9:08:06<1:31:07,  3.71s/it]2025-08-23:03:42:48,589 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10561/12032 [9:08:10<1:31:34,  3.74s/it]2025-08-23:03:42:52,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10562/12032 [9:08:14<1:31:56,  3.75s/it]2025-08-23:03:42:56,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10563/12032 [9:08:18<1:32:07,  3.76s/it]2025-08-23:03:42:59,954 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10564/12032 [9:08:21<1:32:10,  3.77s/it]2025-08-23:03:43:03,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10565/12032 [9:08:25<1:32:13,  3.77s/it]2025-08-23:03:43:07,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10566/12032 [9:08:29<1:31:59,  3.76s/it]2025-08-23:03:43:11,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10567/12032 [9:08:33<1:31:55,  3.76s/it]2025-08-23:03:43:15,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10568/12032 [9:08:34<1:11:42,  2.94s/it]2025-08-23:03:43:16,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10569/12032 [9:08:37<1:17:39,  3.18s/it]2025-08-23:03:43:19,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10570/12032 [9:08:41<1:22:24,  3.38s/it]2025-08-23:03:43:23,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10571/12032 [9:08:43<1:11:22,  2.93s/it]2025-08-23:03:43:25,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10572/12032 [9:08:47<1:17:20,  3.18s/it]2025-08-23:03:43:29,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10573/12032 [9:08:51<1:21:34,  3.35s/it]2025-08-23:03:43:33,041 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10574/12032 [9:08:52<1:06:48,  2.75s/it]2025-08-23:03:43:34,377 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10575/12032 [9:08:56<1:15:26,  3.11s/it]2025-08-23:03:43:38,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10576/12032 [9:09:00<1:19:58,  3.30s/it]2025-08-23:03:43:42,054 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10577/12032 [9:09:04<1:23:52,  3.46s/it]2025-08-23:03:43:45,894 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10578/12032 [9:09:07<1:26:17,  3.56s/it]2025-08-23:03:43:49,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10579/12032 [9:09:11<1:27:45,  3.62s/it]2025-08-23:03:43:53,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10580/12032 [9:09:15<1:29:03,  3.68s/it]2025-08-23:03:43:57,275 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10581/12032 [9:09:19<1:29:55,  3.72s/it]2025-08-23:03:44:01,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10582/12032 [9:09:23<1:30:47,  3.76s/it]2025-08-23:03:44:04,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10583/12032 [9:09:26<1:30:53,  3.76s/it]2025-08-23:03:44:08,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10584/12032 [9:09:30<1:31:07,  3.78s/it]2025-08-23:03:44:12,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10585/12032 [9:09:34<1:31:11,  3.78s/it]2025-08-23:03:44:16,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10586/12032 [9:09:38<1:31:06,  3.78s/it]2025-08-23:03:44:20,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57746 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10587/12032 [9:09:41<1:28:15,  3.66s/it]2025-08-23:03:44:23,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44096 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10588/12032 [9:09:45<1:29:00,  3.70s/it]2025-08-23:03:44:27,258 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10589/12032 [9:09:49<1:29:53,  3.74s/it]2025-08-23:03:44:31,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10590/12032 [9:09:53<1:30:31,  3.77s/it]2025-08-23:03:44:34,922 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10591/12032 [9:09:56<1:30:44,  3.78s/it]2025-08-23:03:44:38,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10592/12032 [9:10:00<1:30:45,  3.78s/it]2025-08-23:03:44:42,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10593/12032 [9:10:04<1:30:43,  3.78s/it]2025-08-23:03:44:46,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10594/12032 [9:10:08<1:32:17,  3.85s/it]2025-08-23:03:44:50,312 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38558 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10595/12032 [9:10:11<1:29:21,  3.73s/it]2025-08-23:03:44:53,764 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10596/12032 [9:10:15<1:29:43,  3.75s/it]2025-08-23:03:44:57,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38564 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10597/12032 [9:10:19<1:29:42,  3.75s/it]2025-08-23:03:45:01,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10598/12032 [9:10:23<1:29:43,  3.75s/it]2025-08-23:03:45:05,072 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10599/12032 [9:10:25<1:16:22,  3.20s/it]2025-08-23:03:45:06,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10600/12032 [9:10:28<1:20:36,  3.38s/it]2025-08-23:03:45:10,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33014 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10601/12032 [9:10:31<1:11:16,  2.99s/it]2025-08-23:03:45:12,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10602/12032 [9:10:34<1:17:18,  3.24s/it]2025-08-23:03:45:16,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10603/12032 [9:10:38<1:20:59,  3.40s/it]2025-08-23:03:45:20,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10604/12032 [9:10:42<1:23:50,  3.52s/it]2025-08-23:03:45:24,262 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10605/12032 [9:10:46<1:26:30,  3.64s/it]2025-08-23:03:45:28,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10606/12032 [9:10:50<1:27:26,  3.68s/it]2025-08-23:03:45:31,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10607/12032 [9:10:53<1:21:50,  3.45s/it]2025-08-23:03:45:34,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10608/12032 [9:10:56<1:24:01,  3.54s/it]2025-08-23:03:45:38,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60486 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10609/12032 [9:11:00<1:25:33,  3.61s/it]2025-08-23:03:45:42,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10610/12032 [9:11:04<1:26:42,  3.66s/it]2025-08-23:03:45:46,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10611/12032 [9:11:08<1:27:51,  3.71s/it]2025-08-23:03:45:49,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10612/12032 [9:11:11<1:28:50,  3.75s/it]2025-08-23:03:45:53,835 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10613/12032 [9:11:13<1:14:22,  3.15s/it]2025-08-23:03:45:55,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10614/12032 [9:11:17<1:18:47,  3.33s/it]2025-08-23:03:45:59,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10615/12032 [9:11:21<1:21:42,  3.46s/it]2025-08-23:03:46:03,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10616/12032 [9:11:25<1:24:34,  3.58s/it]2025-08-23:03:46:06,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10617/12032 [9:11:26<1:10:08,  2.97s/it]2025-08-23:03:46:08,510 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10618/12032 [9:11:28<1:00:51,  2.58s/it]2025-08-23:03:46:10,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10619/12032 [9:11:29<51:50,  2.20s/it]  2025-08-23:03:46:11,492 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57508 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10620/12032 [9:11:31<45:56,  1.95s/it]2025-08-23:03:46:12,863 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10621/12032 [9:11:32<45:05,  1.92s/it]2025-08-23:03:46:14,699 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10622/12032 [9:11:36<58:06,  2.47s/it]2025-08-23:03:46:18,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10623/12032 [9:11:38<51:45,  2.20s/it]2025-08-23:03:46:20,044 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57548 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10624/12032 [9:11:39<48:23,  2.06s/it]2025-08-23:03:46:21,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10625/12032 [9:11:40<39:12,  1.67s/it]2025-08-23:03:46:22,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10626/12032 [9:11:43<44:55,  1.92s/it]2025-08-23:03:46:25,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10627/12032 [9:11:44<39:29,  1.69s/it]2025-08-23:03:46:26,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10628/12032 [9:11:47<49:40,  2.12s/it]2025-08-23:03:46:29,314 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10629/12032 [9:11:51<59:38,  2.55s/it]2025-08-23:03:46:32,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10630/12032 [9:11:54<1:08:50,  2.95s/it]2025-08-23:03:46:36,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10631/12032 [9:11:58<1:14:36,  3.20s/it]2025-08-23:03:46:40,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10632/12032 [9:12:02<1:19:02,  3.39s/it]2025-08-23:03:46:44,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10633/12032 [9:12:06<1:21:54,  3.51s/it]2025-08-23:03:46:48,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10634/12032 [9:12:10<1:24:00,  3.61s/it]2025-08-23:03:46:51,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10635/12032 [9:12:13<1:25:14,  3.66s/it]2025-08-23:03:46:55,762 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10636/12032 [9:12:17<1:26:11,  3.70s/it]2025-08-23:03:46:59,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10637/12032 [9:12:21<1:26:34,  3.72s/it]2025-08-23:03:47:03,336 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10638/12032 [9:12:25<1:27:20,  3.76s/it]2025-08-23:03:47:07,180 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10639/12032 [9:12:29<1:27:16,  3.76s/it]2025-08-23:03:47:10,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10640/12032 [9:12:32<1:27:59,  3.79s/it]2025-08-23:03:47:14,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10641/12032 [9:12:36<1:28:11,  3.80s/it]2025-08-23:03:47:18,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10642/12032 [9:12:40<1:28:39,  3.83s/it]2025-08-23:03:47:22,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42500 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10643/12032 [9:12:44<1:28:24,  3.82s/it]2025-08-23:03:47:26,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10644/12032 [9:12:48<1:28:08,  3.81s/it]2025-08-23:03:47:30,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10645/12032 [9:12:52<1:28:06,  3.81s/it]2025-08-23:03:47:33,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10646/12032 [9:12:55<1:24:25,  3.65s/it]2025-08-23:03:47:37,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36428 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10647/12032 [9:12:59<1:25:34,  3.71s/it]2025-08-23:03:47:41,043 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36530 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  88%|████████▊ | 10648/12032 [9:13:03<1:26:34,  3.75s/it]2025-08-23:03:47:44,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10649/12032 [9:13:06<1:27:02,  3.78s/it]2025-08-23:03:47:48,734 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36540 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10650/12032 [9:13:10<1:27:33,  3.80s/it]2025-08-23:03:47:52,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10651/12032 [9:13:14<1:27:31,  3.80s/it]2025-08-23:03:47:56,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39686 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10652/12032 [9:13:18<1:27:34,  3.81s/it]2025-08-23:03:48:00,219 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10653/12032 [9:13:22<1:28:05,  3.83s/it]2025-08-23:03:48:04,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10654/12032 [9:13:25<1:22:13,  3.58s/it]2025-08-23:03:48:07,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10655/12032 [9:13:26<1:04:04,  2.79s/it]2025-08-23:03:48:08,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10656/12032 [9:13:29<1:10:31,  3.08s/it]2025-08-23:03:48:11,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10657/12032 [9:13:33<1:15:19,  3.29s/it]2025-08-23:03:48:15,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10658/12032 [9:13:37<1:18:59,  3.45s/it]2025-08-23:03:48:19,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10659/12032 [9:13:41<1:21:35,  3.57s/it]2025-08-23:03:48:23,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10660/12032 [9:13:44<1:18:35,  3.44s/it]2025-08-23:03:48:26,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10661/12032 [9:13:48<1:21:12,  3.55s/it]2025-08-23:03:48:30,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10662/12032 [9:13:52<1:23:08,  3.64s/it]2025-08-23:03:48:34,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10663/12032 [9:13:56<1:24:27,  3.70s/it]2025-08-23:03:48:37,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10664/12032 [9:13:59<1:25:03,  3.73s/it]2025-08-23:03:48:41,685 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10665/12032 [9:14:03<1:25:46,  3.76s/it]2025-08-23:03:48:45,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10666/12032 [9:14:07<1:26:09,  3.78s/it]2025-08-23:03:48:49,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10667/12032 [9:14:11<1:26:15,  3.79s/it]2025-08-23:03:48:53,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57846 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10668/12032 [9:14:15<1:26:31,  3.81s/it]2025-08-23:03:48:57,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10669/12032 [9:14:18<1:26:33,  3.81s/it]2025-08-23:03:49:00,827 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10670/12032 [9:14:21<1:15:27,  3.32s/it]2025-08-23:03:49:03,019 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10671/12032 [9:14:24<1:18:39,  3.47s/it]2025-08-23:03:49:06,820 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10672/12032 [9:14:28<1:20:55,  3.57s/it]2025-08-23:03:49:10,630 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10673/12032 [9:14:31<1:12:10,  3.19s/it]2025-08-23:03:49:12,920 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10674/12032 [9:14:34<1:16:53,  3.40s/it]2025-08-23:03:49:16,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10675/12032 [9:14:38<1:19:41,  3.52s/it]2025-08-23:03:49:20,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10676/12032 [9:14:41<1:12:21,  3.20s/it]2025-08-23:03:49:23,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10677/12032 [9:14:45<1:16:43,  3.40s/it]2025-08-23:03:49:26,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▊ | 10678/12032 [9:14:48<1:19:25,  3.52s/it]2025-08-23:03:49:30,736 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10679/12032 [9:14:52<1:21:49,  3.63s/it]2025-08-23:03:49:34,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60908 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10680/12032 [9:14:56<1:23:00,  3.68s/it]2025-08-23:03:49:38,433 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10681/12032 [9:15:00<1:23:56,  3.73s/it]2025-08-23:03:49:42,263 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10682/12032 [9:15:04<1:24:21,  3.75s/it]2025-08-23:03:49:46,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10683/12032 [9:15:08<1:24:59,  3.78s/it]2025-08-23:03:49:49,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10684/12032 [9:15:11<1:25:18,  3.80s/it]2025-08-23:03:49:53,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10685/12032 [9:15:15<1:25:21,  3.80s/it]2025-08-23:03:49:57,566 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10686/12032 [9:15:18<1:21:11,  3.62s/it]2025-08-23:03:50:00,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10687/12032 [9:15:22<1:22:35,  3.68s/it]2025-08-23:03:50:04,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10688/12032 [9:15:26<1:23:32,  3.73s/it]2025-08-23:03:50:08,429 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10689/12032 [9:15:30<1:24:23,  3.77s/it]2025-08-23:03:50:12,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10690/12032 [9:15:34<1:24:39,  3.78s/it]2025-08-23:03:50:16,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48648 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10691/12032 [9:15:38<1:24:51,  3.80s/it]2025-08-23:03:50:19,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10692/12032 [9:15:41<1:23:42,  3.75s/it]2025-08-23:03:50:23,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35192 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10693/12032 [9:15:45<1:24:08,  3.77s/it]2025-08-23:03:50:27,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10694/12032 [9:15:47<1:13:05,  3.28s/it]2025-08-23:03:50:29,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10695/12032 [9:15:51<1:16:52,  3.45s/it]2025-08-23:03:50:33,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10696/12032 [9:15:55<1:19:13,  3.56s/it]2025-08-23:03:50:37,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10697/12032 [9:15:59<1:20:44,  3.63s/it]2025-08-23:03:50:40,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10698/12032 [9:16:02<1:21:38,  3.67s/it]2025-08-23:03:50:44,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10699/12032 [9:16:06<1:22:29,  3.71s/it]2025-08-23:03:50:48,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10700/12032 [9:16:10<1:22:59,  3.74s/it]2025-08-23:03:50:52,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10701/12032 [9:16:14<1:23:32,  3.77s/it]2025-08-23:03:50:56,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10702/12032 [9:16:18<1:23:46,  3.78s/it]2025-08-23:03:51:00,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10703/12032 [9:16:20<1:16:10,  3.44s/it]2025-08-23:03:51:02,644 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10704/12032 [9:16:24<1:15:08,  3.39s/it]2025-08-23:03:51:05,936 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10705/12032 [9:16:24<58:15,  2.63s/it]  2025-08-23:03:51:06,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10706/12032 [9:16:26<53:26,  2.42s/it]2025-08-23:03:51:08,711 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10707/12032 [9:16:30<1:02:42,  2.84s/it]2025-08-23:03:51:12,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10708/12032 [9:16:34<1:09:02,  3.13s/it]2025-08-23:03:51:16,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10709/12032 [9:16:36<1:04:48,  2.94s/it]2025-08-23:03:51:18,833 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10710/12032 [9:16:38<58:17,  2.65s/it]  2025-08-23:03:51:20,795 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10711/12032 [9:16:42<1:06:01,  3.00s/it]2025-08-23:03:51:24,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10712/12032 [9:16:44<57:40,  2.62s/it]  2025-08-23:03:51:26,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10713/12032 [9:16:46<55:15,  2.51s/it]2025-08-23:03:51:28,620 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10714/12032 [9:16:49<56:59,  2.59s/it]2025-08-23:03:51:31,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10715/12032 [9:16:50<46:56,  2.14s/it]2025-08-23:03:51:32,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10716/12032 [9:16:51<41:09,  1.88s/it]2025-08-23:03:51:33,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10717/12032 [9:16:54<42:44,  1.95s/it]2025-08-23:03:51:35,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10718/12032 [9:16:54<35:51,  1.64s/it]2025-08-23:03:51:36,774 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37336 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10719/12032 [9:16:56<33:46,  1.54s/it]2025-08-23:03:51:38,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10720/12032 [9:16:57<32:30,  1.49s/it]2025-08-23:03:51:39,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10721/12032 [9:17:00<43:06,  1.97s/it]2025-08-23:03:51:42,558 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10722/12032 [9:17:04<55:16,  2.53s/it]2025-08-23:03:51:46,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10723/12032 [9:17:07<58:15,  2.67s/it]2025-08-23:03:51:49,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10724/12032 [9:17:11<1:05:39,  3.01s/it]2025-08-23:03:51:53,198 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10725/12032 [9:17:15<1:10:52,  3.25s/it]2025-08-23:03:51:57,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10726/12032 [9:17:18<1:14:30,  3.42s/it]2025-08-23:03:52:00,834 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10727/12032 [9:17:22<1:16:59,  3.54s/it]2025-08-23:03:52:04,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10728/12032 [9:17:26<1:18:55,  3.63s/it]2025-08-23:03:52:08,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10729/12032 [9:17:30<1:20:01,  3.68s/it]2025-08-23:03:52:12,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10730/12032 [9:17:34<1:20:39,  3.72s/it]2025-08-23:03:52:16,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10731/12032 [9:17:38<1:21:12,  3.74s/it]2025-08-23:03:52:19,902 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10732/12032 [9:17:41<1:21:43,  3.77s/it]2025-08-23:03:52:23,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10733/12032 [9:17:45<1:21:49,  3.78s/it]2025-08-23:03:52:27,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10734/12032 [9:17:48<1:15:31,  3.49s/it]2025-08-23:03:52:30,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10735/12032 [9:17:52<1:17:24,  3.58s/it]2025-08-23:03:52:34,144 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10736/12032 [9:17:56<1:18:47,  3.65s/it]2025-08-23:03:52:37,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10737/12032 [9:17:59<1:19:31,  3.68s/it]2025-08-23:03:52:41,717 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10738/12032 [9:18:03<1:20:23,  3.73s/it]2025-08-23:03:52:45,545 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10739/12032 [9:18:07<1:21:29,  3.78s/it]2025-08-23:03:52:49,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10740/12032 [9:18:11<1:21:41,  3.79s/it]2025-08-23:03:52:53,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10741/12032 [9:18:15<1:21:58,  3.81s/it]2025-08-23:03:52:57,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10742/12032 [9:18:19<1:22:05,  3.82s/it]2025-08-23:03:53:00,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10743/12032 [9:18:22<1:22:20,  3.83s/it]2025-08-23:03:53:04,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10744/12032 [9:18:26<1:19:01,  3.68s/it]2025-08-23:03:53:08,154 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10745/12032 [9:18:30<1:19:45,  3.72s/it]2025-08-23:03:53:11,959 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10746/12032 [9:18:33<1:20:44,  3.77s/it]2025-08-23:03:53:15,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10747/12032 [9:18:37<1:21:08,  3.79s/it]2025-08-23:03:53:19,679 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10748/12032 [9:18:41<1:21:36,  3.81s/it]2025-08-23:03:53:23,551 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10749/12032 [9:18:45<1:22:23,  3.85s/it]2025-08-23:03:53:27,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10750/12032 [9:18:49<1:22:38,  3.87s/it]2025-08-23:03:53:31,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10751/12032 [9:18:53<1:22:20,  3.86s/it]2025-08-23:03:53:35,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10752/12032 [9:18:57<1:22:15,  3.86s/it]2025-08-23:03:53:39,084 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10753/12032 [9:19:01<1:21:53,  3.84s/it]2025-08-23:03:53:42,892 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10754/12032 [9:19:04<1:22:02,  3.85s/it]2025-08-23:03:53:46,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10755/12032 [9:19:08<1:21:29,  3.83s/it]2025-08-23:03:53:50,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10756/12032 [9:19:12<1:21:18,  3.82s/it]2025-08-23:03:53:54,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10757/12032 [9:19:16<1:20:52,  3.81s/it]2025-08-23:03:53:58,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10758/12032 [9:19:20<1:21:06,  3.82s/it]2025-08-23:03:54:01,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10759/12032 [9:19:23<1:21:09,  3.83s/it]2025-08-23:03:54:05,809 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10760/12032 [9:19:27<1:21:04,  3.82s/it]2025-08-23:03:54:09,629 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10761/12032 [9:19:30<1:10:51,  3.34s/it]2025-08-23:03:54:11,857 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10762/12032 [9:19:32<1:07:51,  3.21s/it]2025-08-23:03:54:14,738 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10763/12032 [9:19:36<1:11:30,  3.38s/it]2025-08-23:03:54:18,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10764/12032 [9:19:40<1:14:19,  3.52s/it]2025-08-23:03:54:22,361 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10765/12032 [9:19:44<1:16:05,  3.60s/it]2025-08-23:03:54:26,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10766/12032 [9:19:48<1:17:19,  3.66s/it]2025-08-23:03:54:29,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10767/12032 [9:19:51<1:18:06,  3.70s/it]2025-08-23:03:54:33,772 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  89%|████████▉ | 10768/12032 [9:19:52<58:15,  2.77s/it]  2025-08-23:03:54:34,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10769/12032 [9:19:54<54:01,  2.57s/it]2025-08-23:03:54:36,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10770/12032 [9:19:58<1:01:55,  2.94s/it]2025-08-23:03:54:40,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10771/12032 [9:20:02<1:07:55,  3.23s/it]2025-08-23:03:54:44,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10772/12032 [9:20:06<1:11:21,  3.40s/it]2025-08-23:03:54:47,962 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10773/12032 [9:20:09<1:13:49,  3.52s/it]2025-08-23:03:54:51,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10774/12032 [9:20:13<1:15:36,  3.61s/it]2025-08-23:03:54:55,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10775/12032 [9:20:17<1:17:17,  3.69s/it]2025-08-23:03:54:59,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10776/12032 [9:20:18<1:02:17,  2.98s/it]2025-08-23:03:55:00,765 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10777/12032 [9:20:22<1:07:17,  3.22s/it]2025-08-23:03:55:04,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10778/12032 [9:20:26<1:10:19,  3.37s/it]2025-08-23:03:55:08,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44712 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10779/12032 [9:20:30<1:13:11,  3.50s/it]2025-08-23:03:55:12,087 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10780/12032 [9:20:34<1:15:14,  3.61s/it]2025-08-23:03:55:15,929 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10781/12032 [9:20:37<1:16:19,  3.66s/it]2025-08-23:03:55:19,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10782/12032 [9:20:41<1:17:32,  3.72s/it]2025-08-23:03:55:23,583 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10783/12032 [9:20:45<1:18:10,  3.76s/it]2025-08-23:03:55:27,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10784/12032 [9:20:49<1:18:28,  3.77s/it]2025-08-23:03:55:31,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10785/12032 [9:20:53<1:18:43,  3.79s/it]2025-08-23:03:55:35,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10786/12032 [9:20:57<1:18:54,  3.80s/it]2025-08-23:03:55:38,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10787/12032 [9:20:59<1:10:32,  3.40s/it]2025-08-23:03:55:41,345 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10788/12032 [9:21:03<1:13:07,  3.53s/it]2025-08-23:03:55:45,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10789/12032 [9:21:06<1:09:21,  3.35s/it]2025-08-23:03:55:48,099 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10790/12032 [9:21:10<1:12:12,  3.49s/it]2025-08-23:03:55:51,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10791/12032 [9:21:13<1:13:57,  3.58s/it]2025-08-23:03:55:55,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10792/12032 [9:21:17<1:15:25,  3.65s/it]2025-08-23:03:55:59,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10793/12032 [9:21:21<1:16:30,  3.71s/it]2025-08-23:03:56:03,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10794/12032 [9:21:25<1:16:55,  3.73s/it]2025-08-23:03:56:07,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10795/12032 [9:21:29<1:17:12,  3.74s/it]2025-08-23:03:56:10,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50604 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10796/12032 [9:21:32<1:17:31,  3.76s/it]2025-08-23:03:56:14,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10797/12032 [9:21:36<1:17:44,  3.78s/it]2025-08-23:03:56:18,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10798/12032 [9:21:40<1:17:55,  3.79s/it]2025-08-23:03:56:22,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10799/12032 [9:21:44<1:18:05,  3.80s/it]2025-08-23:03:56:26,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10800/12032 [9:21:47<1:16:30,  3.73s/it]2025-08-23:03:56:29,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10801/12032 [9:21:50<1:08:03,  3.32s/it]2025-08-23:03:56:32,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10802/12032 [9:21:54<1:10:50,  3.46s/it]2025-08-23:03:56:35,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10803/12032 [9:21:57<1:13:08,  3.57s/it]2025-08-23:03:56:39,708 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10804/12032 [9:22:01<1:14:33,  3.64s/it]2025-08-23:03:56:43,519 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53104 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10805/12032 [9:22:05<1:15:12,  3.68s/it]2025-08-23:03:56:47,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10806/12032 [9:22:09<1:15:46,  3.71s/it]2025-08-23:03:56:51,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10807/12032 [9:22:12<1:16:09,  3.73s/it]2025-08-23:03:56:54,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10808/12032 [9:22:16<1:16:17,  3.74s/it]2025-08-23:03:56:58,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10809/12032 [9:22:20<1:16:54,  3.77s/it]2025-08-23:03:57:02,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10810/12032 [9:22:24<1:17:24,  3.80s/it]2025-08-23:03:57:06,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10811/12032 [9:22:28<1:17:18,  3.80s/it]2025-08-23:03:57:10,112 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10812/12032 [9:22:30<1:09:28,  3.42s/it]2025-08-23:03:57:12,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10813/12032 [9:22:33<1:03:28,  3.12s/it]2025-08-23:03:57:15,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10814/12032 [9:22:37<1:07:23,  3.32s/it]2025-08-23:03:57:18,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10815/12032 [9:22:40<1:05:32,  3.23s/it]2025-08-23:03:57:21,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10816/12032 [9:22:42<59:34,  2.94s/it]  2025-08-23:03:57:24,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10817/12032 [9:22:46<1:05:21,  3.23s/it]2025-08-23:03:57:28,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10818/12032 [9:22:49<1:08:47,  3.40s/it]2025-08-23:03:57:31,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10819/12032 [9:22:53<1:11:29,  3.54s/it]2025-08-23:03:57:35,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10820/12032 [9:22:56<1:04:10,  3.18s/it]2025-08-23:03:57:38,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10821/12032 [9:22:58<1:00:26,  2.99s/it]2025-08-23:03:57:40,604 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10822/12032 [9:23:00<52:35,  2.61s/it]  2025-08-23:03:57:42,309 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10823/12032 [9:23:01<44:15,  2.20s/it]2025-08-23:03:57:43,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10824/12032 [9:23:03<44:06,  2.19s/it]2025-08-23:03:57:45,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10825/12032 [9:23:05<37:42,  1.87s/it]2025-08-23:03:57:46,860 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10826/12032 [9:23:05<30:49,  1.53s/it]2025-08-23:03:57:47,598 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10827/12032 [9:23:09<43:41,  2.18s/it]2025-08-23:03:57:51,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|████████▉ | 10828/12032 [9:23:11<43:29,  2.17s/it]2025-08-23:03:57:53,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59872 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10829/12032 [9:23:12<38:54,  1.94s/it]2025-08-23:03:57:54,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10830/12032 [9:23:16<45:54,  2.29s/it]2025-08-23:03:57:57,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10831/12032 [9:23:19<54:49,  2.74s/it]2025-08-23:03:58:01,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39974 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10832/12032 [9:23:20<43:43,  2.19s/it]2025-08-23:03:58:02,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10833/12032 [9:23:21<36:09,  1.81s/it]2025-08-23:03:58:03,551 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10834/12032 [9:23:22<30:20,  1.52s/it]2025-08-23:03:58:04,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40004 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10835/12032 [9:23:25<38:38,  1.94s/it]2025-08-23:03:58:07,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10836/12032 [9:23:28<43:12,  2.17s/it]2025-08-23:03:58:10,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10837/12032 [9:23:31<53:02,  2.66s/it]2025-08-23:03:58:13,830 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10838/12032 [9:23:32<43:07,  2.17s/it]2025-08-23:03:58:14,841 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10839/12032 [9:23:35<46:22,  2.33s/it]2025-08-23:03:58:17,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10840/12032 [9:23:39<55:00,  2.77s/it]2025-08-23:03:58:21,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10841/12032 [9:23:43<1:01:06,  3.08s/it]2025-08-23:03:58:25,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10842/12032 [9:23:47<1:05:47,  3.32s/it]2025-08-23:03:58:29,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10843/12032 [9:23:50<1:08:26,  3.45s/it]2025-08-23:03:58:32,792 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10844/12032 [9:23:54<1:10:29,  3.56s/it]2025-08-23:03:58:36,603 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10845/12032 [9:23:57<1:05:27,  3.31s/it]2025-08-23:03:58:39,324 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10846/12032 [9:24:01<1:08:23,  3.46s/it]2025-08-23:03:58:43,136 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10847/12032 [9:24:05<1:10:09,  3.55s/it]2025-08-23:03:58:46,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10848/12032 [9:24:08<1:12:04,  3.65s/it]2025-08-23:03:58:50,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10849/12032 [9:24:12<1:12:59,  3.70s/it]2025-08-23:03:58:54,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10850/12032 [9:24:16<1:13:24,  3.73s/it]2025-08-23:03:58:58,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51142 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10851/12032 [9:24:20<1:13:48,  3.75s/it]2025-08-23:03:59:02,195 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10852/12032 [9:24:24<1:13:55,  3.76s/it]2025-08-23:03:59:05,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10853/12032 [9:24:27<1:14:10,  3.77s/it]2025-08-23:03:59:09,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10854/12032 [9:24:31<1:14:23,  3.79s/it]2025-08-23:03:59:13,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10855/12032 [9:24:35<1:14:16,  3.79s/it]2025-08-23:03:59:17,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10856/12032 [9:24:39<1:14:20,  3.79s/it]2025-08-23:03:59:21,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10857/12032 [9:24:43<1:14:53,  3.82s/it]2025-08-23:03:59:25,094 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10858/12032 [9:24:47<1:14:49,  3.82s/it]2025-08-23:03:59:28,918 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10859/12032 [9:24:50<1:14:40,  3.82s/it]2025-08-23:03:59:32,728 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10860/12032 [9:24:54<1:14:31,  3.82s/it]2025-08-23:03:59:36,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10861/12032 [9:24:58<1:14:24,  3.81s/it]2025-08-23:03:59:40,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10862/12032 [9:25:02<1:14:20,  3.81s/it]2025-08-23:03:59:44,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10863/12032 [9:25:06<1:14:20,  3.82s/it]2025-08-23:03:59:47,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10864/12032 [9:25:09<1:14:02,  3.80s/it]2025-08-23:03:59:51,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10865/12032 [9:25:13<1:14:59,  3.86s/it]2025-08-23:03:59:55,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10866/12032 [9:25:16<1:06:27,  3.42s/it]2025-08-23:03:59:58,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58094 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10867/12032 [9:25:20<1:09:06,  3.56s/it]2025-08-23:04:00:02,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10868/12032 [9:25:23<1:07:49,  3.50s/it]2025-08-23:04:00:05,363 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10869/12032 [9:25:27<1:09:40,  3.59s/it]2025-08-23:04:00:09,188 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10870/12032 [9:25:31<1:10:53,  3.66s/it]2025-08-23:04:00:13,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10871/12032 [9:25:34<1:11:30,  3.70s/it]2025-08-23:04:00:16,779 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10872/12032 [9:25:38<1:12:07,  3.73s/it]2025-08-23:04:00:20,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10873/12032 [9:25:42<1:12:40,  3.76s/it]2025-08-23:04:00:24,428 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10874/12032 [9:25:46<1:12:55,  3.78s/it]2025-08-23:04:00:28,242 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10875/12032 [9:25:50<1:12:59,  3.79s/it]2025-08-23:04:00:32,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45528 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10876/12032 [9:25:51<57:16,  2.97s/it]  2025-08-23:04:00:33,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10877/12032 [9:25:53<51:16,  2.66s/it]2025-08-23:04:00:35,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10878/12032 [9:25:57<57:48,  3.01s/it]2025-08-23:04:00:38,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10879/12032 [9:25:58<48:30,  2.52s/it]2025-08-23:04:00:40,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10880/12032 [9:26:02<55:55,  2.91s/it]2025-08-23:04:00:44,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10881/12032 [9:26:04<52:29,  2.74s/it]2025-08-23:04:00:46,412 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10882/12032 [9:26:07<53:07,  2.77s/it]2025-08-23:04:00:49,267 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10883/12032 [9:26:09<50:53,  2.66s/it]2025-08-23:04:00:51,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10884/12032 [9:26:11<42:29,  2.22s/it]2025-08-23:04:00:52,861 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10885/12032 [9:26:12<37:36,  1.97s/it]2025-08-23:04:00:54,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10886/12032 [9:26:16<48:05,  2.52s/it]2025-08-23:04:00:58,039 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10887/12032 [9:26:19<50:40,  2.66s/it]2025-08-23:04:01:01,014 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  90%|█████████ | 10888/12032 [9:26:22<57:16,  3.00s/it]2025-08-23:04:01:04,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10889/12032 [9:26:26<1:01:47,  3.24s/it]2025-08-23:04:01:08,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10890/12032 [9:26:30<1:05:05,  3.42s/it]2025-08-23:04:01:12,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10891/12032 [9:26:34<1:07:12,  3.53s/it]2025-08-23:04:01:16,268 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10892/12032 [9:26:38<1:08:42,  3.62s/it]2025-08-23:04:01:20,074 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10893/12032 [9:26:42<1:09:51,  3.68s/it]2025-08-23:04:01:23,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10894/12032 [9:26:45<1:10:38,  3.72s/it]2025-08-23:04:01:27,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10895/12032 [9:26:49<1:11:04,  3.75s/it]2025-08-23:04:01:31,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10896/12032 [9:26:53<1:11:16,  3.76s/it]2025-08-23:04:01:35,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10897/12032 [9:26:57<1:11:26,  3.78s/it]2025-08-23:04:01:39,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10898/12032 [9:27:01<1:11:29,  3.78s/it]2025-08-23:04:01:42,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10899/12032 [9:27:04<1:11:29,  3.79s/it]2025-08-23:04:01:46,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10900/12032 [9:27:08<1:11:33,  3.79s/it]2025-08-23:04:01:50,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10901/12032 [9:27:12<1:11:23,  3.79s/it]2025-08-23:04:01:54,318 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10902/12032 [9:27:16<1:11:23,  3.79s/it]2025-08-23:04:01:58,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10903/12032 [9:27:20<1:11:31,  3.80s/it]2025-08-23:04:02:01,944 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10904/12032 [9:27:23<1:08:03,  3.62s/it]2025-08-23:04:02:05,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10905/12032 [9:27:27<1:09:04,  3.68s/it]2025-08-23:04:02:08,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10906/12032 [9:27:30<1:09:55,  3.73s/it]2025-08-23:04:02:12,790 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34976 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10907/12032 [9:27:34<1:09:43,  3.72s/it]2025-08-23:04:02:16,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10908/12032 [9:27:38<1:10:11,  3.75s/it]2025-08-23:04:02:20,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10909/12032 [9:27:42<1:10:32,  3.77s/it]2025-08-23:04:02:24,124 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10910/12032 [9:27:46<1:10:45,  3.78s/it]2025-08-23:04:02:27,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10911/12032 [9:27:49<1:08:45,  3.68s/it]2025-08-23:04:02:31,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10912/12032 [9:27:53<1:09:45,  3.74s/it]2025-08-23:04:02:35,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10913/12032 [9:27:57<1:09:54,  3.75s/it]2025-08-23:04:02:39,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58182 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10914/12032 [9:28:01<1:10:26,  3.78s/it]2025-08-23:04:02:42,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10915/12032 [9:28:04<1:10:35,  3.79s/it]2025-08-23:04:02:46,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10916/12032 [9:28:08<1:10:28,  3.79s/it]2025-08-23:04:02:50,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10917/12032 [9:28:12<1:10:49,  3.81s/it]2025-08-23:04:02:54,346 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10918/12032 [9:28:16<1:10:43,  3.81s/it]2025-08-23:04:02:58,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10919/12032 [9:28:20<1:10:50,  3.82s/it]2025-08-23:04:03:01,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10920/12032 [9:28:23<1:10:42,  3.81s/it]2025-08-23:04:03:05,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10921/12032 [9:28:27<1:10:28,  3.81s/it]2025-08-23:04:03:09,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10922/12032 [9:28:31<1:10:21,  3.80s/it]2025-08-23:04:03:13,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10923/12032 [9:28:35<1:10:14,  3.80s/it]2025-08-23:04:03:17,172 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10924/12032 [9:28:39<1:10:23,  3.81s/it]2025-08-23:04:03:21,011 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10925/12032 [9:28:42<1:09:25,  3.76s/it]2025-08-23:04:03:24,659 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46606 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10926/12032 [9:28:45<1:04:55,  3.52s/it]2025-08-23:04:03:27,621 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10927/12032 [9:28:49<1:06:33,  3.61s/it]2025-08-23:04:03:31,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10928/12032 [9:28:53<1:07:33,  3.67s/it]2025-08-23:04:03:35,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10929/12032 [9:28:55<59:30,  3.24s/it]  2025-08-23:04:03:37,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10930/12032 [9:28:59<1:02:38,  3.41s/it]2025-08-23:04:03:41,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10931/12032 [9:29:02<1:01:12,  3.34s/it]2025-08-23:04:03:44,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10932/12032 [9:29:04<51:09,  2.79s/it]  2025-08-23:04:03:45,971 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10933/12032 [9:29:06<50:51,  2.78s/it]2025-08-23:04:03:48,715 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10934/12032 [9:29:10<56:24,  3.08s/it]2025-08-23:04:03:52,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10935/12032 [9:29:13<55:42,  3.05s/it]2025-08-23:04:03:55,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10936/12032 [9:29:15<48:28,  2.65s/it]2025-08-23:04:03:57,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10937/12032 [9:29:19<54:35,  2.99s/it]2025-08-23:04:04:00,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10938/12032 [9:29:22<58:47,  3.22s/it]2025-08-23:04:04:04,760 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10939/12032 [9:29:26<1:02:02,  3.41s/it]2025-08-23:04:04:08,587 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10940/12032 [9:29:27<49:44,  2.73s/it]  2025-08-23:04:04:09,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10941/12032 [9:29:31<55:27,  3.05s/it]2025-08-23:04:04:13,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10942/12032 [9:29:35<56:47,  3.13s/it]2025-08-23:04:04:16,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10943/12032 [9:29:38<59:07,  3.26s/it]2025-08-23:04:04:20,409 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10944/12032 [9:29:39<48:05,  2.65s/it]2025-08-23:04:04:21,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10945/12032 [9:29:41<40:08,  2.22s/it]2025-08-23:04:04:22,847 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44128 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10946/12032 [9:29:43<42:56,  2.37s/it]2025-08-23:04:04:25,585 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10947/12032 [9:29:45<36:59,  2.05s/it]2025-08-23:04:04:26,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10948/12032 [9:29:46<34:03,  1.89s/it]2025-08-23:04:04:28,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10949/12032 [9:29:49<38:35,  2.14s/it]2025-08-23:04:04:31,107 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10950/12032 [9:29:51<37:04,  2.06s/it]2025-08-23:04:04:32,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10951/12032 [9:29:54<42:34,  2.36s/it]2025-08-23:04:04:36,051 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10952/12032 [9:29:58<50:28,  2.80s/it]2025-08-23:04:04:39,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10953/12032 [9:30:01<55:51,  3.11s/it]2025-08-23:04:04:43,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10954/12032 [9:30:05<59:24,  3.31s/it]2025-08-23:04:04:47,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10955/12032 [9:30:09<1:01:54,  3.45s/it]2025-08-23:04:04:51,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10956/12032 [9:30:13<1:03:38,  3.55s/it]2025-08-23:04:04:55,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10957/12032 [9:30:16<1:04:51,  3.62s/it]2025-08-23:04:04:58,817 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10958/12032 [9:30:20<1:06:06,  3.69s/it]2025-08-23:04:05:02,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10959/12032 [9:30:24<1:06:50,  3.74s/it]2025-08-23:04:05:06,523 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10960/12032 [9:30:28<1:07:11,  3.76s/it]2025-08-23:04:05:10,337 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10961/12032 [9:30:32<1:07:15,  3.77s/it]2025-08-23:04:05:14,123 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10962/12032 [9:30:36<1:07:38,  3.79s/it]2025-08-23:04:05:17,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10963/12032 [9:30:39<1:07:13,  3.77s/it]2025-08-23:04:05:21,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55764 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10964/12032 [9:30:43<1:07:23,  3.79s/it]2025-08-23:04:05:25,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55770 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10965/12032 [9:30:47<1:07:25,  3.79s/it]2025-08-23:04:05:29,319 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10966/12032 [9:30:51<1:07:15,  3.79s/it]2025-08-23:04:05:33,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42668 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10967/12032 [9:30:55<1:07:24,  3.80s/it]2025-08-23:04:05:36,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10968/12032 [9:30:58<1:07:22,  3.80s/it]2025-08-23:04:05:40,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46098 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10969/12032 [9:31:02<1:07:14,  3.80s/it]2025-08-23:04:05:44,509 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46106 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10970/12032 [9:31:06<1:07:07,  3.79s/it]2025-08-23:04:05:48,293 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10971/12032 [9:31:10<1:07:54,  3.84s/it]2025-08-23:04:05:52,244 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10972/12032 [9:31:14<1:08:07,  3.86s/it]2025-08-23:04:05:56,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46504 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10973/12032 [9:31:18<1:07:51,  3.85s/it]2025-08-23:04:05:59,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10974/12032 [9:31:22<1:08:45,  3.90s/it]2025-08-23:04:06:03,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10975/12032 [9:31:26<1:09:52,  3.97s/it]2025-08-23:04:06:08,106 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50972 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10976/12032 [9:31:30<1:09:04,  3.92s/it]2025-08-23:04:06:11,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10977/12032 [9:31:33<1:08:18,  3.88s/it]2025-08-23:04:06:15,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10978/12032 [9:31:37<1:07:41,  3.85s/it]2025-08-23:04:06:19,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████ | 10979/12032 [9:31:41<1:07:40,  3.86s/it]2025-08-23:04:06:23,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40108 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10980/12032 [9:31:45<1:07:17,  3.84s/it]2025-08-23:04:06:27,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40112 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10981/12032 [9:31:46<51:27,  2.94s/it]  2025-08-23:04:06:27,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40114 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10982/12032 [9:31:48<50:30,  2.89s/it]2025-08-23:04:06:30,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10983/12032 [9:31:51<48:55,  2.80s/it]2025-08-23:04:06:33,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10984/12032 [9:31:54<47:43,  2.73s/it]2025-08-23:04:06:35,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10985/12032 [9:31:55<42:28,  2.43s/it]2025-08-23:04:06:37,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10986/12032 [9:31:56<33:20,  1.91s/it]2025-08-23:04:06:38,370 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41756 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10987/12032 [9:31:58<35:55,  2.06s/it]2025-08-23:04:06:40,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10988/12032 [9:32:02<44:55,  2.58s/it]2025-08-23:04:06:44,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10989/12032 [9:32:06<51:13,  2.95s/it]2025-08-23:04:06:48,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10990/12032 [9:32:10<55:34,  3.20s/it]2025-08-23:04:06:52,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10991/12032 [9:32:14<58:55,  3.40s/it]2025-08-23:04:06:56,020 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10992/12032 [9:32:18<1:01:14,  3.53s/it]2025-08-23:04:06:59,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10993/12032 [9:32:21<1:02:32,  3.61s/it]2025-08-23:04:07:03,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10994/12032 [9:32:25<1:03:22,  3.66s/it]2025-08-23:04:07:07,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10995/12032 [9:32:29<1:03:58,  3.70s/it]2025-08-23:04:07:11,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10996/12032 [9:32:33<1:04:26,  3.73s/it]2025-08-23:04:07:15,045 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10997/12032 [9:32:37<1:04:43,  3.75s/it]2025-08-23:04:07:18,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44136 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10998/12032 [9:32:40<1:04:54,  3.77s/it]2025-08-23:04:07:22,645 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 10999/12032 [9:32:44<1:04:58,  3.77s/it]2025-08-23:04:07:26,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11000/12032 [9:32:48<1:05:08,  3.79s/it]2025-08-23:04:07:30,255 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11001/12032 [9:32:52<1:05:13,  3.80s/it]2025-08-23:04:07:34,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11002/12032 [9:32:56<1:05:06,  3.79s/it]2025-08-23:04:07:37,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11003/12032 [9:32:59<1:05:33,  3.82s/it]2025-08-23:04:07:41,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11004/12032 [9:33:03<1:05:33,  3.83s/it]2025-08-23:04:07:45,582 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11005/12032 [9:33:05<57:21,  3.35s/it]  2025-08-23:04:07:47,824 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11006/12032 [9:33:09<59:31,  3.48s/it]2025-08-23:04:07:51,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11007/12032 [9:33:13<1:01:03,  3.57s/it]2025-08-23:04:07:55,399 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11008/12032 [9:33:16<1:00:02,  3.52s/it]2025-08-23:04:07:58,786 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56332 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  91%|█████████▏| 11009/12032 [9:33:20<1:01:23,  3.60s/it]2025-08-23:04:08:02,581 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11010/12032 [9:33:24<1:02:18,  3.66s/it]2025-08-23:04:08:06,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11011/12032 [9:33:28<1:02:52,  3.69s/it]2025-08-23:04:08:10,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11012/12032 [9:33:32<1:03:15,  3.72s/it]2025-08-23:04:08:13,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11013/12032 [9:33:35<1:03:36,  3.74s/it]2025-08-23:04:08:17,735 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11014/12032 [9:33:39<1:03:39,  3.75s/it]2025-08-23:04:08:21,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11015/12032 [9:33:43<1:03:48,  3.76s/it]2025-08-23:04:08:25,298 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11016/12032 [9:33:47<1:04:05,  3.79s/it]2025-08-23:04:08:29,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11017/12032 [9:33:51<1:04:25,  3.81s/it]2025-08-23:04:08:32,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11018/12032 [9:33:55<1:04:35,  3.82s/it]2025-08-23:04:08:36,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38006 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11019/12032 [9:33:58<1:04:45,  3.84s/it]2025-08-23:04:08:40,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11020/12032 [9:34:02<1:04:30,  3.82s/it]2025-08-23:04:08:44,514 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11021/12032 [9:34:06<1:04:41,  3.84s/it]2025-08-23:04:08:48,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11022/12032 [9:34:09<1:01:01,  3.62s/it]2025-08-23:04:08:51,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11023/12032 [9:34:12<54:33,  3.24s/it]  2025-08-23:04:08:53,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11024/12032 [9:34:13<43:25,  2.58s/it]2025-08-23:04:08:54,914 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11025/12032 [9:34:16<49:27,  2.95s/it]2025-08-23:04:08:58,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11026/12032 [9:34:20<53:56,  3.22s/it]2025-08-23:04:09:02,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11027/12032 [9:34:23<50:39,  3.02s/it]2025-08-23:04:09:05,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11028/12032 [9:34:27<54:26,  3.25s/it]2025-08-23:04:09:08,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11029/12032 [9:34:30<57:12,  3.42s/it]2025-08-23:04:09:12,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11030/12032 [9:34:34<59:01,  3.53s/it]2025-08-23:04:09:16,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51928 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11031/12032 [9:34:38<1:00:13,  3.61s/it]2025-08-23:04:09:20,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11032/12032 [9:34:40<53:53,  3.23s/it]  2025-08-23:04:09:22,671 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11033/12032 [9:34:44<56:39,  3.40s/it]2025-08-23:04:09:26,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11034/12032 [9:34:48<58:30,  3.52s/it]2025-08-23:04:09:30,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11035/12032 [9:34:50<51:41,  3.11s/it]2025-08-23:04:09:32,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56544 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11036/12032 [9:34:54<55:13,  3.33s/it]2025-08-23:04:09:36,246 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56550 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11037/12032 [9:34:58<57:23,  3.46s/it]2025-08-23:04:09:40,018 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11038/12032 [9:35:00<49:59,  3.02s/it]2025-08-23:04:09:42,002 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11039/12032 [9:35:03<53:41,  3.24s/it]2025-08-23:04:09:45,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11040/12032 [9:35:06<49:13,  2.98s/it]2025-08-23:04:09:48,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11041/12032 [9:35:08<45:45,  2.77s/it]2025-08-23:04:09:50,418 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11042/12032 [9:35:12<50:31,  3.06s/it]2025-08-23:04:09:54,160 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11043/12032 [9:35:15<49:42,  3.02s/it]2025-08-23:04:09:57,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11044/12032 [9:35:19<53:24,  3.24s/it]2025-08-23:04:10:00,842 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11045/12032 [9:35:22<56:21,  3.43s/it]2025-08-23:04:10:04,693 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11046/12032 [9:35:26<58:01,  3.53s/it]2025-08-23:04:10:08,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11047/12032 [9:35:30<59:00,  3.59s/it]2025-08-23:04:10:12,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11048/12032 [9:35:32<50:13,  3.06s/it]2025-08-23:04:10:14,033 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11049/12032 [9:35:33<39:14,  2.40s/it]2025-08-23:04:10:14,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11050/12032 [9:35:34<36:16,  2.22s/it]2025-08-23:04:10:16,673 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42658 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11051/12032 [9:35:36<34:04,  2.08s/it]2025-08-23:04:10:18,448 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42670 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11052/12032 [9:35:37<29:26,  1.80s/it]2025-08-23:04:10:19,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11053/12032 [9:35:38<25:29,  1.56s/it]2025-08-23:04:10:20,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11054/12032 [9:35:40<25:29,  1.56s/it]2025-08-23:04:10:22,162 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11055/12032 [9:35:41<22:59,  1.41s/it]2025-08-23:04:10:23,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11056/12032 [9:35:44<31:31,  1.94s/it]2025-08-23:04:10:26,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11057/12032 [9:35:47<35:40,  2.20s/it]2025-08-23:04:10:29,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11058/12032 [9:35:51<43:25,  2.67s/it]2025-08-23:04:10:32,975 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11059/12032 [9:35:54<48:44,  3.01s/it]2025-08-23:04:10:36,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11060/12032 [9:35:58<52:38,  3.25s/it]2025-08-23:04:10:40,570 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11061/12032 [9:36:02<55:11,  3.41s/it]2025-08-23:04:10:44,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11062/12032 [9:36:06<56:57,  3.52s/it]2025-08-23:04:10:48,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11063/12032 [9:36:10<58:03,  3.59s/it]2025-08-23:04:10:51,903 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11064/12032 [9:36:13<59:27,  3.69s/it]2025-08-23:04:10:55,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11065/12032 [9:36:17<1:00:19,  3.74s/it]2025-08-23:04:10:59,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11066/12032 [9:36:20<56:13,  3.49s/it]  2025-08-23:04:11:02,586 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11067/12032 [9:36:24<58:04,  3.61s/it]2025-08-23:04:11:06,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11068/12032 [9:36:28<59:06,  3.68s/it]2025-08-23:04:11:10,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11069/12032 [9:36:32<59:49,  3.73s/it]2025-08-23:04:11:14,151 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57080 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11070/12032 [9:36:36<1:00:21,  3.77s/it]2025-08-23:04:11:18,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11071/12032 [9:36:39<57:55,  3.62s/it]  2025-08-23:04:11:21,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11072/12032 [9:36:43<58:55,  3.68s/it]2025-08-23:04:11:25,111 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11073/12032 [9:36:47<59:29,  3.72s/it]2025-08-23:04:11:28,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11074/12032 [9:36:50<59:50,  3.75s/it]2025-08-23:04:11:32,733 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11075/12032 [9:36:54<1:00:05,  3.77s/it]2025-08-23:04:11:36,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11076/12032 [9:36:58<1:00:24,  3.79s/it]2025-08-23:04:11:40,395 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58936 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11077/12032 [9:37:02<1:00:21,  3.79s/it]2025-08-23:04:11:44,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58946 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11078/12032 [9:37:06<1:00:14,  3.79s/it]2025-08-23:04:11:47,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58960 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11079/12032 [9:37:09<1:00:06,  3.78s/it]2025-08-23:04:11:51,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11080/12032 [9:37:13<1:00:15,  3.80s/it]2025-08-23:04:11:55,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58992 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11081/12032 [9:37:17<1:00:17,  3.80s/it]2025-08-23:04:11:59,391 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11082/12032 [9:37:21<1:00:10,  3.80s/it]2025-08-23:04:12:03,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51930 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11083/12032 [9:37:25<1:00:09,  3.80s/it]2025-08-23:04:12:06,994 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51940 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11084/12032 [9:37:28<1:00:05,  3.80s/it]2025-08-23:04:12:10,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11085/12032 [9:37:32<1:00:13,  3.82s/it]2025-08-23:04:12:14,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11086/12032 [9:37:34<51:43,  3.28s/it]  2025-08-23:04:12:16,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11087/12032 [9:37:35<41:19,  2.62s/it]2025-08-23:04:12:17,767 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11088/12032 [9:37:37<35:33,  2.26s/it]2025-08-23:04:12:19,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11089/12032 [9:37:38<31:36,  2.01s/it]2025-08-23:04:12:20,608 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11090/12032 [9:37:39<27:43,  1.77s/it]2025-08-23:04:12:21,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11091/12032 [9:37:40<23:24,  1.49s/it]2025-08-23:04:12:22,657 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11092/12032 [9:37:41<20:04,  1.28s/it]2025-08-23:04:12:23,445 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32912 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11093/12032 [9:37:42<19:14,  1.23s/it]2025-08-23:04:12:24,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32918 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11094/12032 [9:37:46<31:27,  2.01s/it]2025-08-23:04:12:28,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11095/12032 [9:37:47<28:29,  1.82s/it]2025-08-23:04:12:29,778 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:32934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11096/12032 [9:37:49<26:58,  1.73s/it]2025-08-23:04:12:31,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57998 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11097/12032 [9:37:52<31:42,  2.03s/it]2025-08-23:04:12:34,031 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58012 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11098/12032 [9:37:56<40:13,  2.58s/it]2025-08-23:04:12:37,899 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11099/12032 [9:37:59<45:58,  2.96s/it]2025-08-23:04:12:41,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11100/12032 [9:38:03<49:41,  3.20s/it]2025-08-23:04:12:45,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11101/12032 [9:38:07<52:29,  3.38s/it]2025-08-23:04:12:49,300 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11102/12032 [9:38:11<54:31,  3.52s/it]2025-08-23:04:12:53,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11103/12032 [9:38:15<55:58,  3.61s/it]2025-08-23:04:12:56,974 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11104/12032 [9:38:18<56:54,  3.68s/it]2025-08-23:04:13:00,806 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11105/12032 [9:38:22<57:33,  3.73s/it]2025-08-23:04:13:04,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11106/12032 [9:38:26<57:47,  3.74s/it]2025-08-23:04:13:08,426 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11107/12032 [9:38:30<58:00,  3.76s/it]2025-08-23:04:13:12,232 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11108/12032 [9:38:34<58:15,  3.78s/it]2025-08-23:04:13:16,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48896 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11109/12032 [9:38:38<58:21,  3.79s/it]2025-08-23:04:13:19,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11110/12032 [9:38:41<58:15,  3.79s/it]2025-08-23:04:13:23,667 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11111/12032 [9:38:45<58:12,  3.79s/it]2025-08-23:04:13:27,462 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11112/12032 [9:38:49<58:32,  3.82s/it]2025-08-23:04:13:31,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11113/12032 [9:38:51<49:37,  3.24s/it]2025-08-23:04:13:33,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11114/12032 [9:38:54<49:51,  3.26s/it]2025-08-23:04:13:36,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11115/12032 [9:38:58<52:31,  3.44s/it]2025-08-23:04:13:40,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11116/12032 [9:38:59<43:18,  2.84s/it]2025-08-23:04:13:41,821 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11117/12032 [9:39:03<47:43,  3.13s/it]2025-08-23:04:13:45,632 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11118/12032 [9:39:07<50:44,  3.33s/it]2025-08-23:04:13:49,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11119/12032 [9:39:11<52:51,  3.47s/it]2025-08-23:04:13:53,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53714 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11120/12032 [9:39:13<46:57,  3.09s/it]2025-08-23:04:13:55,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11121/12032 [9:39:17<50:26,  3.32s/it]2025-08-23:04:13:59,301 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11122/12032 [9:39:21<52:56,  3.49s/it]2025-08-23:04:14:03,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11123/12032 [9:39:25<54:19,  3.59s/it]2025-08-23:04:14:06,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11124/12032 [9:39:29<55:33,  3.67s/it]2025-08-23:04:14:10,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11125/12032 [9:39:32<56:05,  3.71s/it]2025-08-23:04:14:14,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49836 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11126/12032 [9:39:36<56:33,  3.75s/it]2025-08-23:04:14:18,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11127/12032 [9:39:40<56:58,  3.78s/it]2025-08-23:04:14:22,343 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47574 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11128/12032 [9:39:44<57:30,  3.82s/it]2025-08-23:04:14:26,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47586 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  92%|█████████▏| 11129/12032 [9:39:47<55:39,  3.70s/it]2025-08-23:04:14:29,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47596 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11130/12032 [9:39:51<53:28,  3.56s/it]2025-08-23:04:14:32,901 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11131/12032 [9:39:53<49:46,  3.31s/it]2025-08-23:04:14:35,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11132/12032 [9:39:57<49:59,  3.33s/it]2025-08-23:04:14:39,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11133/12032 [9:39:59<43:21,  2.89s/it]2025-08-23:04:14:40,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11134/12032 [9:40:02<47:30,  3.17s/it]2025-08-23:04:14:44,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11135/12032 [9:40:04<42:08,  2.82s/it]2025-08-23:04:14:46,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55814 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11136/12032 [9:40:05<33:42,  2.26s/it]2025-08-23:04:14:47,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11137/12032 [9:40:09<39:31,  2.65s/it]2025-08-23:04:14:51,227 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11138/12032 [9:40:11<38:02,  2.55s/it]2025-08-23:04:14:53,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11139/12032 [9:40:12<32:19,  2.17s/it]2025-08-23:04:14:54,837 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11140/12032 [9:40:14<27:11,  1.83s/it]2025-08-23:04:14:55,866 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40306 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11141/12032 [9:40:15<23:41,  1.60s/it]2025-08-23:04:14:56,916 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11142/12032 [9:40:18<33:35,  2.26s/it]2025-08-23:04:15:00,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11143/12032 [9:40:22<40:25,  2.73s/it]2025-08-23:04:15:04,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11144/12032 [9:40:26<45:12,  3.05s/it]2025-08-23:04:15:08,367 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11145/12032 [9:40:30<48:27,  3.28s/it]2025-08-23:04:15:12,168 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42524 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11146/12032 [9:40:34<50:37,  3.43s/it]2025-08-23:04:15:15,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11147/12032 [9:40:37<52:14,  3.54s/it]2025-08-23:04:15:19,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11148/12032 [9:40:41<52:09,  3.54s/it]2025-08-23:04:15:23,290 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11149/12032 [9:40:45<53:17,  3.62s/it]2025-08-23:04:15:27,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11150/12032 [9:40:49<54:05,  3.68s/it]2025-08-23:04:15:30,915 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11151/12032 [9:40:52<54:37,  3.72s/it]2025-08-23:04:15:34,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11152/12032 [9:40:56<54:58,  3.75s/it]2025-08-23:04:15:38,547 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11153/12032 [9:41:00<55:18,  3.78s/it]2025-08-23:04:15:42,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11154/12032 [9:41:04<55:20,  3.78s/it]2025-08-23:04:15:46,181 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11155/12032 [9:41:08<55:17,  3.78s/it]2025-08-23:04:15:49,967 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11156/12032 [9:41:11<55:12,  3.78s/it]2025-08-23:04:15:53,743 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11157/12032 [9:41:15<55:16,  3.79s/it]2025-08-23:04:15:57,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33478 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11158/12032 [9:41:19<55:03,  3.78s/it]2025-08-23:04:16:01,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11159/12032 [9:41:20<44:49,  3.08s/it]2025-08-23:04:16:02,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60120 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11160/12032 [9:41:24<47:01,  3.24s/it]2025-08-23:04:16:06,356 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11161/12032 [9:41:28<49:21,  3.40s/it]2025-08-23:04:16:10,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11162/12032 [9:41:32<51:09,  3.53s/it]2025-08-23:04:16:13,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11163/12032 [9:41:35<52:10,  3.60s/it]2025-08-23:04:16:17,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37318 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11164/12032 [9:41:39<53:01,  3.67s/it]2025-08-23:04:16:21,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11165/12032 [9:41:43<53:34,  3.71s/it]2025-08-23:04:16:25,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11166/12032 [9:41:47<54:06,  3.75s/it]2025-08-23:04:16:29,209 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11167/12032 [9:41:51<54:14,  3.76s/it]2025-08-23:04:16:33,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11168/12032 [9:41:54<54:14,  3.77s/it]2025-08-23:04:16:36,777 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36102 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11169/12032 [9:41:57<48:46,  3.39s/it]2025-08-23:04:16:39,294 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11170/12032 [9:42:01<50:56,  3.55s/it]2025-08-23:04:16:43,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11171/12032 [9:42:05<52:24,  3.65s/it]2025-08-23:04:16:47,101 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60286 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11172/12032 [9:42:09<53:01,  3.70s/it]2025-08-23:04:16:50,910 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11173/12032 [9:42:12<53:34,  3.74s/it]2025-08-23:04:16:54,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11174/12032 [9:42:14<42:51,  3.00s/it]2025-08-23:04:16:56,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11175/12032 [9:42:15<35:02,  2.45s/it]2025-08-23:04:16:57,194 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11176/12032 [9:42:17<31:59,  2.24s/it]2025-08-23:04:16:58,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11177/12032 [9:42:18<27:43,  1.95s/it]2025-08-23:04:17:00,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11178/12032 [9:42:19<22:11,  1.56s/it]2025-08-23:04:17:00,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11179/12032 [9:42:22<31:51,  2.24s/it]2025-08-23:04:17:04,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11180/12032 [9:42:24<28:41,  2.02s/it]2025-08-23:04:17:06,196 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11181/12032 [9:42:28<36:29,  2.57s/it]2025-08-23:04:17:10,055 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11182/12032 [9:42:32<41:47,  2.95s/it]2025-08-23:04:17:13,887 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11183/12032 [9:42:35<45:30,  3.22s/it]2025-08-23:04:17:17,724 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11184/12032 [9:42:39<47:56,  3.39s/it]2025-08-23:04:17:21,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11185/12032 [9:42:43<49:36,  3.51s/it]2025-08-23:04:17:25,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11186/12032 [9:42:47<51:01,  3.62s/it]2025-08-23:04:17:29,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11187/12032 [9:42:51<51:52,  3.68s/it]2025-08-23:04:17:33,023 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11188/12032 [9:42:54<52:21,  3.72s/it]2025-08-23:04:17:36,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11189/12032 [9:42:58<50:31,  3.60s/it]2025-08-23:04:17:40,137 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11190/12032 [9:43:02<51:27,  3.67s/it]2025-08-23:04:17:43,970 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11191/12032 [9:43:05<52:03,  3.71s/it]2025-08-23:04:17:47,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11192/12032 [9:43:09<52:20,  3.74s/it]2025-08-23:04:17:51,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45018 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11193/12032 [9:43:13<52:32,  3.76s/it]2025-08-23:04:17:55,394 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45022 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11194/12032 [9:43:17<52:40,  3.77s/it]2025-08-23:04:17:59,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11195/12032 [9:43:21<52:21,  3.75s/it]2025-08-23:04:18:02,909 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11196/12032 [9:43:24<52:27,  3.77s/it]2025-08-23:04:18:06,702 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11197/12032 [9:43:28<52:40,  3.78s/it]2025-08-23:04:18:10,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11198/12032 [9:43:32<52:53,  3.80s/it]2025-08-23:04:18:14,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53074 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11199/12032 [9:43:36<52:46,  3.80s/it]2025-08-23:04:18:18,177 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11200/12032 [9:43:40<52:43,  3.80s/it]2025-08-23:04:18:21,982 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11201/12032 [9:43:43<52:42,  3.81s/it]2025-08-23:04:18:25,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46302 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11202/12032 [9:43:47<52:22,  3.79s/it]2025-08-23:04:18:29,534 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11203/12032 [9:43:50<47:21,  3.43s/it]2025-08-23:04:18:32,128 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11204/12032 [9:43:54<48:56,  3.55s/it]2025-08-23:04:18:35,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11205/12032 [9:43:57<49:57,  3.62s/it]2025-08-23:04:18:39,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11206/12032 [9:44:01<50:42,  3.68s/it]2025-08-23:04:18:43,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11207/12032 [9:44:05<51:10,  3.72s/it]2025-08-23:04:18:47,389 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11208/12032 [9:44:09<51:30,  3.75s/it]2025-08-23:04:18:51,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60602 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11209/12032 [9:44:11<46:50,  3.41s/it]2025-08-23:04:18:53,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11210/12032 [9:44:13<38:47,  2.83s/it]2025-08-23:04:18:55,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11211/12032 [9:44:14<30:43,  2.25s/it]2025-08-23:04:18:56,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60620 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11212/12032 [9:44:14<24:03,  1.76s/it]2025-08-23:04:18:56,816 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60636 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11213/12032 [9:44:15<20:31,  1.50s/it]2025-08-23:04:18:57,719 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11214/12032 [9:44:16<18:31,  1.36s/it]2025-08-23:04:18:58,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11215/12032 [9:44:20<28:27,  2.09s/it]2025-08-23:04:19:02,536 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11216/12032 [9:44:24<35:27,  2.61s/it]2025-08-23:04:19:06,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11217/12032 [9:44:28<40:21,  2.97s/it]2025-08-23:04:19:10,170 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11218/12032 [9:44:32<43:42,  3.22s/it]2025-08-23:04:19:13,977 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58214 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11219/12032 [9:44:35<45:58,  3.39s/it]2025-08-23:04:19:17,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11220/12032 [9:44:39<47:54,  3.54s/it]2025-08-23:04:19:21,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11221/12032 [9:44:43<48:55,  3.62s/it]2025-08-23:04:19:25,457 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37062 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11222/12032 [9:44:47<49:39,  3.68s/it]2025-08-23:04:19:29,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11223/12032 [9:44:51<50:11,  3.72s/it]2025-08-23:04:19:33,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11224/12032 [9:44:55<50:40,  3.76s/it]2025-08-23:04:19:36,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11225/12032 [9:44:58<50:58,  3.79s/it]2025-08-23:04:19:40,808 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11226/12032 [9:45:02<50:53,  3.79s/it]2025-08-23:04:19:44,593 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11227/12032 [9:45:06<50:48,  3.79s/it]2025-08-23:04:19:48,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11228/12032 [9:45:10<50:51,  3.79s/it]2025-08-23:04:19:52,190 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43126 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11229/12032 [9:45:14<50:47,  3.79s/it]2025-08-23:04:19:55,984 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43130 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11230/12032 [9:45:17<50:45,  3.80s/it]2025-08-23:04:19:59,789 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11231/12032 [9:45:21<50:56,  3.82s/it]2025-08-23:04:20:03,646 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51674 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11232/12032 [9:45:25<50:52,  3.82s/it]2025-08-23:04:20:07,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11233/12032 [9:45:29<50:59,  3.83s/it]2025-08-23:04:20:11,323 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11234/12032 [9:45:33<50:54,  3.83s/it]2025-08-23:04:20:15,147 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11235/12032 [9:45:35<43:39,  3.29s/it]2025-08-23:04:20:17,171 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11236/12032 [9:45:39<45:34,  3.44s/it]2025-08-23:04:20:20,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34792 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11237/12032 [9:45:39<34:35,  2.61s/it]2025-08-23:04:20:21,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34798 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11238/12032 [9:45:43<39:18,  2.97s/it]2025-08-23:04:20:25,451 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11239/12032 [9:45:47<42:46,  3.24s/it]2025-08-23:04:20:29,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11240/12032 [9:45:49<36:40,  2.78s/it]2025-08-23:04:20:31,017 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11241/12032 [9:45:51<32:59,  2.50s/it]2025-08-23:04:20:32,876 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11242/12032 [9:45:54<37:56,  2.88s/it]2025-08-23:04:20:36,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11243/12032 [9:45:56<31:30,  2.40s/it]2025-08-23:04:20:37,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11244/12032 [9:45:57<26:27,  2.01s/it]2025-08-23:04:20:39,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11245/12032 [9:45:58<23:07,  1.76s/it]2025-08-23:04:20:40,204 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11246/12032 [9:45:58<18:24,  1.41s/it]2025-08-23:04:20:40,776 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11247/12032 [9:46:02<26:17,  2.01s/it]2025-08-23:04:20:44,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11248/12032 [9:46:05<31:29,  2.41s/it]2025-08-23:04:20:47,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  93%|█████████▎| 11249/12032 [9:46:07<28:54,  2.22s/it]2025-08-23:04:20:49,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11250/12032 [9:46:10<33:20,  2.56s/it]2025-08-23:04:20:52,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11251/12032 [9:46:12<30:54,  2.37s/it]2025-08-23:04:20:54,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11252/12032 [9:46:14<29:01,  2.23s/it]2025-08-23:04:20:56,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11253/12032 [9:46:17<29:41,  2.29s/it]2025-08-23:04:20:58,919 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11254/12032 [9:46:18<25:20,  1.95s/it]2025-08-23:04:21:00,098 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11255/12032 [9:46:19<22:10,  1.71s/it]2025-08-23:04:21:01,245 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38026 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11256/12032 [9:46:20<19:17,  1.49s/it]2025-08-23:04:21:02,223 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11257/12032 [9:46:21<18:44,  1.45s/it]2025-08-23:04:21:03,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11258/12032 [9:46:25<27:42,  2.15s/it]2025-08-23:04:21:07,352 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38048 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11259/12032 [9:46:27<28:29,  2.21s/it]2025-08-23:04:21:09,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38064 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11260/12032 [9:46:28<22:37,  1.76s/it]2025-08-23:04:21:10,414 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11261/12032 [9:46:29<19:53,  1.55s/it]2025-08-23:04:21:11,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60028 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11262/12032 [9:46:30<17:33,  1.37s/it]2025-08-23:04:21:12,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11263/12032 [9:46:31<15:27,  1.21s/it]2025-08-23:04:21:13,247 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11264/12032 [9:46:33<20:04,  1.57s/it]2025-08-23:04:21:15,662 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11265/12032 [9:46:34<18:08,  1.42s/it]2025-08-23:04:21:16,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11266/12032 [9:46:35<16:26,  1.29s/it]2025-08-23:04:21:17,714 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11267/12032 [9:46:39<26:24,  2.07s/it]2025-08-23:04:21:21,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11268/12032 [9:46:40<22:04,  1.73s/it]2025-08-23:04:21:22,561 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11269/12032 [9:46:41<19:33,  1.54s/it]2025-08-23:04:21:23,641 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11270/12032 [9:46:42<17:59,  1.42s/it]2025-08-23:04:21:24,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11271/12032 [9:46:46<26:27,  2.09s/it]2025-08-23:04:21:28,423 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11272/12032 [9:46:48<26:17,  2.08s/it]2025-08-23:04:21:30,475 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11273/12032 [9:46:52<32:48,  2.59s/it]2025-08-23:04:21:34,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11274/12032 [9:46:53<28:51,  2.28s/it]2025-08-23:04:21:35,838 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11275/12032 [9:46:56<29:59,  2.38s/it]2025-08-23:04:21:38,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11276/12032 [9:46:59<30:48,  2.45s/it]2025-08-23:04:21:41,036 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11277/12032 [9:47:00<26:38,  2.12s/it]2025-08-23:04:21:42,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11278/12032 [9:47:01<21:33,  1.72s/it]2025-08-23:04:21:43,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▎| 11279/12032 [9:47:02<19:05,  1.52s/it]2025-08-23:04:21:44,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11280/12032 [9:47:03<19:03,  1.52s/it]2025-08-23:04:21:45,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11281/12032 [9:47:07<26:30,  2.12s/it]2025-08-23:04:21:49,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11282/12032 [9:47:09<25:46,  2.06s/it]2025-08-23:04:21:51,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11283/12032 [9:47:13<32:02,  2.57s/it]2025-08-23:04:21:54,943 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11284/12032 [9:47:16<36:48,  2.95s/it]2025-08-23:04:21:58,793 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48864 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11285/12032 [9:47:19<35:45,  2.87s/it]2025-08-23:04:22:01,480 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11286/12032 [9:47:22<33:48,  2.72s/it]2025-08-23:04:22:03,844 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11287/12032 [9:47:22<26:54,  2.17s/it]2025-08-23:04:22:04,723 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11288/12032 [9:47:23<22:13,  1.79s/it]2025-08-23:04:22:05,640 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11289/12032 [9:47:27<29:42,  2.40s/it]2025-08-23:04:22:09,453 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11290/12032 [9:47:31<34:22,  2.78s/it]2025-08-23:04:22:13,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11291/12032 [9:47:33<33:25,  2.71s/it]2025-08-23:04:22:15,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11292/12032 [9:47:37<37:23,  3.03s/it]2025-08-23:04:22:19,450 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11293/12032 [9:47:41<40:01,  3.25s/it]2025-08-23:04:22:23,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11294/12032 [9:47:43<36:26,  2.96s/it]2025-08-23:04:22:25,497 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11295/12032 [9:47:45<32:45,  2.67s/it]2025-08-23:04:22:27,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11296/12032 [9:47:49<36:59,  3.02s/it]2025-08-23:04:22:31,305 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11297/12032 [9:47:51<33:01,  2.70s/it]2025-08-23:04:22:33,254 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11298/12032 [9:47:54<35:20,  2.89s/it]2025-08-23:04:22:36,595 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11299/12032 [9:47:55<27:26,  2.25s/it]2025-08-23:04:22:37,342 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43278 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11300/12032 [9:47:56<23:15,  1.91s/it]2025-08-23:04:22:38,456 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11301/12032 [9:47:58<23:44,  1.95s/it]2025-08-23:04:22:40,502 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11302/12032 [9:48:01<28:27,  2.34s/it]2025-08-23:04:22:43,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11303/12032 [9:48:05<33:39,  2.77s/it]2025-08-23:04:22:47,530 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45242 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11304/12032 [9:48:09<37:11,  3.07s/it]2025-08-23:04:22:51,284 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52612 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11305/12032 [9:48:13<39:37,  3.27s/it]2025-08-23:04:22:55,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11306/12032 [9:48:17<41:34,  3.44s/it]2025-08-23:04:22:58,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52626 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11307/12032 [9:48:20<42:40,  3.53s/it]2025-08-23:04:23:02,610 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11308/12032 [9:48:23<38:36,  3.20s/it]2025-08-23:04:23:05,034 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11309/12032 [9:48:24<31:14,  2.59s/it]2025-08-23:04:23:06,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11310/12032 [9:48:25<25:41,  2.14s/it]2025-08-23:04:23:07,280 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11311/12032 [9:48:27<24:35,  2.05s/it]2025-08-23:04:23:09,120 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58450 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11312/12032 [9:48:29<25:50,  2.15s/it]2025-08-23:04:23:11,520 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11313/12032 [9:48:30<21:29,  1.79s/it]2025-08-23:04:23:12,473 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11314/12032 [9:48:34<28:37,  2.39s/it]2025-08-23:04:23:16,264 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47988 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11315/12032 [9:48:36<27:01,  2.26s/it]2025-08-23:04:23:18,221 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11316/12032 [9:48:37<23:21,  1.96s/it]2025-08-23:04:23:19,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11317/12032 [9:48:38<19:34,  1.64s/it]2025-08-23:04:23:20,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11318/12032 [9:48:39<16:40,  1.40s/it]2025-08-23:04:23:21,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11319/12032 [9:48:41<18:44,  1.58s/it]2025-08-23:04:23:23,202 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11320/12032 [9:48:42<16:18,  1.37s/it]2025-08-23:04:23:24,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11321/12032 [9:48:43<15:20,  1.29s/it]2025-08-23:04:23:25,213 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11322/12032 [9:48:47<24:08,  2.04s/it]2025-08-23:04:23:28,993 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11323/12032 [9:48:48<21:28,  1.82s/it]2025-08-23:04:23:30,289 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11324/12032 [9:48:50<21:56,  1.86s/it]2025-08-23:04:23:32,248 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11325/12032 [9:48:54<28:41,  2.43s/it]2025-08-23:04:23:36,025 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11326/12032 [9:48:55<23:29,  2.00s/it]2025-08-23:04:23:36,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11327/12032 [9:48:58<29:42,  2.53s/it]2025-08-23:04:23:40,769 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11328/12032 [9:49:02<34:03,  2.90s/it]2025-08-23:04:23:44,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11329/12032 [9:49:06<36:45,  3.14s/it]2025-08-23:04:23:48,228 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11330/12032 [9:49:07<28:19,  2.42s/it]2025-08-23:04:23:48,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11331/12032 [9:49:08<25:33,  2.19s/it]2025-08-23:04:23:50,623 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35194 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11332/12032 [9:49:12<31:02,  2.66s/it]2025-08-23:04:23:54,387 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11333/12032 [9:49:14<29:16,  2.51s/it]2025-08-23:04:23:56,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35210 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11334/12032 [9:49:15<22:54,  1.97s/it]2025-08-23:04:23:57,253 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35226 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11335/12032 [9:49:16<19:01,  1.64s/it]2025-08-23:04:23:58,119 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11336/12032 [9:49:18<19:46,  1.70s/it]2025-08-23:04:23:59,978 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11337/12032 [9:49:21<26:01,  2.25s/it]2025-08-23:04:24:03,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11338/12032 [9:49:25<31:14,  2.70s/it]2025-08-23:04:24:07,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11339/12032 [9:49:26<25:18,  2.19s/it]2025-08-23:04:24:08,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11340/12032 [9:49:27<20:44,  1.80s/it]2025-08-23:04:24:09,134 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11341/12032 [9:49:31<27:25,  2.38s/it]2025-08-23:04:24:12,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11342/12032 [9:49:31<21:38,  1.88s/it]2025-08-23:04:24:13,592 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11343/12032 [9:49:34<25:30,  2.22s/it]2025-08-23:04:24:16,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11344/12032 [9:49:37<28:50,  2.52s/it]2025-08-23:04:24:19,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58452 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11345/12032 [9:49:41<33:15,  2.90s/it]2025-08-23:04:24:23,619 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48150 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11346/12032 [9:49:43<27:39,  2.42s/it]2025-08-23:04:24:24,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11347/12032 [9:49:44<25:01,  2.19s/it]2025-08-23:04:24:26,568 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11348/12032 [9:49:45<20:42,  1.82s/it]2025-08-23:04:24:27,511 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11349/12032 [9:49:46<18:07,  1.59s/it]2025-08-23:04:24:28,578 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11350/12032 [9:49:50<25:29,  2.24s/it]2025-08-23:04:24:32,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11351/12032 [9:49:53<29:16,  2.58s/it]2025-08-23:04:24:35,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11352/12032 [9:49:56<29:45,  2.63s/it]2025-08-23:04:24:38,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11353/12032 [9:49:57<25:05,  2.22s/it]2025-08-23:04:24:39,701 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11354/12032 [9:49:59<23:21,  2.07s/it]2025-08-23:04:24:41,417 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11355/12032 [9:50:02<24:45,  2.19s/it]2025-08-23:04:24:43,908 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11356/12032 [9:50:05<29:57,  2.66s/it]2025-08-23:04:24:47,649 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11357/12032 [9:50:08<30:54,  2.75s/it]2025-08-23:04:24:50,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11358/12032 [9:50:12<34:10,  3.04s/it]2025-08-23:04:24:54,335 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11359/12032 [9:50:15<32:43,  2.92s/it]2025-08-23:04:24:56,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39730 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11360/12032 [9:50:16<25:52,  2.31s/it]2025-08-23:04:24:57,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39732 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11361/12032 [9:50:17<23:38,  2.11s/it]2025-08-23:04:24:59,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39748 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11362/12032 [9:50:21<29:14,  2.62s/it]2025-08-23:04:25:03,307 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11363/12032 [9:50:22<25:01,  2.24s/it]2025-08-23:04:25:04,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11364/12032 [9:50:26<30:02,  2.70s/it]2025-08-23:04:25:08,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11365/12032 [9:50:27<25:06,  2.26s/it]2025-08-23:04:25:09,666 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37834 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11366/12032 [9:50:28<19:40,  1.77s/it]2025-08-23:04:25:10,306 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11367/12032 [9:50:30<22:09,  2.00s/it]2025-08-23:04:25:12,832 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39916 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11368/12032 [9:50:32<20:11,  1.82s/it]2025-08-23:04:25:14,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11369/12032 [9:50:34<21:00,  1.90s/it]2025-08-23:04:25:16,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  94%|█████████▍| 11370/12032 [9:50:37<26:13,  2.38s/it]2025-08-23:04:25:19,819 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11371/12032 [9:50:40<25:50,  2.35s/it]2025-08-23:04:25:22,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11372/12032 [9:50:43<28:16,  2.57s/it]2025-08-23:04:25:25,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11373/12032 [9:50:46<31:08,  2.84s/it]2025-08-23:04:25:28,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11374/12032 [9:50:48<28:12,  2.57s/it]2025-08-23:04:25:30,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11375/12032 [9:50:49<23:11,  2.12s/it]2025-08-23:04:25:31,656 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36894 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11376/12032 [9:50:52<26:06,  2.39s/it]2025-08-23:04:25:34,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11377/12032 [9:50:54<23:16,  2.13s/it]2025-08-23:04:25:36,208 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11378/12032 [9:50:55<19:49,  1.82s/it]2025-08-23:04:25:37,297 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11379/12032 [9:50:56<18:22,  1.69s/it]2025-08-23:04:25:38,681 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11380/12032 [9:50:58<17:55,  1.65s/it]2025-08-23:04:25:40,241 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11381/12032 [9:50:59<16:15,  1.50s/it]2025-08-23:04:25:41,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44482 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11382/12032 [9:51:01<16:30,  1.52s/it]2025-08-23:04:25:42,968 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11383/12032 [9:51:04<23:58,  2.22s/it]2025-08-23:04:25:46,802 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11384/12032 [9:51:05<19:42,  1.82s/it]2025-08-23:04:25:47,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44514 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11385/12032 [9:51:07<19:19,  1.79s/it]2025-08-23:04:25:49,430 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11386/12032 [9:51:09<19:14,  1.79s/it]2025-08-23:04:25:51,207 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50350 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11387/12032 [9:51:11<19:41,  1.83s/it]2025-08-23:04:25:53,139 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11388/12032 [9:51:12<17:32,  1.63s/it]2025-08-23:04:25:54,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11389/12032 [9:51:16<24:31,  2.29s/it]2025-08-23:04:25:58,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11390/12032 [9:51:20<29:19,  2.74s/it]2025-08-23:04:26:01,925 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51664 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11391/12032 [9:51:23<29:55,  2.80s/it]2025-08-23:04:26:04,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51672 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11392/12032 [9:51:24<26:30,  2.49s/it]2025-08-23:04:26:06,618 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11393/12032 [9:51:25<21:34,  2.03s/it]2025-08-23:04:26:07,571 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11394/12032 [9:51:26<18:16,  1.72s/it]2025-08-23:04:26:08,572 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11395/12032 [9:51:28<18:52,  1.78s/it]2025-08-23:04:26:10,489 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50796 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11396/12032 [9:51:29<16:36,  1.57s/it]2025-08-23:04:26:11,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11397/12032 [9:51:33<23:42,  2.24s/it]2025-08-23:04:26:15,373 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11398/12032 [9:51:36<25:10,  2.38s/it]2025-08-23:04:26:18,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11399/12032 [9:51:38<23:29,  2.23s/it]2025-08-23:04:26:19,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11400/12032 [9:51:41<28:26,  2.70s/it]2025-08-23:04:26:23,755 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11401/12032 [9:51:45<31:16,  2.97s/it]2025-08-23:04:26:27,371 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11402/12032 [9:51:46<25:13,  2.40s/it]2025-08-23:04:26:28,436 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11403/12032 [9:51:48<24:09,  2.31s/it]2025-08-23:04:26:30,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11404/12032 [9:51:51<25:14,  2.41s/it]2025-08-23:04:26:33,178 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11405/12032 [9:51:52<20:06,  1.92s/it]2025-08-23:04:26:33,961 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49736 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11406/12032 [9:51:56<26:12,  2.51s/it]2025-08-23:04:26:37,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11407/12032 [9:51:58<25:02,  2.40s/it]2025-08-23:04:26:39,997 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11408/12032 [9:52:02<29:30,  2.84s/it]2025-08-23:04:26:43,848 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11409/12032 [9:52:02<23:36,  2.27s/it]2025-08-23:04:26:44,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54188 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11410/12032 [9:52:03<18:16,  1.76s/it]2025-08-23:04:26:45,378 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54190 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11411/12032 [9:52:04<16:07,  1.56s/it]2025-08-23:04:26:46,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11412/12032 [9:52:05<14:29,  1.40s/it]2025-08-23:04:26:47,493 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11413/12032 [9:52:06<13:17,  1.29s/it]2025-08-23:04:26:48,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11414/12032 [9:52:09<18:48,  1.83s/it]2025-08-23:04:26:51,597 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11415/12032 [9:52:10<15:41,  1.53s/it]2025-08-23:04:26:52,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11416/12032 [9:52:13<19:50,  1.93s/it]2025-08-23:04:26:55,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11417/12032 [9:52:14<16:28,  1.61s/it]2025-08-23:04:26:56,150 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11418/12032 [9:52:18<23:17,  2.28s/it]2025-08-23:04:26:59,990 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11419/12032 [9:52:19<19:45,  1.93s/it]2025-08-23:04:27:01,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35790 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11420/12032 [9:52:22<23:56,  2.35s/it]2025-08-23:04:27:04,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11421/12032 [9:52:23<19:48,  1.95s/it]2025-08-23:04:27:05,444 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11422/12032 [9:52:26<22:37,  2.23s/it]2025-08-23:04:27:08,325 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11423/12032 [9:52:30<27:21,  2.70s/it]2025-08-23:04:27:12,117 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11424/12032 [9:52:32<27:23,  2.70s/it]2025-08-23:04:27:14,836 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11425/12032 [9:52:35<28:01,  2.77s/it]2025-08-23:04:27:17,766 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11426/12032 [9:52:39<28:56,  2.87s/it]2025-08-23:04:27:20,851 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11427/12032 [9:52:40<23:43,  2.35s/it]2025-08-23:04:27:22,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11428/12032 [9:52:43<26:25,  2.63s/it]2025-08-23:04:27:25,269 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11429/12032 [9:52:46<27:27,  2.73s/it]2025-08-23:04:27:28,252 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56212 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▍| 11430/12032 [9:52:50<30:34,  3.05s/it]2025-08-23:04:27:32,032 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37256 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11431/12032 [9:52:54<33:09,  3.31s/it]2025-08-23:04:27:35,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11432/12032 [9:52:57<34:29,  3.45s/it]2025-08-23:04:27:39,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11433/12032 [9:53:01<35:17,  3.53s/it]2025-08-23:04:27:43,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11434/12032 [9:53:02<26:41,  2.68s/it]2025-08-23:04:27:44,142 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11435/12032 [9:53:06<29:51,  3.00s/it]2025-08-23:04:27:47,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11436/12032 [9:53:07<24:00,  2.42s/it]2025-08-23:04:27:48,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11437/12032 [9:53:09<24:40,  2.49s/it]2025-08-23:04:27:51,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11438/12032 [9:53:11<22:07,  2.23s/it]2025-08-23:04:27:53,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11439/12032 [9:53:13<22:15,  2.25s/it]2025-08-23:04:27:55,543 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45794 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11440/12032 [9:53:14<17:22,  1.76s/it]2025-08-23:04:27:56,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11441/12032 [9:53:16<18:11,  1.85s/it]2025-08-23:04:27:58,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11442/12032 [9:53:17<16:34,  1.69s/it]2025-08-23:04:27:59,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11443/12032 [9:53:19<17:45,  1.81s/it]2025-08-23:04:28:01,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11444/12032 [9:53:20<14:37,  1.49s/it]2025-08-23:04:28:02,364 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11445/12032 [9:53:21<12:19,  1.26s/it]2025-08-23:04:28:03,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11446/12032 [9:53:22<11:49,  1.21s/it]2025-08-23:04:28:04,179 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11447/12032 [9:53:23<11:00,  1.13s/it]2025-08-23:04:28:05,118 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11448/12032 [9:53:26<17:26,  1.79s/it]2025-08-23:04:28:08,455 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11449/12032 [9:53:28<19:03,  1.96s/it]2025-08-23:04:28:10,813 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11450/12032 [9:53:31<19:32,  2.02s/it]2025-08-23:04:28:12,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11451/12032 [9:53:32<17:25,  1.80s/it]2025-08-23:04:28:14,250 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11452/12032 [9:53:34<17:13,  1.78s/it]2025-08-23:04:28:15,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52244 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11453/12032 [9:53:34<14:09,  1.47s/it]2025-08-23:04:28:16,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11454/12032 [9:53:36<15:21,  1.59s/it]2025-08-23:04:28:18,612 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11455/12032 [9:53:39<19:06,  1.99s/it]2025-08-23:04:28:21,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42202 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11456/12032 [9:53:43<24:14,  2.52s/it]2025-08-23:04:28:25,295 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11457/12032 [9:53:44<20:23,  2.13s/it]2025-08-23:04:28:26,499 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11458/12032 [9:53:48<25:11,  2.63s/it]2025-08-23:04:28:30,310 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11459/12032 [9:53:49<21:36,  2.26s/it]2025-08-23:04:28:31,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11460/12032 [9:53:51<19:36,  2.06s/it]2025-08-23:04:28:33,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11461/12032 [9:53:52<16:22,  1.72s/it]2025-08-23:04:28:34,220 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53352 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11462/12032 [9:53:53<14:33,  1.53s/it]2025-08-23:04:28:35,311 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53362 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11463/12032 [9:53:54<12:20,  1.30s/it]2025-08-23:04:28:36,073 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53374 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11464/12032 [9:53:55<11:28,  1.21s/it]2025-08-23:04:28:37,078 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11465/12032 [9:53:56<11:09,  1.18s/it]2025-08-23:04:28:38,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11466/12032 [9:53:57<10:19,  1.09s/it]2025-08-23:04:28:39,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53406 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11467/12032 [9:54:00<15:52,  1.69s/it]2025-08-23:04:28:42,146 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34390 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11468/12032 [9:54:02<16:16,  1.73s/it]2025-08-23:04:28:43,981 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11469/12032 [9:54:03<14:53,  1.59s/it]2025-08-23:04:28:45,231 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34410 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11470/12032 [9:54:07<21:03,  2.25s/it]2025-08-23:04:28:49,021 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:34424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11471/12032 [9:54:11<25:36,  2.74s/it]2025-08-23:04:28:52,905 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11472/12032 [9:54:11<19:54,  2.13s/it]2025-08-23:04:28:53,628 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35372 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11473/12032 [9:54:14<20:12,  2.17s/it]2025-08-23:04:28:55,882 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11474/12032 [9:54:16<21:07,  2.27s/it]2025-08-23:04:28:58,392 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35384 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11475/12032 [9:54:17<17:13,  1.86s/it]2025-08-23:04:28:59,274 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11476/12032 [9:54:21<22:37,  2.44s/it]2025-08-23:04:29:03,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33878 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11477/12032 [9:54:21<17:45,  1.92s/it]2025-08-23:04:29:03,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11478/12032 [9:54:23<17:51,  1.93s/it]2025-08-23:04:29:05,756 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11479/12032 [9:54:25<17:12,  1.87s/it]2025-08-23:04:29:07,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33902 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11480/12032 [9:54:28<20:00,  2.17s/it]2025-08-23:04:29:10,358 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47156 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11481/12032 [9:54:32<24:28,  2.67s/it]2025-08-23:04:29:14,167 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47160 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11482/12032 [9:54:36<27:34,  3.01s/it]2025-08-23:04:29:17,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11483/12032 [9:54:37<24:05,  2.63s/it]2025-08-23:04:29:19,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47172 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11484/12032 [9:54:41<27:06,  2.97s/it]2025-08-23:04:29:23,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35370 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11485/12032 [9:54:44<27:44,  3.04s/it]2025-08-23:04:29:26,700 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11486/12032 [9:54:48<29:43,  3.27s/it]2025-08-23:04:29:30,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11487/12032 [9:54:51<28:44,  3.16s/it]2025-08-23:04:29:33,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59844 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11488/12032 [9:54:55<29:39,  3.27s/it]2025-08-23:04:29:36,937 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11489/12032 [9:54:58<31:00,  3.43s/it]2025-08-23:04:29:40,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45308 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  95%|█████████▌| 11490/12032 [9:55:02<31:55,  3.53s/it]2025-08-23:04:29:44,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45310 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11491/12032 [9:55:04<26:55,  2.99s/it]2025-08-23:04:29:46,215 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45324 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11492/12032 [9:55:08<28:43,  3.19s/it]2025-08-23:04:29:49,886 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11493/12032 [9:55:09<24:31,  2.73s/it]2025-08-23:04:29:51,542 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11494/12032 [9:55:11<22:38,  2.53s/it]2025-08-23:04:29:53,588 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11495/12032 [9:55:12<18:40,  2.09s/it]2025-08-23:04:29:54,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11496/12032 [9:55:15<19:10,  2.15s/it]2025-08-23:04:29:56,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11497/12032 [9:55:18<23:12,  2.60s/it]2025-08-23:04:30:00,605 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53380 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11498/12032 [9:55:22<26:14,  2.95s/it]2025-08-23:04:30:04,359 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11499/12032 [9:55:24<23:46,  2.68s/it]2025-08-23:04:30:06,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53398 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11500/12032 [9:55:28<26:05,  2.94s/it]2025-08-23:04:30:09,969 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11501/12032 [9:55:28<20:00,  2.26s/it]2025-08-23:04:30:10,638 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11502/12032 [9:55:32<24:00,  2.72s/it]2025-08-23:04:30:14,420 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11503/12032 [9:55:36<26:45,  3.03s/it]2025-08-23:04:30:18,193 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11504/12032 [9:55:37<21:45,  2.47s/it]2025-08-23:04:30:19,355 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11505/12032 [9:55:38<17:18,  1.97s/it]2025-08-23:04:30:20,155 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11506/12032 [9:55:40<16:55,  1.93s/it]2025-08-23:04:30:21,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11507/12032 [9:55:41<14:09,  1.62s/it]2025-08-23:04:30:22,881 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11508/12032 [9:55:44<18:40,  2.14s/it]2025-08-23:04:30:26,235 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41084 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11509/12032 [9:55:46<19:02,  2.19s/it]2025-08-23:04:30:28,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41086 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11510/12032 [9:55:48<16:58,  1.95s/it]2025-08-23:04:30:29,932 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11511/12032 [9:55:51<21:43,  2.50s/it]2025-08-23:04:30:33,722 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35218 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11512/12032 [9:55:52<17:59,  2.08s/it]2025-08-23:04:30:34,803 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35222 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11513/12032 [9:55:54<15:29,  1.79s/it]2025-08-23:04:30:35,928 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11514/12032 [9:55:54<12:38,  1.46s/it]2025-08-23:04:30:36,627 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35236 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11515/12032 [9:55:58<18:35,  2.16s/it]2025-08-23:04:30:40,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59198 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11516/12032 [9:56:01<21:01,  2.44s/it]2025-08-23:04:30:43,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59204 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11517/12032 [9:56:03<19:25,  2.26s/it]2025-08-23:04:30:45,360 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11518/12032 [9:56:04<16:01,  1.87s/it]2025-08-23:04:30:46,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11519/12032 [9:56:06<15:12,  1.78s/it]2025-08-23:04:30:47,878 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11520/12032 [9:56:09<19:25,  2.28s/it]2025-08-23:04:30:51,315 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11521/12032 [9:56:10<17:19,  2.03s/it]2025-08-23:04:30:52,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44316 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11522/12032 [9:56:11<13:42,  1.61s/it]2025-08-23:04:30:53,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11523/12032 [9:56:13<14:06,  1.66s/it]2025-08-23:04:30:55,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44338 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11524/12032 [9:56:14<12:19,  1.46s/it]2025-08-23:04:30:56,166 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44344 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11525/12032 [9:56:18<18:14,  2.16s/it]2025-08-23:04:30:59,963 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11526/12032 [9:56:19<15:04,  1.79s/it]2025-08-23:04:31:00,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11527/12032 [9:56:21<16:14,  1.93s/it]2025-08-23:04:31:03,145 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11528/12032 [9:56:23<16:57,  2.02s/it]2025-08-23:04:31:05,376 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56502 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11529/12032 [9:56:24<14:39,  1.75s/it]2025-08-23:04:31:06,490 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56518 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11530/12032 [9:56:25<11:51,  1.42s/it]2025-08-23:04:31:07,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56522 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11531/12032 [9:56:26<10:10,  1.22s/it]2025-08-23:04:31:07,893 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11532/12032 [9:56:27<11:10,  1.34s/it]2025-08-23:04:31:09,517 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11533/12032 [9:56:29<11:45,  1.41s/it]2025-08-23:04:31:11,104 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51646 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11534/12032 [9:56:30<10:33,  1.27s/it]2025-08-23:04:31:12,046 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51654 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11535/12032 [9:56:34<16:52,  2.04s/it]2025-08-23:04:31:15,867 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11536/12032 [9:56:37<19:34,  2.37s/it]2025-08-23:04:31:19,004 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51662 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11537/12032 [9:56:40<21:28,  2.60s/it]2025-08-23:04:31:22,159 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48408 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11538/12032 [9:56:41<19:05,  2.32s/it]2025-08-23:04:31:23,812 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11539/12032 [9:56:43<18:03,  2.20s/it]2025-08-23:04:31:25,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11540/12032 [9:56:46<19:24,  2.37s/it]2025-08-23:04:31:28,491 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11541/12032 [9:56:48<17:16,  2.11s/it]2025-08-23:04:31:30,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11542/12032 [9:56:49<15:29,  1.90s/it]2025-08-23:04:31:31,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11543/12032 [9:56:51<16:11,  1.99s/it]2025-08-23:04:31:33,599 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11544/12032 [9:56:53<16:40,  2.05s/it]2025-08-23:04:31:35,799 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11545/12032 [9:56:56<17:40,  2.18s/it]2025-08-23:04:31:38,273 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11546/12032 [9:56:58<17:38,  2.18s/it]2025-08-23:04:31:40,452 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11547/12032 [9:57:02<20:59,  2.60s/it]2025-08-23:04:31:44,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11548/12032 [9:57:06<23:57,  2.97s/it]2025-08-23:04:31:47,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11549/12032 [9:57:08<23:08,  2.87s/it]2025-08-23:04:31:50,518 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56322 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11550/12032 [9:57:10<19:21,  2.41s/it]2025-08-23:04:31:51,846 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56326 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11551/12032 [9:57:13<21:46,  2.72s/it]2025-08-23:04:31:55,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11552/12032 [9:57:17<24:20,  3.04s/it]2025-08-23:04:31:59,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56340 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11553/12032 [9:57:21<26:09,  3.28s/it]2025-08-23:04:32:02,904 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11554/12032 [9:57:23<23:01,  2.89s/it]2025-08-23:04:32:04,889 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11555/12032 [9:57:24<19:26,  2.45s/it]2025-08-23:04:32:06,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56400 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11556/12032 [9:57:28<22:36,  2.85s/it]2025-08-23:04:32:10,091 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11557/12032 [9:57:30<20:27,  2.58s/it]2025-08-23:04:32:12,058 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49800 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11558/12032 [9:57:33<22:56,  2.90s/it]2025-08-23:04:32:15,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11559/12032 [9:57:37<25:04,  3.18s/it]2025-08-23:04:32:19,532 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49806 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11560/12032 [9:57:40<24:07,  3.07s/it]2025-08-23:04:32:22,332 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58614 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11561/12032 [9:57:44<25:56,  3.31s/it]2025-08-23:04:32:26,197 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11562/12032 [9:57:45<21:53,  2.79s/it]2025-08-23:04:32:27,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11563/12032 [9:57:46<16:59,  2.17s/it]2025-08-23:04:32:28,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11564/12032 [9:57:48<15:35,  2.00s/it]2025-08-23:04:32:30,114 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11565/12032 [9:57:51<19:21,  2.49s/it]2025-08-23:04:32:33,744 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38434 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11566/12032 [9:57:53<16:30,  2.13s/it]2025-08-23:04:32:35,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38444 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11567/12032 [9:57:55<17:24,  2.25s/it]2025-08-23:04:32:37,548 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11568/12032 [9:57:59<20:58,  2.71s/it]2025-08-23:04:32:41,353 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45216 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11569/12032 [9:58:00<16:30,  2.14s/it]2025-08-23:04:32:42,152 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45232 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11570/12032 [9:58:01<14:10,  1.84s/it]2025-08-23:04:32:43,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45238 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11571/12032 [9:58:04<17:22,  2.26s/it]2025-08-23:04:32:46,538 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45250 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11572/12032 [9:58:07<17:38,  2.30s/it]2025-08-23:04:32:48,934 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11573/12032 [9:58:10<21:06,  2.76s/it]2025-08-23:04:32:52,761 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11574/12032 [9:58:12<17:22,  2.28s/it]2025-08-23:04:32:53,911 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51050 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11575/12032 [9:58:14<17:03,  2.24s/it]2025-08-23:04:32:56,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11576/12032 [9:58:14<13:27,  1.77s/it]2025-08-23:04:32:56,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51068 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11577/12032 [9:58:18<18:03,  2.38s/it]2025-08-23:04:33:00,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48762 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11578/12032 [9:58:21<18:52,  2.49s/it]2025-08-23:04:33:03,302 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48774 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11579/12032 [9:58:23<16:54,  2.24s/it]2025-08-23:04:33:04,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48788 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▌| 11580/12032 [9:58:24<14:08,  1.88s/it]2025-08-23:04:33:05,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11581/12032 [9:58:25<12:12,  1.62s/it]2025-08-23:04:33:07,012 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48812 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11582/12032 [9:58:26<10:26,  1.39s/it]2025-08-23:04:33:07,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11583/12032 [9:58:28<12:49,  1.71s/it]2025-08-23:04:33:10,329 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11584/12032 [9:58:29<10:45,  1.44s/it]2025-08-23:04:33:11,135 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53366 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11585/12032 [9:58:29<08:49,  1.18s/it]2025-08-23:04:33:11,717 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53378 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11586/12032 [9:58:30<08:01,  1.08s/it]2025-08-23:04:33:12,552 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11587/12032 [9:58:34<14:00,  1.89s/it]2025-08-23:04:33:16,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11588/12032 [9:58:35<12:11,  1.65s/it]2025-08-23:04:33:17,413 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53402 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11589/12032 [9:58:39<16:58,  2.30s/it]2025-08-23:04:33:21,236 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11590/12032 [9:58:40<14:29,  1.97s/it]2025-08-23:04:33:22,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11591/12032 [9:58:41<12:21,  1.68s/it]2025-08-23:04:33:23,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38044 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11592/12032 [9:58:45<16:57,  2.31s/it]2025-08-23:04:33:27,225 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38054 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11593/12032 [9:58:46<15:10,  2.07s/it]2025-08-23:04:33:28,742 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38070 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11594/12032 [9:58:47<11:59,  1.64s/it]2025-08-23:04:33:29,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11595/12032 [9:58:48<09:55,  1.36s/it]2025-08-23:04:33:30,088 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38088 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11596/12032 [9:58:49<08:47,  1.21s/it]2025-08-23:04:33:30,939 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11597/12032 [9:58:49<08:00,  1.11s/it]2025-08-23:04:33:31,801 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11598/12032 [9:58:53<13:47,  1.91s/it]2025-08-23:04:33:35,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11599/12032 [9:58:55<13:25,  1.86s/it]2025-08-23:04:33:37,328 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49180 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11600/12032 [9:58:59<17:29,  2.43s/it]2025-08-23:04:33:41,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11601/12032 [9:59:03<20:23,  2.84s/it]2025-08-23:04:33:44,879 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11602/12032 [9:59:06<22:19,  3.11s/it]2025-08-23:04:33:48,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11603/12032 [9:59:07<18:01,  2.52s/it]2025-08-23:04:33:49,773 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11604/12032 [9:59:08<13:56,  1.95s/it]2025-08-23:04:33:50,405 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11605/12032 [9:59:11<15:29,  2.18s/it]2025-08-23:04:33:53,100 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11606/12032 [9:59:14<16:48,  2.37s/it]2025-08-23:04:33:55,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11607/12032 [9:59:17<19:40,  2.78s/it]2025-08-23:04:33:59,652 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11608/12032 [9:59:19<17:08,  2.43s/it]2025-08-23:04:34:01,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11609/12032 [9:59:23<20:07,  2.85s/it]2025-08-23:04:34:05,108 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  96%|█████████▋| 11610/12032 [9:59:25<18:26,  2.62s/it]2025-08-23:04:34:07,185 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47858 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11611/12032 [9:59:27<17:52,  2.55s/it]2025-08-23:04:34:09,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11612/12032 [9:59:28<14:41,  2.10s/it]2025-08-23:04:34:10,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48360 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11613/12032 [9:59:30<14:19,  2.05s/it]2025-08-23:04:34:12,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11614/12032 [9:59:31<11:48,  1.69s/it]2025-08-23:04:34:13,415 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48386 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11615/12032 [9:59:34<15:10,  2.18s/it]2025-08-23:04:34:16,741 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48392 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11616/12032 [9:59:36<13:05,  1.89s/it]2025-08-23:04:34:17,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48394 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11617/12032 [9:59:36<10:55,  1.58s/it]2025-08-23:04:34:18,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11618/12032 [9:59:39<12:48,  1.86s/it]2025-08-23:04:34:21,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11619/12032 [9:59:42<14:24,  2.09s/it]2025-08-23:04:34:23,947 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33468 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11620/12032 [9:59:45<16:04,  2.34s/it]2025-08-23:04:34:26,868 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11621/12032 [9:59:46<13:58,  2.04s/it]2025-08-23:04:34:28,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33492 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11622/12032 [9:59:47<11:46,  1.72s/it]2025-08-23:04:34:29,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11623/12032 [9:59:48<10:02,  1.47s/it]2025-08-23:04:34:30,082 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33516 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11624/12032 [9:59:49<09:01,  1.33s/it]2025-08-23:04:34:31,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11625/12032 [9:59:52<13:19,  1.96s/it]2025-08-23:04:34:34,513 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11626/12032 [9:59:53<11:13,  1.66s/it]2025-08-23:04:34:35,464 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37526 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11627/12032 [9:59:56<13:49,  2.05s/it]2025-08-23:04:34:38,416 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11628/12032 [10:00:00<17:18,  2.57s/it]2025-08-23:04:34:42,205 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52660 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11629/12032 [10:00:01<14:23,  2.14s/it]2025-08-23:04:34:43,347 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11630/12032 [10:00:04<15:33,  2.32s/it]2025-08-23:04:34:46,089 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11631/12032 [10:00:05<14:10,  2.12s/it]2025-08-23:04:34:47,739 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11632/12032 [10:00:08<14:36,  2.19s/it]2025-08-23:04:34:50,097 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11633/12032 [10:00:12<17:48,  2.68s/it]2025-08-23:04:34:53,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11634/12032 [10:00:13<14:20,  2.16s/it]2025-08-23:04:34:54,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51138 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11635/12032 [10:00:13<11:56,  1.80s/it]2025-08-23:04:34:55,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11636/12032 [10:00:16<13:28,  2.04s/it]2025-08-23:04:34:58,438 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51162 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11637/12032 [10:00:17<10:56,  1.66s/it]2025-08-23:04:34:59,210 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51166 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11638/12032 [10:00:18<09:51,  1.50s/it]2025-08-23:04:35:00,334 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37856 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11639/12032 [10:00:19<08:59,  1.37s/it]2025-08-23:04:35:01,408 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11640/12032 [10:00:20<08:10,  1.25s/it]2025-08-23:04:35:02,380 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11641/12032 [10:00:21<07:38,  1.17s/it]2025-08-23:04:35:03,365 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37886 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11642/12032 [10:00:25<12:41,  1.95s/it]2025-08-23:04:35:07,141 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:37890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11643/12032 [10:00:28<15:49,  2.44s/it]2025-08-23:04:35:10,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40808 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11644/12032 [10:00:32<18:23,  2.85s/it]2025-08-23:04:35:14,507 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40810 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11645/12032 [10:00:36<20:14,  3.14s/it]2025-08-23:04:35:18,327 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40822 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11646/12032 [10:00:37<16:48,  2.61s/it]2025-08-23:04:35:19,718 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11647/12032 [10:00:40<16:15,  2.53s/it]2025-08-23:04:35:22,063 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38880 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11648/12032 [10:00:43<18:26,  2.88s/it]2025-08-23:04:35:25,753 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38888 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11649/12032 [10:00:44<14:40,  2.30s/it]2025-08-23:04:35:26,692 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11650/12032 [10:00:46<13:59,  2.20s/it]2025-08-23:04:35:28,660 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11651/12032 [10:00:47<11:58,  1.89s/it]2025-08-23:04:35:29,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11652/12032 [10:00:49<10:35,  1.67s/it]2025-08-23:04:35:30,991 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36906 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11653/12032 [10:00:51<12:11,  1.93s/it]2025-08-23:04:35:33,521 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36914 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11654/12032 [10:00:52<10:18,  1.64s/it]2025-08-23:04:35:34,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11655/12032 [10:00:56<14:19,  2.28s/it]2025-08-23:04:35:38,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36932 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11656/12032 [10:00:57<12:12,  1.95s/it]2025-08-23:04:35:39,424 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36944 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11657/12032 [10:01:01<15:18,  2.45s/it]2025-08-23:04:35:43,048 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11658/12032 [10:01:02<13:08,  2.11s/it]2025-08-23:04:35:44,362 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54264 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11659/12032 [10:01:03<11:07,  1.79s/it]2025-08-23:04:35:45,403 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11660/12032 [10:01:06<13:17,  2.14s/it]2025-08-23:04:35:48,372 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11661/12032 [10:01:07<10:39,  1.72s/it]2025-08-23:04:35:49,116 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54298 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11662/12032 [10:01:08<09:19,  1.51s/it]2025-08-23:04:35:50,133 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11663/12032 [10:01:11<13:06,  2.13s/it]2025-08-23:04:35:53,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11664/12032 [10:01:15<16:09,  2.64s/it]2025-08-23:04:35:57,524 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11665/12032 [10:01:16<13:04,  2.14s/it]2025-08-23:04:35:58,503 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11666/12032 [10:01:19<14:48,  2.43s/it]2025-08-23:04:36:01,607 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11667/12032 [10:01:20<12:19,  2.02s/it]2025-08-23:04:36:02,691 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11668/12032 [10:01:24<15:23,  2.54s/it]2025-08-23:04:36:06,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52056 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11669/12032 [10:01:25<12:49,  2.12s/it]2025-08-23:04:36:07,565 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11670/12032 [10:01:29<15:57,  2.65s/it]2025-08-23:04:36:11,441 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46676 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11671/12032 [10:01:32<15:44,  2.62s/it]2025-08-23:04:36:13,985 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46690 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11672/12032 [10:01:33<14:11,  2.37s/it]2025-08-23:04:36:15,770 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11673/12032 [10:01:34<11:35,  1.94s/it]2025-08-23:04:36:16,706 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46700 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11674/12032 [10:01:35<09:16,  1.55s/it]2025-08-23:04:36:17,366 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11675/12032 [10:01:38<11:33,  1.94s/it]2025-08-23:04:36:20,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45534 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11676/12032 [10:01:41<13:51,  2.34s/it]2025-08-23:04:36:23,470 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45542 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11677/12032 [10:01:43<13:32,  2.29s/it]2025-08-23:04:36:25,650 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11678/12032 [10:01:45<12:10,  2.06s/it]2025-08-23:04:36:27,184 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11679/12032 [10:01:48<13:39,  2.32s/it]2025-08-23:04:36:30,110 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11680/12032 [10:01:52<16:14,  2.77s/it]2025-08-23:04:36:33,924 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43420 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11681/12032 [10:01:55<17:59,  3.07s/it]2025-08-23:04:36:37,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11682/12032 [10:01:56<13:54,  2.38s/it]2025-08-23:04:36:38,483 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43440 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11683/12032 [10:01:58<12:16,  2.11s/it]2025-08-23:04:36:39,952 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:43456 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11684/12032 [10:01:58<09:56,  1.71s/it]2025-08-23:04:36:40,745 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11685/12032 [10:02:00<09:07,  1.58s/it]2025-08-23:04:36:42,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50630 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11686/12032 [10:02:01<08:05,  1.40s/it]2025-08-23:04:36:43,000 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11687/12032 [10:02:02<07:09,  1.25s/it]2025-08-23:04:36:43,880 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50644 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11688/12032 [10:02:05<10:08,  1.77s/it]2025-08-23:04:36:46,872 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50650 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11689/12032 [10:02:08<13:26,  2.35s/it]2025-08-23:04:36:50,577 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11690/12032 [10:02:10<11:47,  2.07s/it]2025-08-23:04:36:51,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33422 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11691/12032 [10:02:13<14:39,  2.58s/it]2025-08-23:04:36:55,754 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11692/12032 [10:02:17<16:33,  2.92s/it]2025-08-23:04:36:59,476 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33438 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11693/12032 [10:02:18<13:31,  2.39s/it]2025-08-23:04:37:00,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48282 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11694/12032 [10:02:20<12:38,  2.24s/it]2025-08-23:04:37:02,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48290 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11695/12032 [10:02:24<15:12,  2.71s/it]2025-08-23:04:37:06,326 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11696/12032 [10:02:28<16:55,  3.02s/it]2025-08-23:04:37:10,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11697/12032 [10:02:28<12:59,  2.33s/it]2025-08-23:04:37:10,783 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59358 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11698/12032 [10:02:31<12:33,  2.26s/it]2025-08-23:04:37:12,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59364 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11699/12032 [10:02:34<13:58,  2.52s/it]2025-08-23:04:37:15,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59376 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11700/12032 [10:02:35<12:37,  2.28s/it]2025-08-23:04:37:17,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59388 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11701/12032 [10:02:37<11:03,  2.01s/it]2025-08-23:04:37:19,093 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59404 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11702/12032 [10:02:40<13:04,  2.38s/it]2025-08-23:04:37:22,341 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56820 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11703/12032 [10:02:43<13:36,  2.48s/it]2025-08-23:04:37:25,066 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11704/12032 [10:02:46<14:07,  2.58s/it]2025-08-23:04:37:27,888 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11705/12032 [10:02:46<10:53,  2.00s/it]2025-08-23:04:37:28,515 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11706/12032 [10:02:49<12:36,  2.32s/it]2025-08-23:04:37:31,587 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58144 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11707/12032 [10:02:50<10:05,  1.86s/it]2025-08-23:04:37:32,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11708/12032 [10:02:52<10:17,  1.90s/it]2025-08-23:04:37:34,388 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11709/12032 [10:02:53<08:18,  1.54s/it]2025-08-23:04:37:35,086 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11710/12032 [10:02:54<07:57,  1.48s/it]2025-08-23:04:37:36,434 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11711/12032 [10:02:56<08:27,  1.58s/it]2025-08-23:04:37:38,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58196 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11712/12032 [10:02:58<08:37,  1.62s/it]2025-08-23:04:37:39,945 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58206 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11713/12032 [10:03:01<12:05,  2.27s/it]2025-08-23:04:37:43,752 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48920 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11714/12032 [10:03:05<14:26,  2.73s/it]2025-08-23:04:37:47,528 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48922 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11715/12032 [10:03:07<12:10,  2.31s/it]2025-08-23:04:37:48,855 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11716/12032 [10:03:09<11:52,  2.25s/it]2025-08-23:04:37:50,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56580 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11717/12032 [10:03:09<09:24,  1.79s/it]2025-08-23:04:37:51,707 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11718/12032 [10:03:11<09:38,  1.84s/it]2025-08-23:04:37:53,665 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56600 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11719/12032 [10:03:13<08:54,  1.71s/it]2025-08-23:04:37:55,053 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56610 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11720/12032 [10:03:14<08:03,  1.55s/it]2025-08-23:04:37:56,240 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56622 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11721/12032 [10:03:17<09:58,  1.92s/it]2025-08-23:04:37:59,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11722/12032 [10:03:19<09:47,  1.89s/it]2025-08-23:04:38:00,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56802 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11723/12032 [10:03:22<12:44,  2.47s/it]2025-08-23:04:38:04,687 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11724/12032 [10:03:23<10:19,  2.01s/it]2025-08-23:04:38:05,615 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56826 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11725/12032 [10:03:24<08:40,  1.69s/it]2025-08-23:04:38:06,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56842 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11726/12032 [10:03:25<07:14,  1.42s/it]2025-08-23:04:38:07,350 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11727/12032 [10:03:26<06:55,  1.36s/it]2025-08-23:04:38:08,584 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11728/12032 [10:03:30<10:33,  2.09s/it]2025-08-23:04:38:12,354 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45118 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11729/12032 [10:03:32<10:12,  2.02s/it]2025-08-23:04:38:14,230 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45134 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11730/12032 [10:03:36<12:51,  2.55s/it]2025-08-23:04:38:18,026 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  97%|█████████▋| 11731/12032 [10:03:40<14:46,  2.94s/it]2025-08-23:04:38:21,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11732/12032 [10:03:43<16:06,  3.22s/it]2025-08-23:04:38:25,749 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50666 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11733/12032 [10:03:47<16:55,  3.40s/it]2025-08-23:04:38:29,554 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11734/12032 [10:03:48<13:21,  2.69s/it]2025-08-23:04:38:30,590 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42938 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11735/12032 [10:03:52<14:59,  3.03s/it]2025-08-23:04:38:34,411 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42952 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11736/12032 [10:03:53<12:03,  2.45s/it]2025-08-23:04:38:35,495 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11737/12032 [10:03:55<11:32,  2.35s/it]2025-08-23:04:38:37,614 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:42962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11738/12032 [10:03:59<13:44,  2.80s/it]2025-08-23:04:38:41,484 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11739/12032 [10:04:02<13:03,  2.67s/it]2025-08-23:04:38:43,856 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11740/12032 [10:04:05<14:48,  3.04s/it]2025-08-23:04:38:47,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11741/12032 [10:04:06<11:29,  2.37s/it]2025-08-23:04:38:48,559 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33744 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11742/12032 [10:04:10<13:29,  2.79s/it]2025-08-23:04:38:52,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53040 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11743/12032 [10:04:11<10:37,  2.20s/it]2025-08-23:04:38:53,169 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11744/12032 [10:04:13<10:13,  2.13s/it]2025-08-23:04:38:55,131 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53058 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11745/12032 [10:04:17<12:36,  2.63s/it]2025-08-23:04:38:58,940 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11746/12032 [10:04:17<09:59,  2.09s/it]2025-08-23:04:38:59,775 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53082 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11747/12032 [10:04:21<12:20,  2.60s/it]2025-08-23:04:39:03,544 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49024 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11748/12032 [10:04:25<14:00,  2.96s/it]2025-08-23:04:39:07,344 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11749/12032 [10:04:26<11:19,  2.40s/it]2025-08-23:04:39:08,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49034 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11750/12032 [10:04:29<11:39,  2.48s/it]2025-08-23:04:39:11,113 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45396 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11751/12032 [10:04:33<13:27,  2.87s/it]2025-08-23:04:39:14,900 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45412 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11752/12032 [10:04:35<13:12,  2.83s/it]2025-08-23:04:39:17,637 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45416 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11753/12032 [10:04:36<10:27,  2.25s/it]2025-08-23:04:39:18,531 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45430 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11754/12032 [10:04:37<08:53,  1.92s/it]2025-08-23:04:39:19,680 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11755/12032 [10:04:39<08:57,  1.94s/it]2025-08-23:04:39:21,670 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38804 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11756/12032 [10:04:42<09:59,  2.17s/it]2025-08-23:04:39:24,384 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38818 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11757/12032 [10:04:44<08:59,  1.96s/it]2025-08-23:04:39:25,858 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38830 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11758/12032 [10:04:44<07:29,  1.64s/it]2025-08-23:04:39:26,740 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11759/12032 [10:04:48<10:23,  2.28s/it]2025-08-23:04:39:30,525 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11760/12032 [10:04:50<10:16,  2.27s/it]2025-08-23:04:39:32,750 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53470 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11761/12032 [10:04:51<08:34,  1.90s/it]2025-08-23:04:39:33,798 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53484 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11762/12032 [10:04:52<06:59,  1.55s/it]2025-08-23:04:39:34,541 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11763/12032 [10:04:53<05:59,  1.34s/it]2025-08-23:04:39:35,374 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11764/12032 [10:04:54<05:27,  1.22s/it]2025-08-23:04:39:36,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53496 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11765/12032 [10:04:55<04:57,  1.11s/it]2025-08-23:04:39:37,186 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53498 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11766/12032 [10:04:57<06:33,  1.48s/it]2025-08-23:04:39:39,527 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53512 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11767/12032 [10:05:00<08:27,  1.91s/it]2025-08-23:04:39:42,449 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52036 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11768/12032 [10:05:04<10:52,  2.47s/it]2025-08-23:04:39:46,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52042 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11769/12032 [10:05:06<09:55,  2.27s/it]2025-08-23:04:39:48,008 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52046 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11770/12032 [10:05:09<11:50,  2.71s/it]2025-08-23:04:39:51,757 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51414 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11771/12032 [10:05:11<09:54,  2.28s/it]2025-08-23:04:39:53,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51426 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11772/12032 [10:05:14<11:51,  2.74s/it]2025-08-23:04:39:56,826 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11773/12032 [10:05:17<11:34,  2.68s/it]2025-08-23:04:39:59,379 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51448 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11774/12032 [10:05:21<12:34,  2.93s/it]2025-08-23:04:40:02,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55724 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11775/12032 [10:05:22<10:28,  2.45s/it]2025-08-23:04:40:04,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55728 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11776/12032 [10:05:23<08:43,  2.04s/it]2025-08-23:04:40:05,308 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11777/12032 [10:05:24<07:53,  1.86s/it]2025-08-23:04:40:06,730 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55750 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11778/12032 [10:05:25<06:26,  1.52s/it]2025-08-23:04:40:07,469 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55754 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11779/12032 [10:05:27<06:55,  1.64s/it]2025-08-23:04:40:09,390 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55758 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11780/12032 [10:05:28<05:36,  1.33s/it]2025-08-23:04:40:10,005 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55772 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11781/12032 [10:05:30<06:45,  1.62s/it]2025-08-23:04:40:12,281 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57328 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11782/12032 [10:05:34<09:27,  2.27s/it]2025-08-23:04:40:16,070 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57342 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11783/12032 [10:05:36<09:39,  2.33s/it]2025-08-23:04:40:18,529 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11784/12032 [10:05:40<11:01,  2.67s/it]2025-08-23:04:40:21,996 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11785/12032 [10:05:42<10:13,  2.48s/it]2025-08-23:04:40:24,047 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11786/12032 [10:05:44<09:45,  2.38s/it]2025-08-23:04:40:26,189 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56472 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11787/12032 [10:05:45<08:12,  2.01s/it]2025-08-23:04:40:27,331 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56474 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11788/12032 [10:05:48<09:22,  2.31s/it]2025-08-23:04:40:30,333 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11789/12032 [10:05:51<10:04,  2.49s/it]2025-08-23:04:40:33,243 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11790/12032 [10:05:54<10:27,  2.59s/it]2025-08-23:04:40:36,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53170 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11791/12032 [10:05:55<08:42,  2.17s/it]2025-08-23:04:40:37,259 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11792/12032 [10:05:59<10:39,  2.66s/it]2025-08-23:04:40:41,081 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52060 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11793/12032 [10:06:03<11:58,  3.01s/it]2025-08-23:04:40:44,885 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11794/12032 [10:06:06<11:53,  3.00s/it]2025-08-23:04:40:47,864 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11795/12032 [10:06:07<10:31,  2.66s/it]2025-08-23:04:40:49,751 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52090 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11796/12032 [10:06:11<11:52,  3.02s/it]2025-08-23:04:40:53,602 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11797/12032 [10:06:15<12:47,  3.27s/it]2025-08-23:04:40:57,440 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11798/12032 [10:06:17<11:01,  2.83s/it]2025-08-23:04:40:59,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40718 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11799/12032 [10:06:18<09:11,  2.37s/it]2025-08-23:04:41:00,533 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11800/12032 [10:06:19<07:17,  1.89s/it]2025-08-23:04:41:01,303 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11801/12032 [10:06:23<09:28,  2.46s/it]2025-08-23:04:41:05,096 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11802/12032 [10:06:24<08:27,  2.21s/it]2025-08-23:04:41:06,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48480 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11803/12032 [10:06:27<09:23,  2.46s/it]2025-08-23:04:41:09,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48494 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11804/12032 [10:06:30<09:32,  2.51s/it]2025-08-23:04:41:12,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55272 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11805/12032 [10:06:34<10:58,  2.90s/it]2025-08-23:04:41:16,199 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11806/12032 [10:06:37<10:50,  2.88s/it]2025-08-23:04:41:19,035 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55300 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11807/12032 [10:06:38<08:41,  2.32s/it]2025-08-23:04:41:20,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55314 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11808/12032 [10:06:40<08:29,  2.28s/it]2025-08-23:04:41:22,218 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51628 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11809/12032 [10:06:44<10:00,  2.69s/it]2025-08-23:04:41:25,891 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11810/12032 [10:06:45<08:04,  2.18s/it]2025-08-23:04:41:26,884 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11811/12032 [10:06:46<07:09,  1.94s/it]2025-08-23:04:41:28,266 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51638 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11812/12032 [10:06:47<05:46,  1.58s/it]2025-08-23:04:41:28,983 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51652 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11813/12032 [10:06:48<05:16,  1.45s/it]2025-08-23:04:41:30,126 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44738 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11814/12032 [10:06:51<07:05,  1.95s/it]2025-08-23:04:41:33,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44740 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11815/12032 [10:06:55<09:04,  2.51s/it]2025-08-23:04:41:37,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44742 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11816/12032 [10:06:59<10:24,  2.89s/it]2025-08-23:04:41:40,853 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11817/12032 [10:07:02<11:19,  3.16s/it]2025-08-23:04:41:44,635 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11818/12032 [10:07:05<10:58,  3.08s/it]2025-08-23:04:41:47,516 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58230 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11819/12032 [10:07:06<08:39,  2.44s/it]2025-08-23:04:41:48,466 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11820/12032 [10:07:10<09:50,  2.79s/it]2025-08-23:04:41:52,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55258 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11821/12032 [10:07:11<07:54,  2.25s/it]2025-08-23:04:41:53,062 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11822/12032 [10:07:14<08:53,  2.54s/it]2025-08-23:04:41:56,286 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11823/12032 [10:07:15<07:21,  2.11s/it]2025-08-23:04:41:57,402 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11824/12032 [10:07:19<09:03,  2.61s/it]2025-08-23:04:42:01,183 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48348 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11825/12032 [10:07:20<07:24,  2.15s/it]2025-08-23:04:42:02,237 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48354 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11826/12032 [10:07:23<08:16,  2.41s/it]2025-08-23:04:42:05,257 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48356 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11827/12032 [10:07:25<08:18,  2.43s/it]2025-08-23:04:42:07,748 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48368 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11828/12032 [10:07:29<09:40,  2.85s/it]2025-08-23:04:42:11,555 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60560 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11829/12032 [10:07:30<07:23,  2.19s/it]2025-08-23:04:42:12,206 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11830/12032 [10:07:31<06:32,  1.94s/it]2025-08-23:04:42:13,573 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11831/12032 [10:07:35<08:19,  2.48s/it]2025-08-23:04:42:17,320 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11832/12032 [10:07:36<07:01,  2.11s/it]2025-08-23:04:42:18,549 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11833/12032 [10:07:37<05:44,  1.73s/it]2025-08-23:04:42:19,407 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11834/12032 [10:07:41<07:43,  2.34s/it]2025-08-23:04:42:23,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35840 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11835/12032 [10:07:42<06:27,  1.97s/it]2025-08-23:04:42:24,265 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35850 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11836/12032 [10:07:45<07:52,  2.41s/it]2025-08-23:04:42:27,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11837/12032 [10:07:48<07:46,  2.39s/it]2025-08-23:04:42:30,061 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35874 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11838/12032 [10:07:52<09:06,  2.82s/it]2025-08-23:04:42:33,870 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11839/12032 [10:07:55<09:58,  3.10s/it]2025-08-23:04:42:37,631 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44584 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11840/12032 [10:07:58<09:14,  2.89s/it]2025-08-23:04:42:40,028 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44590 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11841/12032 [10:08:00<09:01,  2.84s/it]2025-08-23:04:42:42,737 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57330 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11842/12032 [10:08:04<09:27,  2.98s/it]2025-08-23:04:42:46,069 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57334 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11843/12032 [10:08:07<10:08,  3.22s/it]2025-08-23:04:42:49,839 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57346 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11844/12032 [10:08:10<09:28,  3.02s/it]2025-08-23:04:42:52,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49246 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11845/12032 [10:08:14<10:07,  3.25s/it]2025-08-23:04:42:56,176 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49252 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11846/12032 [10:08:16<08:47,  2.84s/it]2025-08-23:04:42:58,052 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:49268 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11847/12032 [10:08:19<09:00,  2.92s/it]2025-08-23:04:43:01,163 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58778 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11848/12032 [10:08:23<09:42,  3.16s/it]2025-08-23:04:43:04,898 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58780 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11849/12032 [10:08:26<10:12,  3.35s/it]2025-08-23:04:43:08,677 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11850/12032 [10:08:28<08:45,  2.89s/it]2025-08-23:04:43:10,485 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35418 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  98%|█████████▊| 11851/12032 [10:08:29<06:56,  2.30s/it]2025-08-23:04:43:11,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35424 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11852/12032 [10:08:33<08:13,  2.74s/it]2025-08-23:04:43:15,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35432 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11853/12032 [10:08:37<09:01,  3.02s/it]2025-08-23:04:43:18,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:35442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11854/12032 [10:08:40<09:39,  3.26s/it]2025-08-23:04:43:22,668 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33536 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11855/12032 [10:08:44<10:03,  3.41s/it]2025-08-23:04:43:26,435 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11856/12032 [10:08:45<07:41,  2.62s/it]2025-08-23:04:43:27,229 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11857/12032 [10:08:46<06:36,  2.27s/it]2025-08-23:04:43:28,661 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11858/12032 [10:08:47<05:31,  1.90s/it]2025-08-23:04:43:29,716 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33568 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11859/12032 [10:08:49<04:57,  1.72s/it]2025-08-23:04:43:31,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11860/12032 [10:08:50<04:15,  1.49s/it]2025-08-23:04:43:31,951 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11861/12032 [10:08:51<04:19,  1.52s/it]2025-08-23:04:43:33,546 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48572 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11862/12032 [10:08:53<04:52,  1.72s/it]2025-08-23:04:43:35,729 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11863/12032 [10:08:56<05:48,  2.06s/it]2025-08-23:04:43:38,591 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11864/12032 [10:08:58<05:39,  2.02s/it]2025-08-23:04:43:40,512 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11865/12032 [10:09:00<05:12,  1.87s/it]2025-08-23:04:43:42,040 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59000 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11866/12032 [10:09:01<04:59,  1.80s/it]2025-08-23:04:43:43,684 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11867/12032 [10:09:04<05:21,  1.95s/it]2025-08-23:04:43:45,980 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11868/12032 [10:09:07<06:50,  2.50s/it]2025-08-23:04:43:49,763 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59032 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11869/12032 [10:09:08<05:36,  2.07s/it]2025-08-23:04:43:50,818 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33848 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11870/12032 [10:09:11<05:39,  2.09s/it]2025-08-23:04:43:52,972 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33862 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11871/12032 [10:09:12<04:54,  1.83s/it]2025-08-23:04:43:54,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33868 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11872/12032 [10:09:15<05:51,  2.20s/it]2025-08-23:04:43:57,249 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11873/12032 [10:09:16<04:53,  1.84s/it]2025-08-23:04:43:58,261 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33884 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11874/12032 [10:09:17<04:13,  1.61s/it]2025-08-23:04:43:59,316 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:33892 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11875/12032 [10:09:20<05:00,  1.92s/it]2025-08-23:04:44:01,955 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11876/12032 [10:09:21<04:12,  1.62s/it]2025-08-23:04:44:02,883 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39280 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11877/12032 [10:09:24<05:37,  2.18s/it]2025-08-23:04:44:06,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39294 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11878/12032 [10:09:27<06:26,  2.51s/it]2025-08-23:04:44:09,639 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:39304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11879/12032 [10:09:31<07:22,  2.89s/it]2025-08-23:04:44:13,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59124 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11880/12032 [10:09:34<07:40,  3.03s/it]2025-08-23:04:44:16,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59140 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▊| 11881/12032 [10:09:35<06:00,  2.39s/it]2025-08-23:04:44:17,675 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59152 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11882/12032 [10:09:38<06:06,  2.45s/it]2025-08-23:04:44:20,256 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44442 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11883/12032 [10:09:42<07:04,  2.85s/it]2025-08-23:04:44:24,042 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44458 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11884/12032 [10:09:43<05:40,  2.30s/it]2025-08-23:04:44:25,064 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11885/12032 [10:09:45<05:22,  2.19s/it]2025-08-23:04:44:27,001 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44476 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11886/12032 [10:09:46<04:44,  1.95s/it]2025-08-23:04:44:28,383 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44490 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11887/12032 [10:09:47<03:49,  1.59s/it]2025-08-23:04:44:29,122 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44506 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11888/12032 [10:09:48<03:15,  1.35s/it]2025-08-23:04:44:29,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44510 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11889/12032 [10:09:49<03:09,  1.32s/it]2025-08-23:04:44:31,192 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47680 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11890/12032 [10:09:53<04:53,  2.06s/it]2025-08-23:04:44:34,979 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47684 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11891/12032 [10:09:54<04:05,  1.74s/it]2025-08-23:04:44:35,976 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11892/12032 [10:09:57<04:52,  2.09s/it]2025-08-23:04:44:38,877 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:47708 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11893/12032 [10:09:58<04:44,  2.05s/it]2025-08-23:04:44:40,823 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59454 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11894/12032 [10:10:02<05:54,  2.57s/it]2025-08-23:04:44:44,601 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11895/12032 [10:10:04<05:01,  2.20s/it]2025-08-23:04:44:45,938 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59462 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11896/12032 [10:10:07<06:02,  2.67s/it]2025-08-23:04:44:49,696 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:59466 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11897/12032 [10:10:11<06:31,  2.90s/it]2025-08-23:04:44:53,140 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40116 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11898/12032 [10:10:12<05:09,  2.31s/it]2025-08-23:04:44:54,083 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40132 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11899/12032 [10:10:13<04:13,  1.91s/it]2025-08-23:04:44:55,049 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11900/12032 [10:10:14<03:41,  1.68s/it]2025-08-23:04:44:56,202 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11901/12032 [10:10:15<03:23,  1.55s/it]2025-08-23:04:44:57,459 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:40168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11902/12032 [10:10:19<04:48,  2.22s/it]2025-08-23:04:45:01,238 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36576 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11903/12032 [10:10:23<05:48,  2.70s/it]2025-08-23:04:45:05,067 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11904/12032 [10:10:26<06:13,  2.92s/it]2025-08-23:04:45:08,478 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36588 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11905/12032 [10:10:30<06:31,  3.08s/it]2025-08-23:04:45:11,948 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48926 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11906/12032 [10:10:30<05:01,  2.39s/it]2025-08-23:04:45:12,732 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11907/12032 [10:10:31<04:00,  1.92s/it]2025-08-23:04:45:13,553 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48948 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11908/12032 [10:10:34<04:28,  2.17s/it]2025-08-23:04:45:16,299 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48964 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11909/12032 [10:10:36<04:09,  2.03s/it]2025-08-23:04:45:17,999 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48966 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11910/12032 [10:10:38<04:20,  2.14s/it]2025-08-23:04:45:20,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50592 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11911/12032 [10:10:42<05:18,  2.63s/it]2025-08-23:04:45:24,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50608 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11912/12032 [10:10:45<05:27,  2.73s/it]2025-08-23:04:45:27,129 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11913/12032 [10:10:48<05:28,  2.76s/it]2025-08-23:04:45:29,964 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50624 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11914/12032 [10:10:50<05:25,  2.76s/it]2025-08-23:04:45:32,710 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38066 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11915/12032 [10:10:53<05:01,  2.57s/it]2025-08-23:04:45:34,862 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38072 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11916/12032 [10:10:55<04:52,  2.52s/it]2025-08-23:04:45:37,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38078 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11917/12032 [10:10:59<05:33,  2.90s/it]2025-08-23:04:45:41,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55760 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11918/12032 [10:11:02<06:00,  3.16s/it]2025-08-23:04:45:44,810 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55776 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11919/12032 [10:11:04<04:56,  2.63s/it]2025-08-23:04:45:46,191 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55782 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11920/12032 [10:11:06<04:23,  2.35s/it]2025-08-23:04:45:47,896 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55784 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11921/12032 [10:11:09<05:08,  2.78s/it]2025-08-23:04:45:51,669 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51682 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11922/12032 [10:11:11<04:31,  2.47s/it]2025-08-23:04:45:53,421 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11923/12032 [10:11:13<04:21,  2.40s/it]2025-08-23:04:45:55,648 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51702 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11924/12032 [10:11:14<03:34,  1.99s/it]2025-08-23:04:45:56,674 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51710 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11925/12032 [10:11:15<02:55,  1.64s/it]2025-08-23:04:45:57,500 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11926/12032 [10:11:17<03:06,  1.76s/it]2025-08-23:04:45:59,550 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51726 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11927/12032 [10:11:19<02:50,  1.63s/it]2025-08-23:04:46:00,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46262 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11928/12032 [10:11:19<02:15,  1.30s/it]2025-08-23:04:46:01,398 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46274 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11929/12032 [10:11:23<03:30,  2.04s/it]2025-08-23:04:46:05,173 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11930/12032 [10:11:25<03:24,  2.00s/it]2025-08-23:04:46:07,079 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46296 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11931/12032 [10:11:29<04:17,  2.55s/it]2025-08-23:04:46:10,897 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11932/12032 [10:11:32<04:45,  2.86s/it]2025-08-23:04:46:14,479 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60200 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11933/12032 [10:11:35<04:47,  2.91s/it]2025-08-23:04:46:17,505 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60208 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11934/12032 [10:11:36<03:47,  2.32s/it]2025-08-23:04:46:18,468 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60220 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11935/12032 [10:11:37<02:57,  1.83s/it]2025-08-23:04:46:19,130 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60234 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11936/12032 [10:11:40<03:21,  2.10s/it]2025-08-23:04:46:21,869 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38224 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11937/12032 [10:11:43<04:09,  2.62s/it]2025-08-23:04:46:25,712 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38240 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11938/12032 [10:11:44<03:16,  2.10s/it]2025-08-23:04:46:26,576 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38248 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11939/12032 [10:11:45<02:45,  1.78s/it]2025-08-23:04:46:27,625 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11940/12032 [10:11:49<03:38,  2.38s/it]2025-08-23:04:46:31,396 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41678 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11941/12032 [10:11:51<03:12,  2.11s/it]2025-08-23:04:46:32,895 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41694 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11942/12032 [10:11:54<03:55,  2.62s/it]2025-08-23:04:46:36,682 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41704 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11943/12032 [10:11:56<03:21,  2.26s/it]2025-08-23:04:46:38,121 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:41720 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11944/12032 [10:11:59<03:33,  2.43s/it]2025-08-23:04:46:40,942 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45828 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11945/12032 [10:12:00<02:56,  2.03s/it]2025-08-23:04:46:42,022 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11946/12032 [10:12:02<03:14,  2.26s/it]2025-08-23:04:46:44,840 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45852 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11947/12032 [10:12:03<02:37,  1.85s/it]2025-08-23:04:46:45,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45854 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11948/12032 [10:12:04<02:07,  1.52s/it]2025-08-23:04:46:46,461 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:45860 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11949/12032 [10:12:08<03:01,  2.19s/it]2025-08-23:04:46:50,216 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44148 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11950/12032 [10:12:12<03:38,  2.67s/it]2025-08-23:04:46:54,009 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44154 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11951/12032 [10:12:13<02:56,  2.17s/it]2025-08-23:04:46:55,027 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11952/12032 [10:12:14<02:23,  1.79s/it]2025-08-23:04:46:55,931 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11953/12032 [10:12:16<02:31,  1.91s/it]2025-08-23:04:46:58,120 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44174 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11954/12032 [10:12:17<02:01,  1.56s/it]2025-08-23:04:46:58,865 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44178 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11955/12032 [10:12:17<01:45,  1.37s/it]2025-08-23:04:46:59,782 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:44186 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11956/12032 [10:12:19<01:38,  1.30s/it]2025-08-23:04:47:00,926 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55538 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11957/12032 [10:12:19<01:27,  1.16s/it]2025-08-23:04:47:01,758 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55546 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11958/12032 [10:12:20<01:18,  1.06s/it]2025-08-23:04:47:02,587 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55552 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11959/12032 [10:12:22<01:32,  1.27s/it]2025-08-23:04:47:04,338 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11960/12032 [10:12:26<02:25,  2.02s/it]2025-08-23:04:47:08,109 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55556 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11961/12032 [10:12:27<02:06,  1.79s/it]2025-08-23:04:47:09,351 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55562 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11962/12032 [10:12:31<02:43,  2.34s/it]2025-08-23:04:47:12,992 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50824 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11963/12032 [10:12:32<02:19,  2.02s/it]2025-08-23:04:47:14,276 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50832 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11964/12032 [10:12:35<02:44,  2.42s/it]2025-08-23:04:47:17,624 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:50838 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11965/12032 [10:12:38<02:45,  2.47s/it]2025-08-23:04:47:20,214 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51990 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11966/12032 [10:12:40<02:31,  2.30s/it]2025-08-23:04:47:22,105 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:51996 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11967/12032 [10:12:42<02:25,  2.24s/it]2025-08-23:04:47:24,226 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52010 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11968/12032 [10:12:44<02:13,  2.09s/it]2025-08-23:04:47:25,950 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52016 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11969/12032 [10:12:45<01:50,  1.75s/it]2025-08-23:04:47:26,912 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52020 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11970/12032 [10:12:47<01:55,  1.86s/it]2025-08-23:04:47:29,038 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52030 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API:  99%|█████████▉| 11971/12032 [10:12:49<02:03,  2.02s/it]2025-08-23:04:47:31,422 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52158 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11972/12032 [10:12:52<02:10,  2.17s/it]2025-08-23:04:47:33,956 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52164 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11973/12032 [10:12:55<02:36,  2.65s/it]2025-08-23:04:47:37,709 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52168 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11974/12032 [10:12:57<02:19,  2.41s/it]2025-08-23:04:47:39,564 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:52176 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11975/12032 [10:13:01<02:39,  2.80s/it]2025-08-23:04:47:43,278 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48554 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11976/12032 [10:13:03<02:17,  2.45s/it]2025-08-23:04:47:44,913 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48566 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11977/12032 [10:13:05<02:18,  2.51s/it]2025-08-23:04:47:47,569 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48578 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11978/12032 [10:13:07<02:01,  2.25s/it]2025-08-23:04:47:49,203 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:48582 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11979/12032 [10:13:11<02:23,  2.70s/it]2025-08-23:04:47:52,953 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38254 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11980/12032 [10:13:14<02:37,  3.02s/it]2025-08-23:04:47:56,721 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38260 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11981/12032 [10:13:17<02:28,  2.91s/it]2025-08-23:04:47:59,368 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:38270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11982/12032 [10:13:18<01:57,  2.35s/it]2025-08-23:04:48:00,410 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11983/12032 [10:13:22<02:17,  2.80s/it]2025-08-23:04:48:04,251 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11984/12032 [10:13:24<02:01,  2.52s/it]2025-08-23:04:48:06,138 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11985/12032 [10:13:25<01:41,  2.16s/it]2025-08-23:04:48:07,465 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57986 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11986/12032 [10:13:26<01:23,  1.81s/it]2025-08-23:04:48:08,460 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58002 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11987/12032 [10:13:29<01:39,  2.21s/it]2025-08-23:04:48:11,611 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11988/12032 [10:13:31<01:31,  2.09s/it]2025-08-23:04:48:13,404 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11989/12032 [10:13:32<01:19,  1.85s/it]2025-08-23:04:48:14,694 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53900 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11990/12032 [10:13:35<01:31,  2.17s/it]2025-08-23:04:48:17,609 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:53910 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11991/12032 [10:13:38<01:34,  2.31s/it]2025-08-23:04:48:20,233 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46962 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11992/12032 [10:13:41<01:37,  2.44s/it]2025-08-23:04:48:22,987 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46978 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11993/12032 [10:13:41<01:14,  1.92s/it]2025-08-23:04:48:23,704 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46980 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11994/12032 [10:13:45<01:30,  2.38s/it]2025-08-23:04:48:27,156 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46984 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11995/12032 [10:13:46<01:12,  1.95s/it]2025-08-23:04:48:28,115 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46994 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11996/12032 [10:13:50<01:31,  2.55s/it]2025-08-23:04:48:32,056 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11997/12032 [10:13:51<01:14,  2.12s/it]2025-08-23:04:48:33,158 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56292 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11998/12032 [10:13:53<01:13,  2.17s/it]2025-08-23:04:48:35,463 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56304 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 11999/12032 [10:13:57<01:27,  2.66s/it]2025-08-23:04:48:39,272 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56312 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12000/12032 [10:13:58<01:07,  2.11s/it]2025-08-23:04:48:40,095 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:56320 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12001/12032 [10:14:00<01:07,  2.17s/it]2025-08-23:04:48:42,386 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60436 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12002/12032 [10:14:02<01:07,  2.24s/it]2025-08-23:04:48:44,805 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60446 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12003/12032 [10:14:06<01:17,  2.66s/it]2025-08-23:04:48:48,454 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60460 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12004/12032 [10:14:07<01:00,  2.17s/it]2025-08-23:04:48:49,467 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60464 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12005/12032 [10:14:11<01:11,  2.66s/it]2025-08-23:04:48:53,270 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60266 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12006/12032 [10:14:12<00:54,  2.10s/it]2025-08-23:04:48:54,080 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60270 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12007/12032 [10:14:16<01:05,  2.61s/it]2025-08-23:04:48:57,873 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60276 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12008/12032 [10:14:16<00:50,  2.10s/it]2025-08-23:04:48:58,785 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60284 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12009/12032 [10:14:18<00:41,  1.81s/it]2025-08-23:04:48:59,930 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:60288 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12010/12032 [10:14:21<00:50,  2.30s/it]2025-08-23:04:49:03,357 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54616 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12011/12032 [10:14:22<00:42,  2.02s/it]2025-08-23:04:49:04,727 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54632 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12012/12032 [10:14:23<00:34,  1.73s/it]2025-08-23:04:49:05,787 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12013/12032 [10:14:26<00:35,  1.86s/it]2025-08-23:04:49:07,957 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:54640 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12014/12032 [10:14:29<00:40,  2.27s/it]2025-08-23:04:49:11,187 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46934 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12015/12032 [10:14:31<00:40,  2.35s/it]2025-08-23:04:49:13,726 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46942 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12016/12032 [10:14:35<00:44,  2.78s/it]2025-08-23:04:49:17,494 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46958 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12017/12032 [10:14:37<00:38,  2.59s/it]2025-08-23:04:49:19,658 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:46968 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12018/12032 [10:14:39<00:30,  2.20s/it]2025-08-23:04:49:20,946 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57698 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12019/12032 [10:14:42<00:35,  2.70s/it]2025-08-23:04:49:24,807 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57706 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12020/12032 [10:14:45<00:30,  2.50s/it]2025-08-23:04:49:26,843 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57716 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12021/12032 [10:14:47<00:27,  2.46s/it]2025-08-23:04:49:29,217 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:57722 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12022/12032 [10:14:51<00:28,  2.86s/it]2025-08-23:04:49:33,013 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58870 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12023/12032 [10:14:52<00:22,  2.54s/it]2025-08-23:04:49:34,796 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58876 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12024/12032 [10:14:55<00:20,  2.52s/it]2025-08-23:04:49:37,277 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58890 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12025/12032 [10:14:57<00:17,  2.49s/it]2025-08-23:04:49:39,688 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:58904 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12026/12032 [10:14:59<00:13,  2.18s/it]2025-08-23:04:49:41,153 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55618 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12027/12032 [10:15:02<00:12,  2.49s/it]2025-08-23:04:49:44,375 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55634 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12028/12032 [10:15:04<00:08,  2.22s/it]2025-08-23:04:49:45,973 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55642 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12029/12032 [10:15:05<00:05,  1.88s/it]2025-08-23:04:49:47,059 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:55656 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12030/12032 [10:15:09<00:04,  2.45s/it]2025-08-23:04:49:50,845 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36882 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|█████████▉| 12031/12032 [10:15:09<00:01,  1.91s/it]2025-08-23:04:49:51,501 INFO     [lm_eval.models.api_models:619] Tokenized requests are disabled. Context + generation length is not checked.
INFO:     127.0.0.1:36898 - "POST /v1/qwen/chat/completions HTTP/1.1" 200 OK
Requesting API: 100%|██████████| 12032/12032 [10:15:10<00:00,  1.65s/it]Requesting API: 100%|██████████| 12032/12032 [10:15:10<00:00,  3.07s/it]
2025-08-23:04:50:23,118 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
local-chat-completions (base_url=http://127.0.0.1:8004/v1/qwen/chat/completions,model=Qwen/Qwen2.5-7B-Instruct,eos_string='<|im_end|>',truncate=True), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1
|       Tasks       |Version|    Filter    |n-shot|  Metric   |   |Value |   |Stderr|
|-------------------|------:|--------------|-----:|-----------|---|-----:|---|-----:|
|mmlu_pro           |      2|custom-extract|      |exact_match|↑  |0.2985|±  |0.0040|
| - biology         |      1|custom-extract|     5|exact_match|↑  |0.3459|±  |0.0178|
| - business        |      1|custom-extract|     5|exact_match|↑  |0.3815|±  |0.0173|
| - chemistry       |      1|custom-extract|     5|exact_match|↑  |0.0848|±  |0.0083|
| - computer_science|      1|custom-extract|     5|exact_match|↑  |0.2756|±  |0.0221|
| - economics       |      1|custom-extract|     5|exact_match|↑  |0.4514|±  |0.0171|
| - engineering     |      1|custom-extract|     5|exact_match|↑  |0.0960|±  |0.0095|
| - health          |      1|custom-extract|     5|exact_match|↑  |0.3912|±  |0.0171|
| - history         |      1|custom-extract|     5|exact_match|↑  |0.2231|±  |0.0214|
| - law             |      1|custom-extract|     5|exact_match|↑  |0.2089|±  |0.0123|
| - math            |      1|custom-extract|     5|exact_match|↑  |0.2931|±  |0.0124|
| - other           |      1|custom-extract|     5|exact_match|↑  |0.4513|±  |0.0164|
| - philosophy      |      1|custom-extract|     5|exact_match|↑  |0.3747|±  |0.0217|
| - physics         |      1|custom-extract|     5|exact_match|↑  |0.2232|±  |0.0116|
| - psychology      |      1|custom-extract|     5|exact_match|↑  |0.5439|±  |0.0176|

| Groups |Version|    Filter    |n-shot|  Metric   |   |Value |   |Stderr|
|--------|------:|--------------|------|-----------|---|-----:|---|-----:|
|mmlu_pro|      2|custom-extract|      |exact_match|↑  |0.2985|±  | 0.004|

INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [165]

Server is ready!

--- Running Evaluation for: QWEN on Benchmark: mmlu_pro ---
Executing command: python -m lm_eval --model local-chat-completions --model_args 'base_url=http://127.0.0.1:8004/v1/qwen/chat/completions,model=Qwen/Qwen2.5-7B-Instruct,eos_string='"'"'<|im_end|>'"'"',truncate=True' --tasks mmlu_pro --apply_chat_template --output_path temp_results_qwen_mmlu_pro_20250822_183155 --batch_size 1 --num_fewshot 5
Organizing results into: eval_log_baseline/qwen/mmlu_pro
Saved lm-harness results to eval_log_baseline/qwen/mmlu_pro/temp_results_qwen_mmlu_pro_20250822_183155
Qwen Baseline (12032 requests): 36605.36 s | Tokens/s: 67.42
Saved performance report to eval_log_baseline/qwen/mmlu_pro/metrics_report.txt

--- All evaluations complete. Shutting down API server ---
